{
  "hash": "b18fe32ee7d5df7cc0a6331a3ce15f05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Statistical Inference\nsubtitle: Applied Multiple Regression/Correlation Analysis for the Behavioral by Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. AikenSciences\ndate: last-modified\nauthor: Sungkyun Cho\nexecute:\n    warning: false\n    freeze: auto\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n# Confidence Interval \n\n평균이 $\\mu$ 이고 분산이 $\\sigma^2$ 인 모집단으로부터 추출된 표본 사이즈가 n인 표본들에 대해서  \n![](images/sampling2.png){width=400}\n\n::: {style=\"line-height: 1.5em; font-size: .9em\"}\nSource: *The Truthful Art* by Albert Cairo\n:::\n\n각 표본의 **평균** $\\bar{X}$ 들의 분포를 **평균의 표본 분포, the sampling distribution of the mean **이라고 하고, 이 분포는 the central limit theorem에 의해\n\n- 평균:&nbsp; $\\displaystyle E(\\bar{X})=\\frac{m_1+m_2+m_3+\\cdots+m_w}{w}\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\mu$  ; unbiased estimator\n\n- 분산:&nbsp; $\\displaystyle V(\\bar{X})\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\frac{\\sigma^2}{n},$ &emsp; 이 표준 편차 $\\displaystyle\\frac{\\sigma}{\\sqrt{n}}$ 를 **standard error of estimate(표준 오차, SE)**라고 함.\n  - 이 표준 오차는 다시 말하면, 어떤 통계치(여기서는 평균)가 표본들 간에 얼마나 차이가 나는지를 알 수 있는 중요한 지표가 됨.\n\n- 분포: 모집단의 분포가 normal에 가까울 수록, 또는 표본 크기가 클수록 ( $n\\rightarrow\\infty, n > 30$ )\n    $\\displaystyle\\{m_1, m_2, m_3, \\cdots, m_w, \\cdots\\} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}}) : normal ~ distribution$ (정규 분포)\n\n- 값을 정규화하면; $\\displaystyle Z=\\frac{X-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$\n\n    분포: $\\displaystyle\\{z_1, z_2, z_3, \\cdots, z_w, \\cdots\\} \\sim N(0, 1) : standard ~ normal ~ distribution$ (표준 정균 분포)\n\n실제 예를 통해서 살펴보면,  \n예를 들어 어느 섬에 사는 민족의 남성 평균 키가 아래와 같은 분포를 가진다고 할 때 (평균: 173cm, 표준편차: 5cm),  \n관찰한 **100명의 한 표본**에서 남성들의 키가 평균 174cm로 관찰되었다면 이 정도로 큰 값이 나올 가능성은 얼마정도 인가?\n\n## The Sampling Distribution of the Mean\n\n::: {layout=\"[1, 1]\"}\n\n\n\n::: {.cell}\n\n:::\n\n\n\n:::\n\n::: {layout=\"[1, 1]\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](inference_files/figure-html/unnamed-chunk-3-1.png){width=400}\n:::\n:::\n\n\n\n\n:::\n\n표본 사이즈 *n=25, 100, 400* 비교\n\n::: {layout=\"[1, 1, 1]\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](inference_files/figure-html/unnamed-chunk-4-1.png){width=400}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](inference_files/figure-html/unnamed-chunk-5-1.png){width=400}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](inference_files/figure-html/unnamed-chunk-6-1.png){width=400}\n:::\n:::\n\n\n\n:::\n\n- 표본 사이즈가 커짐에 따라 평균들의 분포의 표준편차가 줄어들며,\n- 평균들의 표본 분포는 빠르게 **정규 분포**에 다가가므로, \n- 근사적으로 정규 분포의 값을 이용해 그 확률 값을 쉽게 구할 수 있음.  \n\n특히, 값들을 정규화하여 표준정규분포 (평균 0, 표준편차 1)의 값을 이용함.  \n예를 들어, 표본 사이즈가 100인 (b)의 경우, 평균 키 174cm는 표준화 값으로 2: \n\n$\\displaystyle \\frac{174 - 173}{0.5} = 2, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$\n\n음영된 부분은 대략 2.3%이고, 따라서 100명을 관찰한 표본의 평균 키가 174cm이상이 될 가능성은 2.3%에 밖에 되지 않음. 예를 들어, 1000번 같은 연구를 반복하면 23번 정도는 174cm 이상의 평균 키를 관찰할 수 있을 것임.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](inference_files/figure-html/unnamed-chunk-7-1.png){width=400}\n:::\n:::\n\n\n\n\n실제 성취하고자 하는 것은 위 과정의 반대인 관찰한 특정 표본으로부터 모집단에 대해 추론하는 것임.  \n이를 **통계적 추론, statistical inference**라고 함.\n\n가령, 어느 섬에 사는 민족으로부터 관찰된 100명의 키의 평균이 175cm이고 표준편차가 10cm인 경우, 이 민족의 키의 평균은 얼마 정도라고 파악할 수 있는가?\n\n- 먼저, 모집단의 평균 $\\mu$ 를 **가정**하는데, 가령 $\\mu = 173$ 라면, 우리가 관찰한 표본의 평균 175는 충분히 나올 수 있는 값인가? 이에 대해서는 위의 논리에 따라 구할 수 있음. 즉, \n  - $\\displaystyle \\frac{175 - 173}{\\frac{\\sigma}{10}} = ~?, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$\n  - 만약, 모집단의 표준편차 $\\sigma$ 가 예전처럼 5라면, $\\bar{Z} = 4$ 가 되어 매우 희박한 경우가 될 것임. (실제로 0.0032%)\n  - 모집단의 표준편차를 알 수 없기 때문에 차선책으로, 관찰한 **표본의 표준편차**로 대체해서 전개함\n  - 이 경우, 표본의 표준편차가 10이기 때문에, $\\bar{Z} = 2$ 가 되어 2.3% 정도의 가능성이 있다고 볼 수 있으나,\n  - 표준편차의 대체로 인해 생기는 문제를 보완할 수 있는데, 사실 표본분포가 정규분포가 아닌 Student's t-분포를 따르고, 이를 이용해서 확률값을 구함.\n  - 이 경우는 $\\displaystyle t = \\frac{\\bar{X}-\\mu}{\\frac{s}{\\sqrt{n}}} = 2, ~ (s: the ~sample ~sd)$ 로 t-분포에 의하면 2.4% 정도의 가능성이 있다고 봄\n    - t-분포는 자유도(degree of freedom)에 의해 분포가 바뀌는데 df는 n-1 (n: 표본 크기)\n- 이제 위의 과정을 계속 반복한다고 상상하면, 즉 모집단의 평균을 다른 값으로 가정하면서,  \n  - 관찰된 표본 평균 175cm가 95% (양 극단 2.5%를 제외한) 이내에서 관찰될 수 있는 모집단의 평균들을 모두 찾을 수 있음\n  - 이 평균들의 범위를 95% **confidence interval** 이라고 부르고,\n  - 식으로 전개하면, \n      $\\displaystyle\\Bigg| \\frac{m-\\mu}{\\frac{s}{\\sqrt{n}}} \\Bigg| < 1.66, ~(n=100)$  \n      $\\displaystyle m-1.66\\frac{s}{\\sqrt{n}} < \\mu < m + 1.66\\frac{s}{\\sqrt{n}}$\n  - 위 예의 경우 $\\displaystyle 173.34 < \\mu < 176.66$\n  - 즉, 우리는 95%의 확신을 갖고, 이 섬에 사는 민족의 평균 키는 173.34cm에서 176.66cm 사이에 있을 것이라고 말할 수 있음.\n  - 이 cofidence interval의 크기를 결정하는 것은 $\\displaystyle\\frac{s}{\\sqrt{n}}$ 즉, **standard error of estimate**인데, 범위가 좁아질수록, **precision**이 높다고 표현함.\n  - 한편, 99%의 확신으로 (confidence level: 99%)는 그 키의 범위를 더 넓혀서 말할 수 있음. 이 경우 $|~t~| < 2.36$ 으로부터 모집단의 키가 (172.64cm, 177.36cm) 범위가 있다고 말할 수 있음.\n    - 확신이 커지는 대신 범위가 넓어지므로 모집단의 예측에 대한 유용성이 떨어짐.\n\n::: {.callout-important title=\"Confidence Interval vs. Credible Region\"}\nFrequentist의 입장에서 말하면, \"실험을 계속 반복한다면, 5%의 연구에서만 신뢰구간 밖에 true parameter값이 존재하게 될 것임\"  \n이는 Bayesian의 입장과 매우 다른 것임;    \n\"주어진 데이터에서 parameter의 값이 credible region에 들어갈 확률이 95%임\"(parameter가 변함)\n\n보통 이 둘을 섞어서 말하는 경향이 있음.\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Bayesian Models\"}\n\n불확실성에 대한 가정에 대한 다른 접근: 관측값이 늘어남에 따라 사전 확률(prior probability)을 업데이트(사후 확률, posterior probability)하여 사건 발생에 대한 믿음(확률)을 추정하는 방식\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ![](images/toss-globe.jpg){width=250}\n\n![](images/bayesian-update.png){width=600}\n\nSource: *McElreath, R. (2018). Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman and Hall/CRC.*\n:::\n\n**가설 검정(hypothesis testing)**  \n회귀분석 결과표의 p-values들은 영가설(null hypothesis)을 테스트하는 것이며, 위에서 평균이 0이라고 가정하는 경우에 해당\n\n- 가설/가정: \"모집단의 평균 키가 0cm이라면\", 표본에서 관찰된 175cm는 충분히 나올 수 있는 값인가?\n  - 절편(intercept)만 있는 null 모형($\\hat y = b_0$)에 대한 절편에 대한 가설 검증.\n- 회귀계수 b에 대한 테스트도 마찬가지로, 표본분포가 근사적으로 정규분포를 따르므로, 적절한 표준편차를 얻어 위와 같은 방식으로 테스트를 할 수 있음.\n\n\n## Regression Model Coefficients\n\n위의 논리와 비슷하게 회귀 계수가 표본 마다 얼마나 변하는 지를 구할 수 있고,  \n회귀 계수에 대한 confidence interval을 구할 수 있음.\n\n*변수가 한 개인 경우:*  \n회귀계수 $b$ 에 대한 표본 분포는 평균이 $b$ 인 정규분포를 따르고, 표준편차 즉, standard error of estimate는 근사적으로 다음과 같음  \n\n$\\displaystyle SE^2(b) = \\frac{{MS}_{residual}}{N \\cdot Var(X)}$\n\nConfidence interval: $b\\pm t_{\\alpha/2}SE, ~(df = N-2)$\n\n![](images/se.png){width=600}\n\n\n*다중 회귀 모형의 경우:*  \n예측변수 $X_j$ 에 대해서 모집단의 회귀계수 $b_j$ 에 대한 표본 분포는 평균이 $b_j$ 인 정규분포를 따르고, 표준편차, 즉 standard error는 근사적으로 다음과 같음.\n\n$\\displaystyle SE^2(b_j) = \\frac{{MS}_{residual}}{N \\cdot Var(X_j) \\cdot (1 - R^2_j)} = \\frac{{MS}_{residual}}{N \\cdot Var(X_j)}\\cdot VIF, ~(df = N-k-1)$\n\n- 표본 사이즈가 클수록\n- 평균 잔차가 작을수록\n- j번째 예측변수의 값이 퍼져 있을수록\n- 다른 예측변수들로부터 j번째 예측변수가 예측되지 못할수록; 즉 다른 변수들과 correlate되지 않을수록 \n  - $1 - R^2_j$: tolerance, 그 역수: variance inflation factor (VIF)\n  - Tolerance가 극히 작은 것은 intolerable! 봐줄 수 없음!\n  - 예를 들어, 어느 문화에서 남자아이에게는 자기 주장이 강하도록 훈육하고, 여자아이에게는 반대로 훈육한다고 할 때,  \n    만약, 자기주장이 강하도록 부모가 교육하는 것이 자녀가 자기주장이 강하게 되는데 영향을 미친다는 것을 살펴보는데, 성별을 통계적으로 통제한다면, 훈육의 효과는 통계적으로 계산되기 어려워짐.  \n    이는 성별과 훈육방식이 큰 상관관계를 갖기 때문에, 성별과 독립적인 훈육의 변량이 작아져 회귀계수의 precision이 크게 낮아지기 때문임.\n\n\n# Resampling Methods: Bootstrap\n\n- 모집단에 대한 추론을 하는데 \"특정 분포\"로부터 표본들이 생성된 것이라고 가정하고 이론에 기반해 추론하는 방식과 달리\n- 관찰된 표본이 모집단의 특성을 잘 반영하고 있다는 전제하에\n- 이 표본을 모집단인듯이 취급하여 이 표본으로부터 표본을 (복원) 추출하여 많은 표본들을 얻은 후 (**resampling**)\n- 각 표본들로부터 통계치를 계산하여 \"표본 분포\"을 얻는 방식 (sampling distribution)\n- Bootstrap외에도 다양한 resampling 방법이 있음.\n\n## Multiple Regression에 적용\n**car 패키지의 `Boot()` 이용**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nPrestige2 <- na.omit(Prestige)  # Boot() 함수는 결측치(NA)를 처리하지 못함\n\nmod_prestige <- lm(prestige ~ education + log2(income) + type, data = Prestige2)\nprestige_boot <- car::Boot(mod_prestige, R=1000)\n\ncar::Confint(prestige_boot) %>% round(., 3) |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBootstrap bca confidence intervals\n\n             Estimate    2.5 %  97.5 %\n(Intercept)   -81.202 -105.620 -53.944\neducation       3.284    2.100   4.449\nlog2(income)    7.269    4.991   9.411\ntypeprof        6.751    0.458  12.978\ntypewc         -1.439   -5.314   2.986\n```\n\n\n:::\n:::\n\n\n\n\n`education` 파라미터 추정치 1000개의 분포\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggpubr)\nprestige_boot$t |> as_tibble() |> \n  ggplot(aes(x = education)) +\n  geom_histogram(binwidth = 0.05, fill = \"white\", color = \"black\") +\n  geom_vline(xintercept = c(2.1, 4.4), color = \"red\", linetype = 1)\n```\n\n::: {.cell-output-display}\n![](inference_files/figure-html/unnamed-chunk-9-1.png){width=600}\n:::\n:::\n\n\n\n\n<!-- ```{r}\nhist(prestige_boot, parm = \"education\", den.col = \"orangered\", nor.col = \"deepskyblue2\", col = \"white\")\n``` -->\n\n**parameters 패키지의 `model_parameters()` 이용**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\nmodel_parameters(mod_prestige, boot=TRUE, ci_method=\"bci\") |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter     | Coefficient |            95% CI |      p\n--------------------------------------------------------\n(Intercept)   |      -81.63 | [-106.07, -56.29] | < .001\neducation     |        3.25 | [   2.13,   4.37] | < .001\nincome [log2] |        7.37 | [   5.00,   9.39] | < .001\ntype [prof]   |        6.88 | [   0.91,  12.90] | 0.026 \ntype [wc]     |       -1.36 | [  -5.25,   3.10] | 0.518 \n```\n\n\n:::\n:::\n\n## Mediation Analysis에 적용\n\n![](images/mediation_maternal.png){width=450}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\nmaternal <- read_spss(\"howell/maternal_care.sav\")\nmaternal <- na.omit(maternal)\nmaternal |> head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  FAMID Esteem MatCare Efficacy\n  <dbl>  <dbl>   <dbl>    <dbl>\n1     1   3.83    2.58      3.7\n2     2   3.5     2.83      3.4\n3     4   4       3.17      3.8\n4     8   4       3.75      3.9\n5     9   4       3.58      3.9\n```\n\n\n:::\n:::\n\n\n\n\n### boot 패키지의 `boot()` 활용\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(boot)\n\n# 함수 정의\nindirect_effect <- function(data, indices) {\n  sample <- data[indices, ]  # 부트스트랩 샘플링\n  model_M <- lm(Esteem ~ MatCare, data = sample)\n  model_Y <- lm(Efficacy ~ MatCare + Esteem, data = sample)\n  \n  return (model_M$coef[2] * model_Y$coef[3])\n}\n\nboot_results <- boot(maternal, indirect_effect, R = 1000)\nsummary(boot_results)\n\n# 95% 신뢰구간 계산\nboot.ci(boot_results, type = \"bca\")\n```\n:::\n\n\n\n\n### lavaan 패키지의 활용: SEM 분석툴\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lavaan)\n\nmod1 <- \" \n    # models\n      Esteem ~ a*MatCare\n      Efficacy ~ b*Esteem + c*MatCare\n  \n    # indirect, total effect\n      indirect := a*b\n      total := c + a*b\n\"\n\nfit1 <- sem(model = mod1, data = maternal, se=\"bootstrap\", bootstrap = 1000)\nsummary(fit1, ci=T, fit.measures=F) # ci:confidence interval, fit.measures: fit indices, standardized = F\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                            92\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n  Esteem ~                                                              \n    MatCare    (a)    0.364    0.106    3.430    0.001    0.163    0.580\n  Efficacy ~                                                            \n    Esteem     (b)    0.146    0.054    2.717    0.007    0.049    0.261\n    MatCare    (c)    0.057    0.037    1.525    0.127   -0.023    0.129\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n   .Esteem            0.246    0.044    5.571    0.000    0.162    0.339\n   .Efficacy          0.051    0.007    6.889    0.000    0.036    0.065\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n    indirect          0.053    0.021    2.470    0.014    0.017    0.107\n    total             0.110    0.034    3.228    0.001    0.046    0.176\n```\n\n\n:::\n\n```{.r .cell-code}\n# 모든 parameter에 대한 결과\nparameterEstimates(fit1, level = 0.95, boot.ci.type=\"bca.simple\") # bca.simple: bias-corrected, standardized = F\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       lhs op      rhs    label   est    se     z pvalue ci.lower ci.upper\n1   Esteem  ~  MatCare        a 0.364 0.106 3.430  0.001    0.177    0.585\n2 Efficacy  ~   Esteem        b 0.146 0.054 2.717  0.007    0.034    0.251\n3 Efficacy  ~  MatCare        c 0.057 0.037 1.525  0.127   -0.028    0.123\n4   Esteem ~~   Esteem          0.246 0.044 5.571  0.000    0.169    0.352\n5 Efficacy ~~ Efficacy          0.051 0.007 6.889  0.000    0.039    0.072\n6  MatCare ~~  MatCare          0.361 0.000    NA     NA    0.361    0.361\n7 indirect :=      a*b indirect 0.053 0.021 2.470  0.014    0.018    0.109\n8    total :=    c+a*b    total 0.110 0.034 3.228  0.001    0.038    0.172\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2 <- \"\n    # direct effect\n      Efficacy ~ c*MatCare\n\n    # mediator\n      Esteem ~ a*MatCare\n      Efficacy ~ b*Esteem\n\n    # indirect, total effect\n      indirect := a*b\n      total := c + a*b\n\"\n\nfit2 <- sem(model = mod2, data = maternal, se=\"bootstrap\", bootstrap = 1000)\nsummary(fit2, ci = T, fit.measures = F) # ci:confidence interval, fit.measures: fit indices, standardized = F\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                            92\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n  Efficacy ~                                                            \n    MatCare    (c)    0.057    0.037    1.525    0.127   -0.023    0.129\n  Esteem ~                                                              \n    MatCare    (a)    0.364    0.106    3.430    0.001    0.163    0.580\n  Efficacy ~                                                            \n    Esteem     (b)    0.146    0.054    2.717    0.007    0.049    0.261\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n   .Efficacy          0.051    0.007    6.889    0.000    0.036    0.065\n   .Esteem            0.246    0.044    5.571    0.000    0.162    0.339\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n    indirect          0.053    0.021    2.470    0.014    0.017    0.107\n    total             0.110    0.034    3.228    0.001    0.046    0.176\n```\n\n\n:::\n\n```{.r .cell-code}\n# 모든 parameter에 대한 결과\nparameterEstimates(fit2, level = 0.95, boot.ci.type = \"bca.simple\") # bca.simple: bias-corrected, standardized = F\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       lhs op      rhs    label   est    se     z pvalue ci.lower ci.upper\n1 Efficacy  ~  MatCare        c 0.057 0.037 1.525  0.127   -0.028    0.123\n2   Esteem  ~  MatCare        a 0.364 0.106 3.430  0.001    0.177    0.585\n3 Efficacy  ~   Esteem        b 0.146 0.054 2.717  0.007    0.034    0.251\n4 Efficacy ~~ Efficacy          0.051 0.007 6.889  0.000    0.039    0.072\n5   Esteem ~~   Esteem          0.246 0.044 5.571  0.000    0.169    0.352\n6  MatCare ~~  MatCare          0.361 0.000    NA     NA    0.361    0.361\n7 indirect :=      a*b indirect 0.053 0.021 2.470  0.014    0.018    0.109\n8    total :=    c+a*b    total 0.110 0.034 3.228  0.001    0.038    0.172\n```\n\n\n:::\n:::\n\n\n\n\n## Moderated Mediation에 응용\n\n![](images/moderated-mediation.png){width=500}\n\n::: {style=\"line-height: 1.5em; font-size: .9em\"}\np. 424, *Introduction to Mediation, Moderation, and Conditional Process Analysis (3e)* by Andrew F. Hayes\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteams <- read_csv(\"data/hayes2022data/teams/teams.csv\")\nteams <- teams |> \n  mutate(\n    negtone_c = center(negtone),\n    negexp_c = center(negexp),\n    negtone_negexp_c = negtone_c*negexp_c,\n  )\n\nmod <- \"\n  # models\n    perform ~ c*dysfunc + b1*negtone_c + b2*negexp_c + b3*negtone_negexp_c\n    negtone_c ~ a*dysfunc\n  \n  # conditional effects: m-sd, m, m+sd\n    b_low := b1 + b3*(-0.5437)  # mean - sd; sd = 0.5437\n    b_mean := b1 + b3*0  # mean\n    b_high := b1 + b3*0.5437  # mean + sd\n  \n  # conditional indirect effects\n    ab_low := a * b_low\n    ab_mean := a * b_mean\n    ab_high := a * b_high\n  \n  # index of moderated mediation\n    index_Mod_Med := a*b3\n\"\n\nfit <- lavaan::sem(model = mod, data = teams, se=\"bootstrap\")\nsummary(fit, ci = T, fit.measures = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 2 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n\n  Number of observations                            60\n\nModel Test User Model:\n                                                      \n  Test statistic                                 6.999\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.030\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n  perform ~                                                             \n    dysfunc    (c)    0.366    0.194    1.891    0.059   -0.109    0.669\n    negtone_c (b1)   -0.431    0.129   -3.337    0.001   -0.648   -0.129\n    negexp_c  (b2)   -0.044    0.102   -0.428    0.669   -0.255    0.148\n    ngtn_ngx_ (b3)   -0.517    0.235   -2.200    0.028   -1.052   -0.126\n  negtone_c ~                                                           \n    dysfunc    (a)    0.620    0.227    2.729    0.006    0.221    1.119\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n   .perform           0.185    0.032    5.713    0.000    0.111    0.240\n   .negtone_c         0.219    0.051    4.272    0.000    0.118    0.317\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper\n    b_low            -0.150    0.221   -0.681    0.496   -0.505    0.372\n    b_mean           -0.431    0.129   -3.335    0.001   -0.648   -0.129\n    b_high           -0.713    0.132   -5.407    0.000   -0.985   -0.483\n    ab_low           -0.093    0.150   -0.619    0.536   -0.351    0.268\n    ab_mean          -0.267    0.118   -2.270    0.023   -0.525   -0.054\n    ab_high          -0.442    0.163   -2.710    0.007   -0.773   -0.139\n    index_Mod_Med    -0.320    0.190   -1.682    0.093   -0.791   -0.046\n```\n\n\n:::\n\n```{.r .cell-code}\n# 모든 parameter에 대한 결과\nparameterEstimates(fit, level = 0.95, boot.ci.type = \"bca.simple\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                lhs op              rhs         label    est    se      z\n1           perform  ~          dysfunc             c  0.366 0.194  1.891\n2           perform  ~        negtone_c            b1 -0.431 0.129 -3.337\n3           perform  ~         negexp_c            b2 -0.044 0.102 -0.428\n4           perform  ~ negtone_negexp_c            b3 -0.517 0.235 -2.200\n5         negtone_c  ~          dysfunc             a  0.620 0.227  2.729\n6           perform ~~          perform                0.185 0.032  5.713\n7         negtone_c ~~        negtone_c                0.219 0.051  4.272\n8           dysfunc ~~          dysfunc                0.136 0.000     NA\n9           dysfunc ~~         negexp_c               -0.001 0.000     NA\n10          dysfunc ~~ negtone_negexp_c               -0.003 0.000     NA\n11         negexp_c ~~         negexp_c                0.291 0.000     NA\n12         negexp_c ~~ negtone_negexp_c                0.046 0.000     NA\n13 negtone_negexp_c ~~ negtone_negexp_c                0.072 0.000     NA\n14            b_low :=  b1+b3*(-0.5437)         b_low -0.150 0.221 -0.681\n15           b_mean :=          b1+b3*0        b_mean -0.431 0.129 -3.335\n16           b_high :=     b1+b3*0.5437        b_high -0.713 0.132 -5.407\n17           ab_low :=          a*b_low        ab_low -0.093 0.150 -0.619\n18          ab_mean :=         a*b_mean       ab_mean -0.267 0.118 -2.270\n19          ab_high :=         a*b_high       ab_high -0.442 0.163 -2.710\n20    index_Mod_Med :=             a*b3 index_Mod_Med -0.320 0.190 -1.682\n   pvalue ci.lower ci.upper\n1   0.059   -0.014    0.716\n2   0.001   -0.660   -0.149\n3   0.669   -0.251    0.151\n4   0.028   -1.072   -0.142\n5   0.006    0.216    1.109\n6   0.000    0.137    0.279\n7   0.000    0.135    0.355\n8      NA    0.136    0.136\n9      NA   -0.001   -0.001\n10     NA   -0.003   -0.003\n11     NA    0.291    0.291\n12     NA    0.046    0.046\n13     NA    0.072    0.072\n14  0.496   -0.509    0.346\n15  0.001   -0.660   -0.149\n16  0.000   -1.008   -0.499\n17  0.536   -0.426    0.190\n18  0.023   -0.584   -0.086\n19  0.007   -0.772   -0.138\n20  0.093   -0.797   -0.049\n```\n\n\n:::\n:::",
    "supporting": [
      "inference_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}