{
  "hash": "e43a11fc112c77e16028aaee3f6d3e7f",
  "result": {
    "markdown": "---\ntitle: Diagnostics\nsubtitle: 'Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences by Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. Aiken'\ndate: 'Feb 17, 2023'\nauthor: Sungkyun Cho\nexecute:\n  warning: false\n  freeze: auto\nformat: \n   html:\n    df-print: tibble\n   # monofont: 'FiraCode-Regular'\n---\n\n::: {.cell}\n\n:::\n\n\n# Ordinary least squares (OLS)\n\n- Mean function: $E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i$\n- Variance function: $Var(Y | X = x_i) = \\sigma^2$\n- Distribution: $(Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)$\n\n\n![](images/ols.png){width=650}  \nSource: p.107, *Applied Regression Analysis and Generalized Linear Models (3e), by John Fox*\n\n![](images/glm.png){width=800}  \nSource: p.482, *Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences (3e), by Cohen, J., Cohen, P., West, S. G., & Aiken, L. S.*\n\nSource: Beyond Multiple Linear Regression, by Paul Roback, Julie Legler.\n\n## Linear Least Squared Regression의 가정들\n\n- L (linearity, 선형성): X의 각 값에 해당하는 Y값들의 평균들은 X와 선형적인 관계를 가짐.\n  - Mean function: $E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i$\n- I (independence, 독립성): 잔차들(errors)은 서로 독립.\n- N (normally distributed, 정규성): X의 각 값에 해당하는 Y값들은 정규분포를 이룸.\n  - $(Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)$\n- E (equal variance, 등분산성): X의 각 값에 해당하는 Y값들의 표준편차들은 모두 동일함.\n  - $Var(Y | X = x_i) = \\sigma^2$\n\n### 가정에 위배되는 연구/자료들\n\n- 공부한 시간에 따른 합격 여부\n  - Y가 성공/실패 명목변수로서 0, 1로 코딩된다고 하면, Y는 정규분포를 이루지 않음. \n  - 이런 경우 generalized linear model(GLM)의 일부로서 logistic regression 모형으로 fit을 하는 것이 더 적절함.\n\n- 부유한 가정은 더 적은 아이들을 가지는 경향이 있는가?\n  - 가족의 크기는 정규분포를 이루기보단 한쪽으로 치우친(skewed) 분포를 이룸.\n  - 가족의 크기는 0, 1, 2,... 등의 정수값을 가져, 연속형 변수로 보기 어려워 정규분포의 가정을 만족하기 어려움.\n  - 이런 경우 가족의 크기는 Poisson 분포에 더 가깝다고 보고, Poisson regression 모형이나 그 변형들로 fit을 하는 것이 더 적절함.\n\n- 대학 안에서 임의로 선정한 남녀 학생들의 운동시간과 몸무게의 관계\n  - 운동을 전혀 하지 않는 학생들의 몸무게의 변량이 규칙적으로 한 학생들에 비해 더 넓게 분포할 가능성이 큼: 이는 equal variance 가정을 위배함.\n  - 만약, 대학 내에서 특정 장소에서 학생들을 섭외했다면, 예를 들어, 피트니스 센터에서 섭외된 학생들의 데이터는 서로 연관성이 높을 수 있음: 이는 independent 가정에 위배됨.\n\n- 특정 질병을 가진 환자들에 대한 특정 수술에 대한 효과를 연구한다면,\n  - 동일한 의사에게 수술을 받은 환자들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n  - 동일한 병원에서 수술을 받은 환자들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n\n### 대처방안/대안들 \n\n- **Linearity**의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 고차 다항식 혹은 확장된 모형(eg. spline)을 사용\n- **Normality**의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 generalized linear model(GLM)을 사용\n- **Equal variance**의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 weighted least squares regression을 사용\n- **Independence**의 가정에 위배되는 경우: multi-level (mixed-effects) 모형을 사용\n\n# OLS에서 모집단에 대한 가정들에 대한 진단\nSource: *An R Companion to Applied Regression (3e), by John Fox, Sanford Weisberg.*\n\n연구자는 기본적으로 변수 간의 **true relationship**이 존재할 것이라고 믿으며, 모집단에서 그 관계가 완전한 형태로 존재한다고 가정하고, 그 관계를 표본으로부터 최대한 추론하고자 함.  \nOLS 방식으로 모집단에 대한 추론을 하려면, OLS가 요구하는 **모집단에 대한 가정**들이 위배되지 않아야 함.  \n연구자는 관찰된 표본이 \"LINE 가정들을 만족하는 모집단\"으로부터 표집된 표본이라고 볼만한 충분한 확신이 있어야 함.  \n이를 위해서 표본들로부터 대략적인 추정을 할 수 밖에 없음.\n\n예제: Prestige 데이터셋\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n\nPrestige <- Prestige |> as_tibble() |> \n  mutate(type = factor(type, levels = c(\"bc\", \"wc\", \"prof\")))\nPrestige\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 102 × 6\n   education income women prestige census type \n       <dbl>  <int> <dbl>    <dbl>  <int> <fct>\n 1      13.1  12351 11.2      68.8   1113 prof \n 2      12.3  25879  4.02     69.1   1130 prof \n 3      12.8   9271 15.7      63.4   1171 prof \n 4      11.4   8865  9.11     56.8   1175 prof \n 5      14.6   8403 11.7      73.5   2111 prof \n 6      15.6  11030  5.13     77.6   2113 prof \n 7      15.1   8258 25.6      72.6   2133 prof \n 8      15.4  14163  2.69     78.1   2141 prof \n 9      14.5  11377  1.03     73.1   2143 prof \n10      14.6  11023  0.94     68.8   2153 prof \n# ℹ 92 more rows\n```\n:::\n\n```{.r .cell-code}\nmod_prestige <- lm(prestige ~ education + income + type, data = Prestige)\nS(mod_prestige)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: lm(formula = prestige ~ education + income + type, data = Prestige)\n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.6229292  5.2275255  -0.119    0.905    \neducation    3.6731661  0.6405016   5.735 1.21e-07 ***\nincome       0.0010132  0.0002209   4.586 1.40e-05 ***\ntypewc      -2.7372307  2.5139324  -1.089    0.279    \ntypeprof     6.0389707  3.8668551   1.562    0.122    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 7.095 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8349\nF-statistic: 117.5 on 4 and 93 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n669.02 684.52 \n```\n:::\n:::\n\n\n## Plotting Residuals\n잔차들의 분포: $(e | X = x_i) \\sim N(0, \\sigma^2)$  \n즉, 특별한 패턴이 없어야 함\n\n- 선형적 관계성(Linearity)이 확보되고, \n- 등분산성(Equal variance)이 확보됨.\n\n::: {.cell}\n\n```{.r .cell-code}\nresidualPlots(\n  mod_prestige, \n  id=list(n=3), # outliers의 수\n  smooth=TRUE, # loess smooth 커브\n  quadratic=FALSE # 3차 fitted 커브\n)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n           Test stat Pr(>|Test stat|)   \neducation    -0.6836         0.495942   \nincome       -2.8865         0.004854 **\ntype                                    \nTukey test   -2.6104         0.009043 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 특정 변수만 선택\nresidualPlots(mod_prestige, ~ income, fitted=FALSE, smooth=TRUE, id=list(n=3))\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-4-1.png){width=480}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n       Test stat Pr(>|Test stat|)   \nincome   -2.8865         0.004854 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# QQplot: 전체적인 잔차의 분포가 정규분포를 따르는지 확인: y=x 라인에 가까울수록 정규분포를 따름\nqqPlot(mod_prestige, id=list(n=3)) # qq plot\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-4-2.png){width=480}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31 54 82\n```\n:::\n:::\n\n\n등분산성(equal variance)이 심하게 위배되는 경우;\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_transact <- lm(time ~ t1 + t2, data=Transact)\nresidualPlots(mod_transact, test=FALSE, layout=c(1, 3))\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-5-1.png){width=864}\n:::\n:::\n\n\n통계적으로 등분산성(equal variance)을 테스트할 수 있음: `ncvTest()`\n\n::: {.callout-note}\n등분산성을 만족하지 않는 경우: Heteroskedasticity\n\n- Weighted least squares (WLS) 방식으로 추정\n- 좀 더 자연스러운 generalized linear model (GLM) with the identity link and gamma errors(확률 분포).\n- 등분산성은 회귀계수 값 자체는 크게 영향을 주지 않으므로, OLS로 회귀계수는 추정하되, 유의성 검증(SE, p values)은 **bootstrap**을 이용하거나 **a sandwich coefficient-variance estimator**로 계산하는 방식을 선택.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\nmodel_parameters(mod_transact) |> print(digits=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter   | Coefficient |      SE |            95% CI | t(258) |      p\n-------------------------------------------------------------------------\n(Intercept) |     144.369 | 170.544 | [-191.47, 480.21] |  0.847 | 0.398 \nt1          |       5.462 |   0.433 | [   4.61,   6.32] | 12.607 | < .001\nt2          |       2.035 |   0.094 | [   1.85,   2.22] | 21.567 | < .001\n```\n:::\n:::\n\n\n1. **Sandwich coefficient-variance estimator**\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(mod_transact, vcov = \"HC3\") # HC3 방식\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 9\n  Parameter   Coefficient      SE    CI  CI_low CI_high      t df_error        p\n  <chr>             <dbl>   <dbl> <dbl>   <dbl>   <dbl>  <dbl>    <int>    <dbl>\n1 (Intercept)      144.   203.     0.95 -256.    544.    0.711      258 4.78e- 1\n2 t1                 5.46   0.729  0.95    4.03    6.90  7.49       258 1.06e-12\n3 t2                 2.03   0.163  0.95    1.71    2.36 12.4        258 3.60e-28\n```\n:::\n:::\n\n\n2. **Bootstrap**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\nbootstrap_parameters(mod_transact, ci_method = \"BCI\") # BCI 방식\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  Parameter   Coefficient  CI_low CI_high     p\n  <chr>             <dbl>   <dbl>   <dbl> <dbl>\n1 (Intercept)      149.   -284.    513.    0.46\n2 t1                 5.47    3.99    6.58  0   \n3 t2                 2.03    1.75    2.37  0   \n```\n:::\n:::\n\n\n:::\n\n## Added-Variable Plots\nPartial regression plot이라고도 함.  \n다른 변수들을 partial out시킨 잔차들로 그림.\n\n- 각 회귀계수에 대한 precision을 살펴볼 수 있음\n- 각 관측치에 대한 leverage를 살펴볼 수 있음\n\n::: {.cell}\n\n```{.r .cell-code}\n# 수평선 중심에서 가장 먼 점들 2개\n# 잔차의 값이 가장 큰 점들 2개\navPlots(mod_prestige, id=list(n=2, cex=0.8)) # id: outliers의 수, cex: 점의 크기 80%\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# 특정 관측치 제거 후 다시 그림\nmod_prestige_1 = update(mod_prestige, subset = -c(2, 24))  # 2, 24번째 관측치 제거\navPlots(mod_prestige_1)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncompareCoefs(mod_prestige, mod_prestige_1, se = FALSE, pvals = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCalls:\n1: lm(formula = prestige ~ education + income + type, data = Prestige)\n2: lm(formula = prestige ~ education + income + type, data = Prestige, \n  subset = -c(2, 24))\n\n            Model 1 Model 2\n(Intercept)  -0.623   0.749\nPr(>|z|)      0.905   0.889\n                           \neducation      3.67    3.31\nPr(>|z|)    9.8e-09 1.5e-06\n                           \nincome      0.00101 0.00133\nPr(>|z|)    4.5e-06 1.2e-05\n                           \ntypewc        -2.74   -1.66\nPr(>|z|)      0.276   0.526\n                           \ntypeprof       6.04    7.18\nPr(>|z|)      0.118   0.071\n                           \n```\n:::\n:::\n\n\n## Unusual Data\n- outliers: 모형의 예측값과 크게 다른 관측치\n- high-leverage points: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 관측치\n- influential points: outlier이면서 high-leverage point인 관측치\n\n우선, 위에서 다룬 add-variable plots를 통해서 두 변수의 joint로써 influential points를 찾을 수 있음.\n\n다음은 각 변수들 내에서의 influential points에 관한 진단임.\n\n예제: Duncan 데이터셋\n\n::: {.cell}\n\n```{.r .cell-code}\nDuncan <- Duncan |> as_tibble()\nDuncan\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 45 × 4\n   type  income education prestige\n   <fct>  <int>     <int>    <int>\n 1 prof      62        86       82\n 2 prof      72        76       83\n 3 prof      75        92       90\n 4 prof      55        90       76\n 5 prof      64        86       90\n 6 prof      21        84       87\n 7 prof      64        93       93\n 8 prof      80       100       90\n 9 wc        67        87       52\n10 prof      72        86       88\n# ℹ 35 more rows\n```\n:::\n\n```{.r .cell-code}\nmod_duncan <- lm (prestige ~ income + education, data=Duncan)\nS(mod_duncan)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: lm(formula = prestige ~ income + education, data = Duncan)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -6.06466    4.27194  -1.420    0.163    \nincome       0.59873    0.11967   5.003 1.05e-05 ***\neducation    0.54583    0.09825   5.555 1.73e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 13.37 on 42 degrees of freedom\nMultiple R-squared: 0.8282\nF-statistic: 101.2 on 2 and 42 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n365.96 373.19 \n```\n:::\n:::\n\n\n### **Outliers**  \n`qqPlot()`: 95% pointwise confidence envelope for the Studentized residuals, using a parametric version of the bootstrap.  \n`outlierTest()`: Bonferroni-adjusted p-values for the Studentized residuals.\n\n::: {.cell}\n\n```{.r .cell-code}\nqqPlot(mod_duncan, id=list(n=3))\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  6  9 17\n```\n:::\n\n```{.r .cell-code}\noutlierTest(mod_duncan)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNo Studentized residuals with Bonferroni p < 0.05\nLargest |rstudent|:\n  rstudent unadjusted p-value Bonferroni p\n6 3.134519          0.0031772      0.14297\n```\n:::\n:::\n\n\n### **Influential points에 대한 지표들**\n\n- Cook's distance: i번째 관측치가 제거되었을 때 회귀계수의 변화량에 대한 요약치\n- Studentized residuals: 표준화한 잔차\n- Bonferroni-adjusted p-values: 잔차의 분포에 대한 p-value를 Bonferroni 방식으로 보정한 값\n- hat-values: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 정도\n\n가장 큰 값들에 해당하는 관측치들을 제거해보고 회귀분석을 한 후 결과를 비교  \n원칙적으로 한번에 한 관측치만 제거하고, 차례로 진단을 해야 함; 전체적인 fit이 변하므로\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninfluenceIndexPlot(mod_duncan)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-13-1.png){width=768}\n:::\n\n```{.r .cell-code}\n# 6번째 관측치 제거\nmod_duncan2 <- update(mod_duncan, subset = -6)\ncompareCoefs(mod_duncan, mod_duncan2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -6)\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.63\nSE             4.27    3.89\n                           \nincome        0.599   0.732\nSE            0.120   0.117\n                           \neducation    0.5458  0.4330\nSE           0.0983  0.0963\n                           \n```\n:::\n\n```{.r .cell-code}\n# leave-one-out deletion diagnostics\n# i번째 관측치를 제거했을 때, 각 예측변수들의 변화량을 나타냄\n# dfbeta: 차이, debetas: SE로 표준화한 차이\ndfbetas(mod_duncan) |> head() |> print(digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept)   income education\n1    -2.3e-02  0.00067   0.03594\n2    -2.5e-02  0.05088  -0.00812\n3    -9.2e-03  0.00648   0.00562\n4    -4.7e-05 -0.00006   0.00014\n5    -6.6e-02  0.01700   0.08678\n6     1.4e-01 -1.22094   1.26302\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# dfbetas를 플랏으로 나타내면,\ndf <- dfbetas(mod_duncan) |> as_tibble()\n\nlibrary(ggrepel)\ndf |> \n  ggplot(aes(x=income, y=education)) +\n  geom_point() +\n  geom_text_repel(aes(label = row.names(df)))\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-14-1.png){width=576}\n:::\n:::\n\n\nAdded-variable plot으로도 확인해 볼 수 있음  \n\n- Influential points가 각 예측변수에서 살펴보는 것과는 다르게\n- Added-variable plot은 joint로써의 영향력을 보고 outliers를 찾을 수 있음\n\n::: {.cell}\n\n```{.r .cell-code}\navPlots(mod_duncan, id=list(n=3, method=\"mahal\")) # 중심으로부터의 거리(mahalanobis distance)만 표시\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 6, 16번째 관측치 제거\nmod_duncan3 <- update(mod_duncan, subset = -c(6, 16))\ncompareCoefs(mod_duncan, mod_duncan3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -c(6,\n   16))\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.41\nSE             4.27    3.65\n                           \nincome        0.599   0.867\nSE            0.120   0.122\n                           \neducation    0.5458  0.3322\nSE           0.0983  0.0987\n                           \n```\n:::\n:::\n\n\n## 선형성에 대한 진단\nComponent-Plus-Residual (partial-residual plots): $\\displaystyle e+{\\hat {\\beta }}_{i}X_{i}$  \n`crPlots()`\n\n초기 탐색적 분석이나 모형을 세우 후 `residualPlots`으로도 살펴볼 수 있음.\n\n비선형성에 대해서는 변수를 변환(transform)하거나 고차 다항함수 모형, 혹은 더 복잡한 spline 모형을 이용.\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_prestige_2 <- lm(prestige ~ income + education + women, data=Prestige)\ncrPlots(mod_prestige_2)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## 변수의 변환(transform) 및 고차원 모형\n선형성, 등분산성, 정규성 등은 각각 다른 개념이나 변수의 변형을 통해 동시에 해결되기도 함.\n\n- `log`변환은 정규성과 선형성을 동시에 해결해주는 경우가 많음.\n- 또한 의미적으로도 해석이 용이함. 몇 배의 의미로 바뀜.\n- 복잡한 변환에 대해서 다음을 참조\n  - Box-Cox Power Transformations\n  - `powerTransform()`\n\n예제: UN in carData\n\n::: {.callout-note collapse=\"true\"}\n#### code\n```r\nUN |> \n  ggplot(aes(x=ppgdp)) +\n  geom_density()\nUN |> \n  ggplot(aes(x=infantMortality)) +\n  geom_density()\nUN |> \n  ggplot(aes(x=ppgdp, y=infantMortality)) +\n  geom_point() +\n  geom_smooth()\nUN |> \n  ggplot(aes(x=log(ppgdp), y=log(infantMortality))) +\n  geom_point() +\n  geom_smooth()\n```\n:::\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-18-1.png){width=480}\n:::\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-18-2.png){width=480}\n:::\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-18-3.png){width=480}\n:::\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-18-4.png){width=480}\n:::\n:::\n\n\n위의 Presitge의 예의 경우, `income`을 log변환하는 것이 적절함.\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nmod_prestige <- lm(prestige ~ education + income + type, data = Prestige)\nmod_prestige_log <- lm(prestige ~ education + log2(income) + type, data = Prestige)\n\nresidualPlots(mod_prestige, ~income, test=FALSE, fitted=FALSE)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nresidualPlots(mod_prestige_log, ~log2(income), test=FALSE, fitted=FALSE)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n\n```{.r .cell-code}\nS(mod_prestige_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: lm(formula = prestige ~ education + log2(income) + type, data = Prestige)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -81.2019    13.7431  -5.909 5.63e-08 ***\neducation      3.2845     0.6081   5.401 5.06e-07 ***\nlog2(income)   7.2694     1.1900   6.109 2.31e-08 ***\ntypewc        -1.4394     2.3780  -0.605   0.5465    \ntypeprof       6.7509     3.6185   1.866   0.0652 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 6.637 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8555\nF-statistic: 137.6 on 4 and 93 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n655.93 671.44 \n```\n:::\n:::\n\n이 때, `log2(income)`에 대한 회귀계수의 해석은 `income`이 2배 늘면(=`log2(income)`이 1증가하면) prestige가 7.27점 증가하는지를 나타냄.\n\n\n변수의 변환이 아닌 **모형의 복잡도**를 높혀 좀 더 나은 fit을 얻을 수도 있음.\n\n- 다항함수 모형\n- Spline 모형\n\n예제: CPS85 in mosaicData\n\n::: {.callout-note collapse=\"true\"}\n#### code\n```r\ncps <- mosaicData::CPS85 |> as_tibble()\ncps2 <- cps |> \n  mutate(log_wage = log(wage)) |> \n  filter(wage < 30 & log_wage > 1)\n\ncps2 |>\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .7) +\n  geom_smooth() +\n  scale_y_continuous(label = scales::label_dollar()) +\n  labs(y = \"wage (dollars per hour)\")\n\ncps2 |>\n  ggplot(aes(x = wage)) +\n  geom_density()\n```\n:::\n\n::: {.cell layout=\"[1, 1]\"}\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-20-1.png){width=576}\n:::\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-20-2.png){width=576}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_cps_poly <- lm(log_wage ~ married * sex + age + I(age^2), data = cps2) # 2차 다항함수\nresidualPlots(mod_cps_poly, test=FALSE)\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-21-1.png){width=864}\n:::\n:::\n\nSpline 모형: piece-wise polynomial  \n`bs()`, `ns()` in splines 패키지\n\n- `ns()`: natural spline 모형 (boundary constraints)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\nmod_cps_ns <- lm(log_wage ~ married * sex + ns(age, 3), data = cps2) # 3-piecewise natural spline\n```\n:::\n\n다항함수 모형과 spline 모형의 비교\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nlibrary(effects)\nplot(predictorEffects(mod_cps_poly, ~age))\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-23-1.png){width=384}\n:::\n\n```{.r .cell-code}\nplot(predictorEffects(mod_cps_ns, ~age))\n```\n\n::: {.cell-output-display}\n![](diagnostics_files/figure-html/unnamed-chunk-23-2.png){width=384}\n:::\n:::\n\n\n## 다중공선성에 대한 진단\nOLS의 가정과는 관계없으나, 통계적 파워를 낮추는 요인이 됨.  \n탐색적 분석 과정에서 변수들 간에 심각하게 상관계수(r)가 높은 경우 주의\n\n지표로는 Variance Inflation Factor(VIF)\n\n- 예를 들어, $X_1$에 대한 VIF: $\\displaystyle {1 - R^2_{1.23}}$ 의 역수\n- 즉, $X_2, X_3$로 $X_1$이 설명되지 않는, 즉 독립적인 정도의 역수\n- 다른 예측 변수들로 잘 설명되는 예측변수라면, standard error(SE)가 증폭되어 회귀계수의 신뢰성이 떨어짐. (불안정하다는 의미)\n- VIF 값은 예측변수들이 서로 독립적일 때에 비해 SE가 얼마나 증폭되는지를 나타냄.\n- VIF 값이 10 이면 $\\sqrt{10}=3.16$ 배의 SE 증폭이 발생.\n- VIF 값이 10 이상이면 심각한 다중공선성이 발생했다고 판단.\n- **상호작용항이 포함된 경우**, (두 변수의 곱으로 만든 항이므로) centering을 하지 않은 경우, VIF값이 크게 나올 수 있으나 실질적인 문제는 전혀 없음.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_prestige_2 <- lm(prestige ~ income + education + women, data=Prestige)\nsumm(mod_prestige_2, vif=TRUE, model.info = FALSE) |> print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMODEL FIT:\nF(3,98) = 129.19, p = 0.00\nR² = 0.80\nAdj. R² = 0.79 \n\nStandard errors: OLS\n-------------------------------------------------------\n                     Est.   S.E.   t val.      p    VIF\n----------------- ------- ------ -------- ------ ------\n(Intercept)         -6.79   3.24    -2.10   0.04       \nincome               0.00   0.00     4.73   0.00   2.28\neducation            4.19   0.39    10.77   0.00   1.85\nwomen               -0.01   0.03    -0.29   0.77   1.53\n-------------------------------------------------------\n```\n:::\n:::\n",
    "supporting": [
      "diagnostics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}