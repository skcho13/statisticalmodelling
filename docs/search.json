[
  {
    "objectID": "contents/visualize.html",
    "href": "contents/visualize.html",
    "title": "Visualize",
    "section": "",
    "text": "데이터 시각화는 탐색적 분석에 더 초점이 맞춰져 있음.\n\n소위 data mining이라고 부르는 데이터 내의 숨겨진 패턴을 찾고 분석하는 탐색적 분석은 전통적인 통계에서 discouraging되어 왔음.\n\n확률에 근거한 통계 이론은 데이터를 수집하기 전에 가설을 세우고 그 가설을 confirm하는 방식을 취함.\n\n논란의 여지가 있지만, 원칙적으로 가설에 근거해 수집한 자료가 가설과 일치하는지를 확인하는 작업에서는 자료를 두 번 이상 들여다 보지 않아야 함.\n\n그럼에도 불구하고, 탐색적 분석은 behind doors에서 이루어지거나 새로운 가설을 세우기 위한 방편으로 이용되었음.\n\n또한, 매우 엄격한 잣대를 적용하는 상황에서도 통계 이론의 특성으로 인해 기본적인 탐색적 분석은 반드시 선행되어야 함.\n\n연구 가설의 진위를 탐구할 때, 탐색적 분석에서 쉽게 빠질 수 있는 편향성(bias)는 항상 조심할 필요가 있고, 확신을 위해서는 새로이 자료를 수집해서 가설을 재검증할 필요가 있음.\n\n탐색적 분석을 위해서는 다양한 시각화 기술이 요하나, 일반적인 통계 분석을 위해서 필요로하는 최소한으로 제한하고자 함.\n또한, 복잡한 통계치를 살펴볼 때, 직접 시각화를 하기보다는 패키지가 알아서 시각화를 해주기 때문에 자세히 알지 못해도 무방함.\n좀 더 상세한 내용에 대해서는\n\nR for Data Science/Visualize\nggplot2 book\nggplot2 extensions\n통계치 표현: ggstatsplot, ggpubr\nData Visualization with R by Rob Kabacoff : 적절한 밸런스\nggplot2 cheatsheet : pdf 다운로드\n\n\n\n\n\n\n\nNote\n\n\n\n충분히 큰 데이터의 경우, 일정량의 데이터 가령 1/4을 따로 떼어놓고, 3/4만으로 탐색적 분석을 통해 모델을 만든 후, 따로 떼어놓은 1/4로 (가설)검증을 하는 cross-validation 방법이 있는데, machine leanring분야에서는 기본적인 process.\nCross-validation 방식에는 여러 변형들이 있음; e.g. 데이터를 4등분하여 각각 4번 위의 방식을 반복하여 합치는 방식, 3가지 (training, validation, test sets)로 나누어 분석",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#exploratory-vs.-confirmatory-analysis",
    "href": "contents/visualize.html#exploratory-vs.-confirmatory-analysis",
    "title": "Visualize",
    "section": "",
    "text": "데이터 시각화는 탐색적 분석에 더 초점이 맞춰져 있음.\n\n소위 data mining이라고 부르는 데이터 내의 숨겨진 패턴을 찾고 분석하는 탐색적 분석은 전통적인 통계에서 discouraging되어 왔음.\n\n확률에 근거한 통계 이론은 데이터를 수집하기 전에 가설을 세우고 그 가설을 confirm하는 방식을 취함.\n\n논란의 여지가 있지만, 원칙적으로 가설에 근거해 수집한 자료가 가설과 일치하는지를 확인하는 작업에서는 자료를 두 번 이상 들여다 보지 않아야 함.\n\n그럼에도 불구하고, 탐색적 분석은 behind doors에서 이루어지거나 새로운 가설을 세우기 위한 방편으로 이용되었음.\n\n또한, 매우 엄격한 잣대를 적용하는 상황에서도 통계 이론의 특성으로 인해 기본적인 탐색적 분석은 반드시 선행되어야 함.\n\n연구 가설의 진위를 탐구할 때, 탐색적 분석에서 쉽게 빠질 수 있는 편향성(bias)는 항상 조심할 필요가 있고, 확신을 위해서는 새로이 자료를 수집해서 가설을 재검증할 필요가 있음.\n\n탐색적 분석을 위해서는 다양한 시각화 기술이 요하나, 일반적인 통계 분석을 위해서 필요로하는 최소한으로 제한하고자 함.\n또한, 복잡한 통계치를 살펴볼 때, 직접 시각화를 하기보다는 패키지가 알아서 시각화를 해주기 때문에 자세히 알지 못해도 무방함.\n좀 더 상세한 내용에 대해서는\n\nR for Data Science/Visualize\nggplot2 book\nggplot2 extensions\n통계치 표현: ggstatsplot, ggpubr\nData Visualization with R by Rob Kabacoff : 적절한 밸런스\nggplot2 cheatsheet : pdf 다운로드\n\n\n\n\n\n\n\nNote\n\n\n\n충분히 큰 데이터의 경우, 일정량의 데이터 가령 1/4을 따로 떼어놓고, 3/4만으로 탐색적 분석을 통해 모델을 만든 후, 따로 떼어놓은 1/4로 (가설)검증을 하는 cross-validation 방법이 있는데, machine leanring분야에서는 기본적인 process.\nCross-validation 방식에는 여러 변형들이 있음; e.g. 데이터를 4등분하여 각각 4번 위의 방식을 반복하여 합치는 방식, 3가지 (training, validation, test sets)로 나누어 분석",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#basics",
    "href": "contents/visualize.html#basics",
    "title": "Visualize",
    "section": "Basics",
    "text": "Basics\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\npenguins |&gt;\n    print() # 무시\n\n# A tibble: 344 x 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# i 338 more rows\n# i 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel~\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse~\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ~\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ~\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186~\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ~\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male~\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007~\n\n\nVariabels:\n\nspecies: a penguin’s species (Adelie, Chinstrap, or Gentoo).\n\nflipper_length_mm: length of a penguin’s flipper, in millimeters.\n\nbody_mass_g: body mass of a penguin, in grams.\n\n더 자세한 사항은 ?penguins\nggplot을 이용한 시각화는 주로 3가지 성분으로 나뉨\n\ndata: 사용할 데이터\n\nmapping: data의 변수들을 어떤 특성에 mapping할 것인지 specify\n\ngeom: 어떤 시각화 개체(graphical objects)로 데이터를 표현할 것인지 specify\n\n\n# x, y축에 변수를 mapping\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\n\n\n\n\n\n# point로 데이터를 표시: scatterplot\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#&gt; Warning: Removed 2 rows containing missing values (`geom_point()`).\n\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n실제로 is.na()함수를 이용해 missing을 확인해보면,\npenguins |&gt;\n  select(species, flipper_length_mm, body_mass_g) |&gt;\n  filter(is.na(body_mass_g) | is.na(flipper_length_mm))  # true, false의 boolean type\n#&gt; # A tibble: 2 × 3\n#&gt;   species flipper_length_mm body_mass_g\n#&gt;   &lt;fct&gt;               &lt;int&gt;       &lt;int&gt;\n#&gt; 1 Adelie                 NA          NA\n#&gt; 2 Gentoo                 NA          NA\n\n\n\nAdding aesthetics and layers\n\n# spcies에 color (aesthetics)를 mapping\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\nWarning message:\n\"The `scale_name` argument of `discrete_scale()` is deprecated as of ggplot2\n3.5.0.\"\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n위에서 species마다 다른 색을 입혀서 다른 패턴이 나타나는지 확인해 볼 수 있음\nggplot2는 + 기호로 연결하여 계속 layer를 추가할 수 있음.\n다음은 trendline 혹은 fitted line이라고 부르는 경향성을 확인해 볼 수 있는 라인의 layer를 추가함\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\"\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nData에 fitted curve를 구하는 방식에는 여러 방법이 있음\n\nLinear fit: 1차 함수형태인 직선으로 fit\nSmoothing fit\n\nPolynominal fit: n차 다항함수형태로 fit\nLoess/lowess: locally estimated/weighted scatterplot smoothing\nGAM: generalized additive model\nSpine: piece-wise polynominal regression\n\n\n나중에 좀 더 자세히 알아봄\n\n\nggplot2는 플랏의 대상에 다음과 같은 속성을 부여할 수 있음\ncolor, size, shape, fill, alpha\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species, shape = island)\n) +\n  geom_point()\n\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n어떤 속성을 어떤 변수에 할당하는 것이 적절한지를 선택하는 것이 기술\n\n\n\n\nCategorical vs. continuous\ncolor와 같은 속성은 카테고리 변수가 좀 더 적절하나, 연속변수에서도 적용될 수 있음\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = bill_length_mm)\n) +\n  geom_point()\n\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n반대로, x, y에 카테고리 변수를 mapping하여 scatterplot을 그리면 다음과 같은 overploting의 문제가 생김\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_point()\n\nWarning message:\n\"Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\n\nOverplotting\nOverplotting의 문제를 해결하는 방식은 주로\n\nalpha(투명도)를 조정하거나 랜덤하게 흐뜨려그리는 geom_jitter()를 사용\n\n애초에 겹치지 않게 그리는 방법도 있음: e.g. beeswarm plot\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_jitter(width = .2) # jitter의 정도: width, height\n\nWarning message:\n\"Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_jitter(width = .2, alpha = .5) # alpha: 투명도 0 ~ 1\n\nWarning message:\n\"Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\"",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#geometric-objects",
    "href": "contents/visualize.html#geometric-objects",
    "title": "Visualize",
    "section": "Geometric objects",
    "text": "Geometric objects\nggplot2는 40가지 넘는 geom objects를 제공함.\n주로 통계를 위해 쓰일 geom들은\n\ngeom_point, geom_smooth()\ngeom_boxplot()\ngeom_histogram(), geom_freqploy(), geom_density()\n\nGlobal vs. local mapping\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) + # color mapping은 geom_point에만 적용\n  geom_smooth() # 맨 위의 mapping에 있는 global mapping을 inherit\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\"\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_smooth(mapping = aes(linetype = sex), se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\"\n\n\n\n\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_depth_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) + # color mapping은 geom_point에만\n  geom_smooth(method = lm) # 맨 위의 mapping에 있는 global mapping을 inherit, method: fitted line의 종류\n\n\n\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_depth_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = lm) + # 맨 위의 mapping에 있는 global mapping을 inherit\n  geom_smooth(mapping = aes(color = species), method = lm) # color mapping 추가\n\n\n\n\n\n\n\n\naes() 내부, 외부에서의 mapping\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(mapping = aes(color = species)) # aesthetic color에 변수를 mapping\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(color = \"skyblue\") + # geom의 color 속성에 색을 지정\n    geom_smooth(color = \"orangered\")",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#statistical-transformations",
    "href": "contents/visualize.html#statistical-transformations",
    "title": "Visualize",
    "section": "Statistical transformations",
    "text": "Statistical transformations\nggplot2는 편의를 위해 통계치를 구해 표시해주는데,\n경우에 따라 직접 통계치를 계산 후 새로 얻는 데이터로 그리는 것이 유리함\n\nDistribution\ngeom_histogram(), geom_freqploy(), geom_density()\n\n# y축에 표시되는 통계치들이 계산됨\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 100) # binwidth vs. bins\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, colour = sex)) +\n  geom_freqpoly(binwidth = 100)\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, colour = sex)) +\n  geom_density(bw = 100) # bw: band width\n\n\n\n\n\n\n\n\n\n\n\n\nBoxplot\nBoxplot은 분포에 대한 정보은 줄어드나, 카테고리별로 간결하게 비교되는 장점\nboxplot()\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n    geom_boxplot()\n\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\"\n\n\n\n\n\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n    geom_boxplot() +\n    geom_jitter(alpha = .6)\n\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\"\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\ncps &lt;- as_tibble(mosaicData::CPS85)\ncps |&gt;\n    filter(wage &lt; 30) |&gt;\n    ggplot(aes(x = as.factor(educ), y = wage)) + # as.factor(): numeric을 factor로 변환\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g, fill = sex)) + # color는 box의 테두리 색, fill은 내부색\n  geom_boxplot()\n\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\"\n\n\n\n\n\n\n\n\n\n\n\nBarplot\nBarplot은 여러방식으로 쓸 수 있는데, 문법이 조금 복잡하고, 수업에서 거의 사용하지 않을 예정이므로 웹사이트를 참조\nR for Data Science/Layers/Statistical transformations\n\nggplot(data = penguins) +\n  geom_bar(mapping = aes(x = species)) # 개수\n\n\n\n\n\n\n\n\n\n\nDiscretize\n연속 변수를 임의의 구간으로 나누어 카테고리처럼 적용하기 할 수 있음\ncut_width(), cut_number(), cut_interval()\n\ncut_width(): 구간의 길이를 정함\ncut_number(): 동일한 갯수의 관측값을 갖는 n개의 그룹\ncut_interval(): 동일한 길이의 n개의 그룹\n\n\nggplot(\n  data = penguins,\n  mapping = aes(\n    x = bill_length_mm, y = bill_depth_mm,\n    color = cut_interval(body_mass_g, 3) # body_mass_g의 값을 3개의 동일한 길이의 구간으로 나눔\n  )\n) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) # span: smoothing 정도 조절\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n\"Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\"\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#facets",
    "href": "contents/visualize.html#facets",
    "title": "Visualize",
    "section": "Facets",
    "text": "Facets\n카테고리 변수들이 지니는 카테고리들(레벨)로 나누어 그리기\nfacet_wrap(), facet_grid()\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~species) # species의 레벨로 나뉘어짐\n\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\nfacet_wrap()은 레벨이 많아지면 다음의 facet_grid()와는 다르게 화면크기에 맞춰 다음 줄로 넘어감\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_grid(sex ~ species) # 행과 열에 각각 sex, species\n\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  aes(x = body_mass_g, y = flipper_length_mm, color = sex) # color 추가\n) +\n  geom_point(alpha = .6) +\n  facet_grid(island ~ species) # 행과 열에 각각 sex, species\n\nWarning message:\n\"Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFacet과 color 중 어떤 방식으로 표현하는 것이 유리한가? 밸런스를 잘 선택!\n\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~species)\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm, color = species)) +\n  geom_point()\n\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\nWarning message:\n\"Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\"",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#labels",
    "href": "contents/visualize.html#labels",
    "title": "Visualize",
    "section": "Labels",
    "text": "Labels\nlabs() 안에 각 요소별로 지정\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = island)) +\n  geom_smooth() +\n  labs(\n    title = \"Body mass and flipper length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Flipper length (mm)\", y = \"Body mass (g)\",\n    color = \"Species\", shape = \"Island\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n앞으로는 pipe operator와 함께, 축약 형태로\n\ndata = 대신 첫번째 argument 위치에 data frame이 위치\nmapping = 은 두번째 argument 위치에 aes()을 위치\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n은 다음과 같이\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\nPipe operator로 다음과 연결될 수 있음\n\npenguins |&gt;\n    filter(!is.na(sex) & island != \"Torgersen\") |&gt; # 성별이 missing이 아니고, Torgersen섬은 제외\n    ggplot(aes(x = body_mass_g, y = flipper_length_mm, color = sex)) +\n    geom_point() +\n    geom_smooth() +\n    facet_wrap(~island)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/visualize.html#examples",
    "href": "contents/visualize.html#examples",
    "title": "Visualize",
    "section": "Examples",
    "text": "Examples\n이전에 다뤘던 CPS85 데이터로 보면,\n\ncps &lt;- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\ncps |&gt;\n   print() # 생략!\n\n# A tibble: 534 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# i 528 more rows\n\n\n\ncps |&gt;\n    ggplot(aes(x = wage, color = married)) +\n    geom_freqpoly(binwidth = 1)\n\n\n\n\n\n\n\n\n\ncps |&gt;\n    ggplot(aes(x = wage, color = married)) +\n    geom_freqpoly(binwidth = 1) +\n    facet_wrap(~sex)\n\n\n\n\n\n\n\n\n\ncps |&gt;\n  ggplot(aes(x = married, y = wage)) +\n  geom_boxplot(width = .2) +\n  geom_jitter(width = .2, alpha = .2, color = \"red\") +\n  scale_y_continuous(label = scales::label_dollar()) # y축 scale의 변경\n\n\n\n\n\n\n\n\n\ncps |&gt;\n  ggplot(aes(x = married, y = wage, fill = sex)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\ncps |&gt;\n    filter(wage &lt; 30) |&gt;\n    ggplot(aes(x = sector, y = wage, fill = sex)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\ncps |&gt;\n    filter(wage &lt; 30) |&gt;\n    ggplot(aes(x = sector, y = wage, fill = sex)) +\n    geom_boxplot() +\n    facet_grid(married ~ .)\n\n\n\n\n\n\n\n\n\nplot &lt;- cps |&gt;\n  filter(wage &lt; 30) |&gt;\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .6) +\n  geom_smooth()\nplot\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n확대, 축소 혹은 제한된 범위에서 보려면 다음 2가지를 구분해야 함\ncoord_cartesian() vs. xlim() or ylim()\n\n\n\nplot + coord_cartesian(xlim = c(18, 40)) # zoom in\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nplot + xlim(18, 40) # data crop\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n\"Removed 181 rows containing non-finite outside the scale range\n(`stat_smooth()`).\"\nWarning message:\n\"Removed 181 rows containing missing values or values outside the scale range\n(`geom_point()`).\"\n\n\n\n\n\n\n\n\n\n\ncps |&gt;\n    filter(wage &lt; 30 & sector %in% c(\"manag\", \"manuf\", \"prof\", \"sales\")) |&gt;\n    ggplot(aes(x = age, y = wage, color = sex)) +\n    geom_point() +\n    geom_smooth(se = FALSE, span = 1) +\n    facet_wrap(~sector)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "R tutorial",
      "Visualize"
    ]
  },
  {
    "objectID": "contents/tidyverse.html",
    "href": "contents/tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "함수들: print(), glimpse(), summary(), count()\n() 안에 들어가는 것을 argument라고 부름\n\nlibrary(tidyverse)\n\ncps &lt;- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\nprint(cps) # print 생략!\n\n# A tibble: 534 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# i 528 more rows\n\n\n\n\n\n\n\n\nprint()\n\n\n\n강의 노트에서 print()를 쓰는 것은 jupyter notebook에서 data frame을 표시하는 방식때문이므로 무시하셔도 됩니다.\n\n\n보통 print()없이 데이터 프레임을 살펴보지만, print()을 이용하면, 표시되는 방식을 조정해서 볼 수 있음.\n\nprint(cps, n = 3) # 처음 3개 행\n\n# A tibble: 534 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n1   9      10 W     M     NH       NS    Married    27 Not      43 const \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales \n# i 531 more rows\n\n\n\n\n\n\n\n\ntip: print() 옵션\n\n\n\n\n\nprint(tibble, n = 10, width = Inf) # 10개의 rows와 모든 columns\n기본 셋팅을 변경하려면\noptions(tibble.print_min = 10, tibble.width = Inf)\nColumns/변수들이 많은 경우 화면에서 다음과 같이 축약되어 나오는데, 이를 다 보려면\nprint(nycflights13::flights) # nycflights13 패키지의 flights 데이터\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n# 1  2013     1     1      517         515       2     830     819      11 UA     \n# 2  2013     1     1      533         529       4     850     830      20 UA     \n# 3  2013     1     1      542         540       2     923     850      33 AA     \n# 4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n# 5  2013     1     1      554         600      -6     812     837     -25 DL     \n# 6  2013     1     1      554         558      -4     740     728      12 UA     \n# # … with 336,770 more rows, 9 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;,\n# #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n# #   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, and abbreviated variable names\n# #   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nprint(nycflights13::flights, n = 3, width = Inf) # 가로 열의 개수: Inf (모든 열)\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n# 1  2013     1     1      517            515         2      830            819\n# 2  2013     1     1      533            529         4      850            830\n# 3  2013     1     1      542            540         2      923            850\n#   arr_delay carrier flight tailnum origin dest  air_time distance  hour minute\n#       &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n# 1        11 UA        1545 N14228  EWR    IAH        227     1400     5     15\n# 2        20 UA        1714 N24211  LGA    IAH        227     1416     5     29\n# 3        33 AA        1141 N619AA  JFK    MIA        160     1089     5     40\n#   time_hour          \n#   &lt;dttm&gt;             \n# 1 2013-01-01 05:00:00\n# 2 2013-01-01 05:00:00\n# 3 2013-01-01 05:00:00\n# # … with 336,773 more rows\n\n\n\n많은 변수들을 간략히 보는 방법으로는 glimpse()\n\nglimpse(cps)\n\nRows: 534\nColumns: 11\n$ wage     &lt;dbl&gt; 9.00, 5.50, 3.80, 10.50, 15.00, 9.00, 9.57, 15.00, 11.00, 5.0~\n$ educ     &lt;int&gt; 10, 12, 12, 12, 12, 16, 12, 14, 8, 12, 17, 17, 14, 14, 12, 14~\n$ race     &lt;fct&gt; W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, NW, NW, W,~\n$ sex      &lt;fct&gt; M, M, F, F, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F~\n$ hispanic &lt;fct&gt; NH, NH, NH, NH, NH, NH, NH, NH, NH, NH, Hisp, NH, Hisp, NH, N~\n$ south    &lt;fct&gt; NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, N~\n$ married  &lt;fct&gt; Married, Married, Single, Married, Married, Married, Married,~\n$ exper    &lt;int&gt; 27, 20, 4, 29, 40, 27, 5, 22, 42, 14, 18, 3, 4, 14, 35, 0, 7,~\n$ union    &lt;fct&gt; Not, Not, Not, Not, Union, Not, Union, Not, Not, Not, Not, No~\n$ age      &lt;int&gt; 43, 38, 22, 47, 58, 49, 23, 42, 56, 32, 41, 26, 24, 34, 53, 2~\n$ sector   &lt;fct&gt; const, sales, sales, clerical, const, clerical, service, sale~\n\n\n\n\n\n\n\n\nTip\n\n\n\n엑셀 스프레드시트처럼 보는 방법은\nEnvironment 패널에 보이는 cps 데이터셋 맨 끝에 네모난 마크를 클릭하거나,\nview(cps)\n\n\n변수들에 대한 통계치 요약 summary()\n\nsummary(cps)\n\n      wage             educ       race     sex     hispanic   south   \n Min.   : 1.000   Min.   : 2.00   NW: 67   F:245   Hisp: 27   NS:378  \n 1st Qu.: 5.250   1st Qu.:12.00   W :467   M:289   NH  :507   S :156  \n Median : 7.780   Median :12.00                                       \n Mean   : 9.024   Mean   :13.02                                       \n 3rd Qu.:11.250   3rd Qu.:15.00                                       \n Max.   :44.500   Max.   :18.00                                       \n                                                                      \n    married        exper         union          age             sector   \n Married:350   Min.   : 0.00   Not  :438   Min.   :18.00   prof    :105  \n Single :184   1st Qu.: 8.00   Union: 96   1st Qu.:28.00   clerical: 97  \n               Median :15.00               Median :35.00   service : 83  \n               Mean   :17.82               Mean   :36.83   manuf   : 68  \n               3rd Qu.:26.00               3rd Qu.:44.00   other   : 68  \n               Max.   :55.00               Max.   :64.00   manag   : 55  \n                                                           (Other) : 58  \n\n\n카테고리별 개수를 세주는 count()\nNumber(수)에 대해서도 적용 가능: ex. educ 수준 2, 3, … 18 각각에 대해서\n\ncps |&gt; # pipe operator: alt + . (option + .)\n  count(sector) |&gt;\n  print() # 생략해도 됨\n\n# A tibble: 8 x 2\n  sector       n\n  &lt;fct&gt;    &lt;int&gt;\n1 clerical    97\n2 const       20\n3 manag       55\n4 manuf       68\n5 other       68\n6 prof       105\n7 sales       38\n8 service     83\n\n\n\ncps |&gt;\n  count(sex, married) |&gt;\n  print()\n\n# A tibble: 4 x 3\n  sex   married     n\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n1 F     Married   162\n2 F     Single     83\n3 M     Married   188\n4 M     Single    101\n\n\n\n\n\n\n\n\nPipe operator\n\n\n\n|&gt; 또는 %&gt;% (’then’의 의미로…)\nx |&gt; f(y) # f(x, y),\nx |&gt; f(y) |&gt; g(z) # g(f(x, y), z)\nsummary(cps) 는 다음과 같음\ncps |&gt;\n    summary()\ncount(cps, sector)는 다음과 같음\ncps |&gt; \n    count(sector)",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/tidyverse.html#inspecting-data",
    "href": "contents/tidyverse.html#inspecting-data",
    "title": "Tidyverse",
    "section": "",
    "text": "함수들: print(), glimpse(), summary(), count()\n() 안에 들어가는 것을 argument라고 부름\n\nlibrary(tidyverse)\n\ncps &lt;- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\nprint(cps) # print 생략!\n\n# A tibble: 534 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# i 528 more rows\n\n\n\n\n\n\n\n\nprint()\n\n\n\n강의 노트에서 print()를 쓰는 것은 jupyter notebook에서 data frame을 표시하는 방식때문이므로 무시하셔도 됩니다.\n\n\n보통 print()없이 데이터 프레임을 살펴보지만, print()을 이용하면, 표시되는 방식을 조정해서 볼 수 있음.\n\nprint(cps, n = 3) # 처음 3개 행\n\n# A tibble: 534 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n1   9      10 W     M     NH       NS    Married    27 Not      43 const \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales \n# i 531 more rows\n\n\n\n\n\n\n\n\ntip: print() 옵션\n\n\n\n\n\nprint(tibble, n = 10, width = Inf) # 10개의 rows와 모든 columns\n기본 셋팅을 변경하려면\noptions(tibble.print_min = 10, tibble.width = Inf)\nColumns/변수들이 많은 경우 화면에서 다음과 같이 축약되어 나오는데, 이를 다 보려면\nprint(nycflights13::flights) # nycflights13 패키지의 flights 데이터\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;       &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n# 1  2013     1     1      517         515       2     830     819      11 UA     \n# 2  2013     1     1      533         529       4     850     830      20 UA     \n# 3  2013     1     1      542         540       2     923     850      33 AA     \n# 4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n# 5  2013     1     1      554         600      -6     812     837     -25 DL     \n# 6  2013     1     1      554         558      -4     740     728      12 UA     \n# # … with 336,770 more rows, 9 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;,\n# #   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n# #   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, and abbreviated variable names\n# #   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nprint(nycflights13::flights, n = 3, width = Inf) # 가로 열의 개수: Inf (모든 열)\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n# 1  2013     1     1      517            515         2      830            819\n# 2  2013     1     1      533            529         4      850            830\n# 3  2013     1     1      542            540         2      923            850\n#   arr_delay carrier flight tailnum origin dest  air_time distance  hour minute\n#       &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n# 1        11 UA        1545 N14228  EWR    IAH        227     1400     5     15\n# 2        20 UA        1714 N24211  LGA    IAH        227     1416     5     29\n# 3        33 AA        1141 N619AA  JFK    MIA        160     1089     5     40\n#   time_hour          \n#   &lt;dttm&gt;             \n# 1 2013-01-01 05:00:00\n# 2 2013-01-01 05:00:00\n# 3 2013-01-01 05:00:00\n# # … with 336,773 more rows\n\n\n\n많은 변수들을 간략히 보는 방법으로는 glimpse()\n\nglimpse(cps)\n\nRows: 534\nColumns: 11\n$ wage     &lt;dbl&gt; 9.00, 5.50, 3.80, 10.50, 15.00, 9.00, 9.57, 15.00, 11.00, 5.0~\n$ educ     &lt;int&gt; 10, 12, 12, 12, 12, 16, 12, 14, 8, 12, 17, 17, 14, 14, 12, 14~\n$ race     &lt;fct&gt; W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, NW, NW, W,~\n$ sex      &lt;fct&gt; M, M, F, F, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F~\n$ hispanic &lt;fct&gt; NH, NH, NH, NH, NH, NH, NH, NH, NH, NH, Hisp, NH, Hisp, NH, N~\n$ south    &lt;fct&gt; NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, N~\n$ married  &lt;fct&gt; Married, Married, Single, Married, Married, Married, Married,~\n$ exper    &lt;int&gt; 27, 20, 4, 29, 40, 27, 5, 22, 42, 14, 18, 3, 4, 14, 35, 0, 7,~\n$ union    &lt;fct&gt; Not, Not, Not, Not, Union, Not, Union, Not, Not, Not, Not, No~\n$ age      &lt;int&gt; 43, 38, 22, 47, 58, 49, 23, 42, 56, 32, 41, 26, 24, 34, 53, 2~\n$ sector   &lt;fct&gt; const, sales, sales, clerical, const, clerical, service, sale~\n\n\n\n\n\n\n\n\nTip\n\n\n\n엑셀 스프레드시트처럼 보는 방법은\nEnvironment 패널에 보이는 cps 데이터셋 맨 끝에 네모난 마크를 클릭하거나,\nview(cps)\n\n\n변수들에 대한 통계치 요약 summary()\n\nsummary(cps)\n\n      wage             educ       race     sex     hispanic   south   \n Min.   : 1.000   Min.   : 2.00   NW: 67   F:245   Hisp: 27   NS:378  \n 1st Qu.: 5.250   1st Qu.:12.00   W :467   M:289   NH  :507   S :156  \n Median : 7.780   Median :12.00                                       \n Mean   : 9.024   Mean   :13.02                                       \n 3rd Qu.:11.250   3rd Qu.:15.00                                       \n Max.   :44.500   Max.   :18.00                                       \n                                                                      \n    married        exper         union          age             sector   \n Married:350   Min.   : 0.00   Not  :438   Min.   :18.00   prof    :105  \n Single :184   1st Qu.: 8.00   Union: 96   1st Qu.:28.00   clerical: 97  \n               Median :15.00               Median :35.00   service : 83  \n               Mean   :17.82               Mean   :36.83   manuf   : 68  \n               3rd Qu.:26.00               3rd Qu.:44.00   other   : 68  \n               Max.   :55.00               Max.   :64.00   manag   : 55  \n                                                           (Other) : 58  \n\n\n카테고리별 개수를 세주는 count()\nNumber(수)에 대해서도 적용 가능: ex. educ 수준 2, 3, … 18 각각에 대해서\n\ncps |&gt; # pipe operator: alt + . (option + .)\n  count(sector) |&gt;\n  print() # 생략해도 됨\n\n# A tibble: 8 x 2\n  sector       n\n  &lt;fct&gt;    &lt;int&gt;\n1 clerical    97\n2 const       20\n3 manag       55\n4 manuf       68\n5 other       68\n6 prof       105\n7 sales       38\n8 service     83\n\n\n\ncps |&gt;\n  count(sex, married) |&gt;\n  print()\n\n# A tibble: 4 x 3\n  sex   married     n\n  &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n1 F     Married   162\n2 F     Single     83\n3 M     Married   188\n4 M     Single    101\n\n\n\n\n\n\n\n\nPipe operator\n\n\n\n|&gt; 또는 %&gt;% (’then’의 의미로…)\nx |&gt; f(y) # f(x, y),\nx |&gt; f(y) |&gt; g(z) # g(f(x, y), z)\nsummary(cps) 는 다음과 같음\ncps |&gt;\n    summary()\ncount(cps, sector)는 다음과 같음\ncps |&gt; \n    count(sector)",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/tidyverse.html#rows",
    "href": "contents/tidyverse.html#rows",
    "title": "Tidyverse",
    "section": "Rows",
    "text": "Rows\n행에 적용되는 함수들\nfilter(), arrange(), distinct()\n\nfilter()\n조건에 맞는 행을 선택\n\nConditional operators:\n&gt;, &gt;=, &lt;, &lt;=,\n== (equal to), != (not equal to)\n& (and) | (or)\n! (not)\n%in% (includes)\n\n\n# 임금(wage)가 10이상인 사람들\ncps |&gt;\n  filter(wage &gt;= 10) |&gt;\n  print()\n\n# A tibble: 184 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  15      12 W     M     NH       NS    Married    40 Union    58 const   \n3  15      14 W     M     NH       NS    Single     22 Not      42 sales   \n4  11       8 W     M     NH       NS    Married    42 Not      56 manuf   \n5  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof    \n6  20.4    17 W     M     NH       NS    Single      3 Not      26 prof    \n# i 178 more rows\n\n\n\n# 임금(wage)가 10이상이고 여성(F)들\ncps |&gt;\n  filter(wage &gt;= 10 & sex == \"F\") |&gt;\n  print()\n\n# A tibble: 62 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  11.2    17 NW    F     NH       NS    Married    32 Not      55 clerical\n3  25.0    17 W     F     NH       NS    Single      5 Not      28 prof    \n4  12.6    17 W     F     NH       NS    Married    13 Not      36 manag   \n5  11.7    16 W     F     NH       NS    Single     42 Not      64 clerical\n6  12.5    15 W     F     NH       NS    Married     6 Not      27 clerical\n# i 56 more rows\n\n\n\n# 간부급(management)과 전문직(professional)에 종사하는 사람들\ncps |&gt;\n  filter(sector == \"manag\" | sector == \"prof\") |&gt;\n  print()\n\n# A tibble: 160 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# i 154 more rows\n\n\n다음과 같이 편리하게 %in%을 이용하여 여러 항목을 포함하는, 즉 |와 ==를 합친 조건문을 생성\n즉, include인지 판별\n\n# A shorter way to select sectors for management or professional\ncps |&gt;\n  filter(sector %in% c(\"manag\", \"prof\")) |&gt;\n  print()\n\n# A tibble: 160 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# i 154 more rows\n\n\n\n\n\n\n\n\nImportant\n\n\n\nfilter()로 얻은 데이터 프레임은 원래 데이터 프레임을 수정하는 것이 아니므로 계속 사용하려면 저장해야 함\n이후 모든 함수들에 대해서도 마찬가지\nprestige &lt;- cps |&gt;\n    filter(sector %in% c(\"manag\", \"prof\"))\n\nprestige\n#    wage  educ race  sex   hispanic south married exper union   age sector\n#   &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n# 1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n# 2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n# 3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n# ...\n\n\n\n\n\n\n\n\nTip\n\n\n\n잦은 실수들\ncps |&gt;\n    filter(sex = \"F\") # \"==\" vs. \"=\"\ncps |&gt;\n    filter(sector == \"manage\" | \"prof\") # | 전후 모두 완결된 조건문 필요\n\n\n\n\narrange()\nColumn의 값을 기준으로 row를 정렬\n\n# 교육정도(educ)와 임금(wage)에 따라 오름차순으로 정렬\ncps |&gt;\n  arrange(educ, wage) |&gt;\n  print(n = 10)\n\n# A tibble: 534 x 11\n    wage  educ race  sex   hispanic south married exper union   age sector \n   &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;  \n 1  3.75     2 W     M     Hisp     NS    Single     16 Not      24 service\n 2  7        3 W     M     Hisp     S     Married    55 Not      64 manuf  \n 3  6        4 W     M     NH       NS    Married    54 Not      64 service\n 4 14        5 W     M     NH       S     Married    44 Not      55 const  \n 5  3        6 W     F     Hisp     NS    Married    43 Union    55 manuf  \n 6  4.62     6 NW    F     NH       S     Single     33 Not      45 manuf  \n 7  5.75     6 W     M     NH       S     Married    45 Not      57 manuf  \n 8  3.35     7 W     M     NH       S     Married    43 Not      56 manuf  \n 9  4.5      7 W     M     Hisp     S     Married    14 Not      27 service\n10  6        7 W     F     NH       S     Married    15 Not      28 manuf  \n# i 524 more rows\n\n\ndesc()을 이용하면 내림차순으로 정렬\n\n# educ을 내림차순으로 정렬\ncps |&gt;\n  arrange(desc(educ)) |&gt;\n  print(n = 10)\n\n# A tibble: 534 x 11\n    wage  educ race  sex   hispanic south married exper union   age sector\n   &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n 1 15       18 W     M     NH       NS    Married    12 Not      36 prof  \n 2 14.0     18 W     F     NH       NS    Married    14 Not      38 manag \n 3 13.5     18 W     M     NH       NS    Married    14 Union    38 prof  \n 4 20       18 W     F     NH       NS    Married    19 Not      43 manag \n 5  7       18 W     M     NH       NS    Married    33 Not      57 prof  \n 6 11.2     18 W     M     NH       NS    Married    19 Not      43 prof  \n 7  5.71    18 W     M     NH       NS    Married     3 Not      27 prof  \n 8 18       18 W     M     NH       NS    Married    15 Not      39 prof  \n 9 19       18 W     M     NH       NS    Single     13 Not      37 manag \n10 22.8     18 W     F     NH       NS    Single     37 Not      61 prof  \n# i 524 more rows\n\n\narrange()와 filter()를 함께 사용하여 좀 더 복잡한 문제를 해결할 수 있음\n\n# 높은 지위의 섹터에서 일하는 사람들 중 임금이 상위에 있는 사람들\ncps |&gt;\n  filter(sector == \"manage\" | sector == \"prof\") |&gt;\n  arrange(desc(wage)) |&gt;\n  print()\n\n# A tibble: 105 x 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n3  25.0    17 W     M     NH       NS    Married    31 Not      54 prof  \n4  25.0    16 W     F     NH       S     Single      5 Not      27 prof  \n5  23.2    17 NW    F     NH       NS    Married    25 Union    48 prof  \n6  22.8    18 W     F     NH       NS    Single     37 Not      61 prof  \n# i 99 more rows\n\n\n\n\ndistinct()**\n유티크한 조합들을 리스트\n\ncps |&gt;\n  distinct(sector, sex) |&gt;\n  print()\n\n# A tibble: 15 x 2\n   sector   sex  \n   &lt;fct&gt;    &lt;fct&gt;\n 1 const    M    \n 2 sales    M    \n 3 sales    F    \n 4 clerical F    \n 5 service  F    \n 6 manuf    M    \n 7 prof     M    \n 8 service  M    \n 9 other    M    \n10 clerical M    \n11 manag    M    \n12 prof     F    \n13 manag    F    \n14 manuf    F    \n15 other    F",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/tidyverse.html#columns",
    "href": "contents/tidyverse.html#columns",
    "title": "Tidyverse",
    "section": "Columns",
    "text": "Columns\n열에 적용되는 함수들\nmutate(), select(), rename()\n\nmutate()\nColumns/변수들로부터 값을 계산하여 새로운 변수를 만듦\n\ntips &lt;- as_tibble(reshape::tips) # reshpae 패키지 안에 tips 데이터셋\ntips |&gt; print()\n\n# A tibble: 244 x 7\n  total_bill   tip sex    smoker day   time    size\n       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;\n1       17.0  1.01 Female No     Sun   Dinner     2\n2       10.3  1.66 Male   No     Sun   Dinner     3\n3       21.0  3.5  Male   No     Sun   Dinner     3\n4       23.7  3.31 Male   No     Sun   Dinner     2\n5       24.6  3.61 Female No     Sun   Dinner     4\n6       25.3  4.71 Male   No     Sun   Dinner     4\n# i 238 more rows\n\n\n\ntips |&gt;\n  mutate(\n    tip_pct = tip / total_bill * 100,\n    tip_pct_per = tip_pct / size\n  ) |&gt;\n  print()\n\n# A tibble: 244 x 9\n  total_bill   tip sex    smoker day   time    size tip_pct tip_pct_per\n       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n1       17.0  1.01 Female No     Sun   Dinner     2    5.94        2.97\n2       10.3  1.66 Male   No     Sun   Dinner     3   16.1         5.35\n3       21.0  3.5  Male   No     Sun   Dinner     3   16.7         5.55\n4       23.7  3.31 Male   No     Sun   Dinner     2   14.0         6.99\n5       24.6  3.61 Female No     Sun   Dinner     4   14.7         3.67\n6       25.3  4.71 Male   No     Sun   Dinner     4   18.6         4.66\n# i 238 more rows\n\n\n\n\nselect()\nColumns/변수를 선택\n\ntips |&gt;\n  select(total_bill, tip, day, time) |&gt;\n  print()\n\n# A tibble: 244 x 4\n  total_bill   tip day   time  \n       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; \n1       17.0  1.01 Sun   Dinner\n2       10.3  1.66 Sun   Dinner\n3       21.0  3.5  Sun   Dinner\n4       23.7  3.31 Sun   Dinner\n5       24.6  3.61 Sun   Dinner\n6       25.3  4.71 Sun   Dinner\n# i 238 more rows\n\n\n\n# tip에서 smoker까지, 그리고 size columns 선택\ntips |&gt;\n  select(tip:smoker, size) |&gt; # select(2:4, 7)처럼 number로 선택가능\n  print()\n\n# A tibble: 244 x 4\n    tip sex    smoker  size\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;int&gt;\n1  1.01 Female No         2\n2  1.66 Male   No         3\n3  3.5  Male   No         3\n4  3.31 Male   No         2\n5  3.61 Female No         4\n6  4.71 Male   No         4\n# i 238 more rows\n\n\n\n# sex에서 day까지 columns은 제외하고\ntips |&gt;\n  select(!sex:day) |&gt; # !: not\n  print()\n\n# A tibble: 244 x 4\n  total_bill   tip time    size\n       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt;\n1       17.0  1.01 Dinner     2\n2       10.3  1.66 Dinner     3\n3       21.0  3.5  Dinner     3\n4       23.7  3.31 Dinner     2\n5       24.6  3.61 Dinner     4\n6       25.3  4.71 Dinner     4\n# i 238 more rows\n\n\n\n# factor 타입의 변수들만 선택: 함수를 이용\ntips |&gt;\n  select(where(is.factor)) |&gt; # 다른 함수들: is.numeric, is.character\n  print()\n\n# A tibble: 244 x 4\n  sex    smoker day   time  \n  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt; \n1 Female No     Sun   Dinner\n2 Male   No     Sun   Dinner\n3 Male   No     Sun   Dinner\n4 Male   No     Sun   Dinner\n5 Female No     Sun   Dinner\n6 Male   No     Sun   Dinner\n# i 238 more rows\n\n\n다양한 select()의 선택방법은 ?select로 help참고\n예를 들어, starts_with(\"abc\")는 abc로 시작하는 열의 이름을 가진 열들\n\n\n\n\n\n\nNote\n\n\n\nBase R에서 행과 열의 선택과 비교하면,\ncps[2:5, c(\"wage\", \"married\")] # 2~5행과 wage, married열\n# # A tibble: 4 × 2\n#    wage married\n#   &lt;dbl&gt; &lt;fct&gt;  \n# 1   5.5 Married\n# 2   3.8 Single \n# 3  10.5 Married\n# 4  15   Married\n\ncps |&gt; \n    select(wage, married) |&gt; \n    slice(2:5) # 행을 선택\n\n\n\n\nrelocate()\nColumns의 순서를 변경\n\ntips |&gt; print(n = 2)\n\n# A tibble: 244 x 7\n  total_bill   tip sex    smoker day   time    size\n       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;\n1       17.0  1.01 Female No     Sun   Dinner     2\n2       10.3  1.66 Male   No     Sun   Dinner     3\n# i 242 more rows\n\n\n\ntips |&gt;\n  relocate(day, time) |&gt; # day, time을 맨 앞으로 이동\n  print(n = 2)\n\n# A tibble: 244 x 7\n  day   time   total_bill   tip sex    smoker  size\n  &lt;fct&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;int&gt;\n1 Sun   Dinner       17.0  1.01 Female No         2\n2 Sun   Dinner       10.3  1.66 Male   No         3\n# i 242 more rows\n\n\n\ntips |&gt;\n  relocate(sex:time, tip) |&gt; # sex부터 time까지와 tip을 맨 앞으로 이동\n  print(n = 2)\n\n# A tibble: 244 x 7\n  sex    smoker day   time     tip total_bill  size\n  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 Female No     Sun   Dinner  1.01       17.0     2\n2 Male   No     Sun   Dinner  1.66       10.3     3\n# i 242 more rows\n\n\n\ntips |&gt;\n  relocate(day:size, .after = tip) |&gt; # .before: 앞에, .after: 뒤에\n  print(n = 2)\n\n# A tibble: 244 x 7\n  total_bill   tip day   time    size sex    smoker\n       &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;  &lt;fct&gt; \n1       17.0  1.01 Sun   Dinner     2 Female No    \n2       10.3  1.66 Sun   Dinner     3 Male   No    \n# i 242 more rows\n\n\n\n\nrename()\nColumns의 이름을 변경\n\ncps |&gt;\n  rename(education = educ, marital = married) |&gt; # new = old\n  print()\n\n# A tibble: 534 x 11\n   wage education race  sex   hispanic south marital exper union   age sector  \n  &lt;dbl&gt;     &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9          10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5        12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8        12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5        12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15          12 W     M     NH       NS    Married    40 Union    58 const   \n6   9          16 W     F     NH       NS    Married    27 Not      49 clerical\n# i 528 more rows\n\n\n변수를 select할 때 동시에 이름도 바꿀 수 있음\n\ncps |&gt;\n  select(education = educ, marital = married) |&gt; # new = old\n  print()\n\n# A tibble: 534 x 2\n  education marital\n      &lt;int&gt; &lt;fct&gt;  \n1        10 Married\n2        12 Married\n3        12 Single \n4        12 Married\n5        12 Married\n6        16 Married\n# i 528 more rows",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/tidyverse.html#groups",
    "href": "contents/tidyverse.html#groups",
    "title": "Tidyverse",
    "section": "Groups",
    "text": "Groups\n분석에서는 자주 카테고리별로 데이터를 나누어 통계치를 계산하곤 하는데,\ngroup_by()와 summarise()의 두 함수를 함께 사용하여 가장 자주 사용하게 됨\n\ngroup_by()\n데이터셋을 분석을 위해 의미있는 그룹으로 나눔\n다음은 성별로 데이터셋을 나눈 것인데, 실제 데이터를 수정하는 것은 아니고, 내부적으로 grouping되어 있음.\n맨 위 줄에 보면 Groups:  sex [2]로 표시되어 grouped data frame임을 명시함\n\ncps |&gt;\n  group_by(sex) |&gt;\n  print()\n\n# A tibble: 534 x 11\n# Groups:   sex [2]\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# i 528 more rows\n\n\n\n\nsummarise()\nsummarize()와 동일\ngroup별로 통계치를 구해 하나의 행으로 산출\n\n# 남녀별로 임금의 평균을 구함\ncps |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    avg_wage = mean(wage, na.rm = TRUE), # mean(): 평균, na.rm: NA를 remove할 것인가\n    n = n() # n(): 개수\n  ) |&gt;\n  print()\n\n# A tibble: 2 x 3\n  sex   avg_wage     n\n  &lt;fct&gt;    &lt;dbl&gt; &lt;int&gt;\n1 F         7.88   245\n2 M         9.99   289\n\n\n2개 이상의 변수들로 grouping할 수 있음\n\ncps |&gt;\n  group_by(sex, married) |&gt;\n  summarize(\n    ave_wage = mean(wage),\n    sd_wage = sd(wage)\n  ) |&gt;\n  print()\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 x 4\n# Groups:   sex [2]\n  sex   married ave_wage sd_wage\n  &lt;fct&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n1 F     Married     7.68    3.73\n2 F     Single      8.26    6.23\n3 M     Married    10.9     5.35\n4 M     Single      8.35    4.78\n\n\n이때, 결과 데이터 프레임은 sex로 grouping되어 있음.\ngrouping을 해제하려면 ungroup()이 필요함.\n그렇지 않으면, 저 결과는 sex로 grouped data frame임\n\nUseful summary functions\n자세한 사항은 R for Data Science/Data transformation\n\nMeasures of location: mean(), median()\nMeasures of spread: sd(), IQR(), mad()\nMeasures of rank: min(), max(), quantile(x, 0.25)\nMeasures of position: min_rank(), first(), nth(x, 2), last()\nMeasures of count: count(), n_distinct()",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/tidyverse.html#missing",
    "href": "contents/tidyverse.html#missing",
    "title": "Tidyverse",
    "section": "Missing",
    "text": "Missing\nR에서 missing values (결측치)는 NA로 표시\nNaN (not a number)는 주로 계산 결과로 나오는데, 예들 들어 0으로 나눌 때처럼, R에서는 NA로 취급되니 크게 신경쓰지 않아도 됨. 자세한 사항은 R for Data Science/Missing values 참고\nNA는 다음과 같은 성질을 지님\nNA &gt; 5\n#&gt; [1] NA\n10 == NA\n#&gt; [1] NA\nNA + 10\n#&gt; [1] NA\nNA / 2\n#&gt; [1] NA\nNA == NA\n#&gt; [1] NA\n\nx &lt;- NA\nis.na(x)\n#&gt; [1] TRUE\nNA는 filter()안의 조건문의 참거짓에 상관없이 모두 제외함\n\n실제로 조건문의 결과는 TRUE, FALSE로 이루어지짐\n\ndf &lt;- tibble(\n      one = c(1, NA, 3, 4, 2, NA), \n      two = c(2, 5, 3, NA, 10, NA), \n      three = c(\"a\", \"a\", \"a\", \"a\", \"b\", \"b\")\n  )\ndf\n#     one   two three\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n# 1     1     2 a    \n# 2    NA     5 a    \n# 3     3     3 a    \n# 4     4    NA a    \n# 5     2    10 b    \n# 6    NA    NA b    \n\nfilter(df, one &gt; 1)\n#     one   two three\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n# 1     3     3 a    \n# 2     4    NA a    \n# 3     2    10 b\n\n# NA를 포함하고자 할 때,\nfilter(df, one &gt; 1 | is.na(one))\n#     one   two three\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n# 1    NA     5 a    \n# 2     3     3 a    \n# 3     4    NA a    \n# 4     2    10 b    \n# 5    NA    NA b\n\n# NA를 포함하지 않은 행들만\nfilter(df, !is.na(one))\nfilter(df, !is.na(one) & !is.na(two)) # one, two 열에 모두 NA가 없는 행들만\n\nna.omit(df) # NA가 하나라도 있는 행은 모두 제거, 보통 결측치를 조심스럽게 대체한 후 사용\n#     one   two three\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n# 1     1     2 a    \n# 2     3     3 a    \n# 3     2    10 b \n\n# 함수 중에 NA를 직접 처리하는 경우들이 많음\nmean(df$one)\n## [1] NA\n\nmean(df$one, na.rm = TRUE) # NA removed\n## [1] 2.5\nna.rm = TRUE로 얻은 계산값에서 몇 개의 데이터로 계산되었는지 알기 위해서는\ndf |&gt; \n  group_by(three) |&gt; \n  summarise(\n      ave = mean(two, na.rm = TRUE), \n      n = n(), \n      n_notna = sum(!is.na(two))  # TRUE는 1로, FALSE는 0으로 계산됨\n  )\n#   three   ave     n n_notna\n#   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;\n# 1 a      3.33     4       3\n# 2 b     10        2       1",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/tidyverse.html#summary",
    "href": "contents/tidyverse.html#summary",
    "title": "Tidyverse",
    "section": "Summary",
    "text": "Summary\n다음 dplyr 패키지의 기본 verb 함수들로 데이터를 가공하면서 필요한 통계치를 구함\n\n조건에 맞는 행들(관측치)만 필터링: filter()\n열을 재정렬: arrange()\n변수들의 선택: select()\n변수들과 함수들을 이용하여 새로운 변수를 생성: mutate()\n원하는 요약 통계치를 간추림: summarise()",
    "crumbs": [
      "R tutorial",
      "Tidyverse"
    ]
  },
  {
    "objectID": "contents/regression1.html",
    "href": "contents/regression1.html",
    "title": "Correlation/Simple Regression",
    "section": "",
    "text": "통계에서 데이터의 타입은 대략 다음과 같이 나누어짐",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#linear-correlation의-계산",
    "href": "contents/regression1.html#linear-correlation의-계산",
    "title": "Correlation/Simple Regression",
    "section": "Linear correlation의 계산",
    "text": "Linear correlation의 계산\n교수의 연봉(salary), 학위를 받은 후 지난 시간(time since Ph.D.), 출판물의 수(pubs)의 관계\nData: c0301dt.csv\n\nacad0 &lt;- read_csv(\"data/c0301dt.csv\")\nacad0 |&gt; print()\n\n# A tibble: 15 x 3\n    time  pubs salary\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     3    18  51876\n 2     6     3  54511\n 3     3     2  53425\n 4     8    17  61863\n 5     9    11  52926\n 6     6     6  47034\n 7    16    38  66432\n 8    10    48  61100\n 9     2     9  41934\n10     5    22  47454\n11     5    30  49832\n12     6    21  47047\n13     7    10  39115\n14    11    27  59677\n15    18    37  61458\n\n\nThe formula for Pearson’s correlation coefficient; the product moment correlation coefficient\n\\(X, Y\\)에 대한 standardize (Z score); \\(\\displaystyle z_X = \\frac{X-M_X}{sd_X}, \\thinspace z_Y = \\frac{Y-M_Y}{sd_Y}\\)\n\\(r_{XY} = \\displaystyle 1 - \\frac{\\sum{(z_X - z_Y)^2}}{2n}\\)   \\(z_X, z_Y\\) : 각각 standardized \\(X, Y\\)\n\\(r_{XY} = \\displaystyle\\frac{\\sum_{i=1}^{n}{(x_i - \\bar x)(y_i - \\bar y)}}{\\sqrt{\\sum_{i=1}^{n}{(x_i - \\bar x)^2}} \\sqrt{\\sum_{i=1}^{n}{(y_i - \\bar y)^2}}}\\)   \\(\\bar x : X\\) 의 평균,   \\(\\bar y :Y\\) 의 평균\n\ndf &lt;- acad0 |&gt;\n    mutate(\n        z_time = (time - mean(time)) / sd(time),\n        z_pubs = (pubs - mean(pubs)) / sd(pubs),\n        diff = z_time - z_pubs,\n        squared = diff^2\n    ) |&gt;\n    print()\n\n# A tibble: 15 x 7\n    time  pubs salary  z_time  z_pubs   diff squared\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1     3    18  51876 -1.02   -0.140  -0.880  0.774 \n 2     6     3  54511 -0.364  -1.23    0.861  0.741 \n 3     3     2  53425 -1.02   -1.30    0.278  0.0772\n 4     8    17  61863  0.0728 -0.212   0.285  0.0812\n 5     9    11  52926  0.291  -0.646   0.938  0.879 \n 6     6     6  47034 -0.364  -1.01    0.644  0.415 \n 7    16    38  66432  1.82    1.31    0.514  0.264 \n 8    10    48  61100  0.510   2.03   -1.52   2.31  \n 9     2     9  41934 -1.24   -0.791  -0.447  0.200 \n10     5    22  47454 -0.583   0.150  -0.732  0.536 \n11     5    30  49832 -0.583   0.728  -1.31   1.72  \n12     6    21  47047 -0.364   0.0772 -0.441  0.195 \n13     7    10  39115 -0.146  -0.719   0.573  0.328 \n14    11    27  59677  0.728   0.511   0.217  0.0471\n15    18    37  61458  2.26    1.23    1.02   1.05  \n\n\n\nprint(1 - sum(df$squared) / (2 * 14))\n\n[1] 0.6566546\n\n\n\ncor(acad0) |&gt;\n    round(2) |&gt;  # 반올림 함수\n    print()\n\n       time pubs salary\ntime   1.00 0.66   0.71\npubs   0.66 1.00   0.59\nsalary 0.71 0.59   1.00\n\n\n상관계수 크기에 대한 guidline\n\n\\(| \\thinspace r\\thinspace|&lt;0.3\\): weak\n\\(0.3\\le|\\thinspace r\\thinspace|&lt;0.5\\): moderate\n\\(|\\thinspace r\\thinspace|&gt;0.5\\) : strong relationship\n\n상관계수를 제곱한 \\(r^2\\) 는 변량의 설명 정도를 나타내주는 계수; 결정계수 (\\(R^2\\), \\(R\\) squared)\n이는 좀 더 해석가능한 값이 되고, strength of association를 나타내는 주요한 지표임.\n뒤에서 자세히 다룸.\ncorrr 패키지의 correlate() 함수를 사용: tibble로 반환\n\n\n\n\n\n\nvignette 참고\n\n\n\n\n\ncorrr\nvignette(topic = \"using-corrr\",\n         package = \"corrr\")\n\n\n\n\nlibrary(corrr)\nacad0 |&gt;\n  correlate(quiet = T) |&gt;  # quiet = True: 간결한 output, 숫자형 변수만 선택됨\n  print()\n\n# A tibble: 3 x 4\n  term     time   pubs salary\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 time   NA      0.657  0.710\n2 pubs    0.657 NA      0.588\n3 salary  0.710  0.588 NA    \n\n\n\n\n\n\n\n\n다른 패키지들\n\n\n\n\n\n# Base R의 cor()의 옵션들\ncor(acad0, use = \"pairwise.complete.obs\") # NA의 처리: pairwise deletion\n\n# psych 패키지의 corr.test() 또는 lowerCor()이용\nlibrary(psych) \ncorr.test(acad0) # NA를 pairwise deletion으로 처리해줌\n\n## Correlation matrix \n##        time pubs salary\n## time   1.00 0.66   0.71\n## pubs   0.66 1.00   0.59\n## salary 0.71 0.59   1.00\n\n## Sample Size \n## [1] 15\n## Probability values (Entries above the diagonal are adjusted for multiple tests.) \n##        time pubs salary\n## time   0.00 0.02   0.01\n## pubs   0.01 0.00   0.02\n## salary 0.00 0.02   0.00\n## \n##  To see confidence intervals of the correlations, print with the short=FALSE option\n\nlowerCor(acad0)\n##        time pubs salary\n## time   1.00 \n## pubs   0.66 1.00\n## salary 0.71 0.59   1.00",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#시각화를-통한-상관계수",
    "href": "contents/regression1.html#시각화를-통한-상관계수",
    "title": "Correlation/Simple Regression",
    "section": "시각화를 통한 상관계수",
    "text": "시각화를 통한 상관계수\ncorrgram(), ggpairs()\nvignette for corrgram\n\nlibrary(corrgram)\ncorrgram(acad0,\n         order = TRUE,  # 상관계수가 높은 변수들을 가까이 위치시킴\n         upper.panel = panel.cor,   # 상관계수\n         lower.panel = panel.pie,  # 파이 차트\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntip: use a function\n\n\n\n\n\ncorgrm &lt;- function(df, order = TRUE){\n    corrgram(df,\n         order = order,  # 상관계수가 높은 변수들을 가까이 위치시킴\n         upper.panel = panel.cor,   # 상관계수\n         lower.panel = panel.pie,  # 파이 차트\n    )\n}\n\ncorgrm(acad0)\ncorgrm(acad0, order = FALSE)\n\n\n\nData from the 1985 Current Population Survey (CPS85)\n임금, 교육수준, 연차, 나이, 성별 간의 상관관계\n\ncps &lt;- mosaicData::CPS85\n\ncps |&gt;\n    select(wage, educ, exper, age, sex) |&gt;\n    mutate(sex = as.numeric(sex)) |&gt;   # factor를 숫자로 변환: 1, 2, ...\n    corrgram(\n         order = TRUE, \n         upper.panel = panel.cor, \n         lower.panel = panel.pie, \n    )\n\n\n\n\n\n\n\n\n\ncorrgram(acad0,\n         order = FALSE,\n         lower.panel = panel.pts,\n         upper.panel = panel.cor,\n         diag.panel = panel.density\n)\n\n\n\n\n\n\n\n\n\n# GGally 패키지의 ggpairs()\nGGally::ggpairs(acad0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip: includes fitted lines\n\n\n\n\n\ntrendlines &lt;- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .6) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"skyblue\", ...)\n}\n\nggpairs(acad0, columns = 1:3, lower = list(continuous = trendlines))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n명목변수인 경우에도 measure of association을 계산하는 방법이 있는데, 자세한 사항은 Measures of Association - How to Choose? 참고\nR에서 계산은 corrr::correlate(df, method=\"\")의 옵션 method를 “pearson”, “spearman”, “kendall” 중 선택\n명목변수의 예\n\n한 변수가 binary 인 경우: 물건의 가격 ~ 구매 여부\n두 변수가 모두 binary 인 경우: 남녀 ~ 합격 여부\n두 변수가 rank(ordinal) 인 경우: 다이아몬드 투명도(clarity)와 컬러(color)\n\nbinary인 경우: 0, 1로 코딩\nrank인 경우: 1, 2, 3… 로 코딩",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#simple-linearregression-models",
    "href": "contents/regression1.html#simple-linearregression-models",
    "title": "Correlation/Simple Regression",
    "section": "Simple linear/regression models",
    "text": "Simple linear/regression models\n단순한 상관관계를 넘어서서,\nY가 X에 의해 영향을 받거나 X에 의해 예측되는 변수라는 연구자의 가정이 있음.\n\nY: 종속변수 (dependent variable), regressand, response\n\nX: 독립변수 (independent variable), regressor, 예측변수 (predictor)\n\n선형관계임을 가정하고, 데이터에 가장 근접한 직선을 구함\n이상적으로, 모형(model)이 현상으로부터 노이즈가 제거된 진정한 신호를 잡아내 주기를 기대.\nLinear model: \\(y = ax + b + \\epsilon\\),   \\(\\epsilon\\): errors\n이 직선을 주어진 데이터로부터 두 변수 간의 관계를 가장 잘 represent하는 model (모형)이라고 말함.\n이는 확장된 의미에서 물리법칙에서 변수 간의 관계를 수학식으로 표현하고, 자연현상을 모델링한 것으로 이해할 수 있는 것과 같음.\nErrors:\n\nReducible error: 모형이 잡아내지 못한 신호; 영향을 미치지만 측정하지 않은 변수가 존재\nIrreducible error:\n\n측정 오차 (measurement error): ex. 성별, 젠더, 키, 온도, 강수량, 지능, 불쾌지수, …\nrandom processes\n\n물리적 세계의 불확실성: stochastic vs. deterministic world\n\n\n보통 Gaussian/Normal 분포를 이루거나 가정:\n\n\n예를 들어, 다음과 같이 x와 y의 관계가 나타난 경우,\n\n패턴: 선형 관계\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx와 y의 관계에 대한 모형을 세우는데, 모형은 두 부분으로 나눌 수 있음.\n\nA family of models를 정의: generic 패턴을 표현해 줄 수 있는 모델 타입. 예를 들어,\n\n만약, 선형적인 관계라면 선형 모델인 \\(y = a_2 x + a_1\\)\n곡선 관계라면 가령, \\(y = a_3 x^2 + a_2 x + a_1\\)\n\\(a_1, a_2, a_3\\)는 패턴을 잡아 낼수 있도록 변하는 파라미터\n\nA fitted model을 생성: 데이터에 가장 가까운(적합한) 파라미터에 해당하는 특정 모델을 선택;\n”fit a model to data”. 예를 들어,\n\n\\(y = 3x+7\\)\n\\(y = 2x^2 - 4x + 1\\)\n\n\nA fitted model은 a family of models 중에 데이터에 가장 가까운 모델임\n\n이는 소위 “best” model일 뿐\n“good” model임을 뜻하지 않고, “true” model임을 뜻하는 것은 더더욱 아님\n\n이제 위의 예를 보면, 선형성을 가정하고\n\n선형 모델 family인   \\(y = a_2 x + a_1\\)을 세울 수 있음\n무수히 많은 \\(a_1, a_2\\)의 값들 중 위 데이터에 가장 가까운 값을 찾음\n\n이를 “fit a model to data”라고 하고, 그 특정 모델을 fitted model이라고 함\n\n가깝다는 것을 정의하기 위해 데이터와 모델과의 거리를 정의해야 함; \\(d =|~data - model~|\\)\n대표적으로 모델과 데이터의 수직 차이 (잔차; residuals)의 총체로 거리를 정의할 수 있음\n최적의 모델은 이 거리를 최소로 함\n\n     \n\n\n\n\n\n\n\nNote\n\n\n\n\n특히, 다음과 같은 RMSE (root-mean-square deviation)을 기본적인 거리로 정의하고\n\n    \\(RMSE = \\displaystyle\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}{(Y_i -\\hat Y_i)^2}},\\)   \\(Y_i -\\hat Y_i\\) : residual (잔차)\n\n\nMean absolute error: \\(MAE = \\displaystyle\\frac{1}{n} \\sum_{i=1}^{n}{|~Y_i -\\hat Y_i~|}\\)\n\n이상치에 덜 민감함\n\n\n\n\n\n이 거리를 이용해서 모델의 파라미터를 추정하는 것을 ordinary least square (OLS) esimate이라고 함\n\n이 때, 잔차의 합은 0;   \\(\\displaystyle \\sum_{i=1}^{n}{(Y_i -\\hat Y_i)} = 0\\)\n\n이제, 위 예제의 데이터와 꽤 가까운 임의의 20개의 선형 모델을 그려보면 다음과 같고, 이 중 거리가 최소인 모델이 fitted model이 됨\n\n이 때, fitted model의 기울기는 2.05, y절편은 4.22임\n\n\n\n\n\n\n\n\n\n\nR은 여러 형태의 a family of models을 구성할 수 있는 효율적인 툴을 제공\n\nLinear (regression) models: \\(Y = a_0 + a_1 X_1 + a_2 X_2 + ~... ~ + a_n X_n\\)\n\n앞의 예는 \\(n=1\\) 에 해당하며, \\(Y =a_0 +a_1X_1\\)에 대해서 다음과 같이 편리하게 적용할 수 있음\nsim1_mod &lt;- lm(y ~ x, data = sim1)\n\ncoef(sim1_mod) # 모델의 parameter 즉, coefficients를 내줌\n#&gt; (Intercept)           x \n#&gt;    4.220822    2.051533   # 위에서 구한 파라미터값과 동일함\n\n즉, 앞의 데이터에 최적인 선형 모형은 \\(Y = 4.22 + 2.05X\\)\n\nlm()은 formula y ~ x를 \\(Y =a_0 +a_1X\\) 로 변환해 줌; Y 절편은 formula에서 생략\nOLS estimation인 경우 알고리즘적이 아닌, 방정식의 해를 구하듯 exact form으로 최소값을 구함\n\n\\(n=2\\) 인 경우인 두 변수 \\(X_1\\), \\(X_2\\)로 \\(Y\\)를 예측하는 경우,\nlm(y ~ x1 + x2, data = df)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis formula notation is called “Wilkinson-Rogers notation”, and was initially described in Symbolic Description of Factorial Models for Analysis of Variance by G. N. Wilkinson and C. E. Rogers\n위에서 y ~ x라는 formula는 x, y라는 변수를 바로 evaluate하지 않고, \\(Y = a_0 + a_1X\\)로 해석되어 함수로 전환됨",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#visualising-models",
    "href": "contents/regression1.html#visualising-models",
    "title": "Correlation/Simple Regression",
    "section": "Visualising models",
    "text": "Visualising models\nFitted models을 이해하기 위해 모델이 예측하는 부분(prediction)과 모델이 놓친 부분(residuals)을 시각화해서 보는 것이 유용함\n\nPredictions: the pattern that the model has captured\nResiduals: what the model has missed; 통계 분석의 핵심 요소\n\n앞서 구한 모형 \\(Y = 4.22 + 2.05X\\) 을 데이터와 함께 그려보면,\n\n\n\n\n\n\n\n\n\n\n이 모형에 의한 예측값들(pred)과 잔차(resid)들은\n\n\n# A tibble: 30 × 4\n      x     y  pred  resid\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     1  4.20  6.27 -2.07 \n2     1  7.51  6.27  1.24 \n3     1  2.13  6.27 -4.15 \n4     2  8.99  8.32  0.665\n5     2 10.2   8.32  1.92 \n6     2 11.3   8.32  2.97 \n7     3  7.36 10.4  -3.02 \n8     3 10.5  10.4   0.130\n# … with 22 more rows\n\n\nResiduals의 분포를 시각화해서 살펴보면,\n\nresiduals의 평균은 항상 0\nresiduals의 분포는 predictions이 관측치로부터 전반적으로 얼마나 벗어났는지에 평가할 수 있음\n\n\n\n\n\n\n\n\n\n\n예측 변수와 residuals의 관계를 시각화해서 보면,\n\n이 residuals은 특별한 패턴을 보이지 않아야 모델이 데이터의 패턴을 잘 잡아낸 것으로 판단할 수 있음\n또한 어떤 부분에서 예측이 벗어났는지도 판별할 수 있음\n\n\n\n\n\n\n\n\n\n\n\nResiduals에 패턴이 보이는 경우: 모형을 수정!",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#case-1",
    "href": "contents/regression1.html#case-1",
    "title": "Correlation/Simple Regression",
    "section": "Case 1",
    "text": "Case 1\n교수의 연봉(salary)이 학위를 받은 후 지난 시간(time since Ph.D.)과 출판물의 수(pubs)에 의해 어떻게 영향을 받는가? \n\n\n\n# A tibble: 15 × 3\n   time  pubs salary\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     3    18  51876\n2     6     3  54511\n3     3     2  53425\n4     8    17  61863\n5     9    11  52926\n6     6     6  47034\n# … with 9 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n모형 세우기\n선형모형: lm(y ~ x)\n\n\\(\\hat{Y} = a_0 + a_1X\\),   (\\(\\hat{Y}\\): 예측치)\n또는 \\(Y = a_0 + a_1X +e\\),   (\\(Y\\): 관측치, \\(e\\): 잔차, 에러)\n\\(a_1\\): 기울기 (\\(X\\)가 1 증가할 때, \\(Y\\)의 증가량),   \\(a_0\\): 절편 (\\(X\\)가 0일 때, \\(Y\\)의 값)\n\n\nmod1 &lt;- lm(salary ~ time, data = acad0): \\(\\widehat{salary} = a_0 + a_1time\\)\nmod2 &lt;- lm(salary ~ pubs, data = acad0): \\(\\widehat{salary} = a_0 + a_1pubs\\)\n\n\nFit a model to data\n데이터에 가장 근접한 모델\n\nmod1 &lt;- lm(salary ~ time, data = acad0)\nmod2 &lt;- lm(salary ~ pubs, data = acad0)\n\ncoef(mod1)\n## (Intercept)        time \n##   43658.594    1224.392\ncoef(mod2)\n## (Intercept)        pubs \n##   46357.449     335.526\n\n\nModel 1: \\(\\widehat{salary} = \\$43,659 + \\$1,224\\:time\\)\n\\(a_1\\): 학위를 받은 후 1년이 지날 때마다, 연봉은 $1,224 오름 (표현에 주의!)\n\\(a_0\\): 학위를 받은 후 0년일 때, 연봉은 $43,658; 0년이 의미있는가?\nModel 2 : \\(\\widehat{salary} = \\$46,357 + \\$336\\:pubs\\)\n\\(a_1\\): 출판물 1편을 추가로 발표하면, 연봉은 $336 오름 (표현에 주의!)\n\\(a_0\\): 출판물이 0편일 때, 연봉은 $46,357\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n연봉(salary)을 연차(time)로 예측하는 모델(mod1)에 대해서 prediction과 residuals 값을 구해보면\n단, 간편한 계산을 위해 salary를 1000으로 나누었으며, 51.876는 $51,876을 의미\n\n아래 테이블에서 가령, 6년차인 교수의 연봉은 모형에 의해 $51,000로 예측되고,\n2번째 교수의 경우 그 예측이 $3,510 정도 낮게 예측되었으며,\n6번째 교수의 경우는 $3,9700 정도 높게 예측되었음\n예측이 틀린 정도, 즉 잔차는 왜 생기는가? …\n\n\n\n\n\n\n\nImportant\n\n\n\n모형의 분석은 예측/설명되는 부분과 예측/설명되지 않는 부분으로 쪼개어 보는 것이 기본적인 시각\n예들 들어, 연차로 연봉을 설명할 수는 있는 부분 vs. 연차로 연봉이 설명되지 않는 부분!\n\n\n\n\ncode\nlibrary(modelr)\ndf &lt;- acad0 |&gt;\n  mutate(salary = salary / 1000)\n\nmod1 &lt;- lm(salary ~ time, data = df)\n\ndf |&gt;\n  add_predictions(mod1) |&gt;\n  add_residuals(mod1) |&gt;\n  mutate(\"(pred-m)^2\" = (pred - mean(pred))^2, \"resid^2\" = (resid)^2, \"(salary-m)^2\" = (salary - mean(salary))^2)\n\n\n\n\n   time salary  pred  resid (pred-m)^2 resid^2 (salary-m)^2\n1     3  51.88 47.33   4.54      32.65   20.65         1.37\n2     6  54.51 51.00   3.51       4.16   12.29         2.15\n3     3  53.42 47.33   6.09      32.65   37.13         0.14\n4     8  61.86 53.45   8.41       0.17   70.72        77.75\n5     9  52.93 54.68  -1.75       2.67    3.07         0.01\n6     6  47.03 51.00  -3.97       4.16   15.77        36.14\n7    16  66.43 63.25   3.18     104.11   10.13       179.20\n8    10  61.10 55.90   5.20       8.16   27.01        64.87\n9     2  41.93 46.11  -4.17      48.14   17.42       123.47\n10    5  47.45 49.78  -2.33      10.66    5.41        31.27\n11    5  49.83 49.78   0.05      10.66    0.00        10.33\n12    6  47.05 51.00  -3.96       4.16   15.67        35.98\n13    7  39.12 52.23 -13.11       0.67  171.99       194.06\n14   11  59.68 57.13   2.55      16.66    6.50        43.98\n15   18  61.46 65.70  -4.24     160.07   17.97        70.77\n\n\n\n\n\n\n\n\ngraphical representation\n\n\n\n\n\n\n\n\n\nColumn별로 더하면\n\n\n  time salary   pred resid (pred-m)^2 resid^2 (salary-m)^2\n1  115 795.68 795.68     0     439.75  431.73       871.48\n\n\n우선, 연봉의 합 \\(\\sum{Y}\\) = 예측값의 합 \\(\\sum{\\hat{Y}}\\)  : \\(X\\) 의 평균은 모형에 의해 Y의 평균으로 예측됨\n\n\n\n\n\n\nImportant\n\n\n\nPartitioning of variances\n\\(\\sum{(\\hat{Y}-m)^2}=439.75\\) : 연차의 변량 (variation)으로 모형에 의해 설명되는 (attribute/acount for) 연봉의 변량\n\\(\\sum{(Y-\\hat{Y})^2}=431.73\\) : 연차의 변량 (variation)으로 모형에 의해 설명될 수 없는 (not attribute) 연봉의 변량\n\\(\\sum{(Y-m)^2}=871.48\\) : 연봉의 변량\n이 세 값의 관계는 \\(\\sum{(\\hat{Y}-m)^2} + \\sum{(Y-\\hat{Y})^2} = \\sum{(Y-m)^2}\\)\n\nSum of squares (SS)로 부르며,\n\nSSR, SSE, SSY (각각 sum of squares of Regression, Error, Y)\n\n\n\n위 값을 다시 N(=15)으로 나누면, 즉 column별 평균은\n\n\n  time salary  pred resid (pred-m)^2 resid^2 (salary-m)^2\n1 7.67  53.05 53.05     0      29.32   28.78         58.1\n\n\n위의 관계는 variance (분산)으로 보면,\n  \\(V(predictions) + V(residuals) = V(Y)\\)\n이렇게 간결하게 쪼개지는 것은 predictions과 residuals이 서로 독립(\\(r=0\\))이 되기 때문으로 이해할 수 있음\n\npredictions \\(\\hat{Y}\\) 은 \\(X\\) 의 일차 함수식으로 얻어진 것이므로 \\(cor(X, \\hat Y)=1\\)이 되고,\nresiduals \\(Y-\\hat{Y}\\) 과 \\(X\\)는 상관이 없도록 estimate되었음.\n\n# correlations with residuals\n#         pred time salary\n# resid  0.00 0.00  0.704\n# salary 0.71 0.71  1.000\n다시 위의 식에서 \\(V(Y)\\) 로 양변을 나누면\n  \\(\\displaystyle\\frac{V(predictions)}{V(Y)} + \\frac{V(residuals)}{V(Y)} = 1\\)\n\n\n\n\n\n\nImportant\n\n\n\n즉, “모형에 의해 설명되는 \\(Y\\) 변량의 비율” + “모형에 의해 설명되지 않는 \\(Y\\) 변량의 비율” = 1\n첫 항을 \\(R^2\\) 라고 하고, 결정계수 혹은 R squared라고 부름\n따라서, \\(1-R^2\\) 는 설명되지 않는 변량의 비율이라고 할 수 있음\n\n\n\\(R^2\\) 를 제곱근하면 \\(R\\) 이 나오고, 이는 Pearson’s correlation coefficient와 동일함;\n\n\\(R(=r) = cor(Y, X) = cor(Y, \\hat{Y}=aX+b)\\)\n기울기 \\(\\displaystyle a = r_{XY} \\frac{sd_Y}{sd_X}\\)\n\\(R\\) 은 예측의 정확성에 대한 지표라고 이해할 수 있음\n\nOverlap in variance of correlated variables\n\n\n\n\n\n\n\nANOVA\n\n\n\n모형 자체에 대한 분석으로 ANOVA 결과는 anova()함수를 써서 볼 수 있음\n모집단에 대한 추론: 모형의 설명력이 모집단에서 0은 아닐 것이라는 추론;\n\nNull 모형 대비 주어진 모형이 잔차를 얼마나 줄였는가를 테스트함으로써 주어진 모형의 설명력이 0은 아님을 보임\n\nNull 모형: y ~ 1 (예측변수가 없는 모형, 설명력 0)\n\n잔차 변량(SSE) 대비 예측 변량(SSR)이 얼마나 큰가를 F분포를 이용해 통계적 추론이 이루어짐\n\n[주어진 모형의 잔차 변량 (SSE)] - [null 모형의 잔차 변량] = SSE - SSY = SSR\n즉, 추가된 예측 변수에 의해 설명되는 변량 정도가 sampling error, 즉 표본 추출에 따른 우연성에 의해 나타날 수 있을 확률을 계산\n\n\nanova(mod1)\n# Analysis of Variance Table\n\n# Response: salary\n#           Df Sum Sq Mean Sq F value Pr(&gt;F)   \n# time       1 439.75  439.75  13.241  0.003 **\n# Residuals 13 431.73   33.21                  \n# ---\n# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n대략, (예측변수로 설명되지 않는 Y인) 잔차의 평균 변량: \\(\\sqrt{mean~of~SSE} = \\sqrt{33.21} = 5.763\\)\n\n대략 말하면, 모형이 예측한 연봉과 실제 연봉의 차이는 평균 $5,763 정도 된다는 것을 의미함\n\n\n\n\n모형 \\(\\widehat{salary} = a_0 + a_1time\\) 에 대한\nSPSS 결과 테이블:\n\n\ndf &lt;- acad0 |&gt;\n  mutate(salary = salary / 1000)\nmod1 &lt;- lm(salary ~ time, data = df)\nsummary(mod1)\n\n\nCall:\nlm(formula = salary ~ time, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1143  -3.9644   0.0514   4.0251   8.4093 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  43.6586     2.9780  14.660 1.83e-09 ***\ntime          1.2244     0.3365   3.639    0.003 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.763 on 13 degrees of freedom\nMultiple R-squared:  0.5046,    Adjusted R-squared:  0.4665 \nF-statistic: 13.24 on 1 and 13 DF,  p-value: 0.003\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\\(R^2\\) 는 모형이 predictor들로부터 Y의 변량을 얼마나 예측/설명해주는지에 대한 지표로서 가장 널리 쓰임.\n다음의 두 경우는 1년의 연차가 $1,224의 연봉 증가로 나타나는 동일한 관계를 보여주지만, 그 strength of association에는 큰 차이가 있음\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n출판물의 수(pubs)가 연봉(salary)에 어떻게 영향을 미치는지 살펴보세요.",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#case-2",
    "href": "contents/regression1.html#case-2",
    "title": "Correlation/Simple Regression",
    "section": "Case 2",
    "text": "Case 2\n다음 데이터는 the Octogenarian Twin Study of Aging에서 나타나는 패턴을 기반으로 생성한 데이터\n출처: Longitudinal Analysis: Modeling Within-Person Fluctuation and Change by Lesa Hoffman\n\nincludes 550 older adults age 80 to 97 years.\nCognition was assessed by the Information Test, a measure of general world knowledge (i.e., crystallized intelligence; range = 0 to 44)\ndemgroup 1: those who will not be diagnosed with dementia (none group = 1; 72.55%),\ndemgroup 2: those who will eventually be diagnosed with dementia later in the study (future group = 2; 19.82%)\ndemgroup 3: those who already have been diagnosed with dementia (current group = 3; 7.64%)\n\nspss_chapter2.csv\n\ncognition &lt;- read_csv(\"data/spss_chapter2.csv\")\ncognition |&gt; print()\n\n# A tibble: 550 x 6\n   PersonID cognition   age  grip sexMW demgroup\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1        1        23  92.6     9     1        1\n 2        2        24  91.8    11     0        2\n 3        3        29  92.6    12     0        1\n 4        4        16  94.4     6     1        1\n 5        5        27  85.8     9     1        1\n 6        6        37  83.1    11     0        1\n 7        7         2  93.9    10     1        2\n 8        8        39  83.3     9     0        1\n 9        9        38  80.6    11     0        1\n10       10        32  85.9    10     0        1\n# i 540 more rows\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\ntrendlines &lt;- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .6) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"skyblue\", ...)\n}\n\nggpairs2 &lt;- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\nggpairs2(cognition, columns = 2:6)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(corrr)\ncorrelate(cognition[-1], quiet = T) |&gt; print()\n\n# A tibble: 5 x 6\n  term      cognition     age    grip    sexMW demgroup\n  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 cognition    NA     -0.170   0.242  -0.236   -0.413  \n2 age          -0.170 NA      -0.184   0.0456   0.0144 \n3 grip          0.242 -0.184  NA      -0.403    0.0368 \n4 sexMW        -0.236  0.0456 -0.403  NA        0.00992\n5 demgroup     -0.413  0.0144  0.0368  0.00992 NA      \n\n\n\n\n\n\n\n\nTip\n\n\n\ncognition |&gt;\n    select(cognition, age, grip) |&gt;\n    corr.test()\n          cognition   age  grip\n# cognition      1.00 -0.17  0.24\n# age           -0.17  1.00 -0.18\n# grip           0.24 -0.18  1.00\n\ncorr.test(cognition[\"cognition\"], cognition[c(\"age\", \"grip\")])\n# Correlation matrix \n#             age grip\n# cognition -0.17 0.24\n\n\n\ncognition |&gt;\n    ggplot(aes(x = grip, y = cognition)) +\n    geom_point(alpha=.5) +\n    geom_smooth()\n\n\n\n\n\n\n\n\n\nmod_cog &lt;- lm(cognition ~ grip, data = cognition)\nsummary(mod_cog)\n\n\nCall:\nlm(formula = cognition ~ grip, data = cognition)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-27.3941  -7.1578   0.3877   8.8377  22.8422 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  16.7033     1.4640  11.409  &lt; 2e-16 ***\ngrip          0.8909     0.1527   5.834 9.24e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.67 on 548 degrees of freedom\nMultiple R-squared:  0.05848,   Adjusted R-squared:  0.05677 \nF-statistic: 34.04 on 1 and 548 DF,  p-value: 9.244e-09\n\n\n\n기울기 0.89를 의미있게 해석할 수 있는가?\n\n절편 16.7은?\n\\(R^2\\) = 0.058; 악력의 변량으로 인지능력 변량의 5.8%가 설명됨\n\n\n\n\n\n\n\nTip: summ()\n\n\n\n\n\nlibrary(jtools)\nsumm(mod_cog)\n\n# MODEL INFO:\n# Observations: 550\n# Dependent Variable: cognition\n# Type: OLS linear regression \n\n# MODEL FIT:\n# F(1,548) = 34.04, p = 0.00\n# R&lt;U+00B2&gt; = 0.06\n# Adj. R&lt;U+00B2&gt; = 0.06 \n\n# Standard errors: OLS\n# ------------------------------------------------\n#                      Est.   S.E.   t val.      p\n# ----------------- ------- ------ -------- ------\n# (Intercept)         16.70   1.46    11.41   0.00\n# grip                 0.89   0.15     5.83   0.00\n# ------------------------------------------------\n\n\n\n\n변수의 표준화\nstandardize/normalize:   \\(\\displaystyle z = \\frac{x-m}{sd}; ~ax+b\\) : zoom + translate\n\n변수를 표준화하면 평균이 0이고, 표준편차가 1로 변환\n변수가 대략적으로 정규분포(normal distribution)을 따를 때,\n내재적인 단위가 없는 측정치들의 경우 그 값을 표준화시키면 해석이 용이하며,\n표준편차(sd)가 그 눈금/단위가 됨으로써 변수에 상관없이 동일한 눈금을 갖게 되어, 변수들 간의 비교가 가능해짐\n\n즉, 표준화된 변수의 1은 1sd를 의미\n\n또한, 평균이 0이 됨으로써 선형모형에서 용이한 trick을 제공해 줌\n변수를 표준화해도 사실상 중요한 통계치는 변화하지 않음; 상관계수, \\(R^2\\), \\(p\\) value 등\n\n좀 더 일반적으로 linear transform에 의해서 변하지 않음; 온도 C/F\n\n반면, 주어진 샘플의 평균과 표준편차를 사용함으로 샘플마다 변동이 생길 수 있음을 인지해야 함.\n\n\n cognition &lt;- cognition |&gt;\n     select(cog_std = cognition, grip_std = grip) |&gt;\n     scale() |&gt;  # standardize 함수\n     bind_cols(cognition)  # column bind: 열 방향으로 두 데이터프레임을 붙힘\n\ncognition |&gt; print()\n\n# A tibble: 550 x 8\n  cog_std grip_std PersonID cognition   age  grip sexMW demgroup\n    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 -0.166   -0.0378        1        23  92.6     9     1        1\n2 -0.0748   0.633         2        24  91.8    11     0        2\n3  0.380    0.968         3        29  92.6    12     0        1\n4 -0.803   -1.04          4        16  94.4     6     1        1\n5  0.198   -0.0378        5        27  85.8     9     1        1\n6  1.11     0.633         6        37  83.1    11     0        1\n# i 544 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\njtools 패키지의 standardize() 함수를 이용\ncognition |&gt;\n    jtools::standardize(c(\"cogition\", \"grip\"))\n\n\ncognition |&gt;\n    ggplot(aes(x = grip_std, y = cog_std)) +\n    geom_point(alpha=.5) +\n    geom_smooth(method=lm)\n\ncognition |&gt;\n    ggplot(aes(x = grip, y = cognition)) +\n    geom_point(alpha=.5) + \n    geom_smooth(method=lm)\n\n\n\n\n\n\n\n\n\n\nlibrary(ggpubr)\ncognition |&gt;\n    ggplot(aes(x = cognition, y = after_stat(density))) +\n    geom_freqpoly(binwidth=2) +\n    stat_overlay_normal_density(color = \"red\")\n\ncognition |&gt;\n    ggplot(aes(x = grip, y = after_stat(density))) +\n    geom_freqpoly(binwidth=1) +\n    stat_overlay_normal_density(color = \"red\")\n\n\n\n\n\n\n\n\n\n\nNormal distribution 정규 분포; 사실상 sd만으로 결정되는 분포 곡선\n\n  Source: The Truthful Art by Albert Cairo\n\nmod_cog_std &lt;- lm(cog_std ~ grip_std, data = cognition)\nsummary(mod_cog_std) |&gt; print(digits = 2)\n\n\nCall:\nlm(formula = cog_std ~ grip_std, data = cognition)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.493 -0.651  0.035  0.804  2.079 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.2e-16    4.1e-02     0.0        1    \ngrip_std     2.4e-01    4.1e-02     5.8    9e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.97 on 548 degrees of freedom\nMultiple R-squared:  0.058, Adjusted R-squared:  0.057 \nF-statistic:  34 on 1 and 548 DF,  p-value: 9.2e-09\n\n\n\n\n\\(R^2\\) 와 p values는 변함이 없으며, y intercept (y 절편)은 0\n기울기 0.24는 두 변수 간의 Pearson’s 상관계수와 같음\n\n\n\n\n\n\n\nTip: summ(df, scale = TRUE, transform.response = TRUE)\n\n\n\n\n\nlibrary(jtools)\n\n# scale: predictors 표준화, transform.response: response 표준화\nsumm(mod_cog_std, scale = TRUE, transform.response = TRUE)  # digits = 3, center = TRUE\n\n# ------------------------------------------------\n#                      Est.   S.E.   t val.      p\n# ----------------- ------- ------ -------- ------\n# (Intercept)         -0.00   0.04    -0.00   1.00\n# grip_std             0.24   0.04     5.83   0.00\n# ------------------------------------------------\n\n# Continuous variables are mean-centered and scaled by 1 s.d.",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/regression1.html#case-3",
    "href": "contents/regression1.html#case-3",
    "title": "Correlation/Simple Regression",
    "section": "Case 3",
    "text": "Case 3\n성별에 따라 인지능력(cognition)에 차이가 있는가?\n성별에 따라 악력(grip)에 차이가 있는가?\n\ncognition &lt;- cognition |&gt;\n    mutate(sex = factor(sexMW, levels = c(0, 1), labels = c(\"male\", \"female\")))\ncognition |&gt; print()\n\n# A tibble: 550 x 9\n  cog_std grip_std PersonID cognition   age  grip sexMW demgroup sex   \n    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt; \n1 -0.166   -0.0378        1        23  92.6     9     1        1 female\n2 -0.0748   0.633         2        24  91.8    11     0        2 male  \n3  0.380    0.968         3        29  92.6    12     0        1 male  \n4 -0.803   -1.04          4        16  94.4     6     1        1 female\n5  0.198   -0.0378        5        27  85.8     9     1        1 female\n6  1.11     0.633         6        37  83.1    11     0        1 male  \n# i 544 more rows\n\n\n\n\nCode\np1 &lt;- cognition |&gt;\n    ggplot(aes(x = sex, y = cognition)) +\n    geom_jitter(width = .1, alpha = .3) +\n    stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\") +\n    labs(title=\"Cognition predicted by sex\")\n\np2 &lt;- cognition |&gt;\n    ggplot(aes(x = sex, y = cognition)) +\n    geom_boxplot() +\n    stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\")\n\nlibrary(patchwork)\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 &lt;- cognition |&gt;\n    ggplot(aes(x = sex, y = grip)) +\n    geom_jitter(width = .1, alpha = .3) +\n    stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 3) +\n    stat_summary(aes(x = as.numeric(sex)), fun = mean, geom = \"line\", color = \"red\") +\n    labs(title = \"Grip predicted by sex\")\n\np2 &lt;- cognition |&gt;\n    ggplot(aes(x = sex, y = grip)) +\n    geom_boxplot() +\n    stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\")\n\np3 &lt;- cognition |&gt;\n    ggplot(aes(x = grip, color = sex)) +\n    geom_density(alpha = .6, bw = 1.5)\n\nlibrary(patchwork)\np1 + p2 + p3 + plot_layout(nrow = 2)\n\n\n\n\n\n\n\n\n\n성별(sex)로 악력(grip)을 예측하는 모형을 세우면,\n\nlibrary(jtools)\nmod_grip &lt;- lm(grip ~ sex, data = cognition)\nsumm(mod_grip, model.info = FALSE)\n\n\nMODEL FIT:\nF(1,548) = 106.41, p = 0.00\nR&lt;U+00B2&gt; = 0.16\nAdj. R&lt;U+00B2&gt; = 0.16 \nStandard errors: OLS\n------------------------------------------------\n                     Est.   S.E.   t val.      p\n----------------- ------- ------ -------- ------\n(Intercept)         10.55   0.18    58.16   0.00\nsexfemale           -2.44   0.24   -10.32   0.00\n------------------------------------------------\n\n\n\nModel: \\(\\widehat{grip} = -2.44\\cdot sexfemale + 10.55\\)\n우선, 잔차의 합이 0이므로 \\(\\displaystyle \\sum_{i=1}^{n}{(y_i - \\hat{y})} = 0,~~ \\hat{y} = \\frac{\\sum_{i=1}^{n}{y_i}}{n}\\) for each \\(x\\)\n즉, 각 카테고리 값에 대해서 모형은 평균으로 예측\n\n기울기 -2.44는 남성과 여성의 평균 악력 차이를 의미함; 남성(0)에서 여성(1)로 1증가할 때, 악력의 증가량\n절편 10.55는 남성(0)일 때의 평균 악력을 의미함.\n따라서, 여성의 평균 약력은 -2.44 * (1) + 10.55 = 8.11\n\\(R^2\\)= 0.16; 성별로 악력의 변량의 16%를 설명할 수 있음.\n\n\n\n# A tibble: 550 x 5\n    grip sex    sexfemale  pred  resid\n   &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     9 female         1  8.11  0.895\n 2    11 male           0 10.5   0.454\n 3    12 male           0 10.5   1.45 \n 4     6 female         1  8.11 -2.11 \n 5     9 female         1  8.11  0.895\n 6    11 male           0 10.5   0.454\n 7    10 female         1  8.11  1.89 \n 8     9 male           0 10.5  -1.55 \n 9    11 male           0 10.5   0.454\n10    10 male           0 10.5  -0.546\n# i 540 more rows\n\n\n\nanova(mod_grip) |&gt; print()\n\nAnalysis of Variance Table\n\nResponse: grip\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsex         1  794.3  794.33  106.41 &lt; 2.2e-16 ***\nResiduals 548 4090.7    7.46                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\ndummmy coding\n\n\n\nFormula는 factor/카테고리 변수가 predictor인 경우 카테고리 값(levels)들을 수치화해줌.\n여러 방식이 있느나, 기본은 dummy coding으로, 각 카테고리를 0과 1로 표현하며, memership으로 이해하는 것이 적절함.\n그 값을 새로운 변수인 dummy variable/indicator variable로 만드는데, 1에 해당하는 level을 변수명에 표시함.\n예를 들어, 다음과 같이 female에 속하면(membership) 1, female에 속하지 않으면 0\nlibrary(modelr)\nmodel_matrix(cognition, formula = grip ~ sex) |&gt; print()\n# # A tibble: 550 x 2\n#   `(Intercept)` sexfemale\n#           &lt;dbl&gt;     &lt;dbl&gt;\n# 1             1         1\n# 2             1         0\n# 3             1         0\n# 4             1         1\n# 5             1         1\n# 6             1         0\n# # i 544 more rows\nCoding을 어떠한 방식으로 하느냐에 따라 회귀 계수의 의미가 달라짐.\n예를 들어, effect coding의 경우 (female: -1, male: 1)\n\\(\\displaystyle b_0 = \\frac{\\overline{Y}_1 + \\overline{Y}_2}{2},~~ b_1 = \\overline{Y}_1 - \\frac{\\overline{Y}_1 + \\overline{Y}_2}{2}\\)\nSequential coding, Helmert coding, effect coding 등등 여러 다른 coding 방식에 대해서는 책을 참고.\n10.1 Alternative Coding Systems in Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n\n\n\n\n\n\n\n\n두 집단 간 차이: t-test\n\n\n\n전통적으로 카테고리 변수에 대한 분석은 ANOVA 프레임워크에서 실시되었음.\n특히, 위의 경우와 같이 두 집단 간의 차이, 즉 남성과 여성의 약력의 평균 차이를 분석할 때 t-test를 실시.\nt.test(grip ~ sex, data = cognition, var.equal = TRUE)  # varance가 동일하다는 가정\n\n#   Two Sample t-test\n\n# data:  grip by sex\n# t = 10.316, df = 548, p-value &lt; 2.2e-16\n# alternative hypothesis: true difference in means between group male and group female is not equal to 0\n# 95 percent confidence interval:\n#  1.976174 2.905811\n# sample estimates:\n#   mean in group male mean in group female \n#            10.546256             8.105263 \n\n\nFactor의 levels을 formula 안에서 간단히 변경하려면, fct_relevel()\n\nmod_grip2 &lt;- lm(grip ~ fct_relevel(sex, \"female\"), data = cognition)\n# 또는 relevel(sex, ref = \"female\")\n\nmodel_matrix(cognition, mod_grip2) |&gt; print()\n\n# A tibble: 550 x 2\n  `(Intercept)` `relevel(sex, ref = \"female\")male`\n          &lt;dbl&gt;                              &lt;dbl&gt;\n1             1                                  0\n2             1                                  1\n3             1                                  1\n4             1                                  0\n5             1                                  0\n6             1                                  1\n# i 544 more rows",
    "crumbs": [
      "Statistics",
      "Simple Regression"
    ]
  },
  {
    "objectID": "contents/inspection.html",
    "href": "contents/inspection.html",
    "title": "Inspecting",
    "section": "",
    "text": "tibble/dataframe 살펴보기 명령어들\nhead(tibble, 20) tail(tibble, 20) view(tibble) # in tidyverse, R에서는 대문자 View()\nglimpse(tibble) slice(tibble, 5:20) # row numbers\nstr() # structure\n\n\npipe operator 이용\nex. iris2 %&gt;% glimpse() # ctrl + enter"
  },
  {
    "objectID": "contents/copilot.html",
    "href": "contents/copilot.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "acad0 &lt;- read_csv(\"data/c0301dt.csv\")\n\n\nacad0\n\n\nA spec_tbl_df: 15 × 3\n\n\ntime\npubs\nsalary\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n3\n18\n51876\n\n\n6\n3\n54511\n\n\n3\n2\n53425\n\n\n8\n17\n61863\n\n\n⋮\n⋮\n⋮\n\n\n6\n21\n47047\n\n\n7\n10\n39115\n\n\n11\n27\n59677\n\n\n18\n37\n61458\n\n\n\n\n\n\n# create a linear model with time as the predictor time, and the outcome being the salary\n# the model is called mod1\nmod1 &lt;- lm(salary ~ time, data = acad0)\n\n# print the model\nmod1\n\n# print the model summary\nsummary(mod1)\n\n\nCall:\nlm(formula = salary ~ time, data = acad0)\n\nCoefficients:\n(Intercept)         time  \n      43659         1224  \n\n\n\nCall:\nlm(formula = salary ~ time, data = acad0)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13114.3  -3964.4     51.4   4025.1   8409.3 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  43658.6     2978.0  14.660 1.83e-09 ***\ntime          1224.4      336.5   3.639    0.003 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5763 on 13 degrees of freedom\nMultiple R-squared:  0.5046,    Adjusted R-squared:  0.4665 \nF-statistic: 13.24 on 1 and 13 DF,  p-value: 0.003\n\n\n\n# r squared of mod1 and round to 2 decimal places\nround(summary(mod1)$r.squared, 2)\n\n0.5\n\n\n\n# correlation between all variables in acad0 with corr.test\n# corr.test is a function from the psych package\nlibrary(psych)\ncorr.test(acad0)\n\nCall:corr.test(x = acad0)\nCorrelation matrix \n       time pubs salary\ntime   1.00 0.66   0.71\npubs   0.66 1.00   0.59\nsalary 0.71 0.59   1.00\nSample Size \n[1] 15\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n       time pubs salary\ntime   0.00 0.02   0.01\npubs   0.01 0.00   0.02\nsalary 0.00 0.02   0.00\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\n\n# buile a linear model with time an pubs as the predictor and salary as the outcome with interaction terms between time and pubs\nmod2 &lt;- lm(salary ~ time + pubs + time:pubs, data = acad0)\n\n# visualize the interaction between time and pubs\nggplot(acad0, aes(x = time, y = pubs, fill = salary)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  labs(x = \"Time\", y = \"Pubs\", fill = \"Salary\") +\n  theme_minimal()\n\n# visualize the interaction between time and pubs with a package visreg\nlibrary(visreg)\nvisreg(mod2, \"time\", \"pubs\")\n\n# visualize the interaction between time and pubs with a package car using effects function\nlibrary(car)\neffects(mod2, \"time\", \"pubs\")\n\n\n\n\n\n\n\n\nERROR: Error in if (set.sign) {: argument is not interpretable as logical\n\nError in if (set.sign) {: argument is not interpretable as logical\nTraceback:\n\n1. effects(mod2, \"time\", \"pubs\")\n2. effects.lm(mod2, \"time\", \"pubs\")\n\n\n\n\n\n\n\n\n\n\n# regression diagnostics for mod2\nlibrary(car)\n\n# plot the residuals against the fitted values\nplot(mod2)\n\n# plot the residuals against the fitted values with a package car\nlibrary(car)\nresidualPlots(mod2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n           Test stat Pr(&gt;|Test stat|)\ntime         -0.9563           0.3615\npubs          0.6334           0.5407\nTukey test   -1.1784           0.2386\n\n\n\n\n\n\n\n\n\n\nhelping &lt;- read_csv(\"data/altruism.csv\")\n\n\n# summary of helping\nsummary(helping)\n\n       id             pho_1            pho_2            pho_3       \n Min.   :  1.00   Min.   :  0.00   Min.   :  0.00   Min.   :  0.00  \n 1st Qu.: 30.75   1st Qu.: 60.50   1st Qu.: 62.50   1st Qu.: 50.00  \n Median : 60.50   Median : 76.00   Median : 77.00   Median : 66.50  \n Mean   : 60.50   Mean   : 70.89   Mean   : 70.25   Mean   : 61.58  \n 3rd Qu.: 90.25   3rd Qu.: 94.50   3rd Qu.: 91.50   3rd Qu.: 84.25  \n Max.   :120.00   Max.   :100.00   Max.   :100.00   Max.   :100.00  \n                  NA's   :1        NA's   :1        NA's   :2       \n      sex             age           emp_q20          emp_q22      \n Min.   :0.000   Min.   :  203   Min.   :  0.00   Min.   :  6.00  \n 1st Qu.:0.000   1st Qu.: 2003   1st Qu.: 62.50   1st Qu.: 65.25  \n Median :1.000   Median : 2003   Median : 80.00   Median : 80.00  \n Mean   :0.678   Mean   : 2100   Mean   : 78.24   Mean   : 78.27  \n 3rd Qu.:1.000   3rd Qu.: 2004   3rd Qu.: 91.50   3rd Qu.: 93.00  \n Max.   :1.000   Max.   :20004   Max.   :100.00   Max.   :100.00  \n NA's   :2       NA's   :3       NA's   :1        NA's   :2       \n    emp_q23          emp_q24          emp_q25          emp_q26     \n Min.   :  0.00   Min.   :  0.00   Min.   :  4.00   Min.   :  2.0  \n 1st Qu.: 56.50   1st Qu.: 60.00   1st Qu.: 64.50   1st Qu.: 59.5  \n Median : 70.00   Median : 71.00   Median : 74.00   Median : 75.0  \n Mean   : 67.49   Mean   : 73.98   Mean   : 74.46   Mean   : 73.5  \n 3rd Qu.: 85.00   3rd Qu.: 90.50   3rd Qu.: 88.00   3rd Qu.: 91.0  \n Max.   :100.00   Max.   :100.00   Max.   :100.00   Max.   :100.0  \n NA's   :1        NA's   :1        NA's   :1        NA's   :1      \n\n\n\n# rename the column pho_1 to pho1, pho_2 to pho2, pho_3 to pho3\nhelping &lt;- helping %&gt;% rename(pho1 = pho_1, pho2 = pho_2, pho3 = pho_3)\n\n# add a column pho to helping that is the average of pho1, pho2, and pho3 with na.rm = TRUE\nhelping &lt;- helping %&gt;% mutate(pho = mean(c(pho1, pho2, pho3), na.rm = TRUE))\n\n\nhelping[\"pho_mean2\"] &lt;- rowMeans(helping[, c(\"pho1\", \"pho2\", \"pho3\")], na.rm = TRUE)\nhelping\n\n\nA tibble: 120 × 14\n\n\nid\npho1\npho2\npho3\nsex\nage\nemp_q20\nemp_q22\nemp_q23\nemp_q24\nemp_q25\nemp_q26\npho\npho_mean2\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n95\n95\n95\n1\n2004\n80\nNA\n80\n80\n70\n70\n67.58989\n95.00000\n\n\n2\n58\n62\nNA\n0\n2003\n62\n58\n59\n57\n56\n59\n67.58989\n60.00000\n\n\n3\n100\n50\n50\nNA\n2003\n90\n51\n51\n51\n52\n100\n67.58989\n66.66667\n\n\n4\n77\n77\n64\n1\n2004\n66\n72\n88\n82\n67\n69\n67.58989\n72.66667\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n117\n50\n50\n76\n0\n2003\n52\n100\n0\n26\n48\n45\n67.58989\n58.66667\n\n\n118\n92\n76\n94\n0\n1108\n55\n51\n51\n60\n53\n64\n67.58989\n87.33333\n\n\n119\n100\n100\n100\n0\n2004\n68\n75\n55\n72\n75\n63\n67.58989\n100.00000\n\n\n120\n60\n78\n26\n0\n2004\n86\n50\n5\n50\n100\n90\n67.58989\n54.66667\n\n\n\n\n\n\nhelping[\"pho_mean3\"] &lt;-    # \"phone\"이라는 새로운 변수에 assign!\n  helping |&gt;\n  select(pho1:pho3) |&gt;\n  rowMeans(na.rm = TRUE)\n\n\nhelping\n\n\nA tibble: 120 × 15\n\n\nid\npho1\npho2\npho3\nsex\nage\nemp_q20\nemp_q22\nemp_q23\nemp_q24\nemp_q25\nemp_q26\npho\npho_mean2\npho_mean3\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n95\n95\n95\n1\n2004\n80\nNA\n80\n80\n70\n70\n67.58989\n95.00000\n95.00000\n\n\n2\n58\n62\nNA\n0\n2003\n62\n58\n59\n57\n56\n59\n67.58989\n60.00000\n60.00000\n\n\n3\n100\n50\n50\nNA\n2003\n90\n51\n51\n51\n52\n100\n67.58989\n66.66667\n66.66667\n\n\n4\n77\n77\n64\n1\n2004\n66\n72\n88\n82\n67\n69\n67.58989\n72.66667\n72.66667\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n117\n50\n50\n76\n0\n2003\n52\n100\n0\n26\n48\n45\n67.58989\n58.66667\n58.66667\n\n\n118\n92\n76\n94\n0\n1108\n55\n51\n51\n60\n53\n64\n67.58989\n87.33333\n87.33333\n\n\n119\n100\n100\n100\n0\n2004\n68\n75\n55\n72\n75\n63\n67.58989\n100.00000\n100.00000\n\n\n120\n60\n78\n26\n0\n2004\n86\n50\n5\n50\n100\n90\n67.58989\n54.66667\n54.66667\n\n\n\n\n\n\n# load a dataset penguins from the palmerpenguins package\nlibrary(palmerpenguins)\n\n# print the first 6 rows of penguins\nhead(penguins)\n\n\nA tibble: 6 × 8\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;fct&gt;\n&lt;int&gt;\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\n# draw a scatterplot of flipper length and body mass with penguins with a facet wrap of species, with a number of columns of 2\npenguins %&gt;% ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + geom_point() + facet_wrap(~species, ncol = 2)\n\n\n\n\n\n\n\n\n\n# Tukey's multiple comparison test of flipper length between species\nTukeyHSD(aov(flipper_length_mm ~ species, data = penguins))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = flipper_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr       upr p adj\nChinstrap-Adelie  5.869887  3.586583  8.153191     0\nGentoo-Adelie    27.233349 25.334376 29.132323     0\nGentoo-Chinstrap 21.363462 19.000841 23.726084     0\n\n\n\n# Tukey's multiple comparison test of flipper length between species using multicomp package, glht function\nlibrary(multcomp)\nglht(aov(flipper_length_mm ~ species, data = penguins), linfct = mcp(species = \"Tukey\"))\n\n# summary of the Tukey's multiple comparison test of flipper length between species using multicomp package, glht function\nsummary(glht(aov(flipper_length_mm ~ species, data = penguins), linfct = mcp(species = \"Tukey\")))\n\n# Tukey's multiple comparison test of flipper length between species using emmeans package\nlibrary(emmeans)\nemmeans(aov(flipper_length_mm ~ species, data = penguins), \"species\")\n\n\n\n     General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nLinear Hypotheses:\n                        Estimate\nChinstrap - Adelie == 0     5.87\nGentoo - Adelie == 0       27.23\nGentoo - Chinstrap == 0    21.36\n\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = flipper_length_mm ~ species, data = penguins)\n\nLinear Hypotheses:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \nChinstrap - Adelie == 0   5.8699     0.9699   6.052 1.06e-08 ***\nGentoo - Adelie == 0     27.2333     0.8067  33.760  &lt; 1e-08 ***\nGentoo - Chinstrap == 0  21.3635     1.0036  21.286  &lt; 1e-08 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n(Adjusted p values reported -- single-step method)\n\n\n species   emmean    SE  df lower.CL upper.CL\n Adelie       190 0.540 339      189      191\n Chinstrap    196 0.805 339      194      197\n Gentoo       217 0.599 339      216      218\n\nConfidence level used: 0.95 \n\n\n\n# import the data from the file \"data/students-shorter.sav\" using haven package\nlibrary(haven)\nstudents &lt;- read_spss(\"data/students-shorter.sav\")\n\n# print the first 6 rows of students\nhead(students)\n\n\nA tibble: 6 × 93\n\n\nstu_id\nsch_id\nsstratid\nsex\nrace\nethnic\nbys42a\nbys42b\nbys44a\nbys44b\n⋯\nf1s83\nffugrad\nf1cncpt1\nf1cncpt2\nf1locus1\nf1locus2\nf1txrstd\nf1txmstd\nf1txsstd\nf1txhstd\n\n\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n⋯\n&lt;dbl+lbl&gt;\n&lt;dbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n&lt;dbl+lbl&gt;\n\n\n\n\n124966\n1249\n1\n2\n4\n1\n3\n4\n2\n4\n⋯\n3\n5.25\n-0.33\n-0.10\n0.03\n-0.14\n48.29\n63.61\n57.73\n61.71\n\n\n124972\n1249\n1\n1\n4\n1\n4\n5\n1\n3\n⋯\n3\n3.00\n-0.33\n-0.45\n-0.43\n-0.58\n36.05\n47.65\n53.36\n46.98\n\n\n175551\n1755\n1\n2\n3\n0\nNA\n3\n2\n3\n⋯\n2\n2.50\n0.42\n0.33\n-0.45\n-0.59\n55.13\n43.44\n46.39\n50.48\n\n\n180660\n1806\n1\n1\n4\n1\n2\nNA\n1\n4\n⋯\n2\n6.50\n0.43\n-0.02\n0.03\n0.07\n42.54\n56.19\n40.14\n56.48\n\n\n180672\n1806\n1\n2\n4\n1\n2\n3\n1\n4\n⋯\n2\n4.25\n0.02\n-0.09\n-0.88\n-0.85\n52.96\n47.36\n46.01\n55.32\n\n\n298885\n2988\n2\n1\n3\n0\n5\n4\n2\n3\n⋯\n2\n6.00\n-0.33\n-0.28\n0.03\n0.07\n44.24\n45.25\n41.88\n39.67"
  },
  {
    "objectID": "contents/categories.html",
    "href": "contents/categories.html",
    "title": "Categorical IVs",
    "section": "",
    "text": "Let us consider a fictitious investigation of background factors and altruism. The researchers have hypothesized that there are influences of population density on altruism, and have drawn samples of residents of a city and the surrounding area outside the city (noncity). (p. 344)"
  },
  {
    "objectID": "contents/analysis1.html",
    "href": "contents/analysis1.html",
    "title": "Analysis I",
    "section": "",
    "text": "helping &lt;- read_csv(\"data/altruism_full.csv\")\n\n\nhelping &lt;- helping |&gt;\n    mutate(\n        status = factor(status, levels = c(\"low\", \"high\")),\n        sex = factor(sex)\n    )\n\nhelping |&gt; print()\n\n# A tibble: 168 × 6\n     id status sex    empathy public_sc helping\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     1 high   female    58.1      88.3   33.8 \n2     2 low    female    43.9      29.8   63.8 \n3     3 low    female    76.8      80     61.0 \n4     6 high   male      42.6      45.2    1.23\n5     8 low    male      80.6      52     20.8 \n6     9 high   male      44.2      69.2    7.61\n# … with 162 more rows\n\n\n\nsummary(mod &lt;- lm(helping ~ public_sc * status + empathy, data = helping))\n\n\nCall:\nlm(formula = helping ~ public_sc * status + empathy, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.117 -14.950  -1.137  15.982  48.022 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -0.3143    11.9954  -0.026  0.97913    \npublic_sc             -0.2133     0.1689  -1.263  0.20849    \nstatushigh           -40.9460    17.0374  -2.403  0.01737 *  \nempathy                0.7392     0.1510   4.895 2.35e-06 ***\npublic_sc:statushigh   0.6423     0.2203   2.916  0.00405 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.68 on 163 degrees of freedom\nMultiple R-squared:  0.293, Adjusted R-squared:  0.2756 \nF-statistic: 16.88 on 4 and 163 DF,  p-value: 1.335e-11\n\n\n\nsummary(mod &lt;- lm(helping ~ scale(public_sc) * status + empathy, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(public_sc) * status + empathy, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.117 -14.950  -1.137  15.982  48.022 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 -16.3357    11.1328  -1.467  0.14421    \nscale(public_sc)             -3.4988     2.7708  -1.263  0.20849    \nstatushigh                    7.3082     3.5847   2.039  0.04310 *  \nempathy                       0.7392     0.1510   4.895 2.35e-06 ***\nscale(public_sc):statushigh  10.5379     3.6139   2.916  0.00405 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.68 on 163 degrees of freedom\nMultiple R-squared:  0.293, Adjusted R-squared:  0.2756 \nF-statistic: 16.88 on 4 and 163 DF,  p-value: 1.335e-11\n\n\n\nlibrary(car)\navPlots(mod)\n\n\n\n\n\n\n\n\n\nsummary(lm(scale(helping) ~ status, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ status, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.73766 -0.70655 -0.09683  0.73752  1.98321 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  -0.1922     0.1041  -1.846  0.06662 . \nstatushigh    0.4086     0.1518   2.692  0.00782 **\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.9818 on 166 degrees of freedom\nMultiple R-squared:  0.04184,   Adjusted R-squared:  0.03607 \nF-statistic:  7.25 on 1 and 166 DF,  p-value: 0.007819\n\n\n\nsummary(lm(scale(helping) ~ empathy, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ empathy, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01691 -0.65267 -0.03413  0.62921  2.02464 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.296418   0.329699  -6.965 7.31e-11 ***\nempathy      0.031909   0.004484   7.117 3.16e-11 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.878 on 166 degrees of freedom\nMultiple R-squared:  0.2338,    Adjusted R-squared:  0.2292 \nF-statistic: 50.65 on 1 and 166 DF,  p-value: 3.158e-11\n\n\n\nsummary(lm(scale(helping) ~ empathy + status, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ empathy + status, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.13949 -0.61254 -0.07061  0.60338  1.99294 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.349779   0.326929  -7.187 2.17e-11 ***\nempathy      0.030721   0.004467   6.878 1.20e-10 ***\nstatushigh   0.295364   0.135204   2.185   0.0303 *  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.8682 on 165 degrees of freedom\nMultiple R-squared:  0.2553,    Adjusted R-squared:  0.2463 \nF-statistic: 28.29 on 2 and 165 DF,  p-value: 2.735e-11\n\n\n\nsummary(mod2 &lt;- lm(helping ~ scale(public_sc) * status, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(public_sc) * status, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.885 -16.726  -0.607  17.828  52.431 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  43.864      2.793  15.703  &lt; 2e-16 ***\nscale(public_sc)             15.077      2.824   5.339 3.07e-07 ***\nstatuslow                    -7.042      3.827  -1.840  0.06757 .  \nscale(public_sc):statuslow  -12.154      3.842  -3.163  0.00186 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 24.22 on 164 degrees of freedom\nMultiple R-squared:  0.189, Adjusted R-squared:  0.1742 \nF-statistic: 12.74 on 3 and 164 DF,  p-value: 1.581e-07\n\n\n\nanova(mod2, mod) |&gt; print()\n\nAnalysis of Variance Table\n\nModel 1: helping ~ scale(public_sc) * status\nModel 2: helping ~ scale(public_sc) * status + empathy\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    164 96189                                 \n2    163 83862  1     12327 23.96 2.348e-06 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n\n\nhelping |&gt;\n    ggplot(aes(x = public_sc, y = helping, color = status)) +\n    geom_point() +\n    geom_smooth(method = lm) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\nlibrary(psych)\n# R squared\ncorr.test(helping |&gt; select(empathy:helping))$r^2 |&gt;\n    round(2) |&gt;\n    print()\n\n          empathy public_sc helping\nempathy      1.00      0.41    0.23\npublic_sc    0.41      1.00    0.12\nhelping      0.23      0.12    1.00\n\n\n\nsummary(lm(helping ~ scale(empathy) * scale(public_sc), data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(empathy) * scale(public_sc), data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.326 -16.613  -0.074  16.524  53.692 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       39.644      2.070  19.151  &lt; 2e-16 ***\nscale(empathy)                    12.013      2.346   5.121 8.42e-07 ***\nscale(public_sc)                   2.301      2.361   0.975   0.3312    \nscale(empathy):scale(public_sc)    2.735      1.620   1.688   0.0932 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 23.3 on 164 degrees of freedom\nMultiple R-squared:  0.2495,    Adjusted R-squared:  0.2358 \nF-statistic: 18.17 on 3 and 164 DF,  p-value: 3.138e-10\n\n\n\nsummary(lm(helping ~ scale(empathy) * scale(public_sc) + scale(public_sc) * status, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(empathy) * scale(public_sc) + scale(public_sc) * \n    status, data = helping)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-66.40 -14.81  -1.10  16.81  48.70 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       43.100      2.853  15.109  &lt; 2e-16 ***\nscale(empathy)                    11.387      2.298   4.956  1.8e-06 ***\nscale(public_sc)                   6.951      3.116   2.231  0.02706 *  \nstatuslow                         -6.980      3.603  -1.937  0.05445 .  \nscale(empathy):scale(public_sc)    1.531      1.621   0.944  0.34637    \nscale(public_sc):statuslow        -9.815      3.695  -2.656  0.00869 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.69 on 162 degrees of freedom\nMultiple R-squared:  0.2968,    Adjusted R-squared:  0.2751 \nF-statistic: 13.68 on 5 and 162 DF,  p-value: 3.876e-11\n\n\n\nsummary(lm(helping ~ status, data = helping))\n\n\nCall:\nlm(formula = helping ~ status, data = helping)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-46.31 -18.83  -2.58  19.66  52.85 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   47.147      2.944  16.016  &lt; 2e-16 ***\nstatuslow    -10.890      4.045  -2.692  0.00782 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 26.17 on 166 degrees of freedom\nMultiple R-squared:  0.04184,   Adjusted R-squared:  0.03607 \nF-statistic:  7.25 on 1 and 166 DF,  p-value: 0.007819"
  },
  {
    "objectID": "contents/test.html",
    "href": "contents/test.html",
    "title": "Case Study tp",
    "section": "",
    "text": "Source: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels &lt;- read_csv(\"data/nels88_sample.csv\")\nnels &lt;- nels |&gt; \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# summarize data\nsummary(nels)\n\n# count values\nnels |&gt; count(pared)\nnels |&gt; count(hw_out)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines &lt;- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 &lt;- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)"
  },
  {
    "objectID": "contents/test.html#national-education-longitudinal-study-of-1988-nels88",
    "href": "contents/test.html#national-education-longitudinal-study-of-1988-nels88",
    "title": "Case Study tp",
    "section": "",
    "text": "Source: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels &lt;- read_csv(\"data/nels88_sample.csv\")\nnels &lt;- nels |&gt; \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# summarize data\nsummary(nels)\n\n# count values\nnels |&gt; count(pared)\nnels |&gt; count(hw_out)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines &lt;- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 &lt;- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)"
  },
  {
    "objectID": "contents/pollr.html",
    "href": "contents/pollr.html",
    "title": "설문",
    "section": "",
    "text": "설문 링크"
  },
  {
    "objectID": "contents/interaction.html",
    "href": "contents/interaction.html",
    "title": "Interaction Effects",
    "section": "",
    "text": "기존 선형모형에서는 각 예측변수들이 additive하게 종속변수에 영향을 미친다고 가정함.\n\\(\\hat{Y} = b_0 + b_1X_1 + b_2X_2 + \\cdots + b_kX_k\\)\n만약, 두 개 이상이 예측변수들이 일종의 시너지 효과와 같이 additive한 효과를 넘어서서 작용한다면,\n그 효과를 잡아낼 수 있도록 모형을 변형해야 함.",
    "crumbs": [
      "Statistics",
      "Interactions"
    ]
  },
  {
    "objectID": "contents/interaction.html#continuous-vs.-continuous",
    "href": "contents/interaction.html#continuous-vs.-continuous",
    "title": "Interaction Effects",
    "section": "Continuous vs. Continuous",
    "text": "Continuous vs. Continuous\n\n예제 1\n나이가 듦(age)에 따른 지구력(endurance)의 감소가 운동을 한 기간(exercise)에 따라 변화하는가? (p.275)\nendurance: the number of minutes of sustained jogging on a treadmill\nexercise: the number of years of vigorous physical exercise\n\n\n연구자의 관심변수에 따라 다르게 표현될 수 있음.\n나이가 지구력에 미치는 부정적 영향을 운동이 완화시키는지 관심; 보효요인 (protective factor) &lt;-&gt; 위험요인 (risk factor)\n이 때, 운동 기간을 moderator (조절변수)라고 말하고, 그 moderating effect (조절효과)를 가지는지 검증.\n통계적으로는 나이과 운동기간이 서로 상호작용(interact)하여 지구력에 영향을 미치는 것으로 나타남.\n\nData: c07e01dt\nacad2 &lt;- read_csv('cohen/data/c07e01dt.csv')\nacad2\nlowerCor(acad2)  # library(psych)\n\n\n\n\n# A tibble: 245 × 3\n     age exercise endurance\n   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1    60       10        18\n 2    40        9        36\n 3    29        2        51\n 4    47       10        18\n 5    48        9        23\n 6    42        6        30\n 7    55        8         8\n 8    43       19        40\n 9    39        9        28\n10    51       14        15\n# ℹ 235 more rows\n\n\n\n\n          age   exrcs endrn\nage        1.00            \nexercise   0.28  1.00      \nendurance -0.13  0.34  1.00\n\n\n\n\nacad2 %&gt;% \n  ggplot(aes(x = age, y = endurance)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\nacad2 %&gt;% \n  ggplot(aes(x = exercise, y = endurance)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n나이와 지구력의 관계가 운동기간에 따라 다른가를 보기 위해, 운동기간을 3구간으로 나눔.\n\n# 편의상 운동기간을 3구간으로 나눔\nacad2 %&gt;% \n  mutate(exercise_cat = cut_number(exercise, 3)) %&gt;% \n  ggplot(aes(x = age, y = endurance, color = exercise_cat)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) +\n  facet_wrap(~exercise_cat)\n\n\n\n\n\n\n\n# 편의상 나이를 3구간으로 나눔\nacad2 %&gt;% \n  mutate(age_cat = cut_number(age, 3)) %&gt;% \n  ggplot(aes(x = exercise, y = endurance, color = age_cat)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) +\n  facet_wrap(~age_cat)\n\n\n\n\n\n\n\n\n두 변수, 나이와 운동기간으로 지구력을 예측하는 모형을 세우면,\n\nmod_s1 &lt;- lm(endurance ~ age, data = acad2)\nmod_s2 &lt;- lm(endurance ~ exercise, data = acad2)\nmod &lt;- lm(endurance ~ age + exercise, data = acad2)\n\nexport_summs(mod_s1, mod_s2, mod)\n\n\n\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)33.16 ***18.39 ***29.40 ***\n\n(3.42)   (1.60)   (3.21)   \n\nage-0.13 *         -0.26 ***\n\n(0.07)          (0.07)   \n\nexercise       0.76 ***0.92 ***\n\n       (0.14)   (0.14)   \n\nN245       245       245       \n\nR20.02    0.11    0.17    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\n\nInteraction term을 추가해서 모형을 세우면\n\\(\\displaystyle \\widehat{endurance} = b_1\\cdot age + b_2\\cdot exercise + b_3\\cdot age \\cdot exercise + b_0\\)\n      \\(\\displaystyle = (b_1 + b_3 \\cdot exercise)\\cdot age + b_2\\cdot exercise + b_0\\)\n이제 age의 기울기가 exercise의 값에 따라 변할 수 있음.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmod_interact &lt;- lm(endurance ~ age * exercise, data = acad2)  \n# 동일: endurance ~ age + exercise + age:exercise\nS(mod_interact) # library(car)\n\nCall: lm(formula = endurance ~ age * exercise, data = acad2)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  53.17896    7.52661   7.065 1.71e-11 ***\nage          -0.76596    0.15980  -4.793 2.87e-06 ***\nexercise     -1.35095    0.66626  -2.028 0.043694 *  \nage:exercise  0.04724    0.01359   3.476 0.000604 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.7 on 241 degrees of freedom\nMultiple R-squared: 0.2061\nF-statistic: 20.86 on 3 and 241 DF,  p-value: 4.764e-12 \n    AIC     BIC \n1814.57 1832.07 \n\n\n\\(\\displaystyle \\widehat{endurance} = -0.766\\cdot age -1.350\\cdot exercise + 0.047\\cdot age \\cdot exercise + 53.18\\)\n      \\(\\displaystyle = (-0.766 + 0.047 \\cdot exercise)\\cdot age -1.350\\cdot exercise + 53.18\\)\n\nage의 기울기는 exercise의 값에 따라 변함\n운동기간이 0년인 경우, 지구력에 미치는 나이의 효과: \\((-0.766+0.047*0)\\cdot age = -0.766\\cdot age\\)\n운동기간이 10년인 경우, 지구력에 미치는 나이의 효과: \\((-0.766+0.047*10)\\cdot age = -0.30\\cdot age\\)\n\n각 회귀계수의 의미는 다른 변수의 값이 0일 때의 기울기/효과임\n\nage: -0.766은 운동기간이 0년일 때의 나이의 효과\nexercise: -1.350은 나이가 0살일 때의 운동기간의 효과\nage:exercise: 0.047는 두 변수의 joint effect\n절편 53.18: 운동기간이 0년인 0세의 지구력\n\n회귀계수를 용이하게 해석하기 위해 변수를 centering하거나 standardizing하는 것이 좋음.\n\n0의 의미가 있는 특별한 경우가 아니면 centering을 기본적으로 함.\n예를 들어, 언어발달 ~ 나이 * 형제자매 수 + 부모의 교육수준\n\n형제자매의 수 0은 의미가 있음.\n\n위의 경우 age와 exercise의 단위가 의미가 있으므로, 표준화보다는 centering\np-value들은 모두 바뀐 의미의 회귀계수에 대한 영가설 검정\n\n\n\n\n\n\n\nImportant\n\n\n\n기존의 additive한 모형에서의 해석을 그대로 적용하면 안됨.\n\\(\\displaystyle \\widehat{endurance} = b_0 + b_1\\cdot age + b_2 \\cdot exercise + b_3 \\cdot age \\cdot exercise\\)\n\nage의 효과는 exercise가 고정되었을 때의 효과가 아님! (hold it constant, control for it)\n다른 변수를 특정 값에 고정했을 때의 조건부 효과라고 해석할 수 있음.\n여기서 \\(b_1\\)은 exercise가 0일 때의 age의 효과라고 말할 수 있음.\n\n\n\n\n# jtools의 center()함수를 이용하거나 데이터셋에서 미리 변환\nmod_interact_c &lt;- lm(endurance ~ center(age) * center(exercise), data = acad2)\nS(mod_interact_c)\n\nCall: lm(formula = endurance ~ center(age) * center(exercise), data = acad2)\n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  25.88872    0.64662  40.037  &lt; 2e-16 ***\ncenter(age)                  -0.26169    0.06406  -4.085 6.01e-05 ***\ncenter(exercise)              0.97272    0.13653   7.124 1.20e-11 ***\ncenter(age):center(exercise)  0.04724    0.01359   3.476 0.000604 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.7 on 241 degrees of freedom\nMultiple R-squared: 0.2061\nF-statistic: 20.86 on 3 and 241 DF,  p-value: 4.764e-12 \n    AIC     BIC \n1814.57 1832.07 \n\n\n\n나이에 대한 회귀계수 -0.26: 운동기간이 평균(10.67년)일 때의 나이의 효과\n운동기간에 대한 회귀계수 0.97: 나이가 평균(49.18세)일 때의 운동기간의 효과\n\n\npsych::describe(acad2)\n\n          vars   n  mean    sd median trimmed   mad min max range skew kurtosis\nage          1 245 49.18 10.11     48   49.11 10.38  20  82    62 0.15    -0.08\nexercise     2 245 10.67  4.78     11   10.56  4.45   0  26    26 0.27     0.23\nendurance    3 245 26.53 10.82     27   26.39 10.38   0  55    55 0.11    -0.30\n            se\nage       0.65\nexercise  0.31\nendurance 0.69\n\n\n\nlibrary(effects)\n# plot(predictorEffect(\"age\", mod_interact, xlevels = 3)) 또는\nplot(predictorEffects(mod_interact, ~age, xlevels = 3))  # centering하지 않은 모형\n\n\n\n\n\n\n\n\n확인하고자 하는 값들을 대입할 수 있음; 보통 평균과에서 +1, -1 표준편차 만큼의 값을 대입함.\n\nm &lt;- mean(acad2$exercise, na.rm = TRUE) |&gt; round(2)\nsd &lt;- sd(acad2$exercise, na.rm = TRUE) |&gt; round(2)\n\nplot(predictorEffects(mod_interact, ~age, xlevels = list(exercise = c(m-sd, m, m+sd))))\n\n\n\n\n\n\n\n\n평균보다 1 표준편차 만큼 오래 운동한 경우: m + 1sd = 10.67 + 4.78 = 15.45년\n\n나이에 따른 지구력 감소가 거의 없는가?\n\n\nmod_interact_t &lt;- lm(endurance ~ age * I(exercise - 15.45), data = acad2)\nS(mod_interact_t)\n\nCall: lm(formula = endurance ~ age * I(exercise - 15.45), data = acad2)\n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             32.30671    4.72744   6.834 6.71e-11 ***\nage                     -0.03602    0.09027  -0.399 0.690184    \nI(exercise - 15.45)     -1.35095    0.66626  -2.028 0.043694 *  \nage:I(exercise - 15.45)  0.04724    0.01359   3.476 0.000604 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.7 on 241 degrees of freedom\nMultiple R-squared: 0.2061\nF-statistic: 20.86 on 3 and 241 DF,  p-value: 4.764e-12 \n    AIC     BIC \n1814.57 1832.07 \n\n\n가설 검정(p-value)보다는 신뢰구간(confidence interval)을 보는 것을 항상 권장함.\n\nR의 confint()나 car 패키지의 Confint() 함수를 이용\njtools에서 summ(mod, confint = TRUE)\n\n\nConfint(mod_interact_t) |&gt; print(digits = 2)  # car 패키지\n\n                        Estimate 2.5 % 97.5 %\n(Intercept)               32.307 22.99 41.619\nage                       -0.036 -0.21  0.142\nI(exercise - 15.45)       -1.351 -2.66 -0.039\nage:I(exercise - 15.45)    0.047  0.02  0.074\n\n\n모든 moderator의 값에 대한 통계적 유의도를 계산\n\n# Johnson-Neyman intervals \nlibrary(interactions)\njohnson_neyman(mod_interact, pred = \"age\", modx = \"exercise\")\n\nJOHNSON-NEYMAN INTERVAL\n\nWhen exercise is OUTSIDE the interval [13.21, 24.37], the slope of age is p\n&lt; .05.\n\nNote: The range of observed values of exercise is [0.00, 26.00]\n\n\n\n\n\n\n\n\n\n회귀모형에 대한 진단\n\navPlots(mod_interact_c, id=list(n=3))\n\n\n\n\n\n\n\nmod_interact_update &lt;- update(mod_interact_c, subset = -c(3, 34)) # 3, 34번째 관측치 제거\navPlots(mod_interact_update)\n\n\n\n\n\n\n\nS(mod_interact_update)\n\nCall: lm(formula = endurance ~ center(age) * center(exercise), data = acad2,\n         subset = -c(3, 34))\n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  25.88331    0.63738  40.609  &lt; 2e-16 ***\ncenter(age)                  -0.25750    0.06371  -4.041 7.17e-05 ***\ncenter(exercise)              0.95987    0.13561   7.078 1.61e-11 ***\ncenter(age):center(exercise)  0.03482    0.01402   2.483   0.0137 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.561 on 239 degrees of freedom\nMultiple R-squared: 0.195\nF-statistic:  19.3 on 3 and 239 DF,  p-value: 3.063e-11 \n    AIC     BIC \n1792.81 1810.27 \n\n\n상호작용 효과의 크기\n\n상호작용 항이 추가된 모형과 추가되지 않은 모형을 비교\n\\(\\Delta R^2 = R^2_{full} - R^2_{reduced} = 0.21 - 0.17 = 0.04\\)\n상호작용이 추가된 모형이 4%의 추가적인 설명력을 가짐.\n이 크기에 대한 가설 검정은 상호작용항의 회귀계수에 대한 검정과 동일; 함수 anova()이용\n\n\nmod &lt;- lm(endurance ~ age + exercise, data = acad2)\nmod_interact &lt;- lm(endurance ~ age * exercise, data = acad2)\n\nexport_summs(mod, mod_interact, error_format = \"({p.value})\", number_format = \"%.4f\")\n\n\n\n\n\n\nModel 1Model 2\n\n(Intercept)29.3952 ***53.1790 ***\n\n(0.0000)   (0.0000)   \n\nage-0.2571 ***-0.7660 ***\n\n(0.0001)   (0.0000)   \n\nexercise0.9163 ***-1.3510 *  \n\n(0.0000)   (0.0437)   \n\nage:exercise         0.0472 ***\n\n         (0.0006)   \n\nN245         245         \n\nR20.1663    0.2061    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\n\n\nanova(mod, mod_interact)\n\nAnalysis of Variance Table\n\nModel 1: endurance ~ age + exercise\nModel 2: endurance ~ age * exercise\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    242 23810                                 \n2    241 22674  1    1136.5 12.08 0.0006042 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nHayes의 PROCESS 매크로\n\n\n\n\n\nModel 1\n\n디폴트로 moderator의 16th, 50th, 84th 세 값에 대한 조건부 효과를 계산\nmoments=1: moderator의 mean, mean+sd, mean-sd 세 값에 대한 조건부 효과를 계산\nwmodval=c(a, b, c)는 moderator 값이 a, b, c일 때의 조건부 효과를 계산\njn=1: Johnson-Neyman interval 계산\ncenter=1: centering\n\n\nprocess(data=acad2, y=\"endurance\", x=\"age\", w=\"exercise\", model=1, center=1, jn=1)\n\n# ********************* PROCESS for R Version 4.3.1 ********************* \n \n#            Written by Andrew F. Hayes, Ph.D.  www.afhayes.com              \n#    Documentation available in Hayes (2022). www.guilford.com/p/hayes3   \n \n# *********************************************************************** \n                 \n# Model : 1        \n#     Y : endurance\n#     X : age      \n#     W : exercise \n\n# Sample size: 245\n\n\n# *********************************************************************** \n# Outcome Variable: endurance\n\n# Model Summary: \n#           R      R-sq       MSE         F       df1       df2         p\n#      0.4540    0.2061   94.0821   20.8585    3.0000  241.0000    0.0000\n\n# Model: \n#              coeff        se         t         p      LLCI      ULCI\n# constant   25.8887    0.6466   40.0371    0.0000   24.6150   27.1625\n# age        -0.2617    0.0641   -4.0848    0.0001   -0.3879   -0.1355\n# exercise    0.9727    0.1365    7.1244    0.0000    0.7038    1.2417\n# Int_1       0.0472    0.0136    3.4757    0.0006    0.0205    0.0740\n\n# Product terms key:\n# Int_1  :  age  x  exercise      \n\n# Test(s) of highest order unconditional interaction(s):\n#       R2-chng         F       df1       df2         p\n# X*W    0.0398   12.0804    1.0000  241.0000    0.0006\n# ----------\n# Focal predictor: age (X)\n#       Moderator: exercise (W)\n\n# Conditional effects of the focal predictor at values of the moderator(s):\n#    exercise    effect        se         t         p      LLCI      ULCI\n#     -4.6735   -0.4825    0.0911   -5.2935    0.0000   -0.6620   -0.3029\n#      0.3265   -0.2463    0.0641   -3.8403    0.0002   -0.3726   -0.1199\n#      4.3265   -0.0573    0.0861   -0.6656    0.5063   -0.2268    0.1123\n\n# Moderator value(s) defining Johnson-Neyman significance region(s):\n#       Value   % below   % above\n#      2.5328   73.8776   26.1224\n#     13.6954   99.1837    0.8163\n\n# Conditional effect of focal predictor at values of the moderator:\n#    exercise    effect        se         t         p      LLCI      ULCI\n#    -10.6735   -0.7660    0.1598   -4.7931    0.0000   -1.0807   -0.4512\n#     -9.3050   -0.7013    0.1430   -4.9057    0.0000   -0.9829   -0.4197\n#     -7.9366   -0.6367    0.1266   -5.0288    0.0000   -0.8860   -0.3873\n#     -6.5682   -0.5720    0.1110   -5.1552    0.0000   -0.7906   -0.3534\n#     -5.1998   -0.5074    0.0964   -5.2647    0.0000   -0.6972   -0.3175\n#     -3.8314   -0.4427    0.0834   -5.3087    0.0000   -0.6070   -0.2784\n#     -2.4629   -0.3781    0.0729   -5.1863    0.0000   -0.5216   -0.2345\n#     -1.0945   -0.3134    0.0661   -4.7437    0.0000   -0.4435   -0.1833\n#      0.2739   -0.2487    0.0641   -3.8809    0.0001   -0.3750   -0.1225\n#      1.6423   -0.1841    0.0674   -2.7312    0.0068   -0.3169   -0.0513\n#      2.5328   -0.1420    0.0721   -1.9699    0.0500   -0.2841    0.0000\n#      3.0107   -0.1194    0.0753   -1.5862    0.1140   -0.2678    0.0289\n#      4.3792   -0.0548    0.0865   -0.6332    0.5272   -0.2253    0.1157\n#      5.7476    0.0099    0.1000    0.0985    0.9216   -0.1871    0.2069\n#      7.1160    0.0745    0.1149    0.6484    0.5174   -0.1519    0.3009\n#      8.4844    0.1392    0.1308    1.0641    0.2883   -0.1184    0.3967\n#      9.8528    0.2038    0.1473    1.3839    0.1677   -0.0863    0.4939\n#     11.2213    0.2685    0.1642    1.6348    0.1034   -0.0550    0.5919\n#     12.5897    0.3331    0.1815    1.8354    0.0677   -0.0244    0.6906\n#     13.6954    0.3853    0.1956    1.9699    0.0500    0.0000    0.7707\n#     13.9581    0.3978    0.1990    1.9988    0.0468    0.0058    0.7898\n#     15.3265    0.4624    0.2167    2.1339    0.0339    0.0356    0.8893\n\n# ******************** ANALYSIS NOTES AND ERRORS ************************ \n\n# Level of confidence for all confidence intervals in output: 95\n\n# W values in conditional tables are the 16th, 50th, and 84th percentiles.\n \n# NOTE: The following variables were mean centered prior to analysis: \n#          exercise age\n\n\n\n\n\n\n\n\n\n\nInteraction의 패턴\n\n\n\n\nSynergistic or enhancing interaction\n\n\n상호작용 효과가 원래 효과들과 같은 방향으로 작용하는 경우\n삶의 만족도(Y)가 직업 스트레스(X)와 부정적인 관계에 있고, 부부관계의 문제(Z)와도 부정적인 관계에 있는 경우\n이 둘의 상호작용이 부정적이라면, 직업 스트레스와 부부관계의 문제가 동시에 증가하면 각각의 sum이 예측하는 것보다 더 낮은 삶의 만족도가 예측됨.\n\n\nBuffering interaction\n\n\n두 변수가 반대 방향으로 Y에 작용하고 있을 때, 한 변수가 다른 변수의 효과를 감소시키는 경우\n즉, 한 변수의 impact가 다른 변수의 impact를 줄여주는 경우\n건강보건에 대한 연구에서, 한 변수가 질병의 위험요인이고 다른 변수가 질병의 위험을 줄여주는 보호요인인 경우\n위의 예에서처럼, 나이(X)는 지구력 감소의 위험요인이고, 운동기간(Z)은 지구력 보호요인인 경우\n\n\nInterference or antagonistic interactionin\n\n\n두 변수가 같은 방향으로 Y에 작용하고 있을 때, 상호작용은 반대 방향으로 작용하는 경우\n대학생의 학업성취도(Y)에 대하여, 학업동기(X)와 학업능력(Z)이 모두 학업성취도(Y)에 긍정적인 영향을 미치나 이 두 변수는 서로 보완적인 효과를 가지고 있음.\n즉, 성취도에 대한 학업능력의 중요성은 높은 학업동기에 의해 낮아질 수 있음.\n반대로, 학업동기에 대한 중요성은 높은 학업능력에 의해 낮아질 수 있음.\n\n\n\n\n\n예제 2\nSource: p.551, Statistical Methods for Psychology (8e) by Dave C. Howell\n오리엔테이션에 참석한 대학 신입생을 대상으로, 스트레스 받은 일(hassles)이 많을 수록 여러 증상들(symptoms)을 더 경험하는데, 주위의 지지(support)가 많을 수록 그 증상들이 감소한다는 것을 알아보고자 설문 조사. (Wagner, Compas, and Howell (1988))\n\nhassles: 소소한 일상적인 스트레스를 경험한 횟수\nsupport: 본인이 인지하는 주위의 지지 정도\nsymptoms: 증상에 대한 checklist로 나타난 증상의 개수\n\n\nData: hassles.csv\n\nhassles &lt;- read_csv(\"data/hassles.csv\")\nhassles\n\n# A tibble: 56 × 3\n   hassles support symptoms\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1     176      10       73\n 2     379      50       88\n 3     126      45      118\n 4     193      40       79\n 5     229      40      127\n 6     153      39       73\n 7     214      38       93\n 8     164      37       99\n 9     143      36       81\n10      27      36       64\n# ℹ 46 more rows\n\ncar::scatterplotMatrix(hassles)\n\n\n\n\n\n\n\nhassles |&gt; \n  lowerCor()  # library(psych)\n\n         hssls spprt sympt\nhassles   1.00            \nsupport  -0.17  1.00      \nsymptoms  0.58 -0.13  1.00\n\nhassles &lt;- hassles |&gt; \n  mutate(\n    hassles_c = center(hassles),  # library(jtools)\n    support_c = center(support)\n  )\n\n\\(\\hat{symptom} = b_0 + b_1\\cdot hassles_c + b_2\\cdot support_c + b_3\\cdot hassles_c \\cdot support_c\\)\n\nmod &lt;- lm(symptoms ~ hassles_c * support_c, data = hassles)\nS(mod)  # library(car)\n\nCall: lm(formula = symptoms ~ hassles_c * support_c, data = hassles)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         89.584940   2.291503  39.094  &lt; 2e-16 ***\nhassles_c            0.085942   0.019213   4.473 4.22e-05 ***\nsupport_c            0.146358   0.305244   0.479   0.6336    \nhassles_c:support_c -0.005065   0.002363  -2.144   0.0368 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 16.89 on 52 degrees of freedom\nMultiple R-squared: 0.3885\nF-statistic: 11.01 on 3 and 52 DF,  p-value: 1.046e-05 \n   AIC    BIC \n481.39 491.51 \n\n\n\nhassles |&gt; ggplot(aes(x = support_c)) + geom_freqpoly()\n\n\n\n\n\n\n\n\n\nlibrary(effects)\n# 임의의 3 levels 선택\npredictorEffects(mod, xlevels = 3) |&gt;  # 임의의 3 levels 선택\n  plot(lines = list(multiline = TRUE)) # 3개의 선을 함께 그림\n\n\n\n\n\n\n\n\n\n# 특정 3 levels 선택: -10(평균-10), 0(평균), 10(평균+10)\npredictorEffects(mod, ~ hassles_c, \n                 xlevels = list(support_c = c(-10, 0, 10))) |&gt;  # 특정 3 levels 선택\n  plot(lines = list(multiline = TRUE))  # 3개의 선을 함께 그림\n\n\n\n\n\n\n\n\nsupport_c가 10일 때, hassels의 기울기는 통계적으로 유의한가를 테스트\n\nmod_probe &lt;- lm(symptoms ~ hassles_c * I(support_c - 10), data = hassles)\nS(mod_probe)  # library(car)\n\nCall: lm(formula = symptoms ~ hassles_c * I(support_c - 10), data = hassles)\n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 91.048515   3.697199  24.626   &lt;2e-16 ***\nhassles_c                    0.035293   0.034034   1.037   0.3045    \nI(support_c - 10)            0.146358   0.305244   0.479   0.6336    \nhassles_c:I(support_c - 10) -0.005065   0.002363  -2.144   0.0368 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 16.89 on 52 degrees of freedom\nMultiple R-squared: 0.3885\nF-statistic: 11.01 on 3 and 52 DF,  p-value: 1.046e-05 \n   AIC    BIC \n481.39 491.51 \n\n\n모든 moderator의 값에 대한 통계적 유의도를 계산\n\n# Johnson-Neyman intervals \nlibrary(interactions)\njohnson_neyman(mod, pred = \"hassles_c\", modx = \"support_c\")\n\nJOHNSON-NEYMAN INTERVAL\n\nWhen support_c is OUTSIDE the interval [6.25, 297.50], the slope of\nhassles_c is p &lt; .05.\n\nNote: The range of observed values of support_c is [-18.96, 21.04]\n\n\n\n\n\n\n\n\n\n회귀모형에 대한 진단\n\navPlots(mod)\n\n\n\n\n\n\n\ninfluenceIndexPlot(mod)\n\n\n\n\n\n\n\nmod_update &lt;- update(mod, subset = -52) # 52번째 관측치 제거\navPlots(mod_update)\n\n\n\n\n\n\n\nS(mod_update)\n\nCall: lm(formula = symptoms ~ hassles_c * support_c, data = hassles, subset =\n         -52)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         89.140023   2.156778  41.330  &lt; 2e-16 ***\nhassles_c            0.070908   0.018801   3.772 0.000423 ***\nsupport_c            0.125998   0.286624   0.440 0.662089    \nhassles_c:support_c -0.001655   0.002524  -0.656 0.515015    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 15.86 on 51 degrees of freedom\nMultiple R-squared: 0.2291\nF-statistic: 5.053 on 3 and 51 DF,  p-value: 0.00385 \n   AIC    BIC \n465.93 475.97 \n\n\n\n\n\n\n\n\nLinear vs. Nonlinear Interaction\n\n\n\n위에서 다룬 예제들은 모두 선형적인 상호작용을 다룸; 가장 단순한 형태의 상호작용\n다음과 같은 비선형적인 상호작용도 가능함. (p. 292)\n\n\n\n\n\n\n\n\n\n\\(X\\)에 대한 2차 다항함수로 fit을 한다면,\n이 때, 상호작용이 없다면\n\\(\\hat{Y} = b_0 + b_1X + b_2X^2 + b_3Z\\)\n상호작용을 추가하면\n\\(\\hat{Y} = b_0 + b_1X + b_2X^2 + b_3XZ + b_4X^2Z\\)\nFormula: Y ~ X + I(X^2) + Z + X:Z + I(X^2):Z",
    "crumbs": [
      "Statistics",
      "Interactions"
    ]
  },
  {
    "objectID": "contents/interaction.html#continuous-vs.-categorical",
    "href": "contents/interaction.html#continuous-vs.-categorical",
    "title": "Interaction Effects",
    "section": "Continuous vs. Categorical",
    "text": "Continuous vs. Categorical\n\n성별 이나 실험조건/통제조건 같이 두 개의 범주를 가지는 변수와의 상호작용\n직업군과 같이 세 개 이상의 범주를 가지는 변수와의 상호작용\n\n\nBinary 변수와의 상호작용\n예제 1: Data from the 1985 Current Population Survey (CPS85)\n나이(age)에 따른 임금(wage)의 증가량이 남녀(sex)에 따라 다른가?\n\ncps &lt;- mosaicData::CPS85 |&gt; as_tibble()\ncps |&gt; head(3)\n\n# A tibble: 3 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; \n1   9      10 W     M     NH       NS    Married    27 Not      43 const \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales \n\n\n편의상 management 섹터에서만 보면,\n\ncps &lt;- cps |&gt; \n  filter(sector == \"manag\") |&gt; \n  filter(wage &lt; 30 & age &lt; 60) |&gt; \n  slice(-51)\n\n\ncps |&gt; ggplot(aes(x = age, y = wage, color = sex)) + geom_point() + geom_smooth(se=F)\n\n\n\n\n\n\n\n\n\\(\\hat{wage} = b_0 + b_1\\cdot age + b_2\\cdot sexM + b_3\\cdot age \\cdot sexM\\)\n\nmod &lt;- lm(wage ~ age * sex, data = cps)\nS(mod)\n\nCall: lm(formula = wage ~ age * sex, data = cps)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   4.1600     3.9354   1.057   0.2960  \nage           0.1526     0.1044   1.463   0.1504  \nsexM         -6.7728     5.4323  -1.247   0.2188  \nage:sexM      0.2852     0.1409   2.025   0.0487 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.795 on 46 degrees of freedom\nMultiple R-squared: 0.4266\nF-statistic: 11.41 on 3 and 46 DF,  p-value: 1.028e-05 \n   AIC    BIC \n304.47 314.03 \n\npredictorEffects(mod) |&gt; plot()\n\n\n\n\n\n\n\n\n상호작용항의 추가 설명력: \\(\\Delta R^2\\) 계산\n\nmod &lt;- lm(wage ~ age * sex, data = cps)\nmod_reduced &lt;- lm(wage ~ age + sex, data = cps)\n\nr2_full &lt;- summary(mod)$r.squared\nr2_reduced &lt;- summary(mod_reduced)$r.squared\n\nsprintf(\"R2 diff: %.3f\", r2_full - r2_reduced)\n\n[1] \"R2 diff: 0.051\"\n\n\n\nanova(mod_reduced, mod)\n\nAnalysis of Variance Table\n\nModel 1: wage ~ age + sex\nModel 2: wage ~ age * sex\n  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n1     47 1151.7                              \n2     46 1057.5  1     94.23 4.0991 0.04874 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n예제 2: 기후 변화 회의론이 원조 보류의 정당성에 미치는 영향\np. 285, Introduction to Mediation, Moderation, and Conditional Process Analysis (3e) by Andrew F. Hayes\n\n\n\n\n\n\n연구 설명\n\n\n\n\n\n저는 7장에서 소개한 조절 분석 방법을 재난의 원인을 기후 변화로 돌리는 것과 원인을 특정하지 않는 것이 기후 변화의 현실에 대한 사람들의 믿음에 따라 피해자에 대한 지원을 보류하는 사람들의 정당성에 차별적으로 영향을 미치는지 조사한 연구 데이터를 사용하여 설명했습니다. 이 예에서 초점 선행 변수는 가뭄의 원인에 대한 프레임을 코딩하는 이분법적 변수였고, 조절 변수는 기후 변화의 현실에 대한 회의론의 연속선상에 각 사람을 위치시키는 측정된 개인적 차이였습니다. 분석 결과, 기후 변화에 대해 회의적인 사람들은 원인을 특정하지 않은 경우보다 기후 변화로 인한 재난일 때 원조 보류에 대한 더 강력한 정당성을 보고했습니다. 기후 변화에 대한 회의적 시각이 상대적으로 낮은 사람들 사이에서는 이러한 효과가 관찰되지 않았습니다. 하지만 재난의 원인을 어떻게 규정하느냐가 아니라 기후변화 회의론이 재난 피해자에 대한 원조 의지에 미치는 영향에 실질적으로 초점을 맞춘다면 어떨까요? 이 질문은 간단한 회귀 분석으로 쉽게 답할 수 있습니다. 기후 변화 회의론(X)으로부터 원조 보류의 정당성(Y)을 추정하는 가장 적합한 OLS 회귀 모델은 Yˆ = 2.186+0.201X입니다. 따라서 기후 변화에 대한 회의론이 1단위 차이가 나는 두 사람은 기근 피해자에 대한 원조 보류의 정당성 강도에서 0.201단위 차이가 나는 것으로 추정됩니다. 이 관계는 통계적으로 유의미합니다. 그러나 이 분석은 이 연구 참여자의 절반은 가뭄과 그로 인한 기근이 기후 변화로 인한 것이라고 들었지만 다른 사람들은 그 원인에 대한 정보가 전혀 제공되지 않았다는 점을 완전히 무시하고 있습니다. 이 연구의 저자에 따르면, 기후 변화로 인한 것으로 표시된 사건은 기후 변화 회의론자들이 기후 변화의 현실에 대해 덜 회의적인 사람들에 비해 피해자를 돕는 것의 가치에 대해 특히 의심하게 만들 수 있다고 합니다. 즉, 기후 변화에 대한 귀인이 동기가 부여된 방어적 태도를 유발할 수 있으며, 기후 변화의 현실에 대한 태도는 그러한 귀인이 없을 때와 비교하여 도움에 대한 태도를 더 잘 예측할 수 있습니다. 다시 말해, 이러한 귀인은 사람들이 아무런 원인이 제공되지 않았을 때보다 자신의 태도와 더 일치하는 방식으로 피해자의 요구에 응답하도록 유도할 수 있습니다. 이러한 추론에 따르면 기후변화가 가뭄의 원인이라고 들었을 때와 원인에 대한 정보가 제공되지 않았을 때 기후변화 회의론과 원조 보류의 정당성 사이의 관계가 다를 것으로 예상할 수 있습니다. 기후변화 회의론 X와 재난 프레임 W(기후변화 조건은 1, 자연적 원인 조건은 0으로 설정)라고 부르면 7장에서와 마찬가지로 간단한 조정 모델을 추정할 수 있는데, 이 모델에서 X가 Y에 미치는 영향은 다음과 같다. 이러한 과정은 그림 8.1, 패널 A에 개념적으로 도식화되어 있으며 그림 8.1, 패널 B의 통계 다이어그램에서와 같이 X, W 및 XW를 선행 변수로 하는 통계 모형으로 변환됩니다.\nTranslated with DeepL.com (free version)\n\n\n\n\n\ndisaster &lt;- read_csv(\"data/hayes2022data/disaster/disaster.csv\")\ndisaster &lt;- disaster |&gt; \n  mutate(frame_f = factor(frame, levels = c(0, 1), labels = c(\"control\", \"framed\")))\ndisaster |&gt; head(3)\n\n# A tibble: 3 × 6\n     id frame donate justify skeptic frame_f\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;  \n1     1     1    5.6    2.95     1.8 framed \n2     2     1    4.2    2.85     5.2 framed \n3     3     1    4.2    3        3.2 framed \n\n\n\n\nShow the code\ndisaster |&gt; \n  ggplot(aes(x = skeptic, y = justify, color = frame_f)) +\n  geom_point() +\n  geom_smooth(se = F, method = \"lm\", color=\"grey50\") +\n  geom_smooth(se = F) +\n  facet_wrap(~frame_f)\n\n\n\n\n\n\n\n\n\n\\(\\hat{justify} = b_0 + b_1\\cdot skeptic + b_2\\cdot frame + b_3\\cdot skeptic \\cdot frame\\)\n\nmod &lt;- lm(justify ~ center(skeptic) * frame_f, data = disaster)\nS(mod)\n\nCall: lm(formula = justify ~ center(skeptic) * frame_f, data = disaster)\n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    2.80650    0.07753  36.201  &lt; 2e-16 ***\ncenter(skeptic)                0.10508    0.03813   2.756 0.006375 ** \nframe_fframed                  0.11712    0.11206   1.045 0.297156    \ncenter(skeptic):frame_fframed  0.20118    0.05527   3.640 0.000344 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.8129 on 207 degrees of freedom\nMultiple R-squared: 0.2463\nF-statistic: 22.54 on 3 and 207 DF,  p-value: 1.138e-12 \n   AIC    BIC \n517.36 534.12 \n\nm &lt;- mean(disaster$skeptic, na.rm = TRUE) |&gt; round(2)\nsd &lt;- sd(disaster$skeptic, na.rm = TRUE) |&gt; round(2)\n\npredictorEffects(mod, xlevels = list(skeptic = c(m-sd, m, m+sd))) |&gt;\n  plot(lines = list(multiline = TRUE)) # 3개의 선을 함께 그림\n\n\n\n\n\n\n\n\n\n# johnson_neyman() 함수의 경우 카테고리 변수를 factor가 아닌 숫자로 입력해야 함\nmod2 &lt;- lm(justify ~ skeptic * frame, data = disaster)  # frame: 0, 1\njohnson_neyman(mod2, pred = \"frame\", modx = \"skeptic\")\n\nJOHNSON-NEYMAN INTERVAL\n\nWhen skeptic is OUTSIDE the interval [1.17, 3.93], the slope of frame is p\n&lt; .05.\n\nNote: The range of observed values of skeptic is [1.00, 9.00]\n\n\n\n\n\n\n\n\n\n상호작용항의 추가 설명력: \\(\\Delta R^2\\) 계산\n\nmod &lt;- lm(justify ~ skeptic * frame_f, data = disaster)\nmod_reduced &lt;- lm(justify ~ skeptic + frame_f, data = disaster)\n\nr2_full &lt;- summary(mod)$r.squared\nr2_reduced &lt;- summary(mod_reduced)$r.squared\n\nsprintf(\"R2 diff: %.3f\", r2_full - r2_reduced)\n\n[1] \"R2 diff: 0.048\"\n\n\n\n\n3개 이상의 범주를 가지는 변수와의 상호작용\nData: c0904dt2.csv\n\nacad3 &lt;- read_csv(\"data/c0904dt2.csv\")\nacad3 |&gt; head(5)\n\n# A tibble: 5 × 5\n  depart    pub  time salary sex   \n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; \n1 anthrop    16     3 56465. female\n2 anthrop    25     7 92044. male  \n3 anthrop    16     2 48980. female\n4 anthrop    24     1 53239. female\n5 anthrop    24     8 98948. male  \n\n\n\nacad3 &lt;- acad3 |&gt; mutate(pub_c = center(pub), time_c = center(time))\nacad3 |&gt; \n  ggplot(aes(x = pub, y = salary, color = depart)) +\n  geom_point() + geom_smooth(method=lm) + facet_wrap(~depart)\n\n\n\n\n\n\n\n\n\\(\\hat{salary} = b_0 + b_1\\cdot pub + b_2\\cdot depart_{hist} + b_3\\cdot depart_{soc} + b_4\\cdot pub \\cdot depart_{hist} + b_5\\cdot pub \\cdot depart_{soc}\\)\n\nmod &lt;- lm(salary ~ pub_c * depart, data = acad3)\nS(mod)\n\nCall: lm(formula = salary ~ pub_c * depart, data = acad3)\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       56917.9     2207.4  25.785  &lt; 2e-16 ***\npub_c              1372.9      252.5   5.438 2.25e-07 ***\ndeparthist         9796.1     3615.1   2.710  0.00755 ** \ndepartsoc          9672.8     3235.2   2.990  0.00328 ** \npub_c:departhist   -961.0      466.2  -2.061  0.04109 *  \npub_c:departsoc   -1115.0      495.4  -2.251  0.02592 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 15670 on 144 degrees of freedom\nMultiple R-squared: 0.1892\nF-statistic: 6.722 on 5 and 144 DF,  p-value: 1.167e-05 \n    AIC     BIC \n3331.44 3352.51 \n\nplot(predictorEffects(mod, ~depart, xlevels = 3))\n\n\n\n\n\n\n\nplot(predictorEffects(mod, ~pub_c))\n\n\n\n\n\n\n\n\n상호작용항의 추가 설명력: \\(\\Delta R^2\\) 계산\n\nmod &lt;- lm(salary ~ pub_c * depart, data = acad3)\nmod_reduced &lt;- lm(salary ~ pub_c + depart, data = acad3)\n\nr2_full &lt;- summary(mod)$r.squared\nr2_reduced &lt;- summary(mod_reduced)$r.squared\n\nsprintf(\"R2 diff: %.3f\", r2_full - r2_reduced)\n\n[1] \"R2 diff: 0.041\"\n\n\n\nanova(mod_reduced, mod)\n\nAnalysis of Variance Table\n\nModel 1: salary ~ pub_c + depart\nModel 2: salary ~ pub_c * depart\n  Res.Df        RSS Df  Sum of Sq      F  Pr(&gt;F)  \n1    146 3.7161e+10                               \n2    144 3.5366e+10  2 1795358985 3.6551 0.02829 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n연차의 효과를 고려한다면\n\nmod2 &lt;- lm(salary ~ (time_c + pub_c) * depart, data = acad3)\nS(mod2, brief = T)\n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        59318.9     2222.0  26.696  &lt; 2e-16 ***\ntime_c              1144.4      387.8   2.951  0.00371 ** \npub_c               1063.7      258.7   4.112 6.62e-05 ***\ndeparthist          4223.7     3632.6   1.163  0.24691    \ndepartsoc           6999.9     3140.1   2.229  0.02738 *  \ntime_c:departhist    253.7      598.2   0.424  0.67212    \ntime_c:departsoc    -151.1      590.0  -0.256  0.79829    \npub_c:departhist    -985.4      462.1  -2.133  0.03470 *  \npub_c:departsoc     -793.6      475.8  -1.668  0.09752 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 14680 on 141 degrees of freedom\nMultiple R-squared: 0.3035\nF-statistic: 7.679 on 8 and 141 DF,  p-value: 1.655e-08 \n    AIC     BIC \n3314.66 3344.77 \n\nmod3 &lt;- lm(salary ~ time_c + pub_c * depart, data = acad3)\nS(mod3, brief = T)\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       59377.2     2119.2  28.018  &lt; 2e-16 ***\ntime_c             1172.2      244.6   4.792 4.09e-06 ***\npub_c              1056.2      244.3   4.324 2.86e-05 ***\ndeparthist         4677.9     3532.7   1.324   0.1876    \ndepartsoc          6892.6     3068.9   2.246   0.0262 *  \npub_c:departhist   -924.0      434.4  -2.127   0.0351 *  \npub_c:departsoc    -783.9      466.6  -1.680   0.0951 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 14600 on 143 degrees of freedom\nMultiple R-squared: 0.3014\nF-statistic: 10.28 on 6 and 143 DF,  p-value: 1.874e-09 \n    AIC     BIC \n3311.10 3335.18 \n\n\n\nplot(predictorEffects(mod3, ~depart, xlevels = 3))",
    "crumbs": [
      "Statistics",
      "Interactions"
    ]
  },
  {
    "objectID": "contents/interaction.html#categorical-vs.-categorical",
    "href": "contents/interaction.html#categorical-vs.-categorical",
    "title": "Interaction Effects",
    "section": "Categorical vs. Categorical",
    "text": "Categorical vs. Categorical\nANOVA: factorical design\n\n실험연구의 예\n실험연구 분석에 대한 더 논의가 필요함…\nData: C0901DT.csv\n2 X 2인 경우: lesion(2 levels) x drug(2 levels)\n\nrats &lt;- read_csv(\"data/C0901DT.csv\")\nrats &lt;- rats |&gt; rename_with(str_to_lower)  # 변수명 소문자로 변경\nrats |&gt; sample_n(6)\n\n# A tibble: 6 × 5\n     ya    yb    yc lesion  drug   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1  9.74  9.74 11.7  SURGERY PLACEBO\n2  9.99 14.0  12.0  SHAM    PLACEBO\n3  7.71 11.7   7.71 SHAM    PLACEBO\n4  3.66  3.66  1.66 SHAM    ACTIVE \n5  4.06  4.06  2.06 SHAM    ACTIVE \n6  7.26 11.3   9.26 SHAM    PLACEBO\n\nrats |&gt; group_by(lesion, drug) |&gt; summarise(yc_mean = mean(yc))\n\n# A tibble: 4 × 3\n  lesion  drug    yc_mean\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 SHAM    ACTIVE     2.00\n2 SHAM    PLACEBO    9.99\n3 SURGERY ACTIVE     8.02\n4 SURGERY PLACEBO   12.0 \n\nmod &lt;- lm(yb ~ lesion * drug, data = rats)\nS(mod)\n\nCall: lm(formula = yb ~ lesion * drug, data = rats)\n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 3.9965     0.1524   26.23   &lt;2e-16 ***\nlesionSURGERY              10.0251     0.2302   43.55   &lt;2e-16 ***\ndrugPLACEBO                 8.0141     0.2056   38.98   &lt;2e-16 ***\nlesionSURGERY:drugPLACEBO -12.0336     0.3256  -36.96   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.9758 on 147 degrees of freedom\nMultiple R-squared: 0.9401\nF-statistic: 768.6 on 3 and 147 DF,  p-value: &lt; 2.2e-16 \n   AIC    BIC \n427.07 442.15 \n\npredictorEffects(mod, ~drug) |&gt; plot()\n\n\n\n\n\n\n\n\nData: C0902DT.csv\n4 X 3인 경우: hospital(4 levels) x treatment(3 levels)\n\ntreat &lt;- read_csv(\"data/C0902DT.csv\")\ntreat &lt;- treat |&gt; rename_with(str_to_lower) # 변수명 소문자로 변경\ntreat |&gt; head(5)\n\n# A tibble: 5 × 3\n  hospital treatmen     y\n     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1        1        1  66.8\n2        1        1  42.4\n3        1        1  20.7\n4        1        1  46.4\n5        1        1  54.3\n\ntreat &lt;- treat |&gt; \n  mutate(hospital = factor(hospital), treatmen = factor(treatmen))\nmod &lt;- lm(y ~ hospital * treatmen, data = treat)\npredictorEffects(mod, ~treatmen) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n관찰연구의 예\n성별과 결혼 여부에 따른 임금차이\n\ncps &lt;- mosaicData::CPS85 |&gt; as_tibble()\ncps |&gt; head(5)\n\n# A tibble: 5 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n\nmod &lt;- lm(wage ~ sex * married, data = cps)\nS(mod)\n\nCall: lm(formula = wage ~ sex * married, data = cps)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          7.6838     0.3898  19.711  &lt; 2e-16 ***\nsexM                 3.1923     0.5319   6.002 3.62e-09 ***\nmarriedSingle        0.5759     0.6697   0.860  0.39026    \nsexM:marriedSingle  -3.0972     0.9073  -3.414  0.00069 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.962 on 530 degrees of freedom\nMultiple R-squared: 0.07314\nF-statistic: 13.94 on 3 and 530 DF,  p-value: 9.234e-09 \n    AIC     BIC \n3232.05 3253.45 \n\npredictorEffects(mod) |&gt; plot()\n\n\n\n\n\n\n\n\n관찰연구의 경우 confounding이 될만한 통제 변수를 충분히 고려해야 하고, 나이가 성별과 결혼 여부와 상관관계가 있으므로 통제 변수로 포함.\n\ncps |&gt; select(age, sex, married) |&gt; lowerCor()\n\n         age   sex*  mrrd*\nage       1.00            \nsex*     -0.08  1.00      \nmarried* -0.28  0.01  1.00\n\n# age와 wage의 관계는 비선형적: spline regression (piecewise polynomial) fit을 고려할 필요있음\nmod2 &lt;- lm(wage ~ sex * married + age + I(age^2), data = cps)  \npredictorEffects(mod2, ~ sex + married) |&gt; plot()\n\n\n\n\n\n\n\nS(mod2)\n\nCall: lm(formula = wage ~ sex * married + age + I(age^2), data = cps)\n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -5.147951   2.391631  -2.152  0.03181 *  \nsexM                3.152425   0.516297   6.106 1.98e-09 ***\nmarriedSingle       1.321511   0.662608   1.994  0.04662 *  \nage                 0.608443   0.121565   5.005 7.62e-07 ***\nI(age^2)           -0.006630   0.001483  -4.470 9.60e-06 ***\nsexM:marriedSingle -2.617902   0.887868  -2.949  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.816 on 528 degrees of freedom\nMultiple R-squared: 0.1301\nF-statistic:  15.8 on 5 and 528 DF,  p-value: 1.649e-14 \n    AIC     BIC \n3202.17 3232.13 \n\n\n결혼 유무에 따른 임금의 차이는 여성의 경우 미혼이 $1.32(p = 0.047) 높음.\n남성의 경우는 아래와 같이 factor level을 변경해서 보면, 남성인 경우 미혼이 $1.29(p = 0.041) 낮음.\n\nmod2_m &lt;- lm(wage ~ fct_relevel(sex, \"M\") * married + age + I(age^2), data = cps)\nS(mod2_m)\n\nCall: lm(formula = wage ~ fct_relevel(sex, \"M\") * married + age + I(age^2),\n         data = cps)\n\nCoefficients:\n                                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                          -1.995525   2.393324  -0.834  0.40478    \nfct_relevel(sex, \"M\")F               -3.152425   0.516297  -6.106 1.98e-09 ***\nmarriedSingle                        -1.296391   0.632255  -2.050  0.04082 *  \nage                                   0.608443   0.121565   5.005 7.62e-07 ***\nI(age^2)                             -0.006630   0.001483  -4.470 9.60e-06 ***\nfct_relevel(sex, \"M\")F:marriedSingle  2.617902   0.887868   2.949  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.816 on 528 degrees of freedom\nMultiple R-squared: 0.1301\nF-statistic:  15.8 on 5 and 528 DF,  p-value: 1.649e-14 \n    AIC     BIC \n3202.17 3232.13 \n\n\n\n\n\n\n\n\nImportant\n\n\n\n특히, 카테고리 변수와의 상호작용을 테스트할 때, 유닉크한 카테고리들의 조합에 해당하는 표본의 수가 급격히 줄기 때문에 표본의 수가 충분히 많아야 함.\n예를 들어, 위의 경우 4가지 조합(싱글 남자, 싱글 여자, 기혼 남자, 기혼 여자)에 대한 표본의 수가 충분히 많아야 함.",
    "crumbs": [
      "Statistics",
      "Interactions"
    ]
  },
  {
    "objectID": "contents/interaction.html#moderated-mediation",
    "href": "contents/interaction.html#moderated-mediation",
    "title": "Interaction Effects",
    "section": "Moderated Mediation",
    "text": "Moderated Mediation\np. 424, Introduction to Mediation, Moderation, and Conditional Process Analysis (3e) by Andrew F. Hayes\n\n\n\n\n\n\n연구 설명\n\n\n\n\n\n11.3 예시: 업무 팀에게 자신의 감정 숨기기 수년에 걸쳐 대중음악은 우리의 직관을 강화해왔고, 친한 친구들이 제공한 조언이나 친한 친구들이 제공하고 토크쇼 심리학자들은 감정을 억누르고 다른 사람의 눈에 띄지 않도록 숨겨서는 좋은 결과를 얻을 수 없다고 강조합니다. 당대의 아티스트들은 “자신을 표현하라”(마돈나)고, “침묵의 강령”(빌리 조엘)에 따라 살면 결코 과거를 잊지 못할 것이며 “절대 말하지 않을 것들”(에이브릴 라빈)의 목록이 길수록 인생에서 원하는 것을 얻을 가능성이 줄어든다는 것을 조심하라고 말합니다. 따라서 다른 사람이 “나랑 얘기 좀 하자”(아니타 베이커)는 요청을 할 때는 경계심을 풀고 마음속에 있는 이야기를 “소통”(B-52)하는 것이 중요합니다. 하지만 적어도 일부 업무 관련 상황에서는 반드시 그렇지는 않다고 M. S. Cole 외(2008)의 팀워크에 관한 연구에 따르면 말합니다. 이 연구자들에 따르면, 때로는 함께 일하는 다른 사람들이 자신을 괴롭히는 행동이나 말에 대해 자신의 감정을 숨기는 것이 더 나을 수 있으며, 그러한 감정이 팀의 관심의 초점이 되어 팀이 적시에 효율적인 방식으로 작업을 수행하는 데 방해가 되지 않도록 하는 것이 더 나을 수 있습니다. 이 연구는 조건부 프로세스 모델의 추정과 해석의 메커니즘을 설명하는 첫 번째 사례의 데이터를 TEAMS라는 데이터 파일로 제공하며, www.afhayes.com 에서 확인할 수 있습니다. 이 연구는 자동차 부품 제조 회사에 고용된 60개의 작업 팀을 대상으로 진행되었으며, 회사 직원 200여 명을 대상으로 작업 팀에 대한 일련의 질문과 팀 감독자에 대한 다양한 인식에 대한 설문조사에 대한 응답을 기반으로 합니다. 이 연구의 일부 변수는 그룹 수준에서 측정된 것으로 같은 팀원들이 말한 내용을 종합하여 도출한 것입니다. 다행히 팀원들이 팀에 대한 질문에 응답하는 방식이 매우 유사하여 이러한 종류의 집계를 정당화할 수 있었습니다. 다른 변수는 순전히 팀 상사의 보고를 기반으로 합니다.\n이 분석과 관련된 네 가지 변수를 측정했습니다. 팀원들이 다른 팀원들의 업무를 약화시키거나 변화와 혁신을 방해하는 행동을 얼마나 자주 했는지 등 팀원들의 역기능적 행동에 대한 일련의 질문(데이터 파일에서 DYSFUNC, 점수가 높을수록 팀 내 역기능적 행동이 많음을 나타냄)을 던져 팀원들의 역기능적 행동을 측정했습니다. 또한 팀원들에게 직장에서 ‘화가 났다’, ‘역겨웠다’ 등을 얼마나 자주 느끼는지 물어봄으로써 그룹의 부정적인 정서적 분위기를 측정했습니다(NEGTONE, 점수가 높을수록 업무 환경의 부정적인 정서적 분위기를 더 많이 반영함). 팀 상사에게는 팀이 얼마나 효율적이고 적시에 일을 처리하는지, 팀이 생산 목표를 달성하는지 등 전반적인 팀 성과에 대한 평가를 제공하도록 요청했습니다(데이터의 성과, 점수가 높을수록 성과가 좋음을 반영하는 척도). 또한 슈퍼바이저는 팀원들이 자신의 감정에 대해 보내는 비언어적 신호를 얼마나 쉽게 읽을 수 있는지를 측정하는 일련의 질문, 즉 비언어적 부정적 표현력(데이터 파일의 NEGEXP, 점수가 높을수록 팀원들이 부정적인 감정 상태를 비언어적으로 더 잘 표현한다는 의미)에 응답했습니다. 이 연구의 목표는 업무 팀원의 역기능적 행동이 업무 팀의 성과에 부정적인 영향을 미칠 수 있는 메커니즘을 조사하는 것이었습니다. 연구진은 역기능적 행동(X)으로 인해 상사와 다른 직원들이 직면하고 관리하려고 하는 부정적인 감정(M)으로 가득 찬 업무 환경이 조성되면 업무에 집중하지 못하고 업무 수행에 방해가 된다는 중재 모델을 제안했습니다(Y). 그러나 이 모델에 따르면 팀원들이 부정적인 감정(W)을 조절할 수 있게 되면, 즉 자신의 감정을 다른 사람에게 숨길 수 있게 되면 업무 환경의 부정적인 분위기와 다른 사람의 감정을 관리하는 데 집중할 필요 없이 당면한 업무에 집중할 수 있게 됩니다. 즉, 이 모델에서는 업무 환경의 부정적인 정서적 어조가 팀 성과에 미치는 영향은 팀원이 자신의 감정을 숨기는 능력에 따라 달라지며, 부정적 감정을 숨기지 않고 표현하는 팀에서 부정적인 정서적 어조가 성과에 미치는 부정적 영향이 더 강하다고 가정합니다.\n\n\n\n\nData: Introduction to Mediation, Moderation, and Conditional Process Analysis; “data files and code”\n\nteams &lt;- read_csv(\"data/hayes2022data/teams/teams.csv\")\n\n뒷 부분: \\(Y \\leftarrow X, M (W)\\)\n\nmod_m &lt;- lm(perform ~ dysfunc + negtone + negexp + negtone:negexp, data = teams)\n# 위와 동일: dysfunc은 통제 변수로 볼 수 있음\nmod_m &lt;- lm(perform ~ dysfunc + center(negtone) * center(negexp), data = teams)\nS(mod_m, brief = T)\n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)                    -0.03207    0.05866  -0.547  0.58680   \ndysfunc                         0.36606    0.17782   2.059  0.04429 * \ncenter(negtone)                -0.43144    0.13118  -3.289  0.00176 **\ncenter(negexp)                 -0.04357    0.11343  -0.384  0.70239   \ncenter(negtone):center(negexp) -0.51697    0.24092  -2.146  0.03632 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.4488 on 55 degrees of freedom\nMultiple R-squared: 0.312\nF-statistic: 6.235 on 4 and 55 DF,  p-value: 0.0003276 \n  AIC   BIC \n80.92 93.49 \n\n\n앞 부분: \\(M \\leftarrow X\\)\n\nmod_x &lt;- lm(center(negtone) ~ dysfunc, data = teams)\nS(mod_x, brief = T)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.02148    0.06176  -0.348 0.729182    \ndysfunc      0.61975    0.16683   3.715 0.000459 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.4763 on 58 degrees of freedom\nMultiple R-squared: 0.1922\nF-statistic:  13.8 on 1 and 58 DF,  p-value: 0.000459 \n  AIC   BIC \n85.23 91.51 \n\npredictorEffects(mod_m, ~negtone) |&gt; plot()\n\n\n\n\n\n\n\navPlots(mod_m)\n\n\n\n\n\n\n\n\nHayes의 PROCESS를 매크로: Model 14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmoments = 1: moderator의 세 값 (mean, mean +/- 1 SD)에 대한 조건적 효과를 계산\ncenter = 1: centering\nIndex of moderated mediation: 조절변수가 1 변할 때, 간접효과의 변화가 얼마나 되는지를 나타내는 지수. 즉 간접효과가 얼마나 조절되는가?\n\n\nprocess(data=teams, y=\"perform\", m=\"negtone\", w=\"negexp\", x=\"dysfunc\", jn=0, moments=1, center=1, model=14)\n\n# ********************* PROCESS for R Version 4.3.1 ********************* \n \n#            Written by Andrew F. Hayes, Ph.D.  www.afhayes.com              \n#    Documentation available in Hayes (2022). www.guilford.com/p/hayes3   \n \n# *********************************************************************** \n               \n# Model : 14     \n#     Y : perform\n#     X : dysfunc\n#     M : negtone\n#     W : negexp \n\n# Sample size: 60\n\n# Random seed: 791081\n\n\n# *********************************************************************** \n# Outcome Variable: negtone\n\n# Model Summary: \n#           R      R-sq       MSE         F       df1       df2         p\n#      0.4384    0.1922    0.2268   13.7999    1.0000   58.0000    0.0005\n\n# Model: \n#              coeff        se         t         p      LLCI      ULCI\n# constant   -0.0215    0.0618   -0.3479    0.7292   -0.1451    0.1021\n# dysfunc     0.6198    0.1668    3.7148    0.0005    0.2858    0.9537\n\n# *********************************************************************** \n# Outcome Variable: perform\n\n# Model Summary: \n#           R      R-sq       MSE         F       df1       df2         p\n#      0.5586    0.3120    0.2015    6.2350    4.0000   55.0000    0.0003\n\n# Model: \n#              coeff        se         t         p      LLCI      ULCI\n# constant   -0.0321    0.0587   -0.5467    0.5868   -0.1496    0.0855\n# dysfunc     0.3661    0.1778    2.0585    0.0443    0.0097    0.7224\n# negtone    -0.4314    0.1312   -3.2890    0.0018   -0.6943   -0.1686\n# negexp     -0.0436    0.1134   -0.3841    0.7024   -0.2709    0.1838\n# Int_1      -0.5170    0.2409   -2.1458    0.0363   -0.9998   -0.0341\n\n# Product terms key:\n# Int_1  :  negtone  x  negexp      \n\n# Test(s) of highest order unconditional interaction(s):\n#       R2-chng         F       df1       df2         p\n# M*W    0.0576    4.6043    1.0000   55.0000    0.0363\n# ----------\n# Focal predictor: negtone (M)\n#       Moderator: negexp (W)\n\n# Conditional effects of the focal predictor at values of the moderator(s):\n#      negexp    effect        se         t         p      LLCI      ULCI\n#     -0.5437   -0.1504    0.2129   -0.7063    0.4830   -0.5770    0.2763\n#      0.0000   -0.4314    0.1312   -3.2890    0.0018   -0.6943   -0.1686\n#      0.5437   -0.7125    0.1530   -4.6565    0.0000   -1.0192   -0.4059\n\n# *********************************************************************** \n# Bootstrapping progress:\n#   |&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;| 100%\n\n# **************** DIRECT AND INDIRECT EFFECTS OF X ON Y ****************\n\n# Direct effect of X on Y:\n#      effect        se         t         p      LLCI      ULCI\n#      0.3661    0.1778    2.0585    0.0443    0.0097    0.7224\n\n# Conditional indirect effects of X on Y:\n\n# INDIRECT EFFECT:\n\n# dysfunc    -&gt;    negtone    -&gt;    perform\n\n#      negexp    Effect    BootSE  BootLLCI  BootULCI\n#     -0.5437   -0.0932    0.1537   -0.3751    0.2613\n#      0.0000   -0.2674    0.1193   -0.5282   -0.0591\n#      0.5437   -0.4416    0.1610   -0.7788   -0.1448\n\n#      Index of moderated mediation:\n#            Index    BootSE  BootLLCI  BootULCI\n# negexp   -0.3204    0.1887   -0.7753   -0.0491\n\n# ******************** ANALYSIS NOTES AND ERRORS ************************ \n\n# Level of confidence for all confidence intervals in output: 95\n\n# Number of bootstraps for percentile bootstrap confidence intervals: 5000\n\n# W values in conditional tables are the mean and +/- SD from the mean.\n \n# NOTE: The following variables were mean centered prior to analysis: \n#          negexp negtone",
    "crumbs": [
      "Statistics",
      "Interactions"
    ]
  },
  {
    "objectID": "contents/diagnostics.html",
    "href": "contents/diagnostics.html",
    "title": "Diagnostics",
    "section": "",
    "text": "\\(Y = \\beta_0 + \\beta_1 X + \\epsilon\\)\nOrdinary least squares (OLS)\n\nMean function: \\(E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i\\)\nDistribution: \\((Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\)\n\n\n\nSource: p.107, Applied Regression Analysis and Generalized Linear Models (3e), by John Fox\n\nGeneralized linear models (GLM)\nOLS의 가정에 맞지 않는 경우, 가정을 완화한 모델\n\nMean function: \\(E(Y | X = x_i) = f(\\beta_0 + \\beta_1 x_i)\\)\nDistribution: \\((Y | X = x_i) \\sim \\text{Exponential family}\\)\n\nBinary outcome: Logistic regression\n\nMean function: \\(\\displaystyle E(Y | X = x_i) = f(\\beta_0 + \\beta_1 x_i)\\),   \\(\\displaystyle f = \\frac{1}{1 + e^{-x}}\\) : sigmoid function\nDistribution: \\((Y | X = x_i) \\sim \\text{Bernoulli}(p)\\): n=1인 이항분포\n\nCount outcome: Poisson regression\n\nMean function: \\(\\displaystyle E(Y | X = x_i) = f(\\beta_0 + \\beta_1 x_i)\\),   \\(\\displaystyle f = e^x\\)\nDistribution: \\((Y | X = x_i) \\sim \\text{Poisson}(\\lambda_i)\\)\n\n전형적으로 나타나는 \\(X\\)와 \\(Y\\)의 관계\n\n\nSource: p.482, Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences (3e), by Cohen, J., Cohen, P., West, S. G., & Aiken, L. S.",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#generalized-linear-models",
    "href": "contents/diagnostics.html#generalized-linear-models",
    "title": "Diagnostics",
    "section": "",
    "text": "\\(Y = \\beta_0 + \\beta_1 X + \\epsilon\\)\nOrdinary least squares (OLS)\n\nMean function: \\(E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i\\)\nDistribution: \\((Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\)\n\n\n\nSource: p.107, Applied Regression Analysis and Generalized Linear Models (3e), by John Fox\n\nGeneralized linear models (GLM)\nOLS의 가정에 맞지 않는 경우, 가정을 완화한 모델\n\nMean function: \\(E(Y | X = x_i) = f(\\beta_0 + \\beta_1 x_i)\\)\nDistribution: \\((Y | X = x_i) \\sim \\text{Exponential family}\\)\n\nBinary outcome: Logistic regression\n\nMean function: \\(\\displaystyle E(Y | X = x_i) = f(\\beta_0 + \\beta_1 x_i)\\),   \\(\\displaystyle f = \\frac{1}{1 + e^{-x}}\\) : sigmoid function\nDistribution: \\((Y | X = x_i) \\sim \\text{Bernoulli}(p)\\): n=1인 이항분포\n\nCount outcome: Poisson regression\n\nMean function: \\(\\displaystyle E(Y | X = x_i) = f(\\beta_0 + \\beta_1 x_i)\\),   \\(\\displaystyle f = e^x\\)\nDistribution: \\((Y | X = x_i) \\sim \\text{Poisson}(\\lambda_i)\\)\n\n전형적으로 나타나는 \\(X\\)와 \\(Y\\)의 관계\n\n\nSource: p.482, Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences (3e), by Cohen, J., Cohen, P., West, S. G., & Aiken, L. S.",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#linear-least-squares-regression의-가정들",
    "href": "contents/diagnostics.html#linear-least-squares-regression의-가정들",
    "title": "Diagnostics",
    "section": "Linear Least Squares Regression의 가정들",
    "text": "Linear Least Squares Regression의 가정들\n\nL (linearity, 선형성): X의 각 값에 해당하는 Y값들의 평균들은 X와 선형적인 관계를 가짐.\n\nMean function: \\(E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i\\)\n\nI (independence, 독립성): 잔차들(errors)은 서로 독립.\nN (normally distributed, 정규성): X의 각 값에 해당하는 Y값들은 정규분포를 이룸.\n\n\\((Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\)\n\nE (equal variance, 등분산성): X의 각 값에 해당하는 Y값들의 표준편차들은 모두 동일함.\n\nVariance fucntion: \\(Var(Y | X = x_i) = \\sigma^2\\)\n\n\n\nSource: Beyond Multiple Linear Regression, by Paul Roback, Julie Legler.\n\n\n가정에 위배되는 연구/자료들\n\n공부한 시간에 따른 합격 여부\n\nY가 성공/실패 명목변수로서 0, 1로 코딩된다고 하면, Y는 정규분포를 이루지 않음.\n이런 경우 generalized linear model(GLM)의 일부로서 logistic regression 모형으로 fit을 하는 것이 더 적절함.\n\n부유한 가정은 더 적은 아이들을 가지는 경향이 있는가?\n\n가족의 크기는 정규분포를 이루기보단 한쪽으로 치우친(skewed) 분포를 이룸.\n가족의 크기는 0, 1, 2,… 등의 정수값을 가져, 연속형 변수로 보기 어려워 정규분포의 가정을 만족하기 어려움.\n이런 경우 가족의 크기는 Poisson 분포에 더 가깝다고 보고, Poisson regression 모형이나 그 변형들로 fit을 하는 것이 더 적절함.\n\n대학 안에서 임의로 선정한 남녀 학생들의 운동시간과 몸무게의 관계\n\n운동을 전혀 하지 않는 학생들의 몸무게의 변량이 규칙적으로 한 학생들에 비해 더 넓게 분포할 가능성이 큼: 이는 equal variance 가정을 위배함.\n만약, 대학 내에서 특정 장소들을 포함해 학생들을 섭외했다면, 예를 들어, 피트니스 센터에서 섭외된 학생들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n\n특정 질병을 가진 환자들에 대한 특정 수술에 대한 효과를 연구한다면,\n\n동일한 의사에게 수술을 받은 환자들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n동일한 병원에서 수술을 받은 환자들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n\n\n\n\n대처방안/대안들\n\nLinearity의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 고차 다항식 혹은 확장된 모형(eg. spline)을 사용\nNormality의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 generalized linear model(GLM)을 사용\nEqual variance의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 weighted least squares regression을 사용\nIndependence의 가정에 위배되는 경우: multi-level (mixed-effects) 모형을 사용",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#plotting-residuals",
    "href": "contents/diagnostics.html#plotting-residuals",
    "title": "Diagnostics",
    "section": "Plotting Residuals",
    "text": "Plotting Residuals\n잔차들의 분포: \\((e | X = x_i) \\sim N(0, \\sigma^2)\\)\n즉, 특별한 패턴이 없어야 함\n\n선형적 관계성(Linearity)이 확보되고,\n등분산성(Equal variance)이 확보됨.\n\n\nresidualPlots(\n  mod_prestige, \n  id=list(n=3), # outliers의 수\n  smooth=TRUE, # loess smooth 커브\n  quadratic=FALSE # 3차 fitted 커브\n)\n\n\n\n\n\n\n\n\n           Test stat Pr(&gt;|Test stat|)   \neducation    -0.6836         0.495942   \nincome       -2.8865         0.004854 **\ntype                                    \nTukey test   -2.6104         0.009043 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# 특정 변수만 선택\nresidualPlots(mod_prestige, ~ income, fitted=FALSE, smooth=TRUE, id=list(n=3))\n\n\n\n\n\n\n\n\n       Test stat Pr(&gt;|Test stat|)   \nincome   -2.8865         0.004854 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# QQplot: 전체적인 잔차의 분포가 정규분포를 따르는지 확인: y=x 라인에 가까울수록 정규분포를 따름\nqqPlot(mod_prestige, id=list(n=3)) # qq plot\n\n\n\n\n\n\n\n\n[1] 31 54 82\n\n\n등분산성(equal variance)이 심하게 위배되는 경우;\n\nmod_transact &lt;- lm(time ~ t1 + t2, data=Transact)\nresidualPlots(mod_transact, test=FALSE, layout=c(1, 3))\n\n\n\n\n\n\n\n\n통계적으로 등분산성(equal variance)을 테스트할 수 있음: ncvTest()\n\n\n\n\n\n\nNote\n\n\n\n등분산성을 만족하지 않는 경우: Heteroskedasticity\n\nWeighted least squares (WLS) 방식으로 추정\n좀 더 자연스러운 generalized linear model (GLM) with the identity link and gamma errors(확률 분포).\n등분산성은 회귀계수 값 자체는 크게 영향을 주지 않으므로, OLS로 회귀계수는 추정하되, 유의성 검증(SE, p values)은 bootstrap을 이용하거나 a sandwich coefficient-variance estimator로 계산하는 방식을 선택.\n\n\nlibrary(parameters)\nmodel_parameters(mod_transact) |&gt; print(digits=3)\n\nParameter   | Coefficient |      SE |              95% CI | t(258) |      p\n---------------------------------------------------------------------------\n(Intercept) |     144.369 | 170.544 | [-191.466, 480.205] |  0.847 | 0.398 \nt1          |       5.462 |   0.433 | [   4.609,   6.315] | 12.607 | &lt; .001\nt2          |       2.035 |   0.094 | [   1.849,   2.220] | 21.567 | &lt; .001\n\n\n\nSandwich coefficient-variance estimator\n\n\nmodel_parameters(mod_transact, vcov = \"HC3\") # HC3 방식\n\n# A tibble: 3 × 9\n  Parameter   Coefficient      SE    CI  CI_low CI_high      t df_error        p\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;\n1 (Intercept)      144.   203.     0.95 -256.    544.    0.711      258 4.78e- 1\n2 t1                 5.46   0.729  0.95    4.03    6.90  7.49       258 1.06e-12\n3 t2                 2.03   0.163  0.95    1.71    2.36 12.4        258 3.60e-28\n\n\n\nBootstrap\n\n\nlibrary(parameters)\nbootstrap_parameters(mod_transact, ci_method = \"BCI\") # BCI 방식\n\n# A tibble: 3 × 5\n  Parameter   Coefficient  CI_low CI_high     p\n  &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 (Intercept)      147.   -220.    542.    0.44\n2 t1                 5.52    4.02    6.68  0   \n3 t2                 2.03    1.74    2.34  0",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#added-variable-plots",
    "href": "contents/diagnostics.html#added-variable-plots",
    "title": "Diagnostics",
    "section": "Added-Variable Plots",
    "text": "Added-Variable Plots\nPartial regression plot이라고도 함.\n다른 변수들을 partial out시킨 잔차들로 그림.\n\n각 회귀계수에 대한 precision을 살펴볼 수 있음\n각 관측치에 대한 leverage를 살펴볼 수 있음\n\n\n# 수평선 중심에서 가장 먼 점들 2개\n# 잔차의 값이 가장 큰 점들 2개\navPlots(mod_prestige, id=list(n=2, cex=0.8)) # id: outliers의 수, cex: 점의 크기 80%\n\n\n\n\n\n\n\n# 특정 관측치 제거 후 다시 그림\nmod_prestige_1 = update(mod_prestige, subset = -c(2, 24))  # 2, 24번째 관측치 제거\navPlots(mod_prestige_1)\n\n\n\n\n\n\n\n\n\ncompareCoefs(mod_prestige, mod_prestige_1, se = FALSE, pvals = TRUE)\n\nCalls:\n1: lm(formula = prestige ~ education + income + type, data = Prestige)\n2: lm(formula = prestige ~ education + income + type, data = Prestige, \n  subset = -c(2, 24))\n\n            Model 1 Model 2\n(Intercept)  -0.623   0.749\nPr(&gt;|z|)      0.905   0.889\n                           \neducation      3.67    3.31\nPr(&gt;|z|)    9.8e-09 1.5e-06\n                           \nincome      0.00101 0.00133\nPr(&gt;|z|)    4.5e-06 1.2e-05\n                           \ntypewc        -2.74   -1.66\nPr(&gt;|z|)      0.276   0.526\n                           \ntypeprof       6.04    7.18\nPr(&gt;|z|)      0.118   0.071",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#unusual-data",
    "href": "contents/diagnostics.html#unusual-data",
    "title": "Diagnostics",
    "section": "Unusual Data",
    "text": "Unusual Data\n\noutliers: 모형의 예측값과 크게 다른 관측치\nhigh-leverage points: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 관측치\ninfluential points: outlier이면서 high-leverage point인 관측치\n\n우선, 위에서 다룬 add-variable plots를 통해서 두 변수의 joint로써 influential points를 찾을 수 있음.\n다음은 각 변수들 내에서의 influential points에 관한 진단임.\n예제: Duncan 데이터셋\n\nDuncan &lt;- Duncan |&gt; as_tibble()\nDuncan\n\n# A tibble: 45 × 4\n   type  income education prestige\n   &lt;fct&gt;  &lt;int&gt;     &lt;int&gt;    &lt;int&gt;\n 1 prof      62        86       82\n 2 prof      72        76       83\n 3 prof      75        92       90\n 4 prof      55        90       76\n 5 prof      64        86       90\n 6 prof      21        84       87\n 7 prof      64        93       93\n 8 prof      80       100       90\n 9 wc        67        87       52\n10 prof      72        86       88\n# ℹ 35 more rows\n\nmod_duncan &lt;- lm (prestige ~ income + education, data=Duncan)\nS(mod_duncan)\n\nCall: lm(formula = prestige ~ income + education, data = Duncan)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.06466    4.27194  -1.420    0.163    \nincome       0.59873    0.11967   5.003 1.05e-05 ***\neducation    0.54583    0.09825   5.555 1.73e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 13.37 on 42 degrees of freedom\nMultiple R-squared: 0.8282\nF-statistic: 101.2 on 2 and 42 DF,  p-value: &lt; 2.2e-16 \n   AIC    BIC \n365.96 373.19 \n\n\n\nOutliers\nqqPlot(): 95% pointwise confidence envelope for the Studentized residuals, using a parametric version of the bootstrap.\noutlierTest(): Bonferroni-adjusted p-values for the Studentized residuals.\n\nqqPlot(mod_duncan, id=list(n=3))\n\n\n\n\n\n\n\n\n[1]  6  9 17\n\noutlierTest(mod_duncan)\n\nNo Studentized residuals with Bonferroni p &lt; 0.05\nLargest |rstudent|:\n  rstudent unadjusted p-value Bonferroni p\n6 3.134519          0.0031772      0.14297\n\n\n\n\nInfluential points에 대한 지표들\n\nCook’s distance: i번째 관측치가 제거되었을 때 회귀계수의 변화량에 대한 요약치\nStudentized residuals: 표준화한 잔차\nBonferroni-adjusted p-values: 잔차의 분포에 대한 p-value를 Bonferroni 방식으로 보정한 값\nhat-values: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 정도\n\n가장 큰 값들에 해당하는 관측치들을 제거해보고 회귀분석을 한 후 결과를 비교\n원칙적으로 한번에 한 관측치만 제거하고, 차례로 진단을 해야 함; 전체적인 fit이 변하므로\n\ninfluenceIndexPlot(mod_duncan)\n\n\n\n\n\n\n\n# 6번째 관측치 제거\nmod_duncan2 &lt;- update(mod_duncan, subset = -6)\ncompareCoefs(mod_duncan, mod_duncan2, pvals = TRUE)\n\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -6)\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.63\nSE             4.27    3.89\nPr(&gt;|z|)      0.156   0.088\n                           \nincome        0.599   0.732\nSE            0.120   0.117\nPr(&gt;|z|)    5.6e-07 3.7e-10\n                           \neducation    0.5458  0.4330\nSE           0.0983  0.0963\nPr(&gt;|z|)    2.8e-08 6.9e-06\n                           \n\n# leave-one-out deletion diagnostics\n# i번째 관측치를 제거했을 때, 각 예측변수들의 변화량을 나타냄\n# dfbeta: 차이, debetas: SE로 표준화한 차이\ndfbetas(mod_duncan) |&gt; head() |&gt; print(digits = 2)\n\n  (Intercept)   income education\n1    -2.3e-02  0.00067   0.03594\n2    -2.5e-02  0.05088  -0.00812\n3    -9.2e-03  0.00648   0.00562\n4    -4.7e-05 -0.00006   0.00014\n5    -6.6e-02  0.01700   0.08678\n6     1.4e-01 -1.22094   1.26302\n\n\n\n# dfbetas를 플랏으로 나타내면,\ndf &lt;- dfbetas(mod_duncan) |&gt; as_tibble()\n\nlibrary(ggrepel)\ndf |&gt; \n  ggplot(aes(x=income, y=education)) +\n  geom_point() +\n  geom_text_repel(aes(label = row.names(df)))\n\n\n\n\n\n\n\n\nAdded-variable plot으로도 확인해 볼 수 있음\n\nInfluential points가 각 예측변수에서 살펴보는 것과는 다르게\nAdded-variable plot은 joint로써의 영향력을 보고 outliers를 찾을 수 있음\n\n\navPlots(mod_duncan, id=list(n=3, method=\"mahal\")) # 중심으로부터의 거리(mahalanobis distance)만 표시\n\n\n\n\n\n\n\n\n\n# 6, 16번째 관측치 제거\nmod_duncan3 &lt;- update(mod_duncan, subset = -c(6, 16))\ncompareCoefs(mod_duncan, mod_duncan3)\n\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -c(6,\n   16))\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.41\nSE             4.27    3.65\n                           \nincome        0.599   0.867\nSE            0.120   0.122\n                           \neducation    0.5458  0.3322\nSE           0.0983  0.0987",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#선형성에-대한-진단",
    "href": "contents/diagnostics.html#선형성에-대한-진단",
    "title": "Diagnostics",
    "section": "선형성에 대한 진단",
    "text": "선형성에 대한 진단\nComponent-Plus-Residual (partial-residual plots): \\(\\displaystyle e+{\\hat {\\beta }}_{i}X_{i}\\)\ncrPlots()\n초기 탐색적 분석이나 모형을 세우 후 residualPlots으로도 살펴볼 수 있음.\n비선형성에 대해서는 변수를 변환(transform)하거나 고차 다항함수 모형, 혹은 더 복잡한 spline 모형을 이용.\n\nmod_prestige_2 &lt;- lm(prestige ~ income + education + women, data=Prestige)\ncrPlots(mod_prestige_2)",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#변수의-변환transform-및-고차원-모형",
    "href": "contents/diagnostics.html#변수의-변환transform-및-고차원-모형",
    "title": "Diagnostics",
    "section": "변수의 변환(transform) 및 고차원 모형",
    "text": "변수의 변환(transform) 및 고차원 모형\n선형성, 등분산성, 정규성 등은 각각 다른 개념이나 변수의 변형을 통해 동시에 해결되기도 함.\n\nlog변환은 정규성과 선형성을 동시에 해결해주는 경우가 많음.\n또한 의미적으로도 해석이 용이함. 몇 배의 의미로 바뀜.\n복잡한 변환에 대해서 다음을 참조\n\nBox-Cox Power Transformations\npowerTransform()\n\n\n예제: UN in carData\n\n\n\n\n\n\ncode\n\n\n\n\n\nUN |&gt; \n  ggplot(aes(x=ppgdp)) +\n  geom_density()\nUN |&gt; \n  ggplot(aes(x=infantMortality)) +\n  geom_density()\nUN |&gt; \n  ggplot(aes(x=ppgdp, y=infantMortality)) +\n  geom_point() +\n  geom_smooth()\nUN |&gt; \n  ggplot(aes(x=log(ppgdp), y=log(infantMortality))) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n위의 Presitge의 예의 경우, income을 log변환하는 것이 적절함.\nmod_prestige &lt;- lm(prestige ~ education + income + type, data = Prestige)\nmod_prestige_log &lt;- lm(prestige ~ education + log2(income) + type, data = Prestige)\n\nresidualPlots(mod_prestige, ~income, test=FALSE, fitted=FALSE)\nresidualPlots(mod_prestige_log, ~log2(income), test=FALSE, fitted=FALSE)\nS(mod_prestige_log)\n\n\n\n\n\n\n\n\n\n\n\nCall: lm(formula = prestige ~ education + log2(income) + type, data = Prestige)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -81.2019    13.7431  -5.909 5.63e-08 ***\neducation      3.2845     0.6081   5.401 5.06e-07 ***\nlog2(income)   7.2694     1.1900   6.109 2.31e-08 ***\ntypewc        -1.4394     2.3780  -0.605   0.5465    \ntypeprof       6.7509     3.6185   1.866   0.0652 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 6.637 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8555\nF-statistic: 137.6 on 4 and 93 DF,  p-value: &lt; 2.2e-16 \n   AIC    BIC \n655.93 671.44 \n\n\n\n이 때, log2(income)에 대한 회귀계수의 해석은 income이 2배 늘면(=log2(income)이 1증가하면) prestige가 7.27점 증가하는지를 나타냄.\n변수의 변환이 아닌 모형의 복잡도를 높혀 좀 더 나은 fit을 얻을 수도 있음.\n\n다항함수 모형\nSpline 모형\n\n예제: CPS85 in mosaicData\n\n\n\n\n\n\ncode\n\n\n\n\n\ncps &lt;- mosaicData::CPS85 |&gt; as_tibble()\ncps2 &lt;- cps |&gt; \n  mutate(log_wage = log(wage)) |&gt; \n  filter(wage &lt; 30 & log_wage &gt; 1)\n\ncps2 |&gt;\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .7) +\n  geom_smooth() +\n  scale_y_continuous(label = scales::label_dollar()) +\n  labs(y = \"wage (dollars per hour)\")\n\ncps2 |&gt;\n  ggplot(aes(x = wage)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmod_cps_poly &lt;- lm(log_wage ~ married * sex + age + I(age^2), data = cps2) # 2차 다항함수\nresidualPlots(mod_cps_poly, test=FALSE)\n\n\n\n\n\n\n\n\nSpline 모형: piece-wise polynomial\nbs(), ns() in splines 패키지\n\nns(): natural spline 모형 (boundary constraints)\n\n\nlibrary(splines)\nmod_cps_ns &lt;- lm(log_wage ~ married * sex + ns(age, 3), data = cps2) # 3-piecewise natural spline\n\n다항함수 모형과 spline 모형의 비교\nlibrary(effects)\nplot(predictorEffects(mod_cps_poly, ~age))\nplot(predictorEffects(mod_cps_ns, ~age))",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/diagnostics.html#다중공선성에-대한-진단",
    "href": "contents/diagnostics.html#다중공선성에-대한-진단",
    "title": "Diagnostics",
    "section": "다중공선성에 대한 진단",
    "text": "다중공선성에 대한 진단\nOLS의 가정과는 관계없으나, 통계적 파워를 낮추는 요인이 됨.\n탐색적 분석 과정에서 변수들 간에 심각하게 상관계수(r)가 높은 경우 주의\n지표로는 Variance Inflation Factor(VIF)\n\n예를 들어, \\(X_1\\)에 대한 VIF: \\(\\displaystyle {1 - R^2_{1.23}}\\) 의 역수\n즉, \\(X_2, X_3\\)로 \\(X_1\\)이 설명되지 않는, 즉 독립적인 정도의 역수\n다른 예측 변수들로 잘 설명되는 예측변수라면, standard error(SE)가 증폭되어 회귀계수의 신뢰성이 떨어짐. (불안정하다는 의미)\nVIF 값은 예측변수들이 서로 독립적일 때에 비해 SE가 얼마나 증폭되는지를 나타냄.\nVIF 값이 10 이면 \\(\\sqrt{10}=3.16\\) 배의 SE 증폭이 발생.\nVIF 값이 10 이상이면 심각한 다중공선성이 발생했다고 판단.\n상호작용항이 포함된 경우, (두 변수의 곱으로 만든 항이므로) centering을 하지 않은 경우, VIF값이 크게 나올 수 있으나 실질적인 문제는 전혀 없음.\n\n\nmod_prestige_2 &lt;- lm(prestige ~ income + education + women, data=Prestige)\nsumm(mod_prestige_2, vif=TRUE, model.info = FALSE) |&gt; print()\n\nMODEL FIT:\nF(3,98) = 129.19, p = 0.00\nR² = 0.80\nAdj. R² = 0.79 \n\nStandard errors: OLS\n-------------------------------------------------------\n                     Est.   S.E.   t val.      p    VIF\n----------------- ------- ------ -------- ------ ------\n(Intercept)         -6.79   3.24    -2.10   0.04       \nincome               0.00   0.00     4.73   0.00   2.28\neducation            4.19   0.39    10.77   0.00   1.85\nwomen               -0.01   0.03    -0.29   0.77   1.53\n-------------------------------------------------------",
    "crumbs": [
      "Statistics",
      "Diagnostics"
    ]
  },
  {
    "objectID": "contents/case5.html",
    "href": "contents/case5.html",
    "title": "Papers",
    "section": "",
    "text": "Asner-Self & Marotta (2005)의 연구\nAsner‐Self, K. K., & Marotta, S. A. (2005). Developmental indices among Central American immigrants exposed to war‐related trauma: Clinical implications for counselors. Journal of Counseling & Development, 83(2), 162-171.\n\n전쟁 관련 외상에 노출되었던 68명의 중앙아메리카 이민자들을 대상\n심리적 스트레스(우울, 불안, 외상성 스트레스)(DV)에 대한 예측변수들(IV)을 검증: 1) 불신, 2) 정체성 혼란, 3) 고립\n세 하위 척도 각각이 다른 두 하위척도와는 독립적인(independent)/고유한(unique) 심리적 스트레스에 주는 영향을 파악할 수 있음.\n\n\n\n\nPina-Watson, Jimenez & Ojeda (2014)의 연구\nPiña‐Watson, B., Jimenez, N., & Ojeda, L. (2014). Self‐construal, career decision self‐efficacy, and perceived barriers predict Mexican American women’s life satisfaction. The Career Development Quarterly, 62(3), 210-223.\n\n멕시코계 미국인 여대생을 대상으로\n 1) 진로결정 자기효능감, 2) 지각된 교육 관련 장벽, 3) 독립적 자기-구인(independent self-construal)(IVs)이 삶의 만족(DV)을 얼마나 예측하는가를 검증\n이 때, 사회경제적 지위(SES)와 세대 지위(genertional status)가 설명하는 것 이상으로 DV를 설명하는지 검증\n\nGenerational status: 1st: immigrants, 2nd: (U.S. born, parents were immigrants), 3th (parents were U.S. born), 4th: (grandparents were U.S. born), 5th: (great grandparents were U.S. born)\n\n\n\n  \n\n\n\nMoradi와 Hasan (2004)의 연구: Path Analysis(경로 분석)\n\n아랍계 미국인을 대상으로 차별의 경험이 자아존중감/심리적 스트레스을 어떻게 변화시키는지를 검증\n개인적 통제감(personal control)이 상실됨에 따른 결과라고 추론\n\n\n \n\n\nWei, Vogel, Ku,와 Zakalik (2005)의 연구: SEM\n애착을 척도 Experiences in Close Relationships Scale (ECRS; Brennan et al., 1998)로 측정 후 2개의 요인으로 나누어 불안/회피 척도로 활용\n\n불안 하위 척도(18개 항목): 거절에 대한 두려움과 버려짐에 대한 강박관념을 측정; “나는 버려질까 봐 걱정된다.”\n회피 하위 척도(18개 항목): 친밀감에 대한 두려움과 타인과 가까워지는 것에 대한 불편함 또는 의존성을 평가; “나는 파트너가 나에게 너무 가까이 다가오면 긴장한다.”\n\nDifferentiation of Self Inventory(DSI; Skowron & Friedlander, 1998)에서 두 하위 척도 사용\n\n감정 반응성 하위 척도(11개 항목): 환경 자극에 감정이 넘치거나, 감정이 불안정하거나, 과민하게 반응하여 감정에 휩쓸릴 정도로 반응하는 정도를 반영; “때때로 나는 마치 감정의 롤러코스터를 타는 것처럼 느낀다.”\n정서적 단절 하위 척도(12개 항목): 내면의 감정 경험이나 대인관계가 너무 강렬할 때 친밀감에 위협을 느끼고 타인과 자신의 감정으로부터 자신을 고립시키는 것을 반영; “나는 가족 중 누구에게도 정서적 지원을 요청하는 것을 고려하지 않는다.” (번역 by DeepL)\n\n\n\n\n\nSEM (구조방정식 모형)\nPath analysis + Confirmatory factor analysis (CFA)\n변수들 간의 인과 관계에 대한 가설 모형\n\nMartens, M. P. (2005). The use of structural equation modeling in counseling psychology research. The Counseling Psychologist, 33(3), 269–298.",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Papers"
    ]
  },
  {
    "objectID": "contents/case3.html",
    "href": "contents/case3.html",
    "title": "Case 3",
    "section": "",
    "text": "Source: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels &lt;- read_csv(\"data/nels88_sample.csv\")\nnels &lt;- nels |&gt; \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# summarize data\nsummary(nels)\n\n# count values\nnels |&gt; count(pared)\nnels |&gt; count(hw_out)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines &lt;- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 &lt;- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 3"
    ]
  },
  {
    "objectID": "contents/case3.html#national-education-longitudinal-study-of-1988-nels88",
    "href": "contents/case3.html#national-education-longitudinal-study-of-1988-nels88",
    "title": "Case 3",
    "section": "",
    "text": "Source: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels &lt;- read_csv(\"data/nels88_sample.csv\")\nnels &lt;- nels |&gt; \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# summarize data\nsummary(nels)\n\n# count values\nnels |&gt; count(pared)\nnels |&gt; count(hw_out)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines &lt;- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 &lt;- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 3"
    ]
  },
  {
    "objectID": "contents/case1.html",
    "href": "contents/case1.html",
    "title": "Case 1",
    "section": "",
    "text": "Source: Statistical Methods for Psychology (8e) by Dave C. Howell\n\n\n\n\n\n\n\n5개월의 아기를 양육하는 92명의 어머니를 대상\n본인이 아이였을 때 어머니에게 받은 양육(maternal care) 정도가 자신이 어머니가 되었을 때 아이를 향한 양육효능감으로 이전될 것이라는 가설\n매개변수로 maternal care로부터 영향을 받은 자존감(self-esteem)을 고려.\n데이터: maternal_care.sav\n\n\n\n\n\n\n\n\nlibrary(haven)\nmaternal &lt;- read_spss(\"howell/maternal_care.sav\")\nmaternal\n\n# A tibble: 92 × 4\n   FAMID Esteem MatCare Efficacy\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1     1   3.83    2.58      3.7\n 2     2   3.5     2.83      3.4\n 3     4   4       3.17      3.8\n 4     8   4       3.75      3.9\n 5     9   4       3.58      3.9\n 6    11   3.33    3.67      3.7\n 7    12   3.5     3.25      3.8\n 8    13   3.67    3.75      3.5\n 9    15   1.83    3.17      3.1\n10    16   2.83    2.67      3.5\n# ℹ 82 more rows\n\n# correlations\n# library(psych)\nlowerCor(maternal[-1])  # lowerCor(maternal[2:4])과 동일 \n\n         Estem MatCr Effcc\nEsteem   1.00             \nMatCare  0.40  1.00       \nEfficacy 0.38  0.27  1.00 \n\n\n\nGGally::ggpairs(maternal[-1])\n\n\n\n\n\n\n\n\n\nmod1 &lt;- lm(Efficacy ~ MatCare, data = maternal)\nmod2 &lt;- lm(Efficacy ~ MatCare + Esteem, data = maternal)\n\n# compare models\n# library(jtools)\nexport_summs(mod1, mod2, error_format = \"(p = {p.value})\") |&gt; print()\n\n\n\n                ───────────────────────────────────────────────\n                                   Model 1         Model 2     \n                              ─────────────────────────────────\n                  (Intercept)        3.27 ***        2.94 ***  \n                                (p = 0.00)      (p = 0.00)     \n                  MatCare            0.11 *          0.06      \n                                (p = 0.01)      (p = 0.20)     \n                  Esteem                             0.15 **   \n                                                (p = 0.00)     \n                              ─────────────────────────────────\n                  N                 92              92         \n                  R2                 0.07            0.16      \n                ───────────────────────────────────────────────\n                  *** p &lt; 0.001; ** p &lt; 0.01; * p &lt;            \n                  0.05.                                        \n\nColumn names: names, Model 1, Model 2\n\n\n\n\nsumm(mod2, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors:OLS\n--------------------------------------------------------------------\n                    Est.   S.E.   t val.      p   partial.r   part.r\n----------------- ------ ------ -------- ------ ----------- --------\n(Intercept)         2.94   0.17    16.95   0.00                     \nMatCare             0.06   0.04     1.30   0.20        0.14     0.13\nEsteem              0.15   0.05     3.02   0.00        0.31     0.29\n--------------------------------------------------------------------",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 1"
    ]
  },
  {
    "objectID": "contents/case1.html#leerkes-and-crockenberg-1999의-육아에-대한-효능감-연구",
    "href": "contents/case1.html#leerkes-and-crockenberg-1999의-육아에-대한-효능감-연구",
    "title": "Case 1",
    "section": "",
    "text": "Source: Statistical Methods for Psychology (8e) by Dave C. Howell\n\n\n\n\n\n\n\n5개월의 아기를 양육하는 92명의 어머니를 대상\n본인이 아이였을 때 어머니에게 받은 양육(maternal care) 정도가 자신이 어머니가 되었을 때 아이를 향한 양육효능감으로 이전될 것이라는 가설\n매개변수로 maternal care로부터 영향을 받은 자존감(self-esteem)을 고려.\n데이터: maternal_care.sav\n\n\n\n\n\n\n\n\nlibrary(haven)\nmaternal &lt;- read_spss(\"howell/maternal_care.sav\")\nmaternal\n\n# A tibble: 92 × 4\n   FAMID Esteem MatCare Efficacy\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1     1   3.83    2.58      3.7\n 2     2   3.5     2.83      3.4\n 3     4   4       3.17      3.8\n 4     8   4       3.75      3.9\n 5     9   4       3.58      3.9\n 6    11   3.33    3.67      3.7\n 7    12   3.5     3.25      3.8\n 8    13   3.67    3.75      3.5\n 9    15   1.83    3.17      3.1\n10    16   2.83    2.67      3.5\n# ℹ 82 more rows\n\n# correlations\n# library(psych)\nlowerCor(maternal[-1])  # lowerCor(maternal[2:4])과 동일 \n\n         Estem MatCr Effcc\nEsteem   1.00             \nMatCare  0.40  1.00       \nEfficacy 0.38  0.27  1.00 \n\n\n\nGGally::ggpairs(maternal[-1])\n\n\n\n\n\n\n\n\n\nmod1 &lt;- lm(Efficacy ~ MatCare, data = maternal)\nmod2 &lt;- lm(Efficacy ~ MatCare + Esteem, data = maternal)\n\n# compare models\n# library(jtools)\nexport_summs(mod1, mod2, error_format = \"(p = {p.value})\") |&gt; print()\n\n\n\n                ───────────────────────────────────────────────\n                                   Model 1         Model 2     \n                              ─────────────────────────────────\n                  (Intercept)        3.27 ***        2.94 ***  \n                                (p = 0.00)      (p = 0.00)     \n                  MatCare            0.11 *          0.06      \n                                (p = 0.01)      (p = 0.20)     \n                  Esteem                             0.15 **   \n                                                (p = 0.00)     \n                              ─────────────────────────────────\n                  N                 92              92         \n                  R2                 0.07            0.16      \n                ───────────────────────────────────────────────\n                  *** p &lt; 0.001; ** p &lt; 0.01; * p &lt;            \n                  0.05.                                        \n\nColumn names: names, Model 1, Model 2\n\n\n\n\nsumm(mod2, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors:OLS\n--------------------------------------------------------------------\n                    Est.   S.E.   t val.      p   partial.r   part.r\n----------------- ------ ------ -------- ------ ----------- --------\n(Intercept)         2.94   0.17    16.95   0.00                     \nMatCare             0.06   0.04     1.30   0.20        0.14     0.13\nEsteem              0.15   0.05     3.02   0.00        0.31     0.29\n--------------------------------------------------------------------",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 1"
    ]
  },
  {
    "objectID": "contents/case1.html#mediation-analysis-매개-분석",
    "href": "contents/case1.html#mediation-analysis-매개-분석",
    "title": "Case 1",
    "section": "Mediation Analysis (매개 분석)",
    "text": "Mediation Analysis (매개 분석)\nBaron, R. M., & Kenny, D. A. (1986). David A. Kenny website\n\n많은 문제점들이 지적되었으며, 이후 계속 extensively revised\n인과 추론에 대한 큰 틀에서 새롭게 접근할 필요가 있음\n\n참고: The Effect: An Introduction to Research Design and Causality\n독립변수가 종속변수에 어떻게(how) 영향을 주는지를 파악; 기제(메커니즘)을 파악\n기제를 파악하는 것은 개입의 효과가 어떻게 일어나는지에 대한 핵심 요소를 규정할 수 있고, 변화과정을 최적화 할 수 있도록 도움을 줌.\n매개 효과는 인과에 대한 강력한 주장을 하는 것이고, 회귀 분석이 기본적으로는 상관관계에 기초한다는 점에서 항상 인과관계에 대해서는 다양한 검증과 깊은 연구가 필요함\n\n변수들 간의 관계에 대한 충분히 설득력있는 이론적 근거가 필요\n추가적 실험 설계나 사전 연구들로 보완해야 함\n변수들 간의 관계를 왜곡할 수 있는 변수들을 모두 분석에 포함해야 함\n\n일반적으로 여러 변수 간의 관계를 동시에 추정하는 SEM(structural equation modeling)의 프레임워크로 분석함\n매개효과 존재의 검증?\n\n\nX → M의 인과 관계를 실험적으로 검증\nM → Y의 인과 관계를 실험적으로 검증\n\n이 때, X → Y의 인과 관계가 유추되는가?\n만약, N을 거쳐가는 효과가 존재한다면?\n\nX → Y의 효과는 0이거나 마이너스가 될 수 있음.\n실제 X → Y의 효과가 없는 경우에도 매개효과를 찾으려는 노력을 하기를 제안하고 있음.\n\n\n이제 X → Y의 인과 관계를 실험적으로 검증하면 되는가?\n\nM이 Y보다 이전에 발생한 것이라는 근거는? Y → M을 발생시킬 수 없는가?\n참고, 직접 효과(direct effect) vs. 간접 효과(indirect effect)의 표현에서 직접효과라는 표현보다는 omiited mediator라는 표현을 사용하는 것이 더 적절함.\n\npsych 패키지의 mediate()\n\n# library(psych)\nfit_Efficacy &lt;- psych::mediate(Efficacy ~ MatCare + (Esteem), data = maternal)\nsummary(fit_Efficacy)\n\n\n\n\n\nProcess Macro by Andrew F. Hayes\nAndrew F. Hayes website\nMacro download link: PROCESS v4.3 for R 폴더 안에 있는 process.R 파일을 이용\n\nsource(\"process.R\")\n\nprocess(data=maternal, y=\"Efficacy\", m=\"Esteem\", x=\"MatCare\", model=4, total=1, bc=1, boot=1000) # stand=1: standardized coefficients\n\n\n\n통제 변수를 함께 고려한 예\n\nSource: p.133, Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach by Andrew F. Hayes\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n이를 설명하기 위해 3.5절에서 설명한 경제적 스트레스 연구를 다시 살펴보겠습니다. Pollack 등(2012)은 262명의 기업가들이 경기 침체기에 경험한 경제적 스트레스와 비즈니스 관련 우울한 영향, 그리고 창업 철수 의도를 평가한 바 있습니다. 단순 매개 분석 결과, 경제적 스트레스가 우울 정서에 미치는 영향을 통해 간접적으로 사업에서 철수하려는 욕구를 유발할 수 있다는 주장과 일치하는 결과가 나왔습니다. 즉, 경제적 스트레스를 더 많이 경험했다고 응답한 사람들은 사업 관련 우울 정서를 더 강하게 느꼈고(a = 0.173), 우울 정서를 더 많이 경험한 사람들은 경제적 스트레스를 보정한 후에도 창업 철회 의도가 더 높았습니다(b = 0.769). 간접 효과는 통계적으로 0과 차이가 없었습니다(ab = 0.133, 95% 부트스트랩 신뢰 구간은 0.071~0.201). 경제적 스트레스가 탈퇴 의도에 미치는 직접적인 영향에 대한 증거는 없었습니다(c′ = -0.077, p = .144). 간접적인 효과는 스트레스가 높아지면 우울한 정서로 이어져 창업 철회 의도로 이어지는 일련의 사건을 반영할 수 있습니다. 하지만 이러한 데이터는 단발성 관찰 연구에서 나온 결과라는 점을 기억하세요. 어떤 것도 조작되지 않았고, 시간이 지남에 따라 측정된 것도 없으며, 잠재적인 혼동 가능성이 많습니다. 예를 들어, 간접 효과는 비즈니스 관리에 대한 자신의 자신감이나 기술에 대한 인식과 같은 개인차가 아닌 다른 것에 의해 나타날 수 있습니다. 자신의 능력에 대해 상대적으로 더 자신감을 느끼는 사람들은 일반적으로 스트레스를 상대적으로 덜 느끼는 경향이 있고, 어떤 상황에서도 자신의 사업에 대해 부정적이고 낙담하는 경향이 적으며, 자신감이 낮은 사람보다 상대적으로 더 일을 즐기는 경향이 있을 수 있습니다. 그렇다면 경제적 스트레스의 간접 효과를 평가할 때 이러한 개인차를 통계적으로 통제하면 그 효과가 약화되거나 제거되어야 합니다. 즉, 자신감이 동일한 사람들 사이에서 경제적 스트레스가 우울한 영향을 통해 인출 의도에 미치는 간접 효과의 증거가 없어야 하는데, 이 추론에 따르면 이 변수는 X와 M, M과 Y 사이의 허위 연관성을 유도하는 과정에서 제거되었기 때문입니다. 그러나 자신감을 일정하게 유지하더라도 간접 효과가 지속된다면 인과 관계 주장은 여전히 유효합니다. 이 대안적 설명은 신뢰도와 유사한 무언가가 측정된 경우에만 시험해 볼 수 있습니다. 다행히도 Pollack 등(2012)은 “기업가적 자기 효능감”(Chen, Green, & Crick, 1998)이라는 측정치를 포함시켰습니다. 이 측정은 목표 설정 및 달성, 신제품 개발, 위험 관리, 의사 결정 등 다양한 기업가정신 관련 업무를 성공적으로 수행할 수 있는 자신의 능력에 대한 자신감을 지수화한 것입니다(ESTRESS 데이터 파일에 있는 ESE). 실제로 기업가적 자기효능감이 상대적으로 낮은 집단에 비해 기업가적 자기효능감이 상대적으로 높은 집단은 경제적 스트레스를 상대적으로 덜 느끼고(r = -0.158, p = .010), 비즈니스 관련 우울 영향을 상대적으로 덜 받으며(r = -0.246, p &lt; .001), 기업가정신에 대한 몰입 의도가 상대적으로 약하다고 응답했습니다(r = -0.243, p &lt; .001). 따라서 경제적 스트레스, 우울한 정동, 철수 의도 간에 관찰된 관계 중 적어도 일부에 대해서는 가짜 연관성 또는 표피적 연관성이 그럴듯한 대체 설명이 될 수 있습니다. 기업가적 자기 효능감과 추정 중인 인과 모형의 주요 변수 간의 공통된 연관성을 설명하기 위해 기업가적 자기 효능감(C1)을 우울 정동(M)과 철수 의도(Y) 모두에 대한 방정식에 포함시켰습니다. 또한 단일 변수가 통계적 통제변수로 사용될 수 있음을 설명하기 위해 참여자의 성별(데이터의 SEX, 0 = 여성, 1 = 남성)과 비즈니스에 종사한 기간(년 단위, C3, 데이터의 TENURE)을 예측변수로 포함시켰습니다. 따라서 경제적 스트레스의 직간접적 영향을 정량화하기 위해 추정된 방정식은 다음과 같습니다.\n이러한 종류의 분석은 이러한 통제 없이 비교 분석의 결과가 통제 대상 변수를 포함하는 대체 설명에 얼마나 민감하거나 취약한지를 확인하기 위해 수행하거나, 특정 변수가 인과 체계의 주요 변수 간에 가짜 연관성을 생성할 수 있다는 것이 선험적으로 알려져 있거나 예비 분석에 근거하여 수행될 수 있습니다. 일시적인 현상이나 가짜 연관성을 대체 설명으로 배제하는 것은 본질적으로 상관관계만 있는 연관성을 포함하는 모든 인과 관계 논증에서 중요한 부분입니다. 하지만 그렇다고 해서 이러한 효과를 인과관계로 일률적으로 해석할 수 있다는 의미는 아닙니다. 물론 이 분석에서 고려되지 않은 다른 혼란 변수가 X, M, Y 사이에 관찰된 연관성을 만들어내고 있을 수 있습니다. 이것이 이 접근법의 문제점 중 하나입니다. 측정된 잠재적 혼동 변수만 설명할 수 있으며, 올바른 잠재적 혼동 변수가 존재한다면 통계적으로 통제되었는지 여부를 알 수 없습니다. 연관성에 대해 이러한 대체 해석이 존재할 수 있을 때 할 수 있는 최선의 방법은 이러한 교란 위협을 예상하고, 연구 중에 이를 측정하며, 분석에서 수학적으로 설명할 수 없는 그럴듯한 대체 교란 변수를 생각해낼 수 있는 비평가가 없기를 바라는 것입니다.\n\n\n\n\n\nData files link from Andrew F. Hayes\n\nestress &lt;- haven::read_sav(\"data/hayes2022data/estress/estress.sav\")\n\nprocess(data=estress, y=\"withdraw\", x=\"estress\", m=\"affect\", cov=c(\"ese\",\n    \"sex\",\"tenure\"), total=1, model=4)  # total: includes total effect\n\n\n\npsych 패키지의 mediate()를 사용하면,\n\nestress &lt;- haven::read_sav(\"data/hayes2022data/estress/estress.sav\")\n\nfit_estress &lt;- psych::mediate(withdraw ~ estress + (affect) + ese + sex, data = estress)\n\n\n\n\n\n\n\nsummary(fit_estress)\n\nCall: psych::mediate(y = withdraw ~ estress + (affect) + ese + sex, \n    data = estress)\n\nDirect effect estimates (traditional regression)    (c') X + M on Y \n          withdraw   se     t  df     Prob\nIntercept     2.73 0.54  5.04 257 8.91e-07\nestress      -0.09 0.05 -1.80 257 7.25e-02\nese          -0.21 0.08 -2.78 257 5.92e-03\nsex           0.13 0.14  0.89 257 3.76e-01\naffect        0.71 0.10  6.81 257 6.70e-11\n\nR = 0.45 R2 = 0.21   F = 16.66 on 4 and 257 DF   p-value:  3.76e-12 \n\n Total effect estimates (c) (X on Y) \n          withdraw   se     t  df     Prob\nIntercept     3.94 0.55  7.11 258 1.14e-11\nestress       0.02 0.05  0.30 258 7.62e-01\nese          -0.32 0.08 -3.94 258 1.03e-04\nsex           0.14 0.16  0.89 258 3.73e-01\n\n 'a'  effect estimates (X on M) \n          affect   se     t  df     Prob\nIntercept   1.71 0.31  5.60 258 5.50e-08\nestress     0.16 0.03  5.25 258 3.22e-07\nese        -0.15 0.04 -3.39 258 7.95e-04\nsex         0.02 0.09  0.19 258 8.50e-01\n\n 'b'  effect estimates (M on Y controlling for X) \n       withdraw  se    t  df    Prob\naffect     0.71 0.1 6.81 257 6.7e-11\n\n 'ab'  effect estimates (through all  mediators)\n        withdraw  boot   sd lower upper\nestress     0.11  0.11 0.03  0.06  0.17\nese        -0.11 -0.10 0.04  0.06  0.17\nsex         0.01  0.02 0.06  0.06  0.17",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 1"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contents/baser.html",
    "href": "contents/baser.html",
    "title": "Base R",
    "section": "",
    "text": "90년대에 통계 분석을 위해 개발된 R 언어와 대비하여, 좀 더 직관적이고 효율적인 데이터 분석을 위해 새로운 문법이 R내의 패키지 형태로 구현되었는데 이 새로운 생태계 안의 패키지들의 모임이 Tidyverse라는 이름하에 발전하고 있음: Tidyverse\n이 패키지들은 design philosophy, grammar, data structures를 공유하며 유기적으로 작동됨.\n기존 R의 문법과는 상당한 차이가 있어 단점도 지적되고 있고, 소위 base-R을 고수하는 사람들과 tidyverse를 기본으로 사용하는 사람들이 나뉘어 있다고 알려져 있음.\n아마도 빠르게 발전하고 있는 tidyverse/tidymodel 생태계의 언어들이 기본으로 자리잡지 않을까 함.\n본 강의에서는 주로 tidyverse의 언어로만 분석하고자 함.",
    "crumbs": [
      "R tutorial",
      "Base R"
    ]
  },
  {
    "objectID": "contents/baser.html#r의-데이터-구조와-변수-타입",
    "href": "contents/baser.html#r의-데이터-구조와-변수-타입",
    "title": "Base R",
    "section": "R의 데이터 구조와 변수 타입",
    "text": "R의 데이터 구조와 변수 타입\n주로 vector (벡터)와 data frame (데이터프레임)을 다룸\n\nSource: R in Action by Rob Kabacoff\nData frame의 예\n\n각 column이 하나의 variable (변수)를 구성하고, 한가지 타입의 데이터로 이루어짐\n\n각 Row가 하나의 observation (관측치)을 구성함.\n\n이러한 형태를 갖춘 데이터를 tidy라고도 부르며, 이를 벗어난 형태의 경우 가공이 필요함.\nex. “m23”: male이고 23세임을 나타내는 표기도 있음\n\n\nlibrary(tidyverse)\n\ncps &lt;- mosaicData::CPS85 # mosaicData package의 CPS85 데이터셋\nhead(cps) |&gt; print() # print()는 생략할 것!\n\n  wage educ race sex hispanic south married exper union age   sector\n1  9.0   10    W   M       NH    NS Married    27   Not  43    const\n2  5.5   12    W   M       NH    NS Married    20   Not  38    sales\n3  3.8   12    W   F       NH    NS  Single     4   Not  22    sales\n4 10.5   12    W   F       NH    NS Married    29   Not  47 clerical\n5 15.0   12    W   M       NH    NS Married    40 Union  58    const\n6  9.0   16    W   F       NH    NS Married    27   Not  49 clerical\n\n\n\ncps &lt;- as_tibble(cps) # tibble vs. data.frame\nhead(cps) |&gt; print()\n\n# A tibble: 6 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n\n\n\n# Dataset의 설명\nhelp(CPS85, package=\"mosaicData\") # 또는\n?mosaicData::CPS85",
    "crumbs": [
      "R tutorial",
      "Base R"
    ]
  },
  {
    "objectID": "contents/baser.html#vector",
    "href": "contents/baser.html#vector",
    "title": "Base R",
    "section": "Vector",
    "text": "Vector\n한 가지 타입으로만 구성: 숫자 (numeric), 문자 (character), 논리형 (logical), factor, etc\n\nvar &lt;- c(1, 2, 5, 3, 6, -2, 4) # 변수에 assign: '=' 대신 '&lt;-'\nnm &lt;- c(\"one\", \"two\", \"three\")\ntf &lt;- c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)\n\n# 타입/클래스 확인\nclass(var)\n## [1] \"double\"\n\nclass(nm)\n## [1] \"character\"\n\nclass(tf)\n## [1] \"logical\"\n\n\n원소의 추출 및 대체\n다음은 원소를 추출, 대체하는 R의 native한 방식임\n수업에서는 뒤에서 다룰 tidyverse 문법을 주로 활용할 것임\nVector의 경우\n\nvar\n## [1]  1  2  5  3  6 -2  4\n\nvar[3]\n## [1] 5\n\nvar[c(1, 3, 5)]\n## [1] 1 5 6\n\nvar[2:6] # \":\"\" slicing: c(2, 3, 4, 5, 6)\n## [1]  2  5  3  6 -2\n\nvar[c(1, 3:5)] # 혼합\n## [1] 1 5 3 6\n\nvar[-c(1, 3)] # \"-\"는 제외라는 의미\n## [1]  2  3  6 -2  4\n\nc(10, var, 100, 101) # 추가\n##  [1]  10   1   2   5   3   6  -2   4 100 101\n\nvar[2] &lt;- 55 # 대체\n## var\n## [1]  1 55  5  3  6 -2  4\n\nvar[c(2, 5)] &lt;- c(200, 500) # 대체\n## var\n## [1]   1 200   5   3 500  -2   4\n\n# numeric 벡터의 연산: recycling rule\n1:5 * 2\n## [1]  2  4  6  8 10\n\nc(1, 3, 5) - 5\n## [1] -4 -2  0\n\nc(2, 4, 6) / 2\n## [1] 1 2 3\n\nc(1, 3) * c(2, 4)\n## [1]  2 12\n\nc(1, 3) - c(2, 4)\n## [1] -1 -1",
    "crumbs": [
      "R tutorial",
      "Base R"
    ]
  },
  {
    "objectID": "contents/baser.html#factor",
    "href": "contents/baser.html#factor",
    "title": "Base R",
    "section": "Factor",
    "text": "Factor\nVector로서 명목변수(카테고리)를 다룸\npatientID &lt;- c(1, 2, 1, 3)\ndiabetes &lt;- c(\"Type1\", \"Type2\", \"Type1\", \"Type1\")\nstatus &lt;- c(\"Poor\", \"Improved\", \"Excellent\", \"Poor\")\n\n# factor로 변환: 알파벳 순서로 levels의 순서가 정해짐\nfactor(patientID)\n## [1] 1 2 1 3\n## Levels: 1 2 3\n\nfactor(diabetes)\n## [1] Type1 Type2 Type1 Type1\n## Levels: Type1 Type2\n\nfactor(status, order = TRUE) # order를 표시\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Excellent &lt; Improved &lt; Poor\n\n# 구체적으로 표시하는 것을 추천: 지정한 성분 순서대로 levels의 순서가 정해짐\nfactor(status, levels = c(\"Poor\", \"Improved\", \"Excellent\"),\n                                         order = TRUE)\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Poor &lt; Improved &lt; Excellent\n\n# order가 없을시\nfactor(status, levels = c(\"Poor\", \"Improved\", \"Excellent\"))\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Poor Improved Excellent\n\n# 대표적으로 성별을 코딩할 때: 숫자대신 레이블로 표시\nsex &lt;- c(1, 2, 1, 1, 1, 2, 2, 1)\nfactor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\n## [1] Male   Female Male   Male   Male   Female Female Male  \n## Levels: Male Female\n\nsex_fct &lt;- factor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\n\nlevels(sex) # 레벨 확인\n## NULL\nlevels(sex_fct) # 레벨 확인\n## [1] \"Male\"   \"Female\"\n\nsex\n## [1] 1 2 1 1 1 2 2 1\nsex_fct\n## [1] Male   Female Male   Male   Male   Female Female Male  \n## Levels: Male Female",
    "crumbs": [
      "R tutorial",
      "Base R"
    ]
  },
  {
    "objectID": "contents/baser.html#data-frame",
    "href": "contents/baser.html#data-frame",
    "title": "Base R",
    "section": "Data Frame",
    "text": "Data Frame\n\n데이터 프레임의 구성\n# 벡터들로부터 데이터 프레임 구성\npatientID &lt;- c(1, 2, 3, 4)\nage &lt;- c(25, 34, 28, 52)\ndiabetes &lt;- c(\"Type1\", \"Type2\", \"Type1\", \"Type1\")\nstatus &lt;- c(\"Poor\", \"Improved\", \"Excellent\", \"Poor\")\n\npatientdata &lt;- data.frame(patientID, age, diabetes, status)\n\npatientdata\n##   patientID age diabetes    status\n## 1         1  25    Type1      Poor\n## 2         2  34    Type2  Improved\n## 3         3  28    Type1 Excellent\n## 4         4  52    Type1      Poor\n\nmidterm &lt;- data.frame(english = c(90, 80, 60, 70),\n                      math = c(50, 60, 100, 20),\n                      class = c(1, 1, 2, 2))\nmidterm\n##   english math class\n## 1      90   50     1\n## 2      80   60     1\n## 3      60  100     2\n## 4      70   20     2\n\n\n원소의 추출 및 대체\n# 원소의 추출\npatientdata[1:2] # 변수의 열을 지정\n##   patientID age\n## 1         1  25\n## 2         2  34\n## 3         3  28\n## 4         4  52\n\npatientdata[c(\"diabetes\", \"status\")] # 열 이름을 지정\n##   diabetes    status\n## 1    Type1      Poor\n## 2    Type2  Improved\n## 3    Type1 Excellent\n## 4    Type1      Poor\n\npatientdata[c(1, 3), c(\"age\", \"status\")] # 행과 열을 모두 지정\n##   age    status\n## 1  25      Poor\n## 3  28 Excellent\n\npatientdata[c(1, 3), c(2, 4)]\n##   age    status\n## 1  25      Poor\n## 3  28 Excellent\n\npatientdata[, 1:2] # patientdata[1:2]과 동일, 빈칸은 모든 행을 의미\n##   patientID age\n## 1         1  25\n## 2         2  34\n## 3         3  28\n## 4         4  52\n\npatientdata[1:2, ] # 빈칸은 모든 열을 의미\n##   patientID age diabetes   status\n## 1         1  25    Type1     Poor\n## 2         2  34    Type2 Improved\n\npatientdata[-1] # 열 제외\n##   age diabetes    status\n## 1  25    Type1      Poor\n## 2  34    Type2  Improved\n## 3  28    Type1 Excellent\n## 4  52    Type1      Poor\n\npatientdata[-c(1, 3)] # 열 제외\n##   age    status\n## 1  25      Poor\n## 2  34  Improved\n## 3  28 Excellent\n## 4  52      Poor\n\npatientdata[-c(1:2), 2:4] # 행 제외 & 열 선택\n##   age diabetes    status\n## 3  28    Type1 Excellent\n## 4  52    Type1      Poor\n\n\n# 변수/열의 성분을 벡터로 추출: $ 또는 [[ ]]을 이용\npatientdata$age # $를 이용\n## [1] 25 34 28 52\n\nclass(patientdata$age) # numeric vector임을 확인\n## [1] \"numeric\"\n\npatientdata[[\"age\"]] # patientdata$age과 동일, [[ ]] doule bracket을 이용해 벡터로 추출\n## [1] 25 34 28 52\n\npatientdata[[2]] # 열의 위치를 이용해도 동일한 추출\n## [1] 25 34 28 52\n\npatientdata[\"age\"] # [ ] single bracket은 열을 선택하는 것으로 데이터 프레임으로 추출\n##   age\n## 1  25\n## 2  34\n## 3  28\n## 4  52\n\npatientdata[2] # 2번째 열을 추출; patientdata[\"age\"]과 동일\n##   age\n## 1  25\n## 2  34\n## 3  28\n## 4  52\n\n\n데이터의 추가 및 대체\n# 데이터 추가\npatientdata$gender &lt;- c(1, 1, 2, 2) \n\npatientdata\n##   patientID age diabetes    status gender\n## 1         1  25    Type1      Poor      1\n## 2         2  34    Type2  Improved      1\n## 3         3  28    Type1 Excellent      2\n## 4         4  52    Type1      Poor      2\n\n# 데이터 대체\npatientdata[c(1,3), \"age\"] # 혼동: 원칙적으로 데이터프레임으로 추출되어야하나 벡터로 추출됨\n## [1] 25 28\n\npatientdata[c(1,3), \"age\"] &lt;- c(88, 99)\npatientdata\n##   patientID age diabetes    status gender\n## 1         1  88    Type1      Poor      1\n## 2         2  34    Type2  Improved      1\n## 3         3  99    Type1 Excellent      2\n## 4         4  52    Type1      Poor      2\n\n# 참고\nrow.names(patientdata) # 데이터 프레임의 행 이름\n## [1] \"1\" \"2\" \"3\" \"4\"\n\nrow.names(patientdata) &lt;- c(\"a\", \"b\", \"c\", \"d\")\npatientdata\n##   patientID age diabetes    status gender\n## a         1  88    Type1      Poor      1\n## b         2  34    Type2  Improved      1\n## c         3  99    Type1 Excellent      2\n## d         4  52    Type1      Poor      2",
    "crumbs": [
      "R tutorial",
      "Base R"
    ]
  },
  {
    "objectID": "contents/baser.html#tibble",
    "href": "contents/baser.html#tibble",
    "title": "Base R",
    "section": "Tibble",
    "text": "Tibble\n기존 data.frame의 단점을 보안한 tidyverse에서 기본이 되는 데이터 형식\n\nData frame vs. tibble\nPrinting의 차이\ncps &lt;- mosaicData::CPS85 # data.frame\ncps\n#   wage educ race sex hispanic south married exper union age   sector\n# 1  9.0   10    W   M       NH    NS Married    27   Not  43    const\n# 2  5.5   12    W   M       NH    NS Married    20   Not  38    sales\n# 3  3.8   12    W   F       NH    NS  Single     4   Not  22    sales\n# 4 10.5   12    W   F       NH    NS Married    29   Not  47 clerical\n# 5 15.0   12    W   M       NH    NS Married    40 Union  58    const\n# 6  9.0   16    W   F       NH    NS Married    27   Not  49 clerical\n...\n\ncps_tibble &lt;- as_tibble(cps)\ncps_tibble\n# # A tibble: 534 × 11\n#    wage  educ race  sex   hispanic south married exper union   age sector  \n#   &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;   \n# 1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n# 2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n# 3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n# 4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n# 5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n# 6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# # … with 528 more rows\n그 외의 차이는 R for Data Science/10.3 Tibbles vs. data.frame을 참고",
    "crumbs": [
      "R tutorial",
      "Base R"
    ]
  },
  {
    "objectID": "contents/case2.html",
    "href": "contents/case2.html",
    "title": "Case 2",
    "section": "",
    "text": "Source: Statistical Methods for Psychology (8e) by Dave C. Howell\n\n\n\n\n\n\n\n각 주에서 집행되는 교육지출이 미국 학생의 SAT 점수에 미치는 효과를 알아보고자 함.\nSAT를 치르는 학생들의 비율이 주마다 상이함.\nData: ACT.csv\n\n\n\n\n\n\n\n\nact &lt;- read_csv(\"howell/ACT.csv\")\nact\n\n# A tibble: 50 × 12\n      id State   Expend PTratio Salary PctSAT Verbal  Math   SAT PctACT   ACT\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     1 Alabama   4.40    17.2   31.1      8    491   538  1029     61  20.2\n 2     2 Alaska    8.96    17.6   48.0     47    445   489   934     32  21  \n 3     3 Arizona   4.78    19.3   32.2     27    448   496   944     27  21.1\n 4     4 Ark       4.46    17.1   28.9      6    482   523  1005     66  20.3\n 5     5 Calif     4.99    24     41.1     45    417   485   902     11  21  \n 6     6 Col       5.44    18.4   34.6     29    462   518   980     62  21.5\n 7     7 Conn      8.82    14.4   50.0     81    431   477   908      3  21.7\n 8     8 Del       7.03    16.6   39.1     68    429   468   897      3  21  \n 9     9 Florida   5.72    19.1   32.6     48    420   469   889     36  20.7\n10    10 Georgia   5.19    16.3   32.3     65    406   448   854     16  20.2\n# ℹ 40 more rows\n# ℹ 1 more variable: LogPctSAT &lt;dbl&gt;\n\n\nA. 변수들 간의 관계 탐색\nlowerCor(act[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")])\nlibrary(corrgram)\nact[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")] |&gt; \n  corrgram(upper.panel = panel.cor, lower.panel = panel.pie)\n\n\n\n          SAT   Expnd LPSAT Salry\nSAT        1.00                  \nExpend    -0.38  1.00            \nLogPctSAT -0.93  0.56  1.00      \nSalary    -0.44  0.87  0.61  1.00\n\n\n\n\n\n\n\nGGally::ggpairs(act[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")])\n\n\n\n\n\n\n\n\nact |&gt; ggplot(aes(x = PctSAT, y = SAT)) + geom_point() + geom_smooth()\nact |&gt; ggplot(aes(x = LogPctSAT, y = SAT)) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\n\nB1. 부분 회귀 계수들\n\nmod1 &lt;- lm(SAT ~ Expend, data = act)\nmod2 &lt;- lm(SAT ~ Expend + LogPctSAT, data = act)\n\n\n\nexport_summs(mod1, mod2, error_format = \"({p.value})\") |&gt; print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)         1089.29 ***      1147.10 ***  \n                                      (0.00)           (0.00)     \n                Expend               -20.89 **         11.13 **   \n                                      (0.01)           (0.00)     \n                LogPctSAT                             -78.20 ***  \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                     50               50         \n                R2                     0.14             0.89      \n              ────────────────────────────────────────────────────\n                *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n# beta: standardized coefficients\nlm.beta::lm.beta(mod2) |&gt; print()\n\n\nCall:\nlm(formula = SAT ~ Expend + LogPctSAT, data = act)\n\nStandardized Coefficients::\n(Intercept)      Expend   LogPctSAT \n         NA    0.202704   -1.039937 \n\n\n\n\n\n\n\n\n\n\n\nB2. 부분 회귀 계수들\n\nmod1 &lt;- lm(SAT ~ LogPctSAT, data = act)\nmod2 &lt;- lm(SAT ~ LogPctSAT + Expend, data = act)\n\n\nexport_summs(mod1, mod2, error_format = \"({p.value})\") |&gt; print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)         1185.83 ***      1147.10 ***  \n                                      (0.00)           (0.00)     \n                LogPctSAT            -69.65 ***       -78.20 ***  \n                                      (0.00)           (0.00)     \n                Expend                                 11.13 **   \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                     50               50         \n                R2                     0.86             0.89      \n              ────────────────────────────────────────────────────\n                *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n\nC. 부분 상관 계수들\n\nlowerCor(act[c(\"SAT\", \"Expend\", \"LogPctSAT\")])\n\n          SAT   Expnd LPSAT\nSAT        1.00            \nExpend    -0.38  1.00      \nLogPctSAT -0.93  0.56  1.00\n\nsumm(mod2, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors:OLS\n------------------------------------------------------------------------\n                       Est.    S.E.   t val.      p   partial.r   part.r\n----------------- --------- ------- -------- ------ ----------- --------\n(Intercept)         1147.10   16.70    68.68   0.00                     \nLogPctSAT            -78.20    4.47   -17.49   0.00       -0.93    -0.86\nExpend                11.13    3.26     3.41   0.00        0.45     0.17\n------------------------------------------------------------------------\n\n\nSummary\n\n\n\n\n\n\n\n\n\n\n\\(r\\)\n\\(\\beta\\)\n\\(pr\\)\n\\(sr\\)\n\n\n\n\nExpend\n-0.38\n0.20\n0.45\n0.17\n\n\nLogPctSAT\n-0.93\n-1.04\n-0.93\n-0.86\n\n\n\n\n\n \n\n\n\n\n\n\n\\(r^2\\)\n\\(\\beta^2\\)\n\\(pr^2\\)\n\\(sr^2\\)\n\n\n\n\nExpend\n0.14\n0.04\n0.20\n0.03\n\n\nLogPctSAT\n0.86\n1.08\n0.86\n0.74\n\n\n\n\n\n\nD. 예측변수의 추가\n예측변수가 3개인 경우\n\nmod3 &lt;- lm(SAT ~ Salary, data = act)\nmod4 &lt;- lm(SAT ~ Salary + Expend, data = act)\nmod5 &lt;- lm(SAT ~ Salary + Expend + LogPctSAT, data = act)\n\nexport_summs(mod0, mod2, mod3, mod4, mod5, model.names = c(\"mod0\", \"mod2\", \"mod3\", \"mod4\", \"mod5\")) |&gt; print()\n\n\n\n───────────────────────────────────────────────────────────────────────────────\n                  mod0         mod2         mod3         mod4         mod5     \n             ──────────────────────────────────────────────────────────────────\n  (Intercept      1089.29      1147.10      1158.86      1159.35      1133.11  \n  )                   ***          ***          ***          ***          ***  \n               (44.39)      (16.70)      (57.66)      (60.22)      (22.73)     \n  Expend       -20.89 **     11.13 **                   0.47         7.10      \n                (7.33)       (3.26)                   (14.58)       (5.50)     \n  LogPctSAT                 -78.20 ***                             -79.51 ***  \n                             (4.47)                                 (4.71)     \n  Salary                                  -5.54 **     -5.63         1.20      \n                                          (1.63)       (3.34)       (1.32)     \n             ──────────────────────────────────────────────────────────────────\n  N             50           50           50           50           50         \n  R2             0.14         0.89         0.19         0.19         0.89      \n───────────────────────────────────────────────────────────────────────────────\n  *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.                                      \n\nColumn names: names, mod0, mod2, mod3, mod4, mod5\n\n\n\n\nmcPlots(mod4, overlaid = FALSE)\n\n\n\n\n\n\n\navPlots(mod5) # library(car)\n\n\n\n\n\n\n\n\nQ: Salary와 Expend 중 하나는 제거해야 되나???\n\n상관관계가 높은 변수들은 서로 partial out되어 남은 잔차들의 변량이 줄어 Y와의 관계를 온전히 테스트하기 어려워짐\n구체적으로는 standard error를 높여서 회귀계수에 대한 모집단에 대한 신뢰도를 낮춤\n이를 다중공선성(multicollinearity)이라고 함\n이들을 하나의 “묶음”(set)으로 취급해도 무방함",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 2"
    ]
  },
  {
    "objectID": "contents/case2.html#guber-1999의-sat-점수와-주states의-교육지출-사이의-관계",
    "href": "contents/case2.html#guber-1999의-sat-점수와-주states의-교육지출-사이의-관계",
    "title": "Case 2",
    "section": "",
    "text": "Source: Statistical Methods for Psychology (8e) by Dave C. Howell\n\n\n\n\n\n\n\n각 주에서 집행되는 교육지출이 미국 학생의 SAT 점수에 미치는 효과를 알아보고자 함.\nSAT를 치르는 학생들의 비율이 주마다 상이함.\nData: ACT.csv\n\n\n\n\n\n\n\n\nact &lt;- read_csv(\"howell/ACT.csv\")\nact\n\n# A tibble: 50 × 12\n      id State   Expend PTratio Salary PctSAT Verbal  Math   SAT PctACT   ACT\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     1 Alabama   4.40    17.2   31.1      8    491   538  1029     61  20.2\n 2     2 Alaska    8.96    17.6   48.0     47    445   489   934     32  21  \n 3     3 Arizona   4.78    19.3   32.2     27    448   496   944     27  21.1\n 4     4 Ark       4.46    17.1   28.9      6    482   523  1005     66  20.3\n 5     5 Calif     4.99    24     41.1     45    417   485   902     11  21  \n 6     6 Col       5.44    18.4   34.6     29    462   518   980     62  21.5\n 7     7 Conn      8.82    14.4   50.0     81    431   477   908      3  21.7\n 8     8 Del       7.03    16.6   39.1     68    429   468   897      3  21  \n 9     9 Florida   5.72    19.1   32.6     48    420   469   889     36  20.7\n10    10 Georgia   5.19    16.3   32.3     65    406   448   854     16  20.2\n# ℹ 40 more rows\n# ℹ 1 more variable: LogPctSAT &lt;dbl&gt;\n\n\nA. 변수들 간의 관계 탐색\nlowerCor(act[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")])\nlibrary(corrgram)\nact[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")] |&gt; \n  corrgram(upper.panel = panel.cor, lower.panel = panel.pie)\n\n\n\n          SAT   Expnd LPSAT Salry\nSAT        1.00                  \nExpend    -0.38  1.00            \nLogPctSAT -0.93  0.56  1.00      \nSalary    -0.44  0.87  0.61  1.00\n\n\n\n\n\n\n\nGGally::ggpairs(act[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")])\n\n\n\n\n\n\n\n\nact |&gt; ggplot(aes(x = PctSAT, y = SAT)) + geom_point() + geom_smooth()\nact |&gt; ggplot(aes(x = LogPctSAT, y = SAT)) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\n\nB1. 부분 회귀 계수들\n\nmod1 &lt;- lm(SAT ~ Expend, data = act)\nmod2 &lt;- lm(SAT ~ Expend + LogPctSAT, data = act)\n\n\n\nexport_summs(mod1, mod2, error_format = \"({p.value})\") |&gt; print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)         1089.29 ***      1147.10 ***  \n                                      (0.00)           (0.00)     \n                Expend               -20.89 **         11.13 **   \n                                      (0.01)           (0.00)     \n                LogPctSAT                             -78.20 ***  \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                     50               50         \n                R2                     0.14             0.89      \n              ────────────────────────────────────────────────────\n                *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n# beta: standardized coefficients\nlm.beta::lm.beta(mod2) |&gt; print()\n\n\nCall:\nlm(formula = SAT ~ Expend + LogPctSAT, data = act)\n\nStandardized Coefficients::\n(Intercept)      Expend   LogPctSAT \n         NA    0.202704   -1.039937 \n\n\n\n\n\n\n\n\n\n\n\nB2. 부분 회귀 계수들\n\nmod1 &lt;- lm(SAT ~ LogPctSAT, data = act)\nmod2 &lt;- lm(SAT ~ LogPctSAT + Expend, data = act)\n\n\nexport_summs(mod1, mod2, error_format = \"({p.value})\") |&gt; print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)         1185.83 ***      1147.10 ***  \n                                      (0.00)           (0.00)     \n                LogPctSAT            -69.65 ***       -78.20 ***  \n                                      (0.00)           (0.00)     \n                Expend                                 11.13 **   \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                     50               50         \n                R2                     0.86             0.89      \n              ────────────────────────────────────────────────────\n                *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n\nC. 부분 상관 계수들\n\nlowerCor(act[c(\"SAT\", \"Expend\", \"LogPctSAT\")])\n\n          SAT   Expnd LPSAT\nSAT        1.00            \nExpend    -0.38  1.00      \nLogPctSAT -0.93  0.56  1.00\n\nsumm(mod2, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors:OLS\n------------------------------------------------------------------------\n                       Est.    S.E.   t val.      p   partial.r   part.r\n----------------- --------- ------- -------- ------ ----------- --------\n(Intercept)         1147.10   16.70    68.68   0.00                     \nLogPctSAT            -78.20    4.47   -17.49   0.00       -0.93    -0.86\nExpend                11.13    3.26     3.41   0.00        0.45     0.17\n------------------------------------------------------------------------\n\n\nSummary\n\n\n\n\n\n\n\n\n\n\n\\(r\\)\n\\(\\beta\\)\n\\(pr\\)\n\\(sr\\)\n\n\n\n\nExpend\n-0.38\n0.20\n0.45\n0.17\n\n\nLogPctSAT\n-0.93\n-1.04\n-0.93\n-0.86\n\n\n\n\n\n \n\n\n\n\n\n\n\\(r^2\\)\n\\(\\beta^2\\)\n\\(pr^2\\)\n\\(sr^2\\)\n\n\n\n\nExpend\n0.14\n0.04\n0.20\n0.03\n\n\nLogPctSAT\n0.86\n1.08\n0.86\n0.74\n\n\n\n\n\n\nD. 예측변수의 추가\n예측변수가 3개인 경우\n\nmod3 &lt;- lm(SAT ~ Salary, data = act)\nmod4 &lt;- lm(SAT ~ Salary + Expend, data = act)\nmod5 &lt;- lm(SAT ~ Salary + Expend + LogPctSAT, data = act)\n\nexport_summs(mod0, mod2, mod3, mod4, mod5, model.names = c(\"mod0\", \"mod2\", \"mod3\", \"mod4\", \"mod5\")) |&gt; print()\n\n\n\n───────────────────────────────────────────────────────────────────────────────\n                  mod0         mod2         mod3         mod4         mod5     \n             ──────────────────────────────────────────────────────────────────\n  (Intercept      1089.29      1147.10      1158.86      1159.35      1133.11  \n  )                   ***          ***          ***          ***          ***  \n               (44.39)      (16.70)      (57.66)      (60.22)      (22.73)     \n  Expend       -20.89 **     11.13 **                   0.47         7.10      \n                (7.33)       (3.26)                   (14.58)       (5.50)     \n  LogPctSAT                 -78.20 ***                             -79.51 ***  \n                             (4.47)                                 (4.71)     \n  Salary                                  -5.54 **     -5.63         1.20      \n                                          (1.63)       (3.34)       (1.32)     \n             ──────────────────────────────────────────────────────────────────\n  N             50           50           50           50           50         \n  R2             0.14         0.89         0.19         0.19         0.89      \n───────────────────────────────────────────────────────────────────────────────\n  *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.                                      \n\nColumn names: names, mod0, mod2, mod3, mod4, mod5\n\n\n\n\nmcPlots(mod4, overlaid = FALSE)\n\n\n\n\n\n\n\navPlots(mod5) # library(car)\n\n\n\n\n\n\n\n\nQ: Salary와 Expend 중 하나는 제거해야 되나???\n\n상관관계가 높은 변수들은 서로 partial out되어 남은 잔차들의 변량이 줄어 Y와의 관계를 온전히 테스트하기 어려워짐\n구체적으로는 standard error를 높여서 회귀계수에 대한 모집단에 대한 신뢰도를 낮춤\n이를 다중공선성(multicollinearity)이라고 함\n이들을 하나의 “묶음”(set)으로 취급해도 무방함",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 2"
    ]
  },
  {
    "objectID": "contents/case4.html",
    "href": "contents/case4.html",
    "title": "Case 4",
    "section": "",
    "text": "데이터: C0302DT.csv\n연봉에 미치는 영향에 대한 full model (p.461)\n다음과 같은 인과관계를 가정하고,\n\n여러 상관계수를 구해 해석해보고,\n회귀계수들과 여러 연관된 값들을 직접 구해보세요.",
    "crumbs": [
      "Statistics",
      "Multiple Regression",
      "Case 4"
    ]
  },
  {
    "objectID": "contents/categorical.html",
    "href": "contents/categorical.html",
    "title": "Categorical IVs",
    "section": "",
    "text": "범주형 변수가 예측변수가 되는 경우, 범주형 변수는 숫자로 변환시켜 분석 가능\n범주가 실험 조건이 되는 경우, 예를 들어 통제집단과 처치집단에 대해서 그 차이를 보는 경우, 실험연구의 전통을 가진 ANOVA 프레임워크에서 다루어져 왔고 다양한 용어(ANCOVA, fatorial ANOVA, repeated ANOVA, MANOVA 등등)와 분석 방식이 행해져왔으나, 관찰연구의 전통을 가진 회귀분석의 프레임워크 안에서 통합될 수 있음.\n범주를 숫자로 변환시키는 방식은 연구의 목적에 따라 여러 방식으로 coding할 수 있는데, 예를 들어 sequential coding, Helmert coding, effect coding 등등에 대해서는 책을 참고.\n10.1 Alternative Coding Systems in Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n앞서, 범주가 2개인 성별의 경우: 남자는 0, 여자는 1로 변형시키는 dummy coding으로 indicator variable을 만들어 사용했음",
    "crumbs": [
      "Statistics",
      "Categorical IVs"
    ]
  },
  {
    "objectID": "contents/categorical.html#attitude-toward-abortion-ata",
    "href": "contents/categorical.html#attitude-toward-abortion-ata",
    "title": "Categorical IVs",
    "section": "Attitude toward abortion (ATA)",
    "text": "Attitude toward abortion (ATA)\n종교에 따른 낙태에 대한 (긍정적) 태도의 차이\n종교: 개신교, 카톡릭, 유대교, 기타\nData: c08e01dt.csv\nata &lt;- read_csv(\"data/c08e01dt.csv\")\nata\nggplot(ata, aes(x = rel, y = ata)) +\n    geom_boxplot(fill = \"white\") +\n    geom_jitter(width= .1, size = 2, color = \"orangered\")\n\n\n\n\n# A tibble: 36 × 2\n   rel          ata\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 Catholic      61\n 2 Other         78\n 3 Protestant    47\n 4 Catholic      65\n 5 Catholic      45\n 6 Other        106\n 7 Protestant   120\n 8 Catholic      49\n 9 Other         45\n10 Other         62\n# ℹ 26 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n다음은 dummy coding을 하는데 기준이 되는 범주(reference group)를 무엇으로 하느냐에 따른 차이를 보여줌\n일반적으로 범주가 N개이면 N-1개의 dummy variable이 필요함.\n각각의 dummy variable은 membership를 나타내며, 해당 범주에 속하는 경우 1, 아닌 경우 0으로 coding됨.\n\n여기서는 Protestant를 reference로 하는 B번을 사용하는데\n\\(C_1\\) : Catholic인지 아닌지\n\\(C_2\\) : Jewish인지 아닌지\n\\(C_3\\) : Other인지 아닌지\n\n\n   p.304\n\n회귀 계수\n우선, 명목변수를 R의 factor 타입으로 변환\n\nrel을 factor로 변환; 순서를 고려해서\nProtestant를 reference group으로 지정하기 위해 첫번째 level로 지정\n\n\nata &lt;- ata |&gt; \n    mutate(rel = factor(rel, levels = c(\"Protestant\", \"Catholic\", \"Jewish\", \"Other\")))\n\nR에서 기본적으로 factor는 dummy coding으로 변환\n실제 내부적으로 어떻게 변환되는지 확인해보면,\n\nmodel.matrix(~ rel, data = ata) |&gt; bind_cols(ata[\"rel\"]) # bind two columns\n\n# A tibble: 36 × 5\n   `(Intercept)` relCatholic relJewish relOther rel       \n           &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     \n 1             1           1         0        0 Catholic  \n 2             1           0         0        1 Other     \n 3             1           0         0        0 Protestant\n 4             1           1         0        0 Catholic  \n 5             1           1         0        0 Catholic  \n 6             1           0         0        1 Other     \n 7             1           0         0        0 Protestant\n 8             1           1         0        0 Catholic  \n 9             1           0         0        1 Other     \n10             1           0         0        1 Other     \n# ℹ 26 more rows\n\n\n이전과 같은 방식으로 선형회귀모형을 세워 분석하면,\nModel: ata ~ rel\n\\(\\widehat{ata} = b_1 \\cdot relCatholic + b_2 \\cdot relJewish + b_3 \\cdot relOther + b_0\\)\n\nmod &lt;- lm(ata ~ rel, data = ata) \nS(mod, brief = TRUE)  # S()는 summmary() 대체 (car 패키지)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   93.308      6.495  14.366 1.66e-15 ***\nrelCatholic  -32.641     10.155  -3.214  0.00298 ** \nrelJewish     10.192     11.558   0.882  0.38444    \nrelOther     -23.183     10.523  -2.203  0.03491 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 23.42 on 32 degrees of freedom\nMultiple R-squared: 0.3549\nF-statistic: 5.869 on 3 and 32 DF,  p-value: 0.002599 \n   AIC    BIC \n334.98 342.89 \n\n\nFitted model:\n\\(\\widehat{ata} = -32.6 \\cdot relCatholic + 10.2 \\cdot relJewish - 23.2 \\cdot relOther + 93.3\\)\n각 회귀계수의 의미는 실제 dummy variable의 값을 대입함으로써 추론할 수 있음.\nProtestant:    \\(\\widehat{ata} = b_1(0) + b_2(0) + b_3(0) + b_0 = b_0 = 93.3 = M_{Protestant}~(reference ~group)\\)\n    Catholic:    \\(\\widehat{ata} = b_1(1) + b_2(0) + b_3(0) + b_0 = b_1 + b_0 = -32.6 + 93.3 = M_{Catholic}\\)\n   Jewish:    \\(\\widehat{ata} = b_1(0) + b_2(1) + b_3(0) + b_0 = b_2 + b_0 = 10.2 + 93.3 = M_{Jewish}\\)\n   Other:    \\(\\widehat{ata} = b_1(0) + b_2(0) + b_3(1) + b_0 = b_3 + b_0 = -23.2 + 93.3 = M_{Other}\\)\n따라서, 각 회귀계수는 기울기로 (마찬가지로) 해석해서 0에서 1로 증가할 때의 변화량으로 해석할 수 있음. 즉,\n\n\\(b_1 = -32.6\\) 은 카톡릭 신자는 개신교도(\\(b_0\\))에 비해 32.6 정도 낙태에 대한 부정적인 태도를 나타냈음.\n\\(b_2 = 10.2\\) 는 유대교도는 개신교도(\\(b_0\\))에 비해 10.2 정도 낙태에 대한 긍정적인 태도를 나타냈음.\n\\(b_3 = -23.2\\) 는 기타 종교는 개신교도(\\(b_0\\))에 비해 23.2 정도 낙태에 대한 부정적인 태도를 나타냈음.\n\n각 범주에 대한 예측값은 해당 범주의 평균과 같음.\nGraphical representation of the model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n회귀계수에 대한 가설검정\n\n각 회귀계수에 대한 가설검정은 해당 범주와 reference group의 평균이 같은지에 대한 테스트\n다른 범주간의 평균 차이에 대한 가설검정은 reference group을 바꿔 테스트\n\n\nS(mod, brief = TRUE)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   93.308      6.495  14.366 1.66e-15 ***\nrelCatholic  -32.641     10.155  -3.214  0.00298 ** \nrelJewish     10.192     11.558   0.882  0.38444    \nrelOther     -23.183     10.523  -2.203  0.03491 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 23.42 on 32 degrees of freedom\nMultiple R-squared: 0.3549\nF-statistic: 5.869 on 3 and 32 DF,  p-value: 0.002599 \n   AIC    BIC \n334.98 342.89 \n\n\nReference group를 잠시 변경하고자 한다면, fct_relevel() 함수를 사용\n\nmod_Catholic &lt;- lm(ata ~ fct_relevel(rel, \"Catholic\"), data = ata)  # Catholic을 첫번째 level로 변경\nS(mod_Catholic, brief = TRUE)\n\nCoefficients:\n                                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                              60.667      7.806   7.772  7.3e-09 ***\nfct_relevel(rel, \"Catholic\")Protestant   32.641     10.155   3.214  0.00298 ** \nfct_relevel(rel, \"Catholic\")Jewish       42.833     12.342   3.470  0.00151 ** \nfct_relevel(rel, \"Catholic\")Other         9.458     11.379   0.831  0.41202    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 23.42 on 32 degrees of freedom\nMultiple R-squared: 0.3549\nF-statistic: 5.869 on 3 and 32 DF,  p-value: 0.002599 \n   AIC    BIC \n334.98 342.89 \n\n\n만약, 여러 조합에 대한 가설검증을 한번에 하고자 한다면, multiple test의 문제를 고려한 다양한 방식이 존재\nChapter 11. Multiple Test 참고, Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n\nBonferroni correction: 비교하는 조합의 수로 나누어서 유의수준을 보정\nex. 3개라면 3으로 p-value를 곱한 후 0.05보다 작은지 확인 (95% 유의수준에서)\n\nemmeans 패키지의 emmeans() 함수는 적절한 방식으로 multiple test를 수행\n\n아래는 모든 조합 (all pairwise)에 대한 가설검정 결과\n\nlibrary(emmeans)\nemmeans(mod, pairwise ~ rel)  # all pairwise\n\n$emmeans\n rel        emmean   SE df lower.CL upper.CL\n Protestant   93.3 6.50 32     80.1    106.5\n Catholic     60.7 7.81 32     44.8     76.6\n Jewish      103.5 9.56 32     84.0    123.0\n Other        70.1 8.28 32     53.3     87.0\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast              estimate   SE df t.ratio p.value\n Protestant - Catholic    32.64 10.2 32   3.214  0.0150\n Protestant - Jewish     -10.19 11.6 32  -0.882  0.8142\n Protestant - Other       23.18 10.5 32   2.203  0.1441\n Catholic - Jewish       -42.83 12.3 32  -3.470  0.0078\n Catholic - Other         -9.46 11.4 32  -0.831  0.8393\n Jewish - Other           33.38 12.6 32   2.639  0.0585\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\n\nThe second part of the output shows all possible pairwise differences of adjusted means and provides p-values for t-tests adjusted for multiple comparisons using, in this instance, Tukey’s HSD (“honestly significant difference”) method (Bretz, Hothorn, & Westfall, 2011, Section 4.2). The emmeans () function chooses an appropriate multiple-comparison method depending on the problem.\nAn R Companion to Applied Regression by John Fox \n\n아래는 reference group과의 차이에 대한 가설검정 결과\n\ndummy coding한 회귀 분석과 같은 비교 단, 보정된 p-value\n\n\nemmeans(mod, trt.vs.ctrl ~ rel)  # treatment vs. control 용어에서 유래\n\n$emmeans\n rel        emmean   SE df lower.CL upper.CL\n Protestant   93.3 6.50 32     80.1    106.5\n Catholic     60.7 7.81 32     44.8     76.6\n Jewish      103.5 9.56 32     84.0    123.0\n Other        70.1 8.28 32     53.3     87.0\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast              estimate   SE df t.ratio p.value\n Catholic - Protestant    -32.6 10.2 32  -3.214  0.0084\n Jewish - Protestant       10.2 11.6 32   0.882  0.6926\n Other - Protestant       -23.2 10.5 32  -2.203  0.0910\n\nP value adjustment: dunnettx method for 3 tests \n\n\n\n\nMeasure of association\n각 더미 변수들과 낙태에 대한 태도와의 고유한 상관계수인 partial correlation에 대해서 논의하는 것은 복잡하나, 원래의 의미를 유지하고 있음.\n더 중요한 관심은 종교라는 변수를 3개의 더미 변수들의 set으로 보고, 3개의 변수들이 합쳐서 낙태에 대한 태도를 얼마나 설명해주는지에 대해 말할 수 있음.\n\n즉, \\(R^2\\)를 보면 0.35로 종교 변수는 낙태에 대한 태도 변량의 35%를 설명해준다고 해석할 수 있음.\n그 상관계수 \\(R = \\sqrt{0.35} = 0.60\\) 은 종교과 낙태에 대한 태도와의 상관 정도(association)를 말해 줌.\n주의! 각 범주의 비율이 상정한 모집단과 어느 정도 일치해야지 모집단에 대한 추정이 의미가 있음.\n\nANOVA 프레임워크에서 effect size를 뜻하는 \\(\\eta^2\\)는 \\(R^2\\)와 동일하며\n보정된 값들인 \\(\\epsilon^2,~ \\omega^2\\)에 대해서 \\(\\epsilon^2 = R^2_{adj}\\)\n\nAdjusted (shrunken) \\(R^2\\) 는 표본에서 biased된 통계치인 \\(R^2\\)를 보정한 값으로, 모집단에서의 true \\(R^2\\)을 추정하기 위한 노력.\n\n참고: Effect Sizes for ANOVAs\n예를 들어,\neta_squared(mod)  # library(effectsize)\nomega_squared(mod)  # library(effectsize)\nepsilon_squared(mod)  # library(effectsize)\n\n\n\n\n# A tibble: 1 × 5\n  Parameter  Eta2    CI CI_low CI_high\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 rel       0.355  0.95  0.105       1\n\n\n\n\n# A tibble: 1 × 5\n  Parameter Omega2    CI CI_low CI_high\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 rel        0.289  0.95 0.0492       1\n\n\n\n\n\n\n# A tibble: 1 × 5\n  Parameter Epsilon2    CI CI_low CI_high\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 rel          0.294  0.95 0.0537       1",
    "crumbs": [
      "Statistics",
      "Categorical IVs"
    ]
  },
  {
    "objectID": "contents/categorical.html#effect-size",
    "href": "contents/categorical.html#effect-size",
    "title": "Categorical IVs",
    "section": "Effect size",
    "text": "Effect size\n효과의 크기를 표현하기 위해 다양한 방식이 존재하며, 이는 연구의 성격과 전달하고자 하는 바에 맞춰 선택.\n크게 두 클래스로 나눌 수 있는데,\n 1. r-family (correlation-based)\n앞서 전개한 r(R), parital r, semi-partial r, (adjusted) R squared 등을 통해 종속변수와 독립변수들의 관계의 크기를 구현함.\nANOVA 프레임워크에서는 \\(\\eta^2, ~\\epsilon^2,~ \\omega^2\\) 로 표현됨.\n\n임금의 변량이 성별에 의해 50% 설명된다면, 즉 \\(R^2\\) = .5 라면, 임금에 미치는 성별의 효과의 크기를 0.5로 표현할 수 있고,\n또는 임금과 성별이 \\(R\\) = .7 정도의 상관을 갖는다고 그 효과를 표현할 수 있음.\n앞서 예에서는 종교가 낙태에 대한 태도를 36% 설명하므로, 종교가 낙태에 대한 생각에 미치는 효과의 크기는 0.36 정도라고 혹은 \\(R\\)을 이용해 0.6 정도 라고 말할 수 있음.\n\n 2. d-family (difference-based)\n두 집단의 평균 차이 혹은 비율을 표현하는데, 보통 표준편차의 단위로 표현. 즉, 표준화된 차이(standardized difference)\n대표적으로 Cohen’s d (Hedges’ g, Glass’s delta)\n\n|d|&lt;0.2 “negligible”, |d|&lt;0.5 “small”, |d|&lt;0.8 “medium”, 그 외 “large”\n예를 들어, 어떤 회사의 남녀의 연봉 차이가 $8000일 때, 그 자체로 연봉에 미치는 성별의 효과로 말할 수 있으나\n표준편차의 단위로 표현하는 것이 더 적절할 수 있음. 예를 들어 그 회사의 연봉의 편차가 $2000일 때와 $4,000일 때 남녀 연봉의 차이가 실제 주는 의미가 다름. 즉, $8000/$2000 = 4와 $8000/$4000 = 2가 되어 표준편차의 단위로 표현하면 더 의미가 있음. (또는 남녀 각각의 표준편차의 (weighted) 평균 (pooled standard deviation)으로 나눔)\n이 때, 어떤 표준편차로 나눌지는 연구내용에 맞춰 효과의 크기가 잘 전달되도록 선택.\n\n참고:\nCohen, J. (1992). A power primer. Psychological Bulletin, 112, 155-159.\nDavid C. Howell (2011). Confidence Intervals on Effect Size\nR에서 d-family 효과 크기를 계산하는 한 방법\n구체적 계산식은 help(cohens_d) 참고\ncohens_d(ata ~ rel,  # library(effectsize)\n    data = filter(ata, \n        rel %in% c(\"Protestant\", \"Catholic\")))\ncohens_d(ata ~ rel, \n    data = filter(ata, \n        rel %in% c(\"Protestant\", \"Jewish\")))\n\n\n\n\n# A tibble: 1 × 4\n  Cohens_d    CI CI_low CI_high\n     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1.37  0.95  0.404    2.30\n\n\n\n\n# A tibble: 1 × 4\n  Cohens_d    CI CI_low CI_high\n     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1   -0.365  0.95  -1.34   0.615",
    "crumbs": [
      "Statistics",
      "Categorical IVs"
    ]
  },
  {
    "objectID": "contents/categorical.html#simpler-model",
    "href": "contents/categorical.html#simpler-model",
    "title": "Categorical IVs",
    "section": "Simpler model",
    "text": "Simpler model\n예제: 이타적인 성향이 인구밀도에 영향을 받을 것이라는 가설 하에 도시지역(city)과 그 주변도시(noncity)의 주민들을 조사 (p. 344)\nData: c08e02dt.csv\n이 때, 연구자는 인구밀도에 따른 이타성의 차이는 그저 두 지역의 neuroticism의 차이를 반영할 뿐일 수 있음을 의심한다고 하면,\n\naltruism &lt;- read_csv(\"data/c08e02dt.csv\")\naltruism\naltruism |&gt; \n  ggplot(aes(x = city, y = altruism)) +\n  geom_boxplot()\n\n\n\n\n# A tibble: 150 × 5\n   altruism   ses neuroticism area       city    \n      &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;   \n 1     69.1  66.7        61.0 small_town non-city\n 2     56.2  58.0        73.6 small_town non-city\n 3     65.6  36.3        41.2 small_town non-city\n 4     65.8  63.8        55.9 small_town non-city\n 5     63.1  46.1        46.4 small_town non-city\n 6     50.6  42.2        58.2 small_town non-city\n 7     63.5  54.4        54.6 small_town non-city\n 8     69.1  26.2        47.5 small_town non-city\n 9     69.9  50.6        59.0 small_town non-city\n10     49.0  31.9        49.0 small_town non-city\n# ℹ 140 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\naltruism |&gt; \n  ggplot(aes(x = city, y = neuroticism)) +\n  geom_boxplot()\naltruism |&gt; \n  ggplot(aes(x = neuroticism, y = altruism)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naltruism |&gt; group_by(city) |&gt; \n  summarise(\n    mean_altruism = mean(altruism), sd_altruism = sd(altruism),\n    mean_neuroticism = mean(neuroticism), sd_neuroticism = sd(neuroticism)\n  )\n\n# A tibble: 2 × 5\n  city     mean_altruism sd_altruism mean_neuroticism sd_neuroticism\n  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 city              34.8        10.9             58.4          10.4 \n2 non-city          53.2        11.8             55.0           9.10\n\n\n위 플랏에서 확인해 볼 수 있으며, 아래 상관계수를 통해서도 세 변수들 간의 상관관계가 있음을 확인할 수 있음.\n\n# factor로 변환; label도 함께 지정\naltruism &lt;- altruism |&gt;\n    mutate(\n        city = factor(city,\n            levels = c(\"non-city\", \"city\"),\n            labels = c(\"noncity\", \"city\")\n        )\n    )\n\n일반적으로 dummy variable과의 상관계수는 해석이 어려우나, 다음과 같은 방식으로 살펴볼 수 있음.\n\naltruism_dummy &lt;- fastDummies::dummy_cols(altruism, \"city\")\nlowerCor(altruism_dummy)\n\n             altrs ses   nrtcs area* city* cty_n cty_c\naltruism      1.00                                    \nses          -0.02  1.00                              \nneuroticism  -0.25  0.12  1.00                        \narea*         0.68 -0.20 -0.20  1.00                  \ncity*        -0.61  0.28  0.17 -0.87  1.00            \ncity_noncity  0.61 -0.28 -0.17  0.87 -1.00  1.00      \ncity_city    -0.61  0.28  0.17 -0.87  1.00 -1.00  1.00\n\n\naltruism |&gt; \n  ggplot(aes(x = neuroticism, y = altruism, color = city)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n이제 neuroticism을 통계적으로 통제(control for, hold it constant, partial the effect of)한 선형회귀모형을 세우면,\n(ANOVA 프레임워크에서 ANCOVA라고도 함; analysis of covariance)\n\n\n\n\n\n\nImportant\n\n\n\n아래 선형모형의 중요한 전제는 city와 altruism의 관계가 neuroticism 정도에 따라 변하지 않을 것이라는 것임.\n위 플랏으로부터 어느 정도 정당화될 수 있고, 추가적으로 통계적 검정를 통해 확인할 수 있음.\n\n\n\nmod &lt;- lm(altruism ~ city + neuroticism, data = altruism)\nS(mod)\n\nCall: lm(formula = altruism ~ city + neuroticism, data = altruism)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  65.23452    5.45529  11.958  &lt; 2e-16 ***\ncitycity    -17.62565    1.94617  -9.057 7.63e-16 ***\nneuroticism  -0.21939    0.09684  -2.266   0.0249 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 11.32 on 147 degrees of freedom\nMultiple R-squared: 0.3972\nF-statistic: 48.44 on 2 and 147 DF,  p-value: &lt; 2.2e-16 \n    AIC     BIC \n1158.63 1170.68 \n\n\n\\(\\widehat Y = -17.62 \\cdot city - 0.22 \\cdot neuroticism + 59.731\\)\nneuroticism을 centering한 후, 선형회귀모형을 세우면,\n\nlibrary(jtools) # for center()\nmod &lt;- lm(altruism ~ city + center(neuroticism), data = altruism)\nS(mod)\n\nCall: lm(formula = altruism ~ city + center(neuroticism), data = altruism)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          52.88494    1.16772  45.289  &lt; 2e-16 ***\ncitycity            -17.62565    1.94617  -9.057 7.63e-16 ***\ncenter(neuroticism)  -0.21939    0.09684  -2.266   0.0249 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 11.32 on 147 degrees of freedom\nMultiple R-squared: 0.3972\nF-statistic: 48.44 on 2 and 147 DF,  p-value: &lt; 2.2e-16 \n    AIC     BIC \n1158.63 1170.68 \n\n\n\\(\\widehat Y = -17.62 \\cdot city - .22 \\cdot neuroticism_C + 52.88\\)\nAdjusted mean: predicted means for each group\n\n절편 52.88은 도시에 살지 않는 사람들(non city: 0)의 이타성의 adjusted mean (neuroticism을 통제했다는 의미에서)\n기울기 -17.62는 도시인과 아닌 사람간의 이타성의 adjusted mean 차이 (adjusted mean difference)\n도시인들에 대한 이타성의 adjusted mean = -17.62(1) -.22(0) + 52.88 = 35.26\n비도시인들에 대한 이타성의 adjusted mean = -17.62(0) -.22(0) + 52.88 = 52.88\n\n즉, neuroticism의 효과가 제거되었을 때 (partial out), 혹은 그 효과만큼 city가 조정받은 후 (adjusted for), 도시인과 아닌 사람들의 이타성은 각각 35.26, 52.88로 추정됨.\n\nlibrary(emmeans)\nemmeans(mod, pairwise ~ city)  # all pairwise\n\n$emmeans\n city    emmean   SE  df lower.CL upper.CL\n noncity   52.9 1.17 147     50.6     55.2\n city      35.3 1.54 147     32.2     38.3\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast       estimate   SE  df t.ratio p.value\n noncity - city     17.6 1.95 147   9.057  &lt;.0001\n\n\nPlot으로 표현하면: effect plot\n\nlibrary(effects)\nplot(predictorEffects(mod))\n\n\n\n\n\n\n\n\nneuroticism의 효과가 partial된 실제 값에 대해 플랏을 그리면: add-variable plot\n\nmcPlots(mod, terms = \"city\", overlaid = FALSE)\n\n\n\n\n\n\n\n\n위의 선형모형 \\(\\widehat Y = -17.62 \\cdot city - .22 \\cdot neuroticism_C + 52.88\\)이 예측하는 값을 플랏에 추가하면,\n\n두 라인의 기울기는 -.22로 “동일”하며, (동일해야 함!)\n그 간격은 도시인이 17.62 낮음\n\n\naltruism |&gt; \n  ggplot(aes(x = center(neuroticism), y = altruism, color = city)) +\n  geom_point() +\n  geom_smooth(se = FALSE, size = .3) +\n  geom_line(aes(y = mod$fitted.values), size = 1) # 모형의 예측값들\n\n\n\n\n\n\n\n\nneuroticism이 평균일 때의 adjusted mean은\n\\(\\widehat{Y}_{city} = -(17.62)(1) - (.22)(0.0) + 52.88 = adjusted ~ M_{city}\\) \\(\\widehat{Y}_{noncity} = -(17.62)(0) - (.22)(0.0) + 52.88 = adjusted ~ M_{noncity}\\)\n만약, centering하지 않은 식이라면 neuroticism의 평균값을 대입.\nPartial association\narea의 고유한 설명력을 파악하기 위해 partial association 대해 알아보는 방식은\n\njtools 패키지의 summ() 함수를 통해 partial, semi-partial correlation 계산\n모형의 비교를 통해 \\(R^2\\)의 변화를 살펴보는 방식: semi-partial (squared) \nANOVA 프레임워크에서 partial eta-squared를 계산하는 방식: semi-paritl, partial (squared)\n\n\n\nsumm(mod, part.corr = T, model.fit = F, model.info = F) |&gt; print()  # jtools package\n\nStandard errors:OLS\n------------------------------------------------------------------------------\n                              Est.   S.E.   t val.      p   partial.r   part.r\n------------------------- -------- ------ -------- ------ ----------- --------\n(Intercept)                  52.88   1.17    45.29   0.00                     \ncitycity                    -17.63   1.95    -9.06   0.00       -0.60    -0.58\ncenter(neuroticism)          -0.22   0.10    -2.27   0.02       -0.18    -0.15\n------------------------------------------------------------------------------\n\n\nneuroticism만을 포함한 모형과 area를 추가한 모형을 비교\n\nmod_reduced &lt;- lm(altruism ~ center(neuroticism), data = altruism) # reduced model\n\nexport_summs(mod_reduced, mod, \n    error_format = \"({p.value})\")\n\n\n\n\n\n\nModel 1Model 2\n\n(Intercept)46.42 ***52.88 ***\n\n(0.00)   (0.00)   \n\ncenter(neuroticism)-0.37 ** -0.22 *  \n\n(0.00)   (0.02)   \n\ncitycity       -17.63 ***\n\n       (0.00)   \n\nN150       150       \n\nR20.06    0.40    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\n\n\n\n\n\\(\\Delta R^2\\) = 0.40 - 0.06 = 0.34 : semi-partical correlation squared\nANOVA의 프레임워크에서 neuroticism의 효과가 partial out된 \\(\\eta^2\\)\n참고: Effect Sizes for ANOVAs\n\neta_squared(car::Anova(mod), partial = TRUE)  # partial correlation squared\n\n# Effect Size for ANOVA (Type II)\n\nParameter           | Eta2 (partial) |       95% CI\n---------------------------------------------------\ncity                |           0.36 | [0.26, 1.00]\ncenter(neuroticism) |           0.03 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].",
    "crumbs": [
      "Statistics",
      "Categorical IVs"
    ]
  },
  {
    "objectID": "contents/categorical.html#full-model",
    "href": "contents/categorical.html#full-model",
    "title": "Categorical IVs",
    "section": "Full model",
    "text": "Full model\n이타적인 성향이 인구밀도에 영향을 받을 것이라는 가설하에, 세 지역 (도시, 교외, 시골)의 주민들을 조사하는데, neuroticism 뿐만 아니라 사회경제적 상태(SES)도 이타성과 관련이 있음을 고려하면,\n\naltruism |&gt; \n  ggplot(aes(x = area, y = altruism)) +\n  geom_boxplot()\naltruism |&gt; \n  ggplot(aes(x = ses, y = altruism)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naltruism |&gt; \n  ggplot(aes(x = area, y = neuroticism)) +\n  geom_boxplot()\naltruism |&gt; \n  ggplot(aes(x = ses, y = neuroticism)) +\n  geom_point() +\n  geom_smooth()\naltruism |&gt; \n  ggplot(aes(x = area, y = ses)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n위 플랏에서 확인해 볼 수 있으며, 아래 상관계수를 통해서도 상관관계가 있음을 확인할 수 있음.\n일반적으로 dummy variable과의 상관계수는 해석이 어려우나, 다음과 같은 방식으로 살펴볼 수 있음.\n\n# factor로 변환; label도 함께 지정\naltruism &lt;- altruism |&gt;\n    mutate(\n        area = factor(area,\n            levels = c(\"small_town\", \"rural\", \"city\"),\n            labels = c(\"small\", \"rural\", \"city\")\n        )\n    )\n\naltruism_dummy &lt;- fastDummies::dummy_cols(altruism, \"area\")\nlowerCor(altruism_dummy)\n\n            altrs ses   nrtcs area* city* ar_sm ar_rr ar_ct\naltruism     1.00                                          \nses         -0.02  1.00                                    \nneuroticism -0.25  0.12  1.00                              \narea*       -0.68  0.20  0.20  1.00                        \ncity*       -0.61  0.28  0.17  0.87  1.00                  \narea_small   0.55 -0.05 -0.17 -0.84 -0.45  1.00            \narea_rural   0.12 -0.23 -0.01 -0.10 -0.59 -0.46  1.00      \narea_city   -0.61  0.28  0.17  0.87  1.00 -0.45 -0.59  1.00\n\n\naltruism |&gt; \n  ggplot(aes(x = neuroticism, y = altruism, color = area)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\naltruism |&gt; \n  ggplot(aes(x = ses, y = altruism, color = area)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n이제 neuroticism과 ses을 통계적으로 통제한 선형회귀모형을 세우면, (ANCOVA)\n\n\n\n\n\n\nImportant\n\n\n\n아래 선형모형의 중요한 전제는 area와 altruism의 관계가 neuroticism 또는 ses정도에 따라 변하지 않을 것이라는 것임.\n위 플랏으로부터 어느 정도 정당화될 수 있고, 추가적으로 통계적 검정를 통해 확인할 수 있음.\n\n\n\nmod_full &lt;- lm(altruism ~ area + neuroticism + ses, data = altruism)\nS(mod_full)\n\nCall: lm(formula = altruism ~ area + neuroticism + ses, data = altruism)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.82541    6.12678   9.928  &lt; 2e-16 ***\narearural   -10.21356    2.18807  -4.668 6.87e-06 ***\nareacity    -24.96670    2.24895 -11.102  &lt; 2e-16 ***\nneuroticism  -0.19045    0.08967  -2.124   0.0354 *  \nses           0.19643    0.08333   2.357   0.0197 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 10.38 on 145 degrees of freedom\nMultiple R-squared: 0.4997\nF-statistic:  36.2 on 4 and 145 DF,  p-value: &lt; 2.2e-16 \n    AIC     BIC \n1134.69 1152.76 \n\n\nCentering한 모형\n\nmod_full_c &lt;- lm(altruism ~ area + center(neuroticism) + center(ses), data = altruism)\nS(mod_full_c)\n\nCall: lm(formula = altruism ~ area + center(neuroticism) + center(ses), data =\n         altruism)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          59.38972    1.68236  35.301  &lt; 2e-16 ***\narearural           -10.21356    2.18807  -4.668 6.87e-06 ***\nareacity            -24.96670    2.24895 -11.102  &lt; 2e-16 ***\ncenter(neuroticism)  -0.19045    0.08967  -2.124   0.0354 *  \ncenter(ses)           0.19643    0.08333   2.357   0.0197 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 10.38 on 145 degrees of freedom\nMultiple R-squared: 0.4997\nF-statistic:  36.2 on 4 and 145 DF,  p-value: &lt; 2.2e-16 \n    AIC     BIC \n1134.69 1152.76 \n\n\n\n\n\n\n\n\nImportant\n\n\n\n통계적으로 유의하지 않는다고 해서, 변수를 제거하는 것은 절대 아님!\n위 모형은 명시적으로 neurotism을 통제한 상태, 즉 neurotism의 효과를 제거한 후 area의 효과를 본다는 것을 말해주고 있음.\n반면, 다른 독립변수들과 상관관계가 없다면 모형에 포함(통제)하지 않는 것이 적절. (명시 후에)\n\n\nneuroticism과 ses가 통제되지 않은 모형과 비교하면,\n또한 표준화된 모형과 비교하면,\nmod_simple &lt;- lm(altruism ~ area, data = altruism)\nexport_summs(mod_simple, mod_full_c, error_format = \"(p = {p.value})\", model.names = c(\"Simple\", \"Full Centered\"))\n# scale: 독립변수들을 표준화, transform.response: 종속변수를 표준화\nexport_summs(mod_simple, mod_full, scale = TRUE, transform.response = TRUE, error_format = \"(p = {p.value})\", model.names = c(\"Simple Std\", \"Full Std\"))\n\n\n\n\n\nSimpleFull Centered\n\n(Intercept)59.73 ***59.39 ***\n\n(p = 0.00)   (p = 0.00)   \n\narearural-11.15 ***-10.21 ***\n\n(p = 0.00)   (p = 0.00)   \n\nareacity-24.94 ***-24.97 ***\n\n(p = 0.00)   (p = 0.00)   \n\ncenter(neuroticism)       -0.19 *  \n\n       (p = 0.04)   \n\ncenter(ses)       0.20 *  \n\n       (p = 0.02)   \n\nN150       150       \n\nR20.47    0.50    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\n\nSimple StdFull Std\n\n(Intercept)0.92 ***0.90 ***\n\n(p = 0.00)   (p = 0.00)   \n\narearural-0.77 ***-0.71 ***\n\n(p = 0.00)   (p = 0.00)   \n\nareacity-1.72 ***-1.72 ***\n\n(p = 0.00)   (p = 0.00)   \n\nneuroticism       -0.13 *  \n\n       (p = 0.04)   \n\nses       0.15 *  \n\n       (p = 0.02)   \n\nN150       150       \n\nR20.47    0.50    \n\nAll continuous variables are mean-centered and scaled by 1 standard deviation.  *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\nmod_full_c: \\(\\widehat Y = -10.21 \\cdot rural - 24.97 \\cdot city -0.190 \\cdot neuroticism_C + 0.196 \\cdot ses_C + 59.39\\)\n\n절편 59.39은 small town 사람들의 이타성의 adjusted mean (neuroticism & ses을 통제했다는 의미에서)\n기울기 -10.21은 small town과 rural 사람간의 이타성의 adjusted mean 차이 (adjusted mean difference)\n기울기 -24.97은 small town과 city 사람간의 이타성의 adjusted mean 차이 (adjusted mean difference)\n\nAdjusted mean: predicted means for each group\n\nsmall town 사람들에 대한 이타성의 adjusted mean = -10.21(0) - 24.97(0) + 59.39 = 59.39\nrural 사람들에 대한 이타성의 adjusted mean = -10.21(1) - 24.97(0) + 59.39 = 49.18\ncity 사람들에 대한 이타성의 adjusted mean = -10.21(0) - 24.97(1) + 59.39 = 34.42\n\n즉, neuroticism과 ses의 효과가 제거되었을 때 (partial out), 혹은 그 효과만큼 city가 조정받은 후 (adjusted for), 각 지역의 사람들의 이타성은 각각 59.39, 49.18, 34.42로 추정됨.\n\nlibrary(emmeans)\n# adjusted means & contrast (adjusted mean difference)\nemmeans(mod_full, pairwise ~ area)\n\n$emmeans\n area  emmean   SE  df lower.CL upper.CL\n small   59.4 1.68 145     56.1     62.7\n rural   49.2 1.41 145     46.4     52.0\n city    34.4 1.45 145     31.6     37.3\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast      estimate   SE  df t.ratio p.value\n small - rural     10.2 2.19 145   4.668  &lt;.0001\n small - city      25.0 2.25 145  11.102  &lt;.0001\n rural - city      14.8 2.06 145   7.145  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nPlot으로 표현하면: effect plot\n\nlibrary(effects)\nplot(predictorEffects(mod_full, ~ area))\n\n\n\n\n\n\n\n\n위의 선형모형 \\(\\widehat Y = -10.21 \\cdot rural - 24.97 \\cdot city -0.190 \\cdot neuroticism_C + 0.196 \\cdot ses_C + 59.39\\) 이 예측하는 값을 플랏에 추가하면,\n\n세 라인의 기울기는 -0.19로 “동일”하며, (동일해야 함!)\n그 간격은 small town 사람들에 비해 rural 사람들이이 -10.21 낮고\n그 간격은 small town 사람들에 비해 city 사람들이이 -24.97 낮음\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\nlibrary(modelr)\ngrid_city &lt;- altruism |&gt; data_grid(neuroticism, area = \"city\", .model = mod_full) |&gt; \n  add_predictions(mod_full)\ngrid_rural &lt;- altruism |&gt; data_grid(neuroticism, area = \"rural\", .model = mod_full) |&gt; \n  add_predictions(mod_full)\ngrid_small &lt;- altruism |&gt; data_grid(neuroticism, area = \"small\", .model = mod_full) |&gt; \n  add_predictions(mod_full)\n\naltruism |&gt; \n  ggplot(aes(x = neuroticism, y = altruism, color = area)) +\n  geom_point() +\n  geom_smooth(se = FALSE, size = .3) +\n  geom_line(data = grid_city, aes(y = pred), size = 1) + \n  geom_line(data = grid_rural, aes(y = pred), size = 1) + \n  geom_line(data = grid_small, aes(y = pred), size = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartial association area의 고유한 설명력을 파악하기 위해 partial association\n\njtools 패키지의 summ() 함수를 통해 보기 어려움…\n모형의 비교를 통해 \\(R^2\\)의 변화를 살펴보는 방식: semi-partial (squared)\nSet correlation을 통해 partial out된 상관계수를 계산하는 방식: partial (squared)\nANOVA 프레임워크에서 partial eta-squared를 계산하는 방식: semi-paritl, partial (squared)\n\n\nsumm(mod_full, part.corr = T, model.fit = F, model.info = F) |&gt; print()  # jtools package\n\nStandard errors:OLS\n----------------------------------------------------------------------\n                      Est.   S.E.   t val.      p   partial.r   part.r\n----------------- -------- ------ -------- ------ ----------- --------\n(Intercept)          60.83   6.13     9.93   0.00                     \narearural           -10.21   2.19    -4.67   0.00       -0.36    -0.27\nareacity            -24.97   2.25   -11.10   0.00       -0.68    -0.65\nneuroticism          -0.19   0.09    -2.12   0.04       -0.17    -0.12\nses                   0.20   0.08     2.36   0.02        0.19     0.14\n----------------------------------------------------------------------\n\n\narea가 빠진 모형과 area를 추가한 모형을 비교\n\nmod_full_reduced &lt;- lm(altruism ~ neuroticism + ses, data = altruism) # reduced model\n\nexport_summs(mod_full_reduced, mod_full, \n    error_format = \"({p.value})\")\n\n\n\n\n\n\nModel 1Model 2\n\n(Intercept)66.88 ***60.83 ***\n\n(0.00)   (0.00)   \n\nneuroticism-0.37 ** -0.19 *  \n\n(0.00)   (0.04)   \n\nses0.01    0.20 *  \n\n(0.95)   (0.02)   \n\narearural       -10.21 ***\n\n       (0.00)   \n\nareacity       -24.97 ***\n\n       (0.00)   \n\nN150       150       \n\nR20.06    0.50    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\n\n\n\n\n\\(\\Delta R^2\\) = 0.50 - 0.06 = 0.44 : semi-partical correlation squared\nANOVA의 프레임워크에서 neuroticism과 ses의 효과가 partial out된 \\(\\eta^2\\)\n참고: Effect Sizes for ANOVAs\n\neta_squared(car::Anova(mod_full), partial = TRUE)  # partial correlation squared\n\n# Effect Size for ANOVA (Type II)\n\nParameter   | Eta2 (partial) |       95% CI\n-------------------------------------------\narea        |           0.47 | [0.37, 1.00]\nneuroticism |           0.03 | [0.00, 1.00]\nses         |           0.04 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nSet correlation을 통해 partial out된 상관계수\n\n# 우선 dummy variable을 생성\naltruism_dummy &lt;- fastDummies::dummy_cols(altruism, \"area\")\naltruism_dummy |&gt; head(3)\n\n# A tibble: 3 × 8\n  altruism   ses neuroticism area  city    area_small area_rural area_city\n     &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;        &lt;int&gt;      &lt;int&gt;     &lt;int&gt;\n1     69.1  66.7        61.0 small noncity          1          0         0\n2     56.2  58.0        73.6 small noncity          1          0         0\n3     65.6  36.3        41.2 small noncity          1          0         0\n\n# neuroticism & sex partialled out!\nsetCor(altruism ~ area_rural + area_city - neuroticism - ses, data = altruism_dummy)\n\n\n\n\n\n\n\n\nCall: setCor(y = altruism ~ area_rural + area_city - neuroticism - \n    ses, data = altruism_dummy)\n\nMultiple Regression from raw data \nThe following variables were partialed out: neuroticism ses \n and are included in the calculation of df1 and df2\n\n DV =  altruism* \n             slope   se      t       p lower.ci upper.ci  VIF  Vy.x\n(Intercept)*  0.00 0.06   0.00 1.0e+00    -0.12     0.12 1.00  0.00\narea_rural*  -0.34 0.07  -4.67 6.9e-06    -0.49    -0.20 1.47 -0.04\narea_city*   -0.83 0.08 -11.10 4.1e-21    -0.98    -0.69 1.47  0.51\n\nResidual Standard Error =  0.72  with  145  degrees of freedom\n\n Multiple Regression\n            R   R2   Ruw R2uw Shrunken R2 SE of R2 overall F df1 df2       p\naltruism 0.68 0.47 -0.55  0.3        0.45     0.06     63.58   2 145 1.5e-20\n\n\n즉, partial correlation = 0.68, partial correlation squared = 0.47 (=\\(\\eta^2\\))",
    "crumbs": [
      "Statistics",
      "Categorical IVs"
    ]
  },
  {
    "objectID": "contents/categorical.html#기타-예들",
    "href": "contents/categorical.html#기타-예들",
    "title": "Categorical IVs",
    "section": "기타 예들",
    "text": "기타 예들\n\n정치학자가 인종 (black, hispanic, white), 성별, 가족 소득 수준이 정치적 태도에 미치는 영향을 연구하고자 할 때,\n교육학자가 공립학교와 사립학교의 수학 성취도를 비교하고자 하는데, 가족 소득 수준을 고정(통제)시키고자 할 때,\n\n\n\n\n\n\n\nImportant\n\n\n\n관심사가 neuroticism이 이타성에 미치는 효과라면, 나머지 변수들(area, ses)는 통제변수로 보고 관심을 두지 않아도 됨.\n\n\nmod_full &lt;- lm(altruism ~ neuroticism + area + ses, data = altruism)\nsumm(mod_full, part.corr = T, model.fit = F, model.info = F) |&gt; print()  # jtools package\n\nStandard errors:OLS\n----------------------------------------------------------------------\n                      Est.   S.E.   t val.      p   partial.r   part.r\n----------------- -------- ------ -------- ------ ----------- --------\n(Intercept)          60.83   6.13     9.93   0.00                     \nneuroticism          -0.19   0.09    -2.12   0.04       -0.17    -0.12\narearural           -10.21   2.19    -4.67   0.00       -0.36    -0.27\nareacity            -24.97   2.25   -11.10   0.00       -0.68    -0.65\nses                   0.20   0.08     2.36   0.02        0.19     0.14\n----------------------------------------------------------------------\n\n\n표준화 계수 포함 lm.beta::lm.beta(mod_full)는 사용하지 말것; lm.beta 패키지는 오래된 방식을 사용하며, jtools 패키지의 summ() 함수를 사용할 것\n\nsumm(mod_full, scale = T, transform.response = T, part.corr = T, model.fit = F, model.info = F) |&gt; print()  # jtools package\n\nStandard errors:OLS\n---------------------------------------------------------------------\n                     Est.   S.E.   t val.      p   partial.r   part.r\n----------------- ------- ------ -------- ------ ----------- --------\n(Intercept)          0.90   0.12     7.71   0.00                     \nneuroticism         -0.13   0.06    -2.12   0.04       -0.17    -0.12\narearural           -0.71   0.15    -4.67   0.00       -0.36    -0.27\nareacity            -1.72   0.16   -11.10   0.00       -0.68    -0.65\nses                  0.15   0.06     2.36   0.02        0.19     0.14\n---------------------------------------------------------------------\n\nContinuous variables are mean-centered and scaled by 1 s.d.",
    "crumbs": [
      "Statistics",
      "Categorical IVs"
    ]
  },
  {
    "objectID": "contents/inference.html",
    "href": "contents/inference.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "평균이 \\(\\mu\\) 이고 분산이 \\(\\sigma^2\\) 인 모집단으로부터 추출된 표본 사이즈가 n인 표본들에 대해서\n\n\nSource: The Truthful Art by Albert Cairo\n\n각 표본의 평균 \\(\\bar{X}\\) 들의 분포를 평균의 표본 분포, the sampling distribution of the mean 이라고 하고, 이 분포는 the central limit theorem에 의해\n\n평균:  \\(\\displaystyle E(\\bar{X})=\\frac{m_1+m_2+m_3+\\cdots+m_w}{w}\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\mu\\) ; unbiased estimator\n분산:  \\(\\displaystyle V(\\bar{X})\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\frac{\\sigma^2}{n},\\)   이 표준 편차 \\(\\displaystyle\\frac{\\sigma}{\\sqrt{n}}\\) 를 standard error of estimate(표준 오차, SE)라고 함.\n\n이 표준 오차는 다시 말하면, 어떤 통계치(여기서는 평균)가 표본들 간에 얼마나 차이가 나는지를 알 수 있는 중요한 지표가 됨.\n\n분포: 모집단의 분포가 normal에 가까울 수록, 또는 표본 크기가 클수록 ( \\(n\\rightarrow\\infty, n &gt; 30\\) ) \\(\\displaystyle\\{m_1, m_2, m_3, \\cdots, m_w, \\cdots\\} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}}) : normal ~ distribution\\) (정규 분포)\n값을 정규화하면; \\(\\displaystyle Z=\\frac{X-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n분포: \\(\\displaystyle\\{z_1, z_2, z_3, \\cdots, z_w, \\cdots\\} \\sim N(0, 1) : standard ~ normal ~ distribution\\) (표준 정균 분포)\n\n실제 예를 통해서 살펴보면,\n예를 들어 어느 섬에 사는 민족의 남성 평균 키가 아래와 같은 분포를 가진다고 할 때 (평균: 173cm, 표준편차: 5cm),\n관찰한 100명의 한 표본에서 남성들의 키가 평균 174cm로 관찰되었다면 이 정도로 큰 값이 나올 가능성은 얼마정도 인가?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n표본 사이즈 n=25, 100, 400 비교\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n표본 사이즈가 커짐에 따라 평균들의 분포의 표준편차가 줄어들며,\n평균들의 표본 분포는 빠르게 정규 분포에 다가가므로,\n근사적으로 정규 분포의 값을 이용해 그 확률 값을 쉽게 구할 수 있음.\n\n특히, 값들을 정규화하여 표준정규분포 (평균 0, 표준편차 1)의 값을 이용함.\n예를 들어, 표본 사이즈가 100인 (b)의 경우, 평균 키 174cm는 표준화 값으로 2:\n\\(\\displaystyle \\frac{174 - 173}{0.5} = 2, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n음영된 부분은 대략 2.3%이고, 따라서 100명을 관찰한 표본의 평균 키가 174cm이상이 될 가능성은 2.3%에 밖에 되지 않음. 예를 들어, 1000번 같은 연구를 반복하면 23번 정도는 174cm 이상의 평균 키를 관찰할 수 있을 것임.\n\n\n\n\n\n\n\n\n\n실제 성취하고자 하는 것은 위 과정의 반대인 관찰한 특정 표본으로부터 모집단에 대해 추론하는 것임.\n이를 통계적 추론, statistical inference라고 함.\n가령, 어느 섬에 사는 민족으로부터 관찰된 100명의 키의 평균이 175cm이고 표준편차가 10cm인 경우, 이 민족의 키의 평균은 얼마 정도라고 파악할 수 있는가?\n\n먼저, 모집단의 평균 \\(\\mu\\) 를 가정하는데, 가령 \\(\\mu = 173\\) 라면, 우리가 관찰한 표본의 평균 175는 충분히 나올 수 있는 값인가? 이에 대해서는 위의 논리에 따라 구할 수 있음. 즉,\n\n\\(\\displaystyle \\frac{175 - 173}{\\frac{\\sigma}{10}} = ~?, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n만약, 모집단의 표준편차 \\(\\sigma\\) 가 예전처럼 5라면, \\(\\bar{Z} = 4\\) 가 되어 매우 희박한 경우가 될 것임. (실제로 0.0032%)\n모집단의 표준편차를 알 수 없기 때문에 차선책으로, 관찰한 표본의 표준편차로 대체해서 전개함\n이 경우, 표본의 표준편차가 10이기 때문에, \\(\\bar{Z} = 2\\) 가 되어 2.3% 정도의 가능성이 있다고 볼 수 있으나,\n표준편차의 대체로 인해 생기는 문제를 보완할 수 있는데, 사실 표본분포가 정규분포가 아닌 Student’s t-분포를 따르고, 이를 이용해서 확률값을 구함.\n이 경우는 \\(\\displaystyle t = \\frac{\\bar{X}-\\mu}{\\frac{s}{\\sqrt{n}}} = 2, ~ (s: the ~sample ~sd)\\) 로 t-분포에 의하면 2.4% 정도의 가능성이 있다고 봄\n\nt-분포는 자유도(degree of freedom)에 의해 분포가 바뀌는데 df는 n-1 (n: 표본 크기)\n\n\n이제 위의 과정을 계속 반복한다고 상상하면, 즉 모집단의 평균을 다른 값으로 가정하면서,\n\n관찰된 표본 평균 175cm가 95% (양 극단 2.5%를 제외한) 이내에서 관찰될 수 있는 모집단의 평균들을 모두 찾을 수 있음\n이 평균들의 범위를 95% confidence interval 이라고 부르고,\n식으로 전개하면, \\(\\displaystyle\\Bigg| \\frac{m-\\mu}{\\frac{s}{\\sqrt{n}}} \\Bigg| &lt; 1.66, ~(n=100)\\)\n\\(\\displaystyle m-1.66\\frac{s}{\\sqrt{n}} &lt; \\mu &lt; m + 1.66\\frac{s}{\\sqrt{n}}\\)\n위 예의 경우 \\(\\displaystyle 173.34 &lt; \\mu &lt; 176.66\\)\n즉, 우리는 95%의 확신을 갖고, 이 섬에 사는 민족의 평균 키는 173.34cm에서 176.66cm 사이에 있을 것이라고 말할 수 있음.\n이 cofidence interval의 크기를 결정하는 것은 \\(\\displaystyle\\frac{s}{\\sqrt{n}}\\) 즉, standard error of estimate인데, 범위가 좁아질수록, precision이 높다고 표현함.\n한편, 99%의 확신으로 (confidence level: 99%)는 그 키의 범위를 더 넓혀서 말할 수 있음. 이 경우 \\(|~t~| &lt; 2.36\\) 으로부터 모집단의 키가 (172.64cm, 177.36cm) 범위가 있다고 말할 수 있음.\n\n확신이 커지는 대신 범위가 넓어지므로 모집단의 예측에 대한 유용성이 떨어짐.\n\n\n\n\n\n\n\n\n\nConfidence Interval vs. Credible Region\n\n\n\nFrequentist의 입장에서 말하면, “실험을 계속 반복한다면, 5%의 연구에서만 신뢰구간 밖에 true parameter값이 존재하게 될 것임”\n이는 Bayesian의 입장과 매우 다른 것임;\n“주어진 데이터에서 parameter의 값이 credible region에 들어갈 확률이 95%임”(parameter가 변함)\n보통 이 둘을 섞어서 말하는 경향이 있음.\n\n\n가설 검정(hypothesis testing)\n회귀분석 결과표의 p-values들은 영가설(null hypothesis)을 테스트하는 것이며, 위에서 평균이 0이라고 가정하는 경우에 해당\n\n가설/가정: “모집단의 평균 키가 0cm이라면”, 표본에서 관찰된 175cm는 충분히 나올 수 있는 값인가?\n\n절편(intercept)만 있는 null 모형(\\(\\hat y = b_0\\))에 대한 절편에 대한 가설 검증.\n\n회귀계수 b에 대한 테스트도 마찬가지로, 표본분포가 근사적으로 정규분포를 따르므로, 적절한 표준편차를 얻어 위와 같은 방식으로 테스트를 할 수 있음.\n\n\n\n\n위의 논리와 비슷하게 회귀 계수가 표본 마다 얼마나 변하는 지를 구할 수 있고,\n회귀 계수에 대한 confidence interval을 구할 수 있음.\n변수가 한 개인 경우:\n회귀계수 \\(b\\) 에 대한 표본 분포는 평균이 \\(b\\) 인 정규분포를 따르고, 표준편차 즉, standard error of estimate는 근사적으로 다음과 같음\n\\(\\displaystyle SE^2(b) = \\frac{{MS}_{residual}}{N \\cdot Var(X)}\\)\nConfidence interval: \\(b\\pm t_{\\alpha/2}SE, ~(df = N-2)\\)\n\n다중 회귀 모형의 경우:\n예측변수 \\(X_j\\) 에 대해서 모집단의 회귀계수 \\(b_j\\) 에 대한 표본 분포는 평균이 \\(b_j\\) 인 정규분포를 따르고, 표준편차, 즉 standard error는 근사적으로 다음과 같음.\n\\(\\displaystyle SE^2(b_j) = \\frac{{MS}_{residual}}{N \\cdot Var(X_j) \\cdot (1 - R^2_j)} = \\frac{{MS}_{residual}}{N \\cdot Var(X_j)}\\cdot VIF, ~(df = N-k-1)\\)\n\n표본 사이즈가 클수록\n평균 잔차가 작을수록\nj번째 예측변수의 값이 퍼져 있을수록\n다른 예측변수들로부터 j번째 예측변수가 예측되지 못할수록; 즉 다른 변수들과 correlate되지 않을수록\n\n\\(1 - R^2_j\\): tolerance, 그 역수: variance inflation factor (VIF)\nTolerance가 극히 작은 것은 intolerable! 봐줄 수 없음!\n예를 들어, 어느 문화에서 남자아이에게는 자기 주장이 강하도록 훈육하고, 여자아이에게는 반대로 훈육한다고 할 때,\n만약, 자기주장이 강하도록 부모가 교육하는 것이 자녀가 자기주장이 강하게 되는데 영향을 미친다는 것을 살펴보는데, 성별을 통계적으로 통제한다면, 훈육의 효과는 통계적으로 계산되기 어려워짐.\n이는 성별과 훈육방식이 큰 상관관계를 갖기 때문에, 성별과 독립적인 훈육의 변량이 작아져 회귀계수의 precision이 크게 낮아지기 때문임.",
    "crumbs": [
      "Statistics",
      "Inference"
    ]
  },
  {
    "objectID": "contents/inference.html#the-sampling-distribution-of-the-mean",
    "href": "contents/inference.html#the-sampling-distribution-of-the-mean",
    "title": "Statistical Inference",
    "section": "",
    "text": "표본 사이즈 n=25, 100, 400 비교\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n표본 사이즈가 커짐에 따라 평균들의 분포의 표준편차가 줄어들며,\n평균들의 표본 분포는 빠르게 정규 분포에 다가가므로,\n근사적으로 정규 분포의 값을 이용해 그 확률 값을 쉽게 구할 수 있음.\n\n특히, 값들을 정규화하여 표준정규분포 (평균 0, 표준편차 1)의 값을 이용함.\n예를 들어, 표본 사이즈가 100인 (b)의 경우, 평균 키 174cm는 표준화 값으로 2:\n\\(\\displaystyle \\frac{174 - 173}{0.5} = 2, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n음영된 부분은 대략 2.3%이고, 따라서 100명을 관찰한 표본의 평균 키가 174cm이상이 될 가능성은 2.3%에 밖에 되지 않음. 예를 들어, 1000번 같은 연구를 반복하면 23번 정도는 174cm 이상의 평균 키를 관찰할 수 있을 것임.\n\n\n\n\n\n\n\n\n\n실제 성취하고자 하는 것은 위 과정의 반대인 관찰한 특정 표본으로부터 모집단에 대해 추론하는 것임.\n이를 통계적 추론, statistical inference라고 함.\n가령, 어느 섬에 사는 민족으로부터 관찰된 100명의 키의 평균이 175cm이고 표준편차가 10cm인 경우, 이 민족의 키의 평균은 얼마 정도라고 파악할 수 있는가?\n\n먼저, 모집단의 평균 \\(\\mu\\) 를 가정하는데, 가령 \\(\\mu = 173\\) 라면, 우리가 관찰한 표본의 평균 175는 충분히 나올 수 있는 값인가? 이에 대해서는 위의 논리에 따라 구할 수 있음. 즉,\n\n\\(\\displaystyle \\frac{175 - 173}{\\frac{\\sigma}{10}} = ~?, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n만약, 모집단의 표준편차 \\(\\sigma\\) 가 예전처럼 5라면, \\(\\bar{Z} = 4\\) 가 되어 매우 희박한 경우가 될 것임. (실제로 0.0032%)\n모집단의 표준편차를 알 수 없기 때문에 차선책으로, 관찰한 표본의 표준편차로 대체해서 전개함\n이 경우, 표본의 표준편차가 10이기 때문에, \\(\\bar{Z} = 2\\) 가 되어 2.3% 정도의 가능성이 있다고 볼 수 있으나,\n표준편차의 대체로 인해 생기는 문제를 보완할 수 있는데, 사실 표본분포가 정규분포가 아닌 Student’s t-분포를 따르고, 이를 이용해서 확률값을 구함.\n이 경우는 \\(\\displaystyle t = \\frac{\\bar{X}-\\mu}{\\frac{s}{\\sqrt{n}}} = 2, ~ (s: the ~sample ~sd)\\) 로 t-분포에 의하면 2.4% 정도의 가능성이 있다고 봄\n\nt-분포는 자유도(degree of freedom)에 의해 분포가 바뀌는데 df는 n-1 (n: 표본 크기)\n\n\n이제 위의 과정을 계속 반복한다고 상상하면, 즉 모집단의 평균을 다른 값으로 가정하면서,\n\n관찰된 표본 평균 175cm가 95% (양 극단 2.5%를 제외한) 이내에서 관찰될 수 있는 모집단의 평균들을 모두 찾을 수 있음\n이 평균들의 범위를 95% confidence interval 이라고 부르고,\n식으로 전개하면, \\(\\displaystyle\\Bigg| \\frac{m-\\mu}{\\frac{s}{\\sqrt{n}}} \\Bigg| &lt; 1.66, ~(n=100)\\)\n\\(\\displaystyle m-1.66\\frac{s}{\\sqrt{n}} &lt; \\mu &lt; m + 1.66\\frac{s}{\\sqrt{n}}\\)\n위 예의 경우 \\(\\displaystyle 173.34 &lt; \\mu &lt; 176.66\\)\n즉, 우리는 95%의 확신을 갖고, 이 섬에 사는 민족의 평균 키는 173.34cm에서 176.66cm 사이에 있을 것이라고 말할 수 있음.\n이 cofidence interval의 크기를 결정하는 것은 \\(\\displaystyle\\frac{s}{\\sqrt{n}}\\) 즉, standard error of estimate인데, 범위가 좁아질수록, precision이 높다고 표현함.\n한편, 99%의 확신으로 (confidence level: 99%)는 그 키의 범위를 더 넓혀서 말할 수 있음. 이 경우 \\(|~t~| &lt; 2.36\\) 으로부터 모집단의 키가 (172.64cm, 177.36cm) 범위가 있다고 말할 수 있음.\n\n확신이 커지는 대신 범위가 넓어지므로 모집단의 예측에 대한 유용성이 떨어짐.\n\n\n\n\n\n\n\n\n\nConfidence Interval vs. Credible Region\n\n\n\nFrequentist의 입장에서 말하면, “실험을 계속 반복한다면, 5%의 연구에서만 신뢰구간 밖에 true parameter값이 존재하게 될 것임”\n이는 Bayesian의 입장과 매우 다른 것임;\n“주어진 데이터에서 parameter의 값이 credible region에 들어갈 확률이 95%임”(parameter가 변함)\n보통 이 둘을 섞어서 말하는 경향이 있음.\n\n\n가설 검정(hypothesis testing)\n회귀분석 결과표의 p-values들은 영가설(null hypothesis)을 테스트하는 것이며, 위에서 평균이 0이라고 가정하는 경우에 해당\n\n가설/가정: “모집단의 평균 키가 0cm이라면”, 표본에서 관찰된 175cm는 충분히 나올 수 있는 값인가?\n\n절편(intercept)만 있는 null 모형(\\(\\hat y = b_0\\))에 대한 절편에 대한 가설 검증.\n\n회귀계수 b에 대한 테스트도 마찬가지로, 표본분포가 근사적으로 정규분포를 따르므로, 적절한 표준편차를 얻어 위와 같은 방식으로 테스트를 할 수 있음.",
    "crumbs": [
      "Statistics",
      "Inference"
    ]
  },
  {
    "objectID": "contents/inference.html#regression-model-coefficients",
    "href": "contents/inference.html#regression-model-coefficients",
    "title": "Statistical Inference",
    "section": "",
    "text": "위의 논리와 비슷하게 회귀 계수가 표본 마다 얼마나 변하는 지를 구할 수 있고,\n회귀 계수에 대한 confidence interval을 구할 수 있음.\n변수가 한 개인 경우:\n회귀계수 \\(b\\) 에 대한 표본 분포는 평균이 \\(b\\) 인 정규분포를 따르고, 표준편차 즉, standard error of estimate는 근사적으로 다음과 같음\n\\(\\displaystyle SE^2(b) = \\frac{{MS}_{residual}}{N \\cdot Var(X)}\\)\nConfidence interval: \\(b\\pm t_{\\alpha/2}SE, ~(df = N-2)\\)\n\n다중 회귀 모형의 경우:\n예측변수 \\(X_j\\) 에 대해서 모집단의 회귀계수 \\(b_j\\) 에 대한 표본 분포는 평균이 \\(b_j\\) 인 정규분포를 따르고, 표준편차, 즉 standard error는 근사적으로 다음과 같음.\n\\(\\displaystyle SE^2(b_j) = \\frac{{MS}_{residual}}{N \\cdot Var(X_j) \\cdot (1 - R^2_j)} = \\frac{{MS}_{residual}}{N \\cdot Var(X_j)}\\cdot VIF, ~(df = N-k-1)\\)\n\n표본 사이즈가 클수록\n평균 잔차가 작을수록\nj번째 예측변수의 값이 퍼져 있을수록\n다른 예측변수들로부터 j번째 예측변수가 예측되지 못할수록; 즉 다른 변수들과 correlate되지 않을수록\n\n\\(1 - R^2_j\\): tolerance, 그 역수: variance inflation factor (VIF)\nTolerance가 극히 작은 것은 intolerable! 봐줄 수 없음!\n예를 들어, 어느 문화에서 남자아이에게는 자기 주장이 강하도록 훈육하고, 여자아이에게는 반대로 훈육한다고 할 때,\n만약, 자기주장이 강하도록 부모가 교육하는 것이 자녀가 자기주장이 강하게 되는데 영향을 미친다는 것을 살펴보는데, 성별을 통계적으로 통제한다면, 훈육의 효과는 통계적으로 계산되기 어려워짐.\n이는 성별과 훈육방식이 큰 상관관계를 갖기 때문에, 성별과 독립적인 훈육의 변량이 작아져 회귀계수의 precision이 크게 낮아지기 때문임.",
    "crumbs": [
      "Statistics",
      "Inference"
    ]
  },
  {
    "objectID": "contents/inference.html#multiple-regression에-적용",
    "href": "contents/inference.html#multiple-regression에-적용",
    "title": "Statistical Inference",
    "section": "Multiple Regression에 적용",
    "text": "Multiple Regression에 적용\ncar 패키지의 Boot() 이용\n\nset.seed(123)\nPrestige2 &lt;- na.omit(Prestige)  # Boot() 함수는 결측치(NA)를 처리하지 못함\n\nmod_prestige &lt;- lm(prestige ~ education + log2(income) + type, data = Prestige2)\nprestige_boot &lt;- car::Boot(mod_prestige, R=1000)\n\ncar::Confint(prestige_boot) %&gt;% round(., 3) |&gt; print()\n\nBootstrap bca confidence intervals\n\n             Estimate    2.5 %  97.5 %\n(Intercept)   -81.202 -105.620 -53.944\neducation       3.284    2.100   4.449\nlog2(income)    7.269    4.991   9.411\ntypeprof        6.751    0.458  12.978\ntypewc         -1.439   -5.314   2.986\n\n\neducation 파라미터 추정치 1000개의 분포\n\nlibrary(ggpubr)\nprestige_boot$t |&gt; as_tibble() |&gt; \n  ggplot(aes(x = education)) +\n  geom_histogram(binwidth = 0.05, fill = \"white\", color = \"black\") +\n  geom_vline(xintercept = c(2.1, 4.4), color = \"red\", linetype = 1)\n\n\n\n\n\n\n\n\n\nparameters 패키지의 model_parameters() 이용\n\nlibrary(parameters)\nmodel_parameters(mod_prestige, boot=TRUE, ci_method=\"bci\") |&gt; print()\n\nParameter     | Coefficient |            95% CI |      p\n--------------------------------------------------------\n(Intercept)   |      -81.63 | [-106.07, -56.29] | &lt; .001\neducation     |        3.25 | [   2.13,   4.37] | &lt; .001\nincome [log2] |        7.37 | [   5.00,   9.39] | &lt; .001\ntype [prof]   |        6.88 | [   0.91,  12.90] | 0.026 \ntype [wc]     |       -1.36 | [  -5.25,   3.10] | 0.518",
    "crumbs": [
      "Statistics",
      "Inference"
    ]
  },
  {
    "objectID": "contents/inference.html#mediation-analysis에-적용",
    "href": "contents/inference.html#mediation-analysis에-적용",
    "title": "Statistical Inference",
    "section": "Mediation Analysis에 적용",
    "text": "Mediation Analysis에 적용\n\n\nlibrary(haven)\nmaternal &lt;- read_spss(\"howell/maternal_care.sav\")\nmaternal &lt;- na.omit(maternal)\nmaternal |&gt; head(5)\n\n# A tibble: 5 × 4\n  FAMID Esteem MatCare Efficacy\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1   3.83    2.58      3.7\n2     2   3.5     2.83      3.4\n3     4   4       3.17      3.8\n4     8   4       3.75      3.9\n5     9   4       3.58      3.9\n\n\n\nboot 패키지의 boot() 활용\n\nlibrary(boot)\n\n# 함수 정의\nindirect_effect &lt;- function(data, indices) {\n  sample &lt;- data[indices, ]  # 부트스트랩 샘플링\n  model_M &lt;- lm(Esteem ~ MatCare, data = sample)\n  model_Y &lt;- lm(Efficacy ~ MatCare + Esteem, data = sample)\n  \n  return (model_M$coef[2] * model_Y$coef[3])\n}\n\nboot_results &lt;- boot(maternal, indirect_effect, R = 1000)\nsummary(boot_results)\n\n# 95% 신뢰구간 계산\nboot.ci(boot_results, type = \"bca\")\n\n\n\nlavaan 패키지의 활용: SEM 분석툴\n\nlibrary(lavaan)\n\nmod1 &lt;- \" \n    # models\n      Esteem ~ a*MatCare\n      Efficacy ~ b*Esteem + c*MatCare\n  \n    # indirect, total effect\n      indirect := a*b\n      total := c + a*b\n\"\n\nfit1 &lt;- sem(model = mod1, data = maternal, se=\"bootstrap\", bootstrap = 1000)\nsummary(fit1, ci=T, fit.measures=F) # ci:confidence interval, fit.measures: fit indices, standardized = F\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                            92\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Esteem ~                                                              \n    MatCare    (a)    0.364    0.106    3.430    0.001    0.163    0.580\n  Efficacy ~                                                            \n    Esteem     (b)    0.146    0.054    2.717    0.007    0.049    0.261\n    MatCare    (c)    0.057    0.037    1.525    0.127   -0.023    0.129\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .Esteem            0.246    0.044    5.571    0.000    0.162    0.339\n   .Efficacy          0.051    0.007    6.889    0.000    0.036    0.065\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n    indirect          0.053    0.021    2.470    0.014    0.017    0.107\n    total             0.110    0.034    3.228    0.001    0.046    0.176\n\n# 모든 parameter에 대한 결과\nparameterEstimates(fit1, level = 0.95, boot.ci.type=\"bca.simple\") # bca.simple: bias-corrected, standardized = F\n\n       lhs op      rhs    label   est    se     z pvalue ci.lower ci.upper\n1   Esteem  ~  MatCare        a 0.364 0.106 3.430  0.001    0.177    0.585\n2 Efficacy  ~   Esteem        b 0.146 0.054 2.717  0.007    0.034    0.251\n3 Efficacy  ~  MatCare        c 0.057 0.037 1.525  0.127   -0.028    0.123\n4   Esteem ~~   Esteem          0.246 0.044 5.571  0.000    0.169    0.352\n5 Efficacy ~~ Efficacy          0.051 0.007 6.889  0.000    0.039    0.072\n6  MatCare ~~  MatCare          0.361 0.000    NA     NA    0.361    0.361\n7 indirect :=      a*b indirect 0.053 0.021 2.470  0.014    0.018    0.109\n8    total :=    c+a*b    total 0.110 0.034 3.228  0.001    0.038    0.172\n\n\n\nmod2 &lt;- \"\n    # direct effect\n      Efficacy ~ c*MatCare\n\n    # mediator\n      Esteem ~ a*MatCare\n      Efficacy ~ b*Esteem\n\n    # indirect, total effect\n      indirect := a*b\n      total := c + a*b\n\"\n\nfit2 &lt;- sem(model = mod2, data = maternal, se=\"bootstrap\", bootstrap = 1000)\nsummary(fit2, ci = T, fit.measures = F) # ci:confidence interval, fit.measures: fit indices, standardized = F\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                            92\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Efficacy ~                                                            \n    MatCare    (c)    0.057    0.037    1.525    0.127   -0.023    0.129\n  Esteem ~                                                              \n    MatCare    (a)    0.364    0.106    3.430    0.001    0.163    0.580\n  Efficacy ~                                                            \n    Esteem     (b)    0.146    0.054    2.717    0.007    0.049    0.261\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .Efficacy          0.051    0.007    6.889    0.000    0.036    0.065\n   .Esteem            0.246    0.044    5.571    0.000    0.162    0.339\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n    indirect          0.053    0.021    2.470    0.014    0.017    0.107\n    total             0.110    0.034    3.228    0.001    0.046    0.176\n\n# 모든 parameter에 대한 결과\nparameterEstimates(fit2, level = 0.95, boot.ci.type = \"bca.simple\") # bca.simple: bias-corrected, standardized = F\n\n       lhs op      rhs    label   est    se     z pvalue ci.lower ci.upper\n1 Efficacy  ~  MatCare        c 0.057 0.037 1.525  0.127   -0.028    0.123\n2   Esteem  ~  MatCare        a 0.364 0.106 3.430  0.001    0.177    0.585\n3 Efficacy  ~   Esteem        b 0.146 0.054 2.717  0.007    0.034    0.251\n4 Efficacy ~~ Efficacy          0.051 0.007 6.889  0.000    0.039    0.072\n5   Esteem ~~   Esteem          0.246 0.044 5.571  0.000    0.169    0.352\n6  MatCare ~~  MatCare          0.361 0.000    NA     NA    0.361    0.361\n7 indirect :=      a*b indirect 0.053 0.021 2.470  0.014    0.018    0.109\n8    total :=    c+a*b    total 0.110 0.034 3.228  0.001    0.038    0.172",
    "crumbs": [
      "Statistics",
      "Inference"
    ]
  },
  {
    "objectID": "contents/inference.html#moderated-mediation에-응용",
    "href": "contents/inference.html#moderated-mediation에-응용",
    "title": "Statistical Inference",
    "section": "Moderated Mediation에 응용",
    "text": "Moderated Mediation에 응용\n\n\np. 424, Introduction to Mediation, Moderation, and Conditional Process Analysis (3e) by Andrew F. Hayes\n\n\nteams &lt;- read_csv(\"data/hayes2022data/teams/teams.csv\")\nteams &lt;- teams |&gt; \n  mutate(\n    negtone_c = center(negtone),\n    negexp_c = center(negexp),\n    negtone_negexp_c = negtone_c*negexp_c,\n  )\n\nmod &lt;- \"\n  # models\n    perform ~ c*dysfunc + b1*negtone_c + b2*negexp_c + b3*negtone_negexp_c\n    negtone_c ~ a*dysfunc\n  \n  # conditional effects: m-sd, m, m+sd\n    b_low := b1 + b3*(-0.5437)  # mean - sd; sd = 0.5437\n    b_mean := b1 + b3*0  # mean\n    b_high := b1 + b3*0.5437  # mean + sd\n  \n  # conditional indirect effects\n    ab_low := a * b_low\n    ab_mean := a * b_mean\n    ab_high := a * b_high\n  \n  # index of moderated mediation\n    index_Mod_Med := a*b3\n\"\n\nfit &lt;- lavaan::sem(model = mod, data = teams, se=\"bootstrap\")\nsummary(fit, ci = T, fit.measures = F)\n\nlavaan 0.6-19 ended normally after 2 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n\n  Number of observations                            60\n\nModel Test User Model:\n                                                      \n  Test statistic                                 6.999\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.030\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  perform ~                                                             \n    dysfunc    (c)    0.366    0.194    1.891    0.059   -0.109    0.669\n    negtone_c (b1)   -0.431    0.129   -3.337    0.001   -0.648   -0.129\n    negexp_c  (b2)   -0.044    0.102   -0.428    0.669   -0.255    0.148\n    ngtn_ngx_ (b3)   -0.517    0.235   -2.200    0.028   -1.052   -0.126\n  negtone_c ~                                                           \n    dysfunc    (a)    0.620    0.227    2.729    0.006    0.221    1.119\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .perform           0.185    0.032    5.713    0.000    0.111    0.240\n   .negtone_c         0.219    0.051    4.272    0.000    0.118    0.317\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n    b_low            -0.150    0.221   -0.681    0.496   -0.505    0.372\n    b_mean           -0.431    0.129   -3.335    0.001   -0.648   -0.129\n    b_high           -0.713    0.132   -5.407    0.000   -0.985   -0.483\n    ab_low           -0.093    0.150   -0.619    0.536   -0.351    0.268\n    ab_mean          -0.267    0.118   -2.270    0.023   -0.525   -0.054\n    ab_high          -0.442    0.163   -2.710    0.007   -0.773   -0.139\n    index_Mod_Med    -0.320    0.190   -1.682    0.093   -0.791   -0.046\n\n# 모든 parameter에 대한 결과\nparameterEstimates(fit, level = 0.95, boot.ci.type = \"bca.simple\")\n\n                lhs op              rhs         label    est    se      z\n1           perform  ~          dysfunc             c  0.366 0.194  1.891\n2           perform  ~        negtone_c            b1 -0.431 0.129 -3.337\n3           perform  ~         negexp_c            b2 -0.044 0.102 -0.428\n4           perform  ~ negtone_negexp_c            b3 -0.517 0.235 -2.200\n5         negtone_c  ~          dysfunc             a  0.620 0.227  2.729\n6           perform ~~          perform                0.185 0.032  5.713\n7         negtone_c ~~        negtone_c                0.219 0.051  4.272\n8           dysfunc ~~          dysfunc                0.136 0.000     NA\n9           dysfunc ~~         negexp_c               -0.001 0.000     NA\n10          dysfunc ~~ negtone_negexp_c               -0.003 0.000     NA\n11         negexp_c ~~         negexp_c                0.291 0.000     NA\n12         negexp_c ~~ negtone_negexp_c                0.046 0.000     NA\n13 negtone_negexp_c ~~ negtone_negexp_c                0.072 0.000     NA\n14            b_low :=  b1+b3*(-0.5437)         b_low -0.150 0.221 -0.681\n15           b_mean :=          b1+b3*0        b_mean -0.431 0.129 -3.335\n16           b_high :=     b1+b3*0.5437        b_high -0.713 0.132 -5.407\n17           ab_low :=          a*b_low        ab_low -0.093 0.150 -0.619\n18          ab_mean :=         a*b_mean       ab_mean -0.267 0.118 -2.270\n19          ab_high :=         a*b_high       ab_high -0.442 0.163 -2.710\n20    index_Mod_Med :=             a*b3 index_Mod_Med -0.320 0.190 -1.682\n   pvalue ci.lower ci.upper\n1   0.059   -0.014    0.716\n2   0.001   -0.660   -0.149\n3   0.669   -0.251    0.151\n4   0.028   -1.072   -0.142\n5   0.006    0.216    1.109\n6   0.000    0.137    0.279\n7   0.000    0.135    0.355\n8      NA    0.136    0.136\n9      NA   -0.001   -0.001\n10     NA   -0.003   -0.003\n11     NA    0.291    0.291\n12     NA    0.046    0.046\n13     NA    0.072    0.072\n14  0.496   -0.509    0.346\n15  0.001   -0.660   -0.149\n16  0.000   -1.008   -0.499\n17  0.536   -0.426    0.190\n18  0.023   -0.584   -0.086\n19  0.007   -0.772   -0.138\n20  0.093   -0.797   -0.049",
    "crumbs": [
      "Statistics",
      "Inference"
    ]
  },
  {
    "objectID": "contents/notice.html#중간시험-대체-과제",
    "href": "contents/notice.html#중간시험-대체-과제",
    "title": "Notice",
    "section": "중간시험 대체 과제",
    "text": "중간시험 대체 과제",
    "crumbs": [
      "Notice"
    ]
  },
  {
    "objectID": "contents/notice.html#기말시험",
    "href": "contents/notice.html#기말시험",
    "title": "Notice",
    "section": "기말시험",
    "text": "기말시험",
    "crumbs": [
      "Notice"
    ]
  },
  {
    "objectID": "contents/regression2.html",
    "href": "contents/regression2.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "독립/예측 변수가 2개 이상인 경우\n예측변수들 각각의 고유한 효과(effect)를 추정(estimate)\n이는 다른 변수들의 영향이 제거된 해당 변수의 효과는 어떠한가를 의미\n\n앞서 논의된 내용은 두 변수 사이의 관계를 다룸으로써 비교적 단순한 추론 및 두 변수 간에 모종의 관계의 유무(영가설) 정도를 살펴보았음.\n3개 이상의 변수 간의 관계에 대해서는 기하급수적으로 복잡한 관계가 나타남으로 인해, 연구자는 영향을 주고 받는 변수들 간의 인과 관계에 대해 충분한 이론적 근거를 갖고, 분석의 목적을 분명히 할 필요가 있음. (탐색적 분석이나 단순한 예측을 위한 것이 아니라면)\n인과분석은 유전학자였던 Sewell Wright(1921)가 유전적 효과와 비유전적 효과를 분리하려는 노력하에 개발했던 경로분석 다이어그램(path analytic diagram)에 그 뿌리를 두고 있으며, 후에 구조모형(structural model)으로 불리어 이어져 왔으며, causal inference 분야에서 완성되어가고 있음.\n기본적인 인과관계의 프레임워크에서, X가 Y의 원인이기 위해서 다음 4가지 조건을 만족해야 함.\n\nX는 시간적으로 Y에 선행\n인과적 효과를 만들어내는 기제(mechanism)를 상정할 수 있음\nX가 변하면 Y도 변화가 발생함 (association or correlation)\n\nX를 변화시키면 Y가 변한다는 것은 뜻은 아님.\n\n성별처럼 변화시킬 수 없는 요인도 있음\nX를 어떻게 manipulate 하느냐에 따라 정상적 기제가 변형되어 다른 효과가 나타날 수 있음.\n\n임금을 갑자기 2배 올리면?\n임금을 줄이면?\n\n\n\n다른 요인들 (confounding)을 제거한 후에도 X의 효과가 나타나야 함.\n\n임금은 연령이 높을수록 높아지는데 삶의 만족도는 늙음으로부터 오는 정신적 여유에서 발생한 것이라면?\n\n\n\n인과관계는 통계적 분석에 의해 증명될 수 있는 것이 아니며,\n관찰된 데이터와 상정한 모형이 어느 정도 일치한다라고 말할 수 있는 정도에서 결론지을 수 있으며,\n그 모형이 맞다면, 그 효과는 어떠하다고 실증적(empirically)으로 보이는 것임.\n모형의 가치는 그 구조적 논리에 크게 좌우됨.\n\n앞서 다뤘던 교수의 연봉에 연차와 성과물이 영향을 미친다는 인과모형을 세우면,\n\n연차와 성과물 간에 인과관계는 상정하지 않았음.\n적어도 연봉이 성과물이나 연차에 영향을 주지는 않는다고 상정했음.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n교수의 연봉(salary)이 학위를 받은 후 지난 시간(time since Ph.D.)과 출판물의 수(pubs)에 의해 어떻게 영향을 받는가?\n\n같은 연차의 교수들 간에 논문 수에 따라 연봉은 얼마나 차이가 나는가?\n동일한 개수의 논문을 발표한 교수들 간에 연차에 따라 연봉은 얼마나 차이가 나는가?\n\n앞서 연봉에 대한 예측모형을 다음과 같이 얻었는데,\n\nModel 1: \\(\\widehat{salary} = \\$1,224\\:time + \\$43,659\\)\nModel 2 : \\(\\widehat{salary} = \\$336\\:pubs + \\$46,357\\)\n\n다음과 같이 연차가 늘면 논문의 수도 따라서 늘어나는 경향이 있기 때문에, 연차 또는 논문 수의 고유한 효과를 추정하기 어려움.\n\n\\(\\widehat{pubs} = 1.98\\:time + 4.73\\)\n\n\nacad0 &lt;- read_csv(\"data/c0301dt.csv\")\n\n\nmod1 &lt;- lm(salary ~ time, data = acad0)\nmod2 &lt;- lm(salary ~ pubs, data = acad0)\n\n두 개의 예측변수를 모두 포함한 모형\nModel 3: \\(\\widehat{Y} = a_1 X_1 + a_2 X_2 + a_0 ~ (z=2x-y+1)\\)\n\\(\\widehat{salary} = \\$983\\:time + \\$122\\:pubs + \\$43,082\\)\nmod3 &lt;- lm(salary ~ time + pubs, data = acad0)\nsumm(mod3) |&gt; print()  # library(jtools)\n\n\n\nMODEL INFO:\nObservations: 15\nDependent Variable: salary\nType: OLS linear regression \n\nMODEL FIT:\nF(2,12) = 6.78, p = 0.01\nR² = 0.53\nAdj. R² = 0.45 \n\nStandard errors: OLS\n------------------------------------------------------\n                        Est.      S.E.   t val.      p\n----------------- ---------- --------- -------- ------\n(Intercept)         43082.39   3099.49    13.90   0.00\ntime                  982.87    452.06     2.17   0.05\npubs                  121.80    149.70     0.81   0.43\n------------------------------------------------------\n\n\n\nThe regression plane: x값이 고정될 때, 혹은 y값이 고정될 때, 동일한 기울기의 직선으로 나타남.\n\n\n\n\n\n\n\n3d plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n교수들의 연차와 그들이 쓴 논문 수는 깊이 연관되어 있으며 (r = 0.66), 두 변수의 redunancy가 각 변수들의 효과를 변화시킴.\n두 예측 변수의 산술적 합으로 연봉을 예측하므로 각 예측변수의 효과는 수정될 수 밖에 없음.\n수학적으로 보면, 각 예측변수의 기울기는 다른 예측변수의 값에 상관없이 일정하므로, 다른 예측변수들을 (임의의 값에) 고정시키는 효과를 가짐\n즉, 다른 변수와는 독립적인, 고유한 효과를 추정하게 됨\n\n세 모형을 비교하면,\nModel 1: \\(\\widehat{salary} = \\$1,224\\:time + \\$43,659\\)\nModel 2 : \\(\\widehat{salary} = \\$336\\:pubs + \\$46,357\\)\nModel 3: \\(\\widehat{salary} = \\$983\\:time + \\$122\\:pubs + \\$43,082\\)\n\n연차(time)의 효과는 $1,224에서 $984로 낮아졌고,\n논문수(pubs)의 효과는 $336에서 $122로 낮아졌음.\n\n각 회귀계수를 partial regression coefficient (부분 회귀 계수) 라고 부름.\n부분 회귀 계수의 첫번째 해석:\n\n만약 논문 수가 일정할 때, 예를 들어 10편의 논문을 쓴 경우만 봤을 때, 연차가 1년 늘 때마다 연봉은 $984 증가함; 평면의 선형모형을 가정했기에 이 관계는 논문 수에 상관없음.\n\n연차가 일정할 때, 예를 들어 연차가 12년차인 경우만 봤을 때, 논문이 1편 늘 때마다 연봉은 $122 증가함; 평면의 선형모형을 가정했기에 이 관계는 연차에 상관없음.\n\n이는 다른 변수를 고려 (통제, controlling for)했을 때 혹은\n다른 변수의 효과를 제거 (partial out) 했을 때의 효과\n즉, 각 변수의 고유한 효과를 의미함;\nholding constant, controlling for, partialing out, adjusted for, residualizing\n뒤집어 말하면, 연차만 고려했을때 연차가 1년 늘면 $1,224 연봉이 증가하는 효과는 연차가 늘 때 함께 늘어나는 논문 수의 효과가 함께 섞여 나온 효과라고 말할 수 있음.\n이는 인과관계에 있는 변수들의 진정한 효과를 찾는 것이 얼마나 어려운지를 보여줌\n\n\n\n\n\n\nThe partial regression coefficients, $983 and $122, are the empirical estimates, respectively, of h and g, the causal effects of our independent variables accompanying the arrows in the causal diagram (Fig. 3.1.1) (p. 69).\n\n부분 회귀 계수에 대한 두번째 해석\n\n다른 변수들이 partial out 된 후의 효과.\n\n실제로 $122는 연차로 (선형적으로) 예측되지 않는 논문수(residuals)로 [연차로 예측되지 않는] 연봉을 예측할 때의 기울기\n\n논문 수(\\(X_2\\))에 대한 부분 회귀 계수에 대해 자세히 들여다 보면,\n  \n\\(\\widehat{Y_1}: X_1\\) 으로만 \\(Y\\)를 예측했을 때의 예측치,   \\(\\widehat{Y}_{12}: X_1\\)과 \\(X_2\\) 로 함께 \\(Y\\)를 예측했을 때의 예측치\n\\(\\widehat{X}_{2.1}\\): \\(X_1\\) 으로 \\(X_2\\) 를 예측했을 때의 예측치; 연차로 예측된 논문수\n\\(X_2 - \\widehat{X}_{2.1}\\): \\(X_1\\)으로 \\(X_2\\)를 예측했을 때의 예측하지 못한 잔차: 연차로 예측되지 않는 논문수\n\\(Y-\\widehat{Y}_1\\): \\(X_1\\)으로 예측되지 않는 \\(Y\\) : 연차로 예측되지 않는 연봉\n논문 수(\\(X_2\\))에 대한 부분 회귀 계수: [연차로 예측되지 않는 논문 수]와 [연차로 예측되지 않는 연봉] 간의 선형관계에 대한 계수\n\\(\\widehat{salary} = \\$983\\:time + \\$122\\:pubs + \\$43,082\\)\n\n\\(\\widehat{salary} = \\$1,224\\:time + \\$43,659\\)\n\n\\(\\widehat{pubs} = 1.98\\:time + 4.73\\)\n\n\n\n\n\n\nAdded-variable plots\naka partial regression plots\n\nlibrary(car)\navPlots(mod3) # partial regression plot\n\n\n\n\n\n\n\n\nMarginal vs. Conditional Plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(R\\): Multiple correlation coefficient\n\n\\(Y\\) 와 \\(\\widehat Y\\) 의 correlation 즉, Y와 회귀모형이 예측한 값의 (선형적) 상관 관계의 정도; 회귀모형의 예측의 정확성\n\n다시말하면, 예측변수들의 최적의 선형 조합과 Y의 상관 관계의 정도.\n\n\\(R^2\\): (평면의) 선형모형에 의해 설명된 Y 변량의 비율:\n또는 예측변수들의 최적의 선형 조합에 의해 설명된 Y 변량의 비율.\n즉, \\(\\displaystyle\\frac{V(\\widehat{Y})}{V(Y)}\\) 또는 \\(\\displaystyle 1 - \\frac{V(e)}{V(Y)}\\)\n\n\n\n\n\n\n\nPartial Associations\n\nPartial correlation (pr)\nSemi-partial correlation (sr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(pr^2\\) : “연차로 설명되지 않는 연봉”의 변량 중 “연차로 설명되지 않는 논문수”의 변량으로 설명되는 비율\n즉, 연차를 연봉과 논문수에서 모두 partial out 시켰을 때 남은(residualized) 연봉의 변량과 논문수의 변량의 중복 정도.\n\\(sr^2\\) : 연봉의 변량 중 “연차로 설명되지 않는 논문수”의 변량으로 설명되는 비율\n즉, 연차를 논문수에서만 partial out 시켰을 때 남은(residualized) 논문수의 변량과 연봉의 변량의 중복 정도.\n\nsumm(mod3, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors: OLS\n---------------------------------------------------------------------------\n                        Est.      S.E.   t val.      p   partial.r   part.r\n----------------- ---------- --------- -------- ------ ----------- --------\n(Intercept)         43082.39   3099.49    13.90   0.00                     \ntime                  982.87    452.06     2.17   0.05        0.53     0.43\npubs                  121.80    149.70     0.81   0.43        0.23     0.16\n---------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nCorrelations tables\n\n\n\n\n\nlibrary(psych)\npartial.r(acad0, c(\"salary\", \"time\"), \"pubs\")\n# partial correlations \n#        salary time\n# salary   1.00 0.53\n# time     0.53 1.00\n\npartial.r(acad0, c(\"salary\", \"pubs\"), \"time\")\n# partial correlations \n#        salary pubs\n# salary   1.00 0.23\n# pubs     0.23 1.00\n\ncor2(acad0[c(\"time\", \"pubs\")], acad0[\"salary\"])\n#      salary\n# time   0.71\n# pubs   0.59\n\n\n\nCorrelations with salary\n\n\n\n\n\n\n\n\n\n\n\\(r\\) (simple)\n\\(pr\\) (partial)\n\\(sr\\) (semi-partial)\n\n\n\n\ntime\n0.71\n0.53\n0.43\n\n\npubs\n0.59\n0.23\n0.16\n\n\n\n\n\n \n\n\n\n\n\n\n\\(r^2\\)\n\\(pr^2\\)\n\\(sr^2\\)\n\n\n\n\ntime\n0.50\n0.28\n0.18\n\n\npubs\n0.35\n0.05\n0.03\n\n\n\n\n\n\n\nSummarizing the results for the running example, we found \\(sr^2\\) = .1850, \\(pr^2\\) = .2826 and \\(sr^2\\) = .0258, \\(pr^2\\) = .0522. Whichever base we use, it is clear that number of publications (\\(X_2\\)) has virtually no unique relationship to salary, that is, no relationship beyond what can be accounted for by time since doctorate (\\(X_1\\)). On the other hand, time since doctorate (\\(X_1\\)) is uniquely related to salary (\\(sr_1\\)) and to salary holding publications constant (\\(pr_1\\)) to a quite substantial degree. (p.75)\n\n\n\n참고: Chapter 8. Assessing the Importance of Regressors,\nin Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n모든 상황에 적용할 수 있는 하나의 방법은 없으며,\n연구 내용과 측정 변수들의 특성에 따라 적절한 방법을 선택. (여전히 논쟁 중이며, 연구 중)\n\n표준화 회귀계수 (standardized regression coefficient)\nSemi-partial correlation coefficient (sr) **\nSemi-partial correlation squared (\\(sr^2\\)) (by David C. Howell)\nDominance analysis\n\n\n\nStandardized regression coefficient\n\n표준화하여 각 변수들의 단위가 1sd로 같아져 계수들 간에 비교가 용이하나\n표준화에 (심각하게) 반대하는 의견도 있음.\n\n현 표본의 특성을 반영하여, 샘플들마다 계수값이 크게 달라질 수 있음. (특히, 변수들간의 상관이 큰 경우)\n표준화가 무의미한 변수들도 존재하며; ex. 성별\n인과적 의미를 지니려면 원 단위로 표현하는 것이 더 적절함. (1sd 만큼 늘어났다는 것이 의미가 있을까?)\n\nSimple regression의 경우, \\(\\beta = r\\) 즉, 표준화 회귀계수는 상관계수와 같음.\n\n\\(b = r\\),   (\\(b=r \\frac{sd_Y}{sd_X}\\))\n\\(b_i = \\beta_i \\frac{sd_Y}{sd_i}\\)\n\n\nR에서 표준화 계수를 구하는 방식: scale(), summ()\n\nscale() 함수로 각 변수들을 직접 표준화\n참고: 표준화 한 후 estimate한 방식 vs. estimate한 후 표준화한 방식\n\n\nacad0 &lt;- acad0 |&gt; \n  mutate(\n    time_std = scale(time),\n    pubs_std = scale(pubs),\n    salary_std = scale(salary)\n  )\n\n또는 formula에서 직접 처리\n\nmod &lt;- lm(scale(salary) ~ scale(time) + scale(pubs), data = acad0)\nsumm(mod3, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors: OLS\n------------------------------------------------------\n                        Est.      S.E.   t val.      p\n----------------- ---------- --------- -------- ------\n(Intercept)         43082.39   3099.49    13.90   0.00\ntime                  982.87    452.06     2.17   0.05\npubs                  121.80    149.70     0.81   0.43\n------------------------------------------------------\n\n\n\nsumm() 함수의 옵션 scale, transform.response을 이용\n\n\n선별적으로 표준화할 변수를 지정할 수 없어서 부적절한 경우 존재\n\n\nsumm(mod3, scale = TRUE, transform.response = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors: OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.00   0.19     0.00   1.00\ntime                0.57   0.26     2.17   0.05\npubs                0.21   0.26     0.81   0.43\n-----------------------------------------------\n\nContinuous variables are mean-centered and scaled by 1 s.d.\n\n\nmod3에서 연봉에 미치는 연차와 논문수의 상대적 중요성에 대한 지표 비교\n\n\n\n\n\n\n\n\n\n\n\\(\\beta\\)\n\\(sr\\)\n\\(sr^2\\)\n\n\n\n\ntime\n0.57\n0.43\n0.18\n\n\npubs\n0.21\n0.16\n0.03\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nmod1 vs. mod3: nested model\n\n\nmod1 &lt;- lm(salary ~ time, data = acad0)\nmod3 &lt;- lm(salary ~ time + pubs, data = acad0)\n\n\n\n\n\n\n\n\n연차로 연봉의 변량을 설명한 모형에 논문 수가 예측변수로 추가되었을 때, 추가로 연봉의 변량을 얼마나 설명하는가?\n\\(R^2\\)의 증가량을 통해 파악할 수 있음.\n\\(\\Delta R^2\\) = 0.530 - 0.505 = 0.025\n논문 수의 \\(sr^2\\) 과 동일 (semi-partial squared)\n\n\n\n\n\n\n\n\nsummary(mod1)$r.squared\n\n[1] 0.5045984\n\nsummary(mod3)$r.squared\n\n[1] 0.5304996\n\n\n\\(\\Delta R^2\\) 가 통계적으로 유의한지, 즉 유의하지 증가했는지를 확인\n\nanova(mod1, mod3)\n\n# A tibble: 2 × 6\n  Res.Df        RSS    Df `Sum of Sq`      F `Pr(&gt;F)`\n   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1     13 431731655.    NA         NA  NA       NA    \n2     12 409159359.     1   22572295.  0.662    0.432\n\n\n 2. mod2 vs. mod3: nested model\n\nmod2 &lt;- lm(salary ~ pubs, data = acad0)\nmod3 &lt;- lm(salary ~ time + pubs, data = acad0)\n\n\n\n\n\n\n\n\n논문수로 연봉의 변량을 설명한 모형에 연차가 예측변수로 추가되었을 때, 추가로 연봉의 변량을 얼마나 설명하는가?\n\\(R^2\\)의 증가량을 통해 파악할 수 있음.\n\\(\\Delta R^2\\) = 0.530 - 0.346 = 0.184\n연차의 \\(sr^2\\) 과 동일 (semi-partial squared)\n\n\n\n\n\n\n\n\nsummary(mod2)$r.squared\n\n[1] 0.3455483\n\nsummary(mod3)$r.squared\n\n[1] 0.5304996\n\n\n\\(\\Delta R^2\\) 가 통계적으로 유의한지, 즉 유의하지 증가했는지를 확인\n\nanova(mod2, mod3)\n\n# A tibble: 2 × 6\n  Res.Df        RSS    Df `Sum of Sq`     F `Pr(&gt;F)`\n   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     13 570340401.    NA         NA  NA     NA     \n2     12 409159359.     1  161181042.  4.73   0.0504\n\n\n\n\n\n\n\n\n만약, 다음과 같은 인과모형을 세운다면,\n\n\n연차가 연봉에 미치는 효과가 두 경로로 나뉘어지고,\n연차 \\(\\rightarrow\\) 연봉: 직접효과 $983\n연차 \\(\\rightarrow\\) 논문 \\(\\rightarrow\\) 연봉: 간접효과 1.98 x $122 = $241.56\n두 효과를 더하면: $983 + $241.56 = $1224.56 = 논문수를 고려하지 않았을 때 연차의 효과\n\n즉, 연차가 1년 늘때 연봉이 $1224 증가하는 것은 연차 자체의 효과($983)와 논문의 증가에 따른 효과($241)가 합쳐져 나온 결과라고 말할 수 있음.\n\n이 때, 논문의 수가 연차와 연봉의 관계를 (부분) 매개한다고 표현. (mediation)\n\n만약, 연차의 효과 $1224이 논문수를 고려했을 때 줄어든($983) 수준을 훨씬 넘어 통계적으로 유의하지 않을 정도로 0에 가까워진다면, 연차의 효과는 모두 논문의 효과를 거쳐 나타나는 것이라고 말할 수 있음. 이 때, 완전 매개 (fully mediate)한다고 표현함.\n\n매개효과의 통계적 분석 절차는 여러 방식이 제시되고 있으나, 일반적인 절차는 부트스랩핑(bootstraping)을 통해 추정.\n\nlibrary(psych)\nmod_med &lt;- mediate(salary ~ time + (pubs), data = acad0)\n\n\n\nsummary(mod_med)\n\nCall: mediate(y = salary ~ time + (pubs), data = acad0)\n\nDirect effect estimates (traditional regression)    (c') X + M on Y \n            salary      se     t df     Prob\nIntercept 43082.39 3099.49 13.90 12 9.26e-09\ntime        982.87  452.06  2.17 12 5.04e-02\npubs        121.80  149.70  0.81 12 4.32e-01\n\nR = 0.73 R2 = 0.53   F = 6.78 on 2 and 12 DF   p-value:  0.0107 \n\n Total effect estimates (c) (X on Y) \n            salary      se     t df     Prob\nIntercept 43658.59 2978.02 14.66 13 1.83e-09\ntime       1224.39  336.48  3.64 13 3.00e-03\n\n 'a'  effect estimates (X on M) \n          pubs   se    t df    Prob\nIntercept 4.73 5.59 0.85 13 0.41300\ntime      1.98 0.63 3.14 13 0.00783\n\n 'b'  effect estimates (M on Y controlling for X) \n     salary    se    t df  Prob\npubs  121.8 149.7 0.81 12 0.432\n\n 'ab'  effect estimates (through all  mediators)\n     salary   boot     sd   lower  upper\ntime 241.53 225.55 284.29 -321.39 785.06\n\n\n\n\n\n\n사실, 위에서 다룬 데이터(N=15)로만 보자면,\n논문수(pubs)와 연봉(salary)의 관계는 spurious한 관계라고 잠정적으로 말할 수 있음.\n\n연차(time)가 “통계적으로 통제” 혹은 “partial out” 되었을 때,\npartial correlation \\(pr\\) = 0.23 이며, 그 제곱 \\(pr^2\\) = 0.05\n뿐만 아니라, not significant\n\n연차(time)를 논문수와 연봉의 common cause 라고 말하며, confounding이 되어 논문수와 연봉의 인과관계는 실제로 없을 수 있음을 암시함.\n\n\n\n\n\n세 변수 간의 일반적인 인과관계의 형태에 대해서 분류해보면, (p.76, p.458)\n\n흔히 나타나는 partial redundancy인 Model B의 예를 보면,\n\nModerators (조절변수): interaction effects\nex. 연령(X)에 따라 지구력(Y)이 감소하는 관계가 운동한 기간(Z)에 따라 변화",
    "crumbs": [
      "Statistics",
      "Multiple Regression"
    ]
  },
  {
    "objectID": "contents/regression2.html#measures-of-association",
    "href": "contents/regression2.html#measures-of-association",
    "title": "Multiple Regression",
    "section": "",
    "text": "\\(R\\): Multiple correlation coefficient\n\n\\(Y\\) 와 \\(\\widehat Y\\) 의 correlation 즉, Y와 회귀모형이 예측한 값의 (선형적) 상관 관계의 정도; 회귀모형의 예측의 정확성\n\n다시말하면, 예측변수들의 최적의 선형 조합과 Y의 상관 관계의 정도.\n\n\\(R^2\\): (평면의) 선형모형에 의해 설명된 Y 변량의 비율:\n또는 예측변수들의 최적의 선형 조합에 의해 설명된 Y 변량의 비율.\n즉, \\(\\displaystyle\\frac{V(\\widehat{Y})}{V(Y)}\\) 또는 \\(\\displaystyle 1 - \\frac{V(e)}{V(Y)}\\)\n\n\n\n\n\n\n\nPartial Associations\n\nPartial correlation (pr)\nSemi-partial correlation (sr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(pr^2\\) : “연차로 설명되지 않는 연봉”의 변량 중 “연차로 설명되지 않는 논문수”의 변량으로 설명되는 비율\n즉, 연차를 연봉과 논문수에서 모두 partial out 시켰을 때 남은(residualized) 연봉의 변량과 논문수의 변량의 중복 정도.\n\\(sr^2\\) : 연봉의 변량 중 “연차로 설명되지 않는 논문수”의 변량으로 설명되는 비율\n즉, 연차를 논문수에서만 partial out 시켰을 때 남은(residualized) 논문수의 변량과 연봉의 변량의 중복 정도.\n\nsumm(mod3, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors: OLS\n---------------------------------------------------------------------------\n                        Est.      S.E.   t val.      p   partial.r   part.r\n----------------- ---------- --------- -------- ------ ----------- --------\n(Intercept)         43082.39   3099.49    13.90   0.00                     \ntime                  982.87    452.06     2.17   0.05        0.53     0.43\npubs                  121.80    149.70     0.81   0.43        0.23     0.16\n---------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nCorrelations tables\n\n\n\n\n\nlibrary(psych)\npartial.r(acad0, c(\"salary\", \"time\"), \"pubs\")\n# partial correlations \n#        salary time\n# salary   1.00 0.53\n# time     0.53 1.00\n\npartial.r(acad0, c(\"salary\", \"pubs\"), \"time\")\n# partial correlations \n#        salary pubs\n# salary   1.00 0.23\n# pubs     0.23 1.00\n\ncor2(acad0[c(\"time\", \"pubs\")], acad0[\"salary\"])\n#      salary\n# time   0.71\n# pubs   0.59\n\n\n\nCorrelations with salary\n\n\n\n\n\n\n\n\n\n\n\\(r\\) (simple)\n\\(pr\\) (partial)\n\\(sr\\) (semi-partial)\n\n\n\n\ntime\n0.71\n0.53\n0.43\n\n\npubs\n0.59\n0.23\n0.16\n\n\n\n\n\n \n\n\n\n\n\n\n\\(r^2\\)\n\\(pr^2\\)\n\\(sr^2\\)\n\n\n\n\ntime\n0.50\n0.28\n0.18\n\n\npubs\n0.35\n0.05\n0.03\n\n\n\n\n\n\n\nSummarizing the results for the running example, we found \\(sr^2\\) = .1850, \\(pr^2\\) = .2826 and \\(sr^2\\) = .0258, \\(pr^2\\) = .0522. Whichever base we use, it is clear that number of publications (\\(X_2\\)) has virtually no unique relationship to salary, that is, no relationship beyond what can be accounted for by time since doctorate (\\(X_1\\)). On the other hand, time since doctorate (\\(X_1\\)) is uniquely related to salary (\\(sr_1\\)) and to salary holding publications constant (\\(pr_1\\)) to a quite substantial degree. (p.75)\n\n\n\n참고: Chapter 8. Assessing the Importance of Regressors,\nin Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n모든 상황에 적용할 수 있는 하나의 방법은 없으며,\n연구 내용과 측정 변수들의 특성에 따라 적절한 방법을 선택. (여전히 논쟁 중이며, 연구 중)\n\n표준화 회귀계수 (standardized regression coefficient)\nSemi-partial correlation coefficient (sr) **\nSemi-partial correlation squared (\\(sr^2\\)) (by David C. Howell)\nDominance analysis\n\n\n\nStandardized regression coefficient\n\n표준화하여 각 변수들의 단위가 1sd로 같아져 계수들 간에 비교가 용이하나\n표준화에 (심각하게) 반대하는 의견도 있음.\n\n현 표본의 특성을 반영하여, 샘플들마다 계수값이 크게 달라질 수 있음. (특히, 변수들간의 상관이 큰 경우)\n표준화가 무의미한 변수들도 존재하며; ex. 성별\n인과적 의미를 지니려면 원 단위로 표현하는 것이 더 적절함. (1sd 만큼 늘어났다는 것이 의미가 있을까?)\n\nSimple regression의 경우, \\(\\beta = r\\) 즉, 표준화 회귀계수는 상관계수와 같음.\n\n\\(b = r\\),   (\\(b=r \\frac{sd_Y}{sd_X}\\))\n\\(b_i = \\beta_i \\frac{sd_Y}{sd_i}\\)\n\n\nR에서 표준화 계수를 구하는 방식: scale(), summ()\n\nscale() 함수로 각 변수들을 직접 표준화\n참고: 표준화 한 후 estimate한 방식 vs. estimate한 후 표준화한 방식\n\n\nacad0 &lt;- acad0 |&gt; \n  mutate(\n    time_std = scale(time),\n    pubs_std = scale(pubs),\n    salary_std = scale(salary)\n  )\n\n또는 formula에서 직접 처리\n\nmod &lt;- lm(scale(salary) ~ scale(time) + scale(pubs), data = acad0)\nsumm(mod3, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors: OLS\n------------------------------------------------------\n                        Est.      S.E.   t val.      p\n----------------- ---------- --------- -------- ------\n(Intercept)         43082.39   3099.49    13.90   0.00\ntime                  982.87    452.06     2.17   0.05\npubs                  121.80    149.70     0.81   0.43\n------------------------------------------------------\n\n\n\nsumm() 함수의 옵션 scale, transform.response을 이용\n\n\n선별적으로 표준화할 변수를 지정할 수 없어서 부적절한 경우 존재\n\n\nsumm(mod3, scale = TRUE, transform.response = TRUE, model.info = FALSE, model.fit = FALSE) |&gt; print()\n\nStandard errors: OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.00   0.19     0.00   1.00\ntime                0.57   0.26     2.17   0.05\npubs                0.21   0.26     0.81   0.43\n-----------------------------------------------\n\nContinuous variables are mean-centered and scaled by 1 s.d.\n\n\nmod3에서 연봉에 미치는 연차와 논문수의 상대적 중요성에 대한 지표 비교\n\n\n\n\n\n\n\n\n\n\n\\(\\beta\\)\n\\(sr\\)\n\\(sr^2\\)\n\n\n\n\ntime\n0.57\n0.43\n0.18\n\n\npubs\n0.21\n0.16\n0.03\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nmod1 vs. mod3: nested model\n\n\nmod1 &lt;- lm(salary ~ time, data = acad0)\nmod3 &lt;- lm(salary ~ time + pubs, data = acad0)\n\n\n\n\n\n\n\n\n연차로 연봉의 변량을 설명한 모형에 논문 수가 예측변수로 추가되었을 때, 추가로 연봉의 변량을 얼마나 설명하는가?\n\\(R^2\\)의 증가량을 통해 파악할 수 있음.\n\\(\\Delta R^2\\) = 0.530 - 0.505 = 0.025\n논문 수의 \\(sr^2\\) 과 동일 (semi-partial squared)\n\n\n\n\n\n\n\n\nsummary(mod1)$r.squared\n\n[1] 0.5045984\n\nsummary(mod3)$r.squared\n\n[1] 0.5304996\n\n\n\\(\\Delta R^2\\) 가 통계적으로 유의한지, 즉 유의하지 증가했는지를 확인\n\nanova(mod1, mod3)\n\n# A tibble: 2 × 6\n  Res.Df        RSS    Df `Sum of Sq`      F `Pr(&gt;F)`\n   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1     13 431731655.    NA         NA  NA       NA    \n2     12 409159359.     1   22572295.  0.662    0.432\n\n\n 2. mod2 vs. mod3: nested model\n\nmod2 &lt;- lm(salary ~ pubs, data = acad0)\nmod3 &lt;- lm(salary ~ time + pubs, data = acad0)\n\n\n\n\n\n\n\n\n논문수로 연봉의 변량을 설명한 모형에 연차가 예측변수로 추가되었을 때, 추가로 연봉의 변량을 얼마나 설명하는가?\n\\(R^2\\)의 증가량을 통해 파악할 수 있음.\n\\(\\Delta R^2\\) = 0.530 - 0.346 = 0.184\n연차의 \\(sr^2\\) 과 동일 (semi-partial squared)\n\n\n\n\n\n\n\n\nsummary(mod2)$r.squared\n\n[1] 0.3455483\n\nsummary(mod3)$r.squared\n\n[1] 0.5304996\n\n\n\\(\\Delta R^2\\) 가 통계적으로 유의한지, 즉 유의하지 증가했는지를 확인\n\nanova(mod2, mod3)\n\n# A tibble: 2 × 6\n  Res.Df        RSS    Df `Sum of Sq`     F `Pr(&gt;F)`\n   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     13 570340401.    NA         NA  NA     NA     \n2     12 409159359.     1  161181042.  4.73   0.0504",
    "crumbs": [
      "Statistics",
      "Multiple Regression"
    ]
  },
  {
    "objectID": "contents/regression2.html#patterns-of-association",
    "href": "contents/regression2.html#patterns-of-association",
    "title": "Multiple Regression",
    "section": "",
    "text": "만약, 다음과 같은 인과모형을 세운다면,\n\n\n연차가 연봉에 미치는 효과가 두 경로로 나뉘어지고,\n연차 \\(\\rightarrow\\) 연봉: 직접효과 $983\n연차 \\(\\rightarrow\\) 논문 \\(\\rightarrow\\) 연봉: 간접효과 1.98 x $122 = $241.56\n두 효과를 더하면: $983 + $241.56 = $1224.56 = 논문수를 고려하지 않았을 때 연차의 효과\n\n즉, 연차가 1년 늘때 연봉이 $1224 증가하는 것은 연차 자체의 효과($983)와 논문의 증가에 따른 효과($241)가 합쳐져 나온 결과라고 말할 수 있음.\n\n이 때, 논문의 수가 연차와 연봉의 관계를 (부분) 매개한다고 표현. (mediation)\n\n만약, 연차의 효과 $1224이 논문수를 고려했을 때 줄어든($983) 수준을 훨씬 넘어 통계적으로 유의하지 않을 정도로 0에 가까워진다면, 연차의 효과는 모두 논문의 효과를 거쳐 나타나는 것이라고 말할 수 있음. 이 때, 완전 매개 (fully mediate)한다고 표현함.\n\n매개효과의 통계적 분석 절차는 여러 방식이 제시되고 있으나, 일반적인 절차는 부트스랩핑(bootstraping)을 통해 추정.\n\nlibrary(psych)\nmod_med &lt;- mediate(salary ~ time + (pubs), data = acad0)\n\n\n\nsummary(mod_med)\n\nCall: mediate(y = salary ~ time + (pubs), data = acad0)\n\nDirect effect estimates (traditional regression)    (c') X + M on Y \n            salary      se     t df     Prob\nIntercept 43082.39 3099.49 13.90 12 9.26e-09\ntime        982.87  452.06  2.17 12 5.04e-02\npubs        121.80  149.70  0.81 12 4.32e-01\n\nR = 0.73 R2 = 0.53   F = 6.78 on 2 and 12 DF   p-value:  0.0107 \n\n Total effect estimates (c) (X on Y) \n            salary      se     t df     Prob\nIntercept 43658.59 2978.02 14.66 13 1.83e-09\ntime       1224.39  336.48  3.64 13 3.00e-03\n\n 'a'  effect estimates (X on M) \n          pubs   se    t df    Prob\nIntercept 4.73 5.59 0.85 13 0.41300\ntime      1.98 0.63 3.14 13 0.00783\n\n 'b'  effect estimates (M on Y controlling for X) \n     salary    se    t df  Prob\npubs  121.8 149.7 0.81 12 0.432\n\n 'ab'  effect estimates (through all  mediators)\n     salary   boot     sd   lower  upper\ntime 241.53 225.55 284.29 -321.39 785.06\n\n\n\n\n\n\n사실, 위에서 다룬 데이터(N=15)로만 보자면,\n논문수(pubs)와 연봉(salary)의 관계는 spurious한 관계라고 잠정적으로 말할 수 있음.\n\n연차(time)가 “통계적으로 통제” 혹은 “partial out” 되었을 때,\npartial correlation \\(pr\\) = 0.23 이며, 그 제곱 \\(pr^2\\) = 0.05\n뿐만 아니라, not significant\n\n연차(time)를 논문수와 연봉의 common cause 라고 말하며, confounding이 되어 논문수와 연봉의 인과관계는 실제로 없을 수 있음을 암시함.\n\n\n\n\n\n세 변수 간의 일반적인 인과관계의 형태에 대해서 분류해보면, (p.76, p.458)\n\n흔히 나타나는 partial redundancy인 Model B의 예를 보면,\n\nModerators (조절변수): interaction effects\nex. 연령(X)에 따라 지구력(Y)이 감소하는 관계가 운동한 기간(Z)에 따라 변화",
    "crumbs": [
      "Statistics",
      "Multiple Regression"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균\nemail: sk.cho@snu.ac.kr\n수업시간: 목 7:00 ~ 9:50\n면담 시간: 수업 후\nWebsite: r.modellings.art\n과제: Notice\n질문: Communicate/Ask",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#강의-정보",
    "href": "index.html#강의-정보",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균\nemail: sk.cho@snu.ac.kr\n수업시간: 목 7:00 ~ 9:50\n면담 시간: 수업 후\nWebsite: r.modellings.art\n과제: Notice\n질문: Communicate/Ask",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n현대적 데이터 분석의 시각에서 통계적 모델링을 중심으로 데이터가 지니는 정보로부터 현상에 대한 올바른 추론을 할 수 있도록 돕습니다. 실사례들을 중심으로 통계 분석의 활용에 중점을 두면서 통계의 여러 개념과 확률 및 분포이론들이 자연스럽게 통합되어 통계적 추정과 검정을 이해하고, 더 나아가 인과관계를 유추할 수 있는 분석에 대해서도 배웁니다. 이를 위해 R과 R Studio의 원활한 이용방법을 익히고, 다양한 실제 사례를 통해 각각에 적절한 통계 분석을 찾아 적용하며, 분석의 결과를 통계 이론의 이해를 바탕으로 올바로 해석할 수 있는 능력을 갖춥니다.\n\n선형모형의 원리를 이해하고 실제 사례에 적용\nR을 활용하여 시각화와 통계적 분석을 수행\n\n수업은 대략 4개의 섹션으로 나눔\n\nR tutorial\n\n통계의 활용에 대한 전반적인 소개\n\n회귀 분석 (regression analysis)\n\n인과 분석 (causal analysis)\n\n\n교재\n\n주로 강의 노트를 위주로!\nR인 액션 - 빅데이터 분석도구, 홍릉 / R in Action (2e) by Rob Kabacoff \n\n\n\nR 참고도서\n\nR for Data Science (2e) by Hadley Wickham and Garrett Grolemund\n\n\n\n통계 참고도서\n\nApplied Multiple Regression/Correlation Analysis for the Behavioral Sciences By Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. Aiken\nRegression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\nMultiple Regression and Beyond (3e) by Timothy Z. Keith",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (10%), 일반과제 (30%), 중간고사 대체 과제 (30%), 기말고사 (30%)",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#수업-일정",
    "href": "index.html#수업-일정",
    "title": "Welcome",
    "section": "수업 일정",
    "text": "수업 일정\n1주. R과 RStudio에 대해 소개 및 설치, 기본적인 R의 작동방식과 기초적인 명령어 사용\n2주. Tidyverse 패키지의 문법: 데이터 클리닝, 시각화와 탐색\n3주. 통계 이론에 대한 전반적인 개관 1\n4주. 통계 이론에 대한 전반적인 개관 2\n5주. 상관계수와 기본 선형회귀모형\n6주. 선형회귀모형에서 변량의 분해\n7주. 다중선형회귀모형과 통계적 통제의 의미 파악 1\n8주. 중간고사 및 다중선형회귀모형과 통계적 통제의 의미 파악 2\n9주. 예측변수들 간의 관계를 분류하고 각 관계성에 따른 의미를 파악\n10주. 범주형 변수에 대한 선형회귀모형 1\n11주. 범주형 변수에 대한 선형회귀모형 2\n12주. 선형회귀모형에서 예측변수들 간의 상호작용 1\n13주. 선형회귀모형에서 예측변수들 간의 상호작용 2\n14주. 선형회귀모형의 가정들에 대한 진단과 조치\n15주. 기말고사 및 선형회귀모형의 확장에 대한 소개",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "contents/anova.html",
    "href": "contents/anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "data(CO2)\nw1b1 &lt;- CO2 |&gt; filter(Treatment == \"chilled\") |&gt; select(-Treatment)\n\n\nw1b1 |&gt; print()\n\n   Plant        Type conc uptake\n1    Qc1      Quebec   95   14.2\n2    Qc1      Quebec  175   24.1\n3    Qc1      Quebec  250   30.3\n4    Qc1      Quebec  350   34.6\n5    Qc1      Quebec  500   32.5\n6    Qc1      Quebec  675   35.4\n7    Qc1      Quebec 1000   38.7\n8    Qc2      Quebec   95    9.3\n9    Qc2      Quebec  175   27.3\n10   Qc2      Quebec  250   35.0\n11   Qc2      Quebec  350   38.8\n12   Qc2      Quebec  500   38.6\n13   Qc2      Quebec  675   37.5\n14   Qc2      Quebec 1000   42.4\n15   Qc3      Quebec   95   15.1\n16   Qc3      Quebec  175   21.0\n17   Qc3      Quebec  250   38.1\n18   Qc3      Quebec  350   34.0\n19   Qc3      Quebec  500   38.9\n20   Qc3      Quebec  675   39.6\n21   Qc3      Quebec 1000   41.4\n22   Mc1 Mississippi   95   10.5\n23   Mc1 Mississippi  175   14.9\n24   Mc1 Mississippi  250   18.1\n25   Mc1 Mississippi  350   18.9\n26   Mc1 Mississippi  500   19.5\n27   Mc1 Mississippi  675   22.2\n28   Mc1 Mississippi 1000   21.9\n29   Mc2 Mississippi   95    7.7\n30   Mc2 Mississippi  175   11.4\n31   Mc2 Mississippi  250   12.3\n32   Mc2 Mississippi  350   13.0\n33   Mc2 Mississippi  500   12.5\n34   Mc2 Mississippi  675   13.7\n35   Mc2 Mississippi 1000   14.4\n36   Mc3 Mississippi   95   10.6\n37   Mc3 Mississippi  175   18.0\n38   Mc3 Mississippi  250   17.9\n39   Mc3 Mississippi  350   17.9\n40   Mc3 Mississippi  500   17.9\n41   Mc3 Mississippi  675   18.9\n42   Mc3 Mississippi 1000   19.9\n\n\n\nw1b1 &lt;- w1b1 |&gt;\n    mutate(\n        conc = factor(conc),\n        Plant = factor(Plant, ordered = FALSE)\n    )\n\n\nw1b1 |&gt; pivot_wider(names_from = \"conc\", values_from = \"uptake\")\n\n\nA tibble: 6 x 9\n\n\nPlant\nType\n95\n175\n250\n350\n500\n675\n1000\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nQc1\nQuebec\n14.2\n24.1\n30.3\n34.6\n32.5\n35.4\n38.7\n\n\nQc2\nQuebec\n9.3\n27.3\n35.0\n38.8\n38.6\n37.5\n42.4\n\n\nQc3\nQuebec\n15.1\n21.0\n38.1\n34.0\n38.9\n39.6\n41.4\n\n\nMc1\nMississippi\n10.5\n14.9\n18.1\n18.9\n19.5\n22.2\n21.9\n\n\nMc2\nMississippi\n7.7\n11.4\n12.3\n13.0\n12.5\n13.7\n14.4\n\n\nMc3\nMississippi\n10.6\n18.0\n17.9\n17.9\n17.9\n18.9\n19.9\n\n\n\n\n\n\nfit &lt;- aov(uptake ~ conc*Type + Error(Plant/conc), w1b1)\nsummary(fit)\n\n\nError: Plant\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nType       1 2667.2  2667.2   60.41 0.00148 **\nResiduals  4  176.6    44.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Plant:conc\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nconc       6 1472.4  245.40   52.52 1.26e-12 ***\nconc:Type  6  428.8   71.47   15.30 3.75e-07 ***\nResiduals 24  112.1    4.67                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(ez)\nw1b1_aov &lt;- ezANOVA(\n    data = w1b1,\n    dv = uptake,\n    wid = Plant,\n    # between = Type,\n    within = conc,\n    # detailed = TRUE,\n    type = 3,\n    # return_aov = TRUE\n)\nw1b1_aov\n\n$ANOVA = \n\nA data.frame: 1 x 7\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n\n\n\n\n2\nconc\n6\n30\n13.6088\n2.09137e-07\n*\n0.3031357\n\n\n\n\n\n\nlmer(uptake ~ conc + (1 | Plant), data = w1b1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: uptake ~ conc + (1 | Plant)\n   Data: w1b1\nREML criterion at convergence: 230.3504\nRandom effects:\n Groups   Name        Std.Dev.\n Plant    (Intercept) 8.870   \n Residual             4.246   \nNumber of obs: 42, groups:  Plant, 6\nFixed Effects:\n(Intercept)      conc175      conc250      conc350      conc500      conc675  \n     11.233        8.217       14.050       14.967       15.417       16.650  \n   conc1000  \n     18.550  \n\n\n\nw1b1 |&gt;\n    ggplot(aes(x = conc, y = uptake, fill = Type)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nw1b1\n\n\nA data.frame: 42 x 4\n\n\n\nPlant\nType\nconc\nuptake\n\n\n\n&lt;ord&gt;\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n\n\n\n\n1\nQc1\nQuebec\n95\n14.2\n\n\n2\nQc1\nQuebec\n175\n24.1\n\n\n3\nQc1\nQuebec\n250\n30.3\n\n\n4\nQc1\nQuebec\n350\n34.6\n\n\n...\n...\n...\n...\n...\n\n\n39\nMc3\nMississippi\n350\n17.9\n\n\n40\nMc3\nMississippi\n500\n17.9\n\n\n41\nMc3\nMississippi\n675\n18.9\n\n\n42\nMc3\nMississippi\n1000\n19.9\n\n\n\n\n\n\nw1b1 |&gt;\n    ggplot(aes(x = conc, y = uptake, color = Type)) +\n    geom_jitter(width = .2) +\n    facet_wrap(~Plant)\n\n\n\n\n\n\n\n\n\nw1b1 |&gt;\n    ggplot(aes(x = Plant, y = uptake)) +\n    geom_jitter(width = .1)"
  },
  {
    "objectID": "contents/anova.html#r-in-action",
    "href": "contents/anova.html#r-in-action",
    "title": "ANOVA",
    "section": "",
    "text": "data(CO2)\nw1b1 &lt;- CO2 |&gt; filter(Treatment == \"chilled\") |&gt; select(-Treatment)\n\n\nw1b1 |&gt; print()\n\n   Plant        Type conc uptake\n1    Qc1      Quebec   95   14.2\n2    Qc1      Quebec  175   24.1\n3    Qc1      Quebec  250   30.3\n4    Qc1      Quebec  350   34.6\n5    Qc1      Quebec  500   32.5\n6    Qc1      Quebec  675   35.4\n7    Qc1      Quebec 1000   38.7\n8    Qc2      Quebec   95    9.3\n9    Qc2      Quebec  175   27.3\n10   Qc2      Quebec  250   35.0\n11   Qc2      Quebec  350   38.8\n12   Qc2      Quebec  500   38.6\n13   Qc2      Quebec  675   37.5\n14   Qc2      Quebec 1000   42.4\n15   Qc3      Quebec   95   15.1\n16   Qc3      Quebec  175   21.0\n17   Qc3      Quebec  250   38.1\n18   Qc3      Quebec  350   34.0\n19   Qc3      Quebec  500   38.9\n20   Qc3      Quebec  675   39.6\n21   Qc3      Quebec 1000   41.4\n22   Mc1 Mississippi   95   10.5\n23   Mc1 Mississippi  175   14.9\n24   Mc1 Mississippi  250   18.1\n25   Mc1 Mississippi  350   18.9\n26   Mc1 Mississippi  500   19.5\n27   Mc1 Mississippi  675   22.2\n28   Mc1 Mississippi 1000   21.9\n29   Mc2 Mississippi   95    7.7\n30   Mc2 Mississippi  175   11.4\n31   Mc2 Mississippi  250   12.3\n32   Mc2 Mississippi  350   13.0\n33   Mc2 Mississippi  500   12.5\n34   Mc2 Mississippi  675   13.7\n35   Mc2 Mississippi 1000   14.4\n36   Mc3 Mississippi   95   10.6\n37   Mc3 Mississippi  175   18.0\n38   Mc3 Mississippi  250   17.9\n39   Mc3 Mississippi  350   17.9\n40   Mc3 Mississippi  500   17.9\n41   Mc3 Mississippi  675   18.9\n42   Mc3 Mississippi 1000   19.9\n\n\n\nw1b1 &lt;- w1b1 |&gt;\n    mutate(\n        conc = factor(conc),\n        Plant = factor(Plant, ordered = FALSE)\n    )\n\n\nw1b1 |&gt; pivot_wider(names_from = \"conc\", values_from = \"uptake\")\n\n\nA tibble: 6 x 9\n\n\nPlant\nType\n95\n175\n250\n350\n500\n675\n1000\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\nQc1\nQuebec\n14.2\n24.1\n30.3\n34.6\n32.5\n35.4\n38.7\n\n\nQc2\nQuebec\n9.3\n27.3\n35.0\n38.8\n38.6\n37.5\n42.4\n\n\nQc3\nQuebec\n15.1\n21.0\n38.1\n34.0\n38.9\n39.6\n41.4\n\n\nMc1\nMississippi\n10.5\n14.9\n18.1\n18.9\n19.5\n22.2\n21.9\n\n\nMc2\nMississippi\n7.7\n11.4\n12.3\n13.0\n12.5\n13.7\n14.4\n\n\nMc3\nMississippi\n10.6\n18.0\n17.9\n17.9\n17.9\n18.9\n19.9\n\n\n\n\n\n\nfit &lt;- aov(uptake ~ conc*Type + Error(Plant/conc), w1b1)\nsummary(fit)\n\n\nError: Plant\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nType       1 2667.2  2667.2   60.41 0.00148 **\nResiduals  4  176.6    44.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Plant:conc\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nconc       6 1472.4  245.40   52.52 1.26e-12 ***\nconc:Type  6  428.8   71.47   15.30 3.75e-07 ***\nResiduals 24  112.1    4.67                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(ez)\nw1b1_aov &lt;- ezANOVA(\n    data = w1b1,\n    dv = uptake,\n    wid = Plant,\n    # between = Type,\n    within = conc,\n    # detailed = TRUE,\n    type = 3,\n    # return_aov = TRUE\n)\nw1b1_aov\n\n$ANOVA = \n\nA data.frame: 1 x 7\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\nges\n\n\n\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n\n\n\n\n2\nconc\n6\n30\n13.6088\n2.09137e-07\n*\n0.3031357\n\n\n\n\n\n\nlmer(uptake ~ conc + (1 | Plant), data = w1b1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: uptake ~ conc + (1 | Plant)\n   Data: w1b1\nREML criterion at convergence: 230.3504\nRandom effects:\n Groups   Name        Std.Dev.\n Plant    (Intercept) 8.870   \n Residual             4.246   \nNumber of obs: 42, groups:  Plant, 6\nFixed Effects:\n(Intercept)      conc175      conc250      conc350      conc500      conc675  \n     11.233        8.217       14.050       14.967       15.417       16.650  \n   conc1000  \n     18.550  \n\n\n\nw1b1 |&gt;\n    ggplot(aes(x = conc, y = uptake, fill = Type)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nw1b1\n\n\nA data.frame: 42 x 4\n\n\n\nPlant\nType\nconc\nuptake\n\n\n\n&lt;ord&gt;\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n\n\n\n\n1\nQc1\nQuebec\n95\n14.2\n\n\n2\nQc1\nQuebec\n175\n24.1\n\n\n3\nQc1\nQuebec\n250\n30.3\n\n\n4\nQc1\nQuebec\n350\n34.6\n\n\n...\n...\n...\n...\n...\n\n\n39\nMc3\nMississippi\n350\n17.9\n\n\n40\nMc3\nMississippi\n500\n17.9\n\n\n41\nMc3\nMississippi\n675\n18.9\n\n\n42\nMc3\nMississippi\n1000\n19.9\n\n\n\n\n\n\nw1b1 |&gt;\n    ggplot(aes(x = conc, y = uptake, color = Type)) +\n    geom_jitter(width = .2) +\n    facet_wrap(~Plant)\n\n\n\n\n\n\n\n\n\nw1b1 |&gt;\n    ggplot(aes(x = Plant, y = uptake)) +\n    geom_jitter(width = .1)"
  },
  {
    "objectID": "contents/anova.html#blog",
    "href": "contents/anova.html#blog",
    "title": "ANOVA",
    "section": "blog",
    "text": "blog\nhttps://yury-zablotski.netlify.app/post/rma/#introduction\n\n# load(url(\"http://coltekin.net/cagri/R/data/newborn.rda\"))\nnewborn &lt;- read.csv(\"data/newborn.csv\")\nnewborn\n\n\nA data.frame: 60 x 3\n\n\nparticipant\nlanguage\nrate\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n\n\n\n\n1\nnative\n29.01\n\n\n1\nforeign\n20.06\n\n\n2\nnative\n29.49\n\n\n2\nforeign\n31.60\n\n\n...\n...\n...\n\n\n29\nnative\n28.62\n\n\n29\nforeign\n20.28\n\n\n30\nnative\n16.56\n\n\n30\nforeign\n14.68\n\n\n\n\n\n\nggplot(newborn, aes(language, rate))+\n  geom_violin()+\n  geom_dotplot(binaxis='y', stackdir='center', dotsize=.5)\n\n\n\n\n\n\n\n\n\nnewborn\n\n\nA data.frame: 60 x 3\n\n\nparticipant\nlanguage\nrate\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n\n\n\n\n1\nnative\n29.01\n\n\n1\nforeign\n20.06\n\n\n2\nnative\n29.49\n\n\n2\nforeign\n31.60\n\n\n...\n...\n...\n\n\n29\nnative\n28.62\n\n\n29\nforeign\n20.28\n\n\n30\nnative\n16.56\n\n\n30\nforeign\n14.68\n\n\n\n\n\n\nnewborn |&gt;\n    ggplot(aes(x = language, y = rate, group = participant, color = as.numeric(participant))) +\n    geom_line() +\n    facet_wrap(~participant)\n\n\n\n\n\n\n\n\n\nnewborn_wide &lt;- newborn |&gt;\n    pivot_wider(names_from = \"language\", values_from = \"rate\") |&gt;\n    mutate(diff = native - foreign)\nnewborn_wide |&gt; print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  &lt;fct&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# ... with 24 more rows\n\n\n\nt.test(rate ~ language, data = newborn)\n\n\n    Welch Two Sample t-test\n\ndata:  rate by language\nt = -1.7074, df = 57.994, p-value = 0.0931\nalternative hypothesis: true difference in means between group foreign and group native is not equal to 0\n95 percent confidence interval:\n -9.8271059  0.7797726\nsample estimates:\nmean in group foreign  mean in group native \n             31.84367              36.36733 \n\n\n\nsummary(lm(rate ~ language, data = newborn))\n\n\nCall:\nlm(formula = rate ~ language, data = newborn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.8837  -7.4548   0.8927   6.5913  21.8863 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      31.844      1.873  16.997   &lt;2e-16 ***\nlanguagenative    4.524      2.649   1.707   0.0931 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.26 on 58 degrees of freedom\nMultiple R-squared:  0.04786,   Adjusted R-squared:  0.03144 \nF-statistic: 2.915 on 1 and 58 DF,  p-value: 0.0931\n\n\n\nt.test(rate ~ language, data = newborn, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  rate by language\nt = -5.3138, df = 29, p-value = 1.06e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -6.264775 -2.782559\nsample estimates:\nmean difference \n      -4.523667 \n\n\n\nezANOVA(data = newborn, \n                dv = rate, \n                wid = participant,, \n                within = language, \n                detailed = TRUE, \n                type = 3,\n                return_aov = TRUE)\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd        F            p p&lt;.05\n1 (Intercept)   1  29 69791.1078 5791.737 349.4534 1.015654e-17     *\n2    language   1  29   306.9534  315.251  28.2367 1.060479e-05     *\n         ges\n1 0.91953700\n2 0.04785722\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 34.1055\n\nStratum 1: participant\n\nTerms:\n                Residuals\nSum of Squares   5791.737\nDeg. of Freedom        29\n\nResidual standard error: 14.13206\n\nStratum 2: participant:language\n\nTerms:\n                language Residuals\nSum of Squares  306.9534  315.2511\nDeg. of Freedom        1        29\n\nResidual standard error: 3.297078\nEstimated effects are balanced\n\n\n\nlibrary(lme4)\nmodel_lmer &lt;- lmer(rate ~ language + (1 | participant), data = newborn)\nsummary(model_lmer)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: rate ~ language + (1 | participant)\n   Data: newborn\n\nREML criterion at convergence: 394.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.79385 -0.50665 -0.03044  0.42331  2.00234 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n participant (Intercept) 94.42    9.717   \n Residual                10.87    3.297   \nNumber of obs: 60, groups:  participant, 30\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     31.8437     1.8734  16.997\nlanguagenative   4.5237     0.8513   5.314\n\nCorrelation of Fixed Effects:\n            (Intr)\nlanguagentv -0.227\n\n\n\nlibrary(report)\nreport(model_lmer) |&gt; print()\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict rate with language (formula: rate ~ language). The model included\nparticipant as random effect (formula: ~1 | participant). The model's total\nexplanatory power is substantial (conditional R2 = 0.90) and the part related\nto the fixed effects alone (marginal R2) is of 0.05. The model's intercept,\ncorresponding to language = foreign, is at 31.84 (95% CI [28.09, 35.60], t(56)\n= 17.00, p &lt; .001). Within this model:\n\n  - The effect of language [native] is statistically significant and positive\n(beta = 4.52, 95% CI [2.82, 6.23], t(56) = 5.31, p &lt; .001; Std. beta = 0.43,\n95% CI [0.27, 0.60])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\nreport(model_lmer) |&gt;\n    table_long() |&gt;\n    print()\n\nERROR: Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': could not find function \"table_long\"\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': could not find function \"table_long\"\nTraceback:\n\n1. print(table_long(report(model_lmer)))\n2. .handleSimpleError(function (cond) \n . .Internal(C_tryCatchHelper(addr, 1L, cond)), \"could not find function \\\"table_long\\\"\", \n .     base::quote(table_long(report(model_lmer))))\n3. h(simpleError(msg, call))\n\n\n\nlibrary(broom)\nlibrary(emmeans)\nemmeans(model_lmer, pairwise ~ language, adjust = \"bonferroni\")\n\n$emmeans\n language emmean   SE   df lower.CL upper.CL\n foreign    31.8 1.87 32.1     28.0     35.7\n native     36.4 1.87 32.1     32.6     40.2\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n$contrasts\n contrast         estimate    SE df t.ratio p.value\n foreign - native    -4.52 0.851 29  -5.314  &lt;.0001\n\nDegrees-of-freedom method: kenward-roger \n\n\n\n# install.packages(\"TMB\", type = \"source\")\nplot_model(model_lmer, type = \"diag\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[[1]]\n\n[[2]]\n[[2]]$participant\n\n\n[[3]]\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar::influencePlot(model_lmer)\n\n\nA data.frame: 4 x 3\n\n\n\nStudRes\nHat\nCookD\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0.7189496\n0.4903583\n0.2486654\n\n\n2\n-1.1615895\n0.4903583\n0.6491183\n\n\n25\n2.8048223\n0.4903583\n3.7846806\n\n\n26\n-2.5127739\n0.4903583\n3.0375634\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_model(model_lmer)\n\n\nlibrary(effects)\nplot(allEffects(model_lmer))\n\n\n\n\n\n\n\n\n\nlibrary(sjPlot)\ntab_model(model_lmer, p.style = \"scientific\")"
  },
  {
    "objectID": "contents/anova.html#appendix-mlm",
    "href": "contents/anova.html#appendix-mlm",
    "title": "ANOVA",
    "section": "Appendix MLM",
    "text": "Appendix MLM\n\nOBrienKaiser &lt;- carData::OBrienKaiser\nOBrienKaiser\n\n\nA data.frame: 16 x 17\n\n\n\ntreatment\ngender\npre.1\npre.2\npre.3\npre.4\npre.5\npost.1\npost.2\npost.3\npost.4\npost.5\nfup.1\nfup.2\nfup.3\nfup.4\nfup.5\n\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\ncontrol\nM\n1\n2\n4\n2\n1\n3\n2\n5\n3\n2\n2\n3\n2\n4\n4\n\n\n2\ncontrol\nM\n4\n4\n5\n3\n4\n2\n2\n3\n5\n3\n4\n5\n6\n4\n1\n\n\n3\ncontrol\nM\n5\n6\n5\n7\n7\n4\n5\n7\n5\n4\n7\n6\n9\n7\n6\n\n\n4\ncontrol\nF\n5\n4\n7\n5\n4\n2\n2\n3\n5\n3\n4\n4\n5\n3\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13\nB\nF\n5\n5\n6\n8\n6\n4\n6\n6\n8\n6\n7\n7\n8\n10\n8\n\n\n14\nB\nF\n2\n2\n3\n1\n2\n5\n6\n7\n5\n2\n6\n7\n8\n6\n3\n\n\n15\nB\nF\n2\n2\n3\n4\n4\n6\n6\n7\n9\n7\n7\n7\n8\n6\n7\n\n\n16\nB\nF\n4\n5\n7\n5\n4\n7\n7\n8\n6\n7\n7\n8\n10\n8\n7\n\n\n\n\n\n\nphase &lt;- factor(rep(c(\"pretest\", \"posttest\", \"followup\"), c(5, 5, 5)),\n    levels=c(\"pretest\", \"posttest\", \"followup\"))\nhour &lt;- ordered(rep(1:5, 3))\nidata &lt;- data.frame(phase, hour)\nidata\n\n\nA data.frame: 15 x 2\n\n\nphase\nhour\n\n\n&lt;fct&gt;\n&lt;ord&gt;\n\n\n\n\npretest\n1\n\n\npretest\n2\n\n\npretest\n3\n\n\npretest\n4\n\n\n...\n...\n\n\nfollowup\n2\n\n\nfollowup\n3\n\n\nfollowup\n4\n\n\nfollowup\n5\n\n\n\n\n\n\nOBrien.long &lt;- reshape(OBrienKaiser,\n    varying=c(\"pre.1\", \"pre.2\", \"pre.3\", \"pre.4\", \"pre.5\",\n        \"post.1\", \"post.2\", \"post.3\", \"post.4\", \"post.5\",\n        \"fup.1\", \"fup.2\", \"fup.3\",  \"fup.4\", \"fup.5\"),\n    v.names=\"score\",\n    timevar=\"phase.hour\", direction=\"long\")\nOBrien.long$phase &lt;- ordered(\n      c(\"pre\", \"post\", \"fup\")[1 + ((OBrien.long$phase.hour - 1) %/% 5)],\n    levels=c(\"pre\", \"post\", \"fup\"))\nOBrien.long$hour &lt;- ordered(1 + ((OBrien.long$phase.hour - 1) %% 5))\n\n\nOBrien.long\n\n\nA data.frame: 240 x 7\n\n\n\ntreatment\ngender\nphase.hour\nscore\nid\nphase\nhour\n\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;ord&gt;\n&lt;ord&gt;\n\n\n\n\n1.1\ncontrol\nM\n1\n1\n1\npre\n1\n\n\n2.1\ncontrol\nM\n1\n4\n2\npre\n1\n\n\n3.1\ncontrol\nM\n1\n5\n3\npre\n1\n\n\n4.1\ncontrol\nF\n1\n5\n4\npre\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13.15\nB\nF\n15\n8\n13\nfup\n5\n\n\n14.15\nB\nF\n15\n3\n14\nfup\n5\n\n\n15.15\nB\nF\n15\n7\n15\nfup\n5\n\n\n16.15\nB\nF\n15\n7\n16\nfup\n5\n\n\n\n\n\n\nmod.ok &lt;- lm(cbind(pre.1, pre.2, pre.3, pre.4, pre.5,\n                     post.1, post.2, post.3, post.4, post.5,\n                     fup.1, fup.2, fup.3, fup.4, fup.5) ~  treatment*gender,\n                data=OBrienKaiser)\nmod.ok\n\n\nCall:\nlm(formula = cbind(pre.1, pre.2, pre.3, pre.4, pre.5, post.1, \n    post.2, post.3, post.4, post.5, fup.1, fup.2, fup.3, fup.4, \n    fup.5) ~ treatment * gender, data = OBrienKaiser)\n\nCoefficients:\n                    pre.1       pre.2       pre.3       pre.4       pre.5     \n(Intercept)          3.903e+00   4.278e+00   5.431e+00   4.611e+00   4.139e+00\ntreatment1           1.181e-01   1.389e-01  -7.639e-02   1.806e-01   1.944e-01\ntreatment2          -2.292e-01  -3.333e-01  -1.458e-01  -7.083e-01  -6.667e-01\ngender1             -6.528e-01  -7.778e-01  -1.806e-01  -1.111e-01  -6.389e-01\ntreatment1:gender1  -4.931e-01  -3.889e-01  -5.486e-01  -1.806e-01  -1.944e-01\ntreatment2:gender1   6.042e-01   5.833e-01   2.708e-01   7.083e-01   1.167e+00\n                    post.1      post.2      post.3      post.4      post.5    \n(Intercept)          5.028e+00   5.542e+00   6.917e+00   6.361e+00   4.833e+00\ntreatment1           7.639e-01   8.958e-01   8.333e-01   7.222e-01   9.167e-01\ntreatment2           2.917e-01   1.875e-01  -2.500e-01   8.333e-02  -2.047e-17\ngender1             -8.611e-01  -4.583e-01  -4.167e-01  -5.278e-01  -1.000e+00\ntreatment1:gender1  -6.806e-01  -6.042e-01  -3.333e-01  -5.556e-01  -5.000e-01\ntreatment2:gender1   9.583e-01   6.875e-01   2.500e-01   9.167e-01   1.250e+00\n                    fup.1       fup.2       fup.3       fup.4       fup.5     \n(Intercept)          6.014e+00   6.153e+00   7.778e+00   6.167e+00   5.347e+00\ntreatment1           9.236e-01   1.035e+00   1.097e+00   9.583e-01   8.819e-01\ntreatment2          -6.250e-02  -6.250e-02  -1.250e-01   1.250e-01   2.292e-01\ngender1             -5.972e-01  -9.028e-01  -7.778e-01  -8.333e-01  -4.306e-01\ntreatment1:gender1  -2.153e-01  -1.597e-01  -3.472e-01  -4.167e-02  -1.736e-01\ntreatment2:gender1   6.875e-01   1.187e+00   8.750e-01   1.125e+00   3.958e-01\n\n\n\nlibrary(car)\n(av.ok &lt;- Anova(mod.ok, idata=idata, idesign=~phase*hour, type=3))\n\n\nType III Repeated Measures MANOVA Tests: Pillai test statistic\n                            Df test stat approx F num Df den Df    Pr(&gt;F)    \n(Intercept)                  1   0.96736  296.389      1     10 9.241e-09 ***\ntreatment                    2   0.44075    3.940      2     10 0.0547069 .  \ngender                       1   0.26789    3.659      1     10 0.0848003 .  \ntreatment:gender             2   0.36350    2.855      2     10 0.1044692    \nphase                        1   0.81363   19.645      2      9 0.0005208 ***\ntreatment:phase              2   0.69621    2.670      4     20 0.0621085 .  \ngender:phase                 1   0.06614    0.319      2      9 0.7349696    \ntreatment:gender:phase       2   0.31060    0.919      4     20 0.4721498    \nhour                         1   0.93286   24.315      4      7 0.0003345 ***\ntreatment:hour               2   0.31634    0.376      8     16 0.9183275    \ngender:hour                  1   0.33922    0.898      4      7 0.5129764    \ntreatment:gender:hour        2   0.57022    0.798      8     16 0.6131884    \nphase:hour                   1   0.56043    0.478      8      3 0.8202673    \ntreatment:phase:hour         2   0.66238    0.248     16      8 0.9915531    \ngender:phase:hour            1   0.71151    0.925      8      3 0.5894907    \ntreatment:gender:phase:hour  2   0.79277    0.328     16      8 0.9723693    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "contents/cleaning.html",
    "href": "contents/cleaning.html",
    "title": "Cleaning",
    "section": "",
    "text": "select(), mutate(), filter(), rename() : 기본 tidyverse verbs\n\nrowSums(), rowMeans() : composite 변수들의 합 또는 평균을 구함\n\nfactor() : 카테고리 변수의 변환\n\n앞서 다운받은 데이터: altruism.csv 파일 링크\n\nlibrary(tidyverse)\n\n# import data\nhelping &lt;- read_csv(\"data/altruism.csv\")\nhelping |&gt; print()\n\n# A tibble: 120 x 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n\n\nrename()\n\nhelping |&gt;\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3) |&gt;\n  print()\n\n# A tibble: 120 x 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n변형 후에는 꼭 변수에 assign!\n\nhelping &lt;- # 원래 데이터에 overwrite\n  helping |&gt;\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3)\n\nhelping |&gt; print()\n\n# A tibble: 120 x 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n\n\n\nrowSums(row, na.rm = TRUE) 함수를 이용하는 것이 직접 덧셈보다 더 적절함\nph1, ph2, ph3 세 문항을 더하려면,\n\n# 먼저 문항을 선택/확인\nhelping |&gt;\n  select(ph1:ph3) |&gt; # position!\n  print()\n\n# A tibble: 120 x 3\n    ph1   ph2   ph3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    95    95    95\n2    58    62    NA\n3   100    50    50\n4    77    77    64\n5    NA    NA    NA\n6   100    75   100\n# i 114 more rows\n\n\n\nhelping |&gt;\n  select(ph1:ph3) |&gt;\n  rowSums(na.rm = TRUE) |&gt;\n  print()\n\n  [1] 285 120 200 218   0 275 257 178 256 189 215 226 209 246 159 197 205 225\n [19] 150 195  44   0   0 125 225 211 270 176 241 205   0 220  98  79 143 165\n [37]  49 294 300 292 101 285 208 230 255 150 299 188 208 205 138 267 187 300\n [55] 195 300 236  59 226 193 213 250  32 228 250 300 300 190 230 281 196 268\n [73] 240 250  39 233 211 198 199 234 300 215 240   9 261 209 281 201 270 255\n [91] 177 235 161   0 242 151 182 170   3 222 172 194 300 300 293 238 243 260\n[109] 197 294 280 195 255   1 162 278 176 262 300 164\n\n\n\nhelping[\"phone\"] &lt;- # \"phone\"이라는 새로운 변수에 assign!\n  helping |&gt;\n  select(ph1:ph3) |&gt;\n  rowSums(na.rm = TRUE)\n\nhelping |&gt; print(width = Inf)\n\n# A tibble: 120 x 13\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone\n    &lt;dbl&gt; &lt;dbl&gt;\n1      70   285\n2      59   120\n3     100   200\n4      69   218\n5      NA     0\n6      90   275\n# i 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n다음과 같이 직접 더하는 것은 부적절\nhelping |&gt;\n  mutate(phone = ph1 + ph2 + ph3) \n#      id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n# 1     1    95    95    95     1  2004      80      NA      80      80      70\n# 2     2    58    62    NA     0  2003      62      58      59      57      56\n# 3     3   100    50    50    NA  2003      90      51      51      51      52\n# 4     4    77    77    64     1  2004      66      72      88      82      67\n# 5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n# 6     6   100    75   100     0  2004     100      60      70      55      70\n#   emp_q26 phone\n#     &lt;dbl&gt; &lt;dbl&gt;\n# 1      70   285\n# 2      59    NA\n# 3     100   200\n# 4      69   218\n# 5      NA    NA\n# 6      90   275\n# # … with 114 more rows\n\n\n\n\n\nrowMeans(row, na.rm = TRUE) 함수를 이용하는 것이 적절함\n\n# 먼저, 평균을 낼 문항을 선택/확인\nhelping |&gt;\n  select(emp_q20, emp_q22:emp_q26) |&gt; # \":\" operator와 \",\" 섞어써도 무방\n  print()\n\n# A tibble: 120 x 6\n  emp_q20 emp_q22 emp_q23 emp_q24 emp_q25 emp_q26\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1      80      NA      80      80      70      70\n2      62      58      59      57      56      59\n3      90      51      51      51      52     100\n4      66      72      88      82      67      69\n5      NA      NA      NA      NA      NA      NA\n6     100      60      70      55      70      90\n# i 114 more rows\n\n\n\nhelping[\"persp\"] &lt;- helping |&gt; # \"persp\"라는 새로운 변수에 assign!\n  select(emp_q20, emp_q22:emp_q26) |&gt;\n  rowMeans(na.rm = TRUE)\n\nhelping |&gt; print(width = Inf)\n\n# A tibble: 120 x 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone persp\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      70   285  76  \n2      59   120  58.5\n3     100   200  65.8\n4      69   218  74  \n5      NA     0 NaN  \n6      90   275  74.2\n# i 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nTidyverse에서 row-wise operation을 하려면,\nhelping |&gt;\n    rowwise() |&gt;\n    mutate(persp = mean(c(emp_q20, c_across(emp_q22:emp_q26)), na.rm = TRUE)) |&gt;\n    ungroup()\n참고: column-wise operation\n\n\n\n\n\n\n표준화(standardize): scale(x) 함수를 이용\n중심화(center): scale(x, scale = FALSE) 함수를 이용\n\n\nhelping |&gt;\n  mutate(\n    phone_z = scale(phone) |&gt; as.vector(), # scale()은 matrix로 반환; vector 변환 필요\n    persp_z = scale(persp) |&gt; as.vector()\n  ) |&gt;\n  print(n = 3, width = Inf)\n\n# A tibble: 120 x 16\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n  emp_q26 phone persp  phone_z persp_z\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      70   285  76    1.05      0.104\n2      59   120  58.5 -1.00     -0.981\n3     100   200  65.8 -0.00643  -0.527\n# i 117 more rows\n\n\nacross() 함수를 이용하면 여러 변수를 한 번에 변환할 수 있음\n\nhelping |&gt;\n  mutate(across(\n    .cols = c(phone, persp),\n    .fns = ~ (scale(.) |&gt; as.vector()),\n    .names = \"{.col}_z\"\n  )) |&gt; # 변수명을 일괄 변경: 변수명 + \"_z\"\n  print(n = 3, width = Inf)\n\n# A tibble: 120 x 16\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n  emp_q26 phone persp  phone_z persp_z\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      70   285  76    1.05      0.104\n2      59   120  58.5 -1.00     -0.981\n3     100   200  65.8 -0.00643  -0.527\n# i 117 more rows\n\n\n\n\n\n카테고리 변수는 R의 factor 타입으로 바꾸어 분석하는 것이 유리함.\n간단한 연산은 직접 계산.\n\nhelping |&gt;\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")), # factor 타입의 변수로 변환\n    age = 2023 - age # 출생년도로부터 나이 계산\n  ) |&gt;\n  print(width = Inf)\n\n# A tibble: 120 x 14\n     id   ph1   ph2   ph3 sex      age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95 female    19      80      NA      80      80      70\n2     2    58    62    NA male      20      62      58      59      57      56\n3     3   100    50    50 NA        20      90      51      51      51      52\n4     4    77    77    64 female    19      66      72      88      82      67\n5     5    NA    NA    NA NA        NA      NA      NA      NA      NA      NA\n6     6   100    75   100 male      19     100      60      70      55      70\n  emp_q26 phone persp\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      70   285  76  \n2      59   120  58.5\n3     100   200  65.8\n4      69   218  74  \n5      NA     0 NaN  \n6      90   275  74.2\n# i 114 more rows\n\n\n\n\n\nfilter()를 활용\n예를 들어, 5번째 행을 지우려면\n\nhelping |&gt;\n  filter(!id == 5) |&gt; # !는 not의 의미\n  print()\n\n# 다시 helping에 assign 해야 수정됨!\n\n# A tibble: 119 x 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     6   100    75   100     0  2004     100      60      70      55      70\n6     7    77    94    86     1  2004      91      93      85      91      73\n# i 113 more rows\n# i 3 more variables: emp_q26 &lt;dbl&gt;, phone &lt;dbl&gt;, persp &lt;dbl&gt;\n\n\n여러 행을 지우려면?\n%in% 응용\n\nhelping |&gt;\n  filter(!id %in% c(1, 3, 5)) |&gt; # !는 not의 의미\n  print()\n\n# A tibble: 117 x 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     2    58    62    NA     0  2003      62      58      59      57      56\n2     4    77    77    64     1  2004      66      72      88      82      67\n3     6   100    75   100     0  2004     100      60      70      55      70\n4     7    77    94    86     1  2004      91      93      85      91      73\n5     8    90    68    20     0  2004      67      66      31      67      63\n6     9   100    79    77     0  2003      61      51      30      51      51\n# i 111 more rows\n# i 3 more variables: emp_q26 &lt;dbl&gt;, phone &lt;dbl&gt;, persp &lt;dbl&gt;\n\n\n\n\n\nselect() 활용\nemp_q23, emp_q25 두 열을 삭제\n\nhelping |&gt;\n  select(-emp_q23, -emp_q25) |&gt;\n  print()\n\n# A tibble: 120 x 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q24 emp_q26 phone\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      70   285\n2     2    58    62    NA     0  2003      62      58      57      59   120\n3     3   100    50    50    NA  2003      90      51      51     100   200\n4     4    77    77    64     1  2004      66      72      82      69   218\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA     0\n6     6   100    75   100     0  2004     100      60      55      90   275\n# i 114 more rows\n# i 1 more variable: persp &lt;dbl&gt;\n\n\nemp_q23부터 emp_q26 열을 삭제 (위치의 의미로)\n\nhelping |&gt;\n  select(-(emp_q23:emp_q26)) |&gt; # () 꼭 필요\n  print()\n\n# A tibble: 120 x 10\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 phone persp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA   285  76  \n2     2    58    62    NA     0  2003      62      58   120  58.5\n3     3   100    50    50    NA  2003      90      51   200  65.8\n4     4    77    77    64     1  2004      66      72   218  74  \n5     5    NA    NA    NA    NA    NA      NA      NA     0 NaN  \n6     6   100    75   100     0  2004     100      60   275  74.2\n# i 114 more rows",
    "crumbs": [
      "R tutorial",
      "Cleaning"
    ]
  },
  {
    "objectID": "contents/cleaning.html#유용한-함수들",
    "href": "contents/cleaning.html#유용한-함수들",
    "title": "Cleaning",
    "section": "",
    "text": "select(), mutate(), filter(), rename() : 기본 tidyverse verbs\n\nrowSums(), rowMeans() : composite 변수들의 합 또는 평균을 구함\n\nfactor() : 카테고리 변수의 변환\n\n앞서 다운받은 데이터: altruism.csv 파일 링크\n\nlibrary(tidyverse)\n\n# import data\nhelping &lt;- read_csv(\"data/altruism.csv\")\nhelping |&gt; print()\n\n# A tibble: 120 x 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n\n\nrename()\n\nhelping |&gt;\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3) |&gt;\n  print()\n\n# A tibble: 120 x 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n변형 후에는 꼭 변수에 assign!\n\nhelping &lt;- # 원래 데이터에 overwrite\n  helping |&gt;\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3)\n\nhelping |&gt; print()\n\n# A tibble: 120 x 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n\n\n\nrowSums(row, na.rm = TRUE) 함수를 이용하는 것이 직접 덧셈보다 더 적절함\nph1, ph2, ph3 세 문항을 더하려면,\n\n# 먼저 문항을 선택/확인\nhelping |&gt;\n  select(ph1:ph3) |&gt; # position!\n  print()\n\n# A tibble: 120 x 3\n    ph1   ph2   ph3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    95    95    95\n2    58    62    NA\n3   100    50    50\n4    77    77    64\n5    NA    NA    NA\n6   100    75   100\n# i 114 more rows\n\n\n\nhelping |&gt;\n  select(ph1:ph3) |&gt;\n  rowSums(na.rm = TRUE) |&gt;\n  print()\n\n  [1] 285 120 200 218   0 275 257 178 256 189 215 226 209 246 159 197 205 225\n [19] 150 195  44   0   0 125 225 211 270 176 241 205   0 220  98  79 143 165\n [37]  49 294 300 292 101 285 208 230 255 150 299 188 208 205 138 267 187 300\n [55] 195 300 236  59 226 193 213 250  32 228 250 300 300 190 230 281 196 268\n [73] 240 250  39 233 211 198 199 234 300 215 240   9 261 209 281 201 270 255\n [91] 177 235 161   0 242 151 182 170   3 222 172 194 300 300 293 238 243 260\n[109] 197 294 280 195 255   1 162 278 176 262 300 164\n\n\n\nhelping[\"phone\"] &lt;- # \"phone\"이라는 새로운 변수에 assign!\n  helping |&gt;\n  select(ph1:ph3) |&gt;\n  rowSums(na.rm = TRUE)\n\nhelping |&gt; print(width = Inf)\n\n# A tibble: 120 x 13\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone\n    &lt;dbl&gt; &lt;dbl&gt;\n1      70   285\n2      59   120\n3     100   200\n4      69   218\n5      NA     0\n6      90   275\n# i 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n다음과 같이 직접 더하는 것은 부적절\nhelping |&gt;\n  mutate(phone = ph1 + ph2 + ph3) \n#      id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n# 1     1    95    95    95     1  2004      80      NA      80      80      70\n# 2     2    58    62    NA     0  2003      62      58      59      57      56\n# 3     3   100    50    50    NA  2003      90      51      51      51      52\n# 4     4    77    77    64     1  2004      66      72      88      82      67\n# 5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n# 6     6   100    75   100     0  2004     100      60      70      55      70\n#   emp_q26 phone\n#     &lt;dbl&gt; &lt;dbl&gt;\n# 1      70   285\n# 2      59    NA\n# 3     100   200\n# 4      69   218\n# 5      NA    NA\n# 6      90   275\n# # … with 114 more rows\n\n\n\n\n\nrowMeans(row, na.rm = TRUE) 함수를 이용하는 것이 적절함\n\n# 먼저, 평균을 낼 문항을 선택/확인\nhelping |&gt;\n  select(emp_q20, emp_q22:emp_q26) |&gt; # \":\" operator와 \",\" 섞어써도 무방\n  print()\n\n# A tibble: 120 x 6\n  emp_q20 emp_q22 emp_q23 emp_q24 emp_q25 emp_q26\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1      80      NA      80      80      70      70\n2      62      58      59      57      56      59\n3      90      51      51      51      52     100\n4      66      72      88      82      67      69\n5      NA      NA      NA      NA      NA      NA\n6     100      60      70      55      70      90\n# i 114 more rows\n\n\n\nhelping[\"persp\"] &lt;- helping |&gt; # \"persp\"라는 새로운 변수에 assign!\n  select(emp_q20, emp_q22:emp_q26) |&gt;\n  rowMeans(na.rm = TRUE)\n\nhelping |&gt; print(width = Inf)\n\n# A tibble: 120 x 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone persp\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      70   285  76  \n2      59   120  58.5\n3     100   200  65.8\n4      69   218  74  \n5      NA     0 NaN  \n6      90   275  74.2\n# i 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nTidyverse에서 row-wise operation을 하려면,\nhelping |&gt;\n    rowwise() |&gt;\n    mutate(persp = mean(c(emp_q20, c_across(emp_q22:emp_q26)), na.rm = TRUE)) |&gt;\n    ungroup()\n참고: column-wise operation\n\n\n\n\n\n\n표준화(standardize): scale(x) 함수를 이용\n중심화(center): scale(x, scale = FALSE) 함수를 이용\n\n\nhelping |&gt;\n  mutate(\n    phone_z = scale(phone) |&gt; as.vector(), # scale()은 matrix로 반환; vector 변환 필요\n    persp_z = scale(persp) |&gt; as.vector()\n  ) |&gt;\n  print(n = 3, width = Inf)\n\n# A tibble: 120 x 16\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n  emp_q26 phone persp  phone_z persp_z\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      70   285  76    1.05      0.104\n2      59   120  58.5 -1.00     -0.981\n3     100   200  65.8 -0.00643  -0.527\n# i 117 more rows\n\n\nacross() 함수를 이용하면 여러 변수를 한 번에 변환할 수 있음\n\nhelping |&gt;\n  mutate(across(\n    .cols = c(phone, persp),\n    .fns = ~ (scale(.) |&gt; as.vector()),\n    .names = \"{.col}_z\"\n  )) |&gt; # 변수명을 일괄 변경: 변수명 + \"_z\"\n  print(n = 3, width = Inf)\n\n# A tibble: 120 x 16\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n  emp_q26 phone persp  phone_z persp_z\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      70   285  76    1.05      0.104\n2      59   120  58.5 -1.00     -0.981\n3     100   200  65.8 -0.00643  -0.527\n# i 117 more rows\n\n\n\n\n\n카테고리 변수는 R의 factor 타입으로 바꾸어 분석하는 것이 유리함.\n간단한 연산은 직접 계산.\n\nhelping |&gt;\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")), # factor 타입의 변수로 변환\n    age = 2023 - age # 출생년도로부터 나이 계산\n  ) |&gt;\n  print(width = Inf)\n\n# A tibble: 120 x 14\n     id   ph1   ph2   ph3 sex      age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95 female    19      80      NA      80      80      70\n2     2    58    62    NA male      20      62      58      59      57      56\n3     3   100    50    50 NA        20      90      51      51      51      52\n4     4    77    77    64 female    19      66      72      88      82      67\n5     5    NA    NA    NA NA        NA      NA      NA      NA      NA      NA\n6     6   100    75   100 male      19     100      60      70      55      70\n  emp_q26 phone persp\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      70   285  76  \n2      59   120  58.5\n3     100   200  65.8\n4      69   218  74  \n5      NA     0 NaN  \n6      90   275  74.2\n# i 114 more rows\n\n\n\n\n\nfilter()를 활용\n예를 들어, 5번째 행을 지우려면\n\nhelping |&gt;\n  filter(!id == 5) |&gt; # !는 not의 의미\n  print()\n\n# 다시 helping에 assign 해야 수정됨!\n\n# A tibble: 119 x 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     6   100    75   100     0  2004     100      60      70      55      70\n6     7    77    94    86     1  2004      91      93      85      91      73\n# i 113 more rows\n# i 3 more variables: emp_q26 &lt;dbl&gt;, phone &lt;dbl&gt;, persp &lt;dbl&gt;\n\n\n여러 행을 지우려면?\n%in% 응용\n\nhelping |&gt;\n  filter(!id %in% c(1, 3, 5)) |&gt; # !는 not의 의미\n  print()\n\n# A tibble: 117 x 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     2    58    62    NA     0  2003      62      58      59      57      56\n2     4    77    77    64     1  2004      66      72      88      82      67\n3     6   100    75   100     0  2004     100      60      70      55      70\n4     7    77    94    86     1  2004      91      93      85      91      73\n5     8    90    68    20     0  2004      67      66      31      67      63\n6     9   100    79    77     0  2003      61      51      30      51      51\n# i 111 more rows\n# i 3 more variables: emp_q26 &lt;dbl&gt;, phone &lt;dbl&gt;, persp &lt;dbl&gt;\n\n\n\n\n\nselect() 활용\nemp_q23, emp_q25 두 열을 삭제\n\nhelping |&gt;\n  select(-emp_q23, -emp_q25) |&gt;\n  print()\n\n# A tibble: 120 x 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q24 emp_q26 phone\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      70   285\n2     2    58    62    NA     0  2003      62      58      57      59   120\n3     3   100    50    50    NA  2003      90      51      51     100   200\n4     4    77    77    64     1  2004      66      72      82      69   218\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA     0\n6     6   100    75   100     0  2004     100      60      55      90   275\n# i 114 more rows\n# i 1 more variable: persp &lt;dbl&gt;\n\n\nemp_q23부터 emp_q26 열을 삭제 (위치의 의미로)\n\nhelping |&gt;\n  select(-(emp_q23:emp_q26)) |&gt; # () 꼭 필요\n  print()\n\n# A tibble: 120 x 10\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 phone persp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA   285  76  \n2     2    58    62    NA     0  2003      62      58   120  58.5\n3     3   100    50    50    NA  2003      90      51   200  65.8\n4     4    77    77    64     1  2004      66      72   218  74  \n5     5    NA    NA    NA    NA    NA      NA      NA     0 NaN  \n6     6   100    75   100     0  2004     100      60   275  74.2\n# i 114 more rows",
    "crumbs": [
      "R tutorial",
      "Cleaning"
    ]
  },
  {
    "objectID": "contents/cleaning.html#이상치-발견",
    "href": "contents/cleaning.html#이상치-발견",
    "title": "Cleaning",
    "section": "이상치 발견",
    "text": "이상치 발견\nOutliers을 찾는 방법은 다양하고 복잡한 테크닉을 요하기도 하는데, 앞으로 점차 익히게 될 것임\n예를 들어, age에 잘못 기입한 경우가 있는데\n\nhelping &lt;- read_csv(\"data/altruism.csv\")\n\nhelping |&gt;\n  ggplot(aes(x = age)) +\n  geom_histogram(binwidth = 100)\n\n\n\n\n\n\n\n\nage는 출생년도를 물어봤으나 다른 답을 한 경우들이 있음\n값은 2002 ~ 2004 사이가 정상이므로 filter()를 써서 확인해 볼 수 있음\n\nhelping |&gt;\n  filter(age &lt; 2002 | age &gt; 2004) |&gt;\n  print()\n\n# A tibble: 7 x 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    11    65    94    56     1   203      62      86      58      47      62\n2    21    17    10    17     1 20004       0       6       1       0       4\n3    43    90    88    30     1   507     100      78      62     100      78\n4    52   100    82    85     1   723      87      83      89     100      88\n5    59    76    86    64     0   709     100      93      67      94      79\n6   108    75   100    85     1  2005     100     100     100     100      97\n7   118    92    76    94     0  1108      55      51      51      60      53\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n값을 수정\n\n# 이상치에 대한 id를 우선 추출\nids_anomaly &lt;- helping |&gt;\n  filter(age &lt; 2002 | age &gt; 2004) |&gt;\n  pull(id) # vector로 반환\nids_anomaly |&gt; print()\n\n[1]  11  21  43  52  59 108 118\n\n\n\n# 모두 NA로 변경하는 경우\nhelping |&gt;\n  # ifelse(조건, 참일 때 값, 거짓일 때 값)\n  mutate(\n    age = ifelse(age &gt; 2004, 2004, age),\n    age = ifelse(age &lt; 2002, NA, age)\n    # 대신, age = ifelse(age &gt; 2004, 2004, ifelse(age &lt; 2002, NA, age))\n  ) |&gt;\n  filter(id %in% ids_anomaly) |&gt;\n  print()\n\n# A tibble: 7 x 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    11    65    94    56     1    NA      62      86      58      47      62\n2    21    17    10    17     1  2004       0       6       1       0       4\n3    43    90    88    30     1    NA     100      78      62     100      78\n4    52   100    82    85     1    NA      87      83      89     100      88\n5    59    76    86    64     0    NA     100      93      67      94      79\n6   108    75   100    85     1  2004     100     100     100     100      97\n7   118    92    76    94     0    NA      55      51      51      60      53\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n\n# 직접 입력하는 방식\nhelping[helping$id %in% ids_anomaly, \"age\"] |&gt; print()\n\n# A tibble: 7 x 1\n    age\n  &lt;dbl&gt;\n1   203\n2 20004\n3   507\n4   723\n5   709\n6  2005\n7  1108\n\n\n\n# 직접 입력하는 방식\nhelping[helping$id %in% ids_anomaly, \"age\"] &lt;- c(NA, 2004, NA, NA, NA, 2005, NA)\nhelping |&gt;\n  filter(id %in% ids_anomaly) |&gt;\n  print()\n\n# A tibble: 7 x 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    11    65    94    56     1    NA      62      86      58      47      62\n2    21    17    10    17     1  2004       0       6       1       0       4\n3    43    90    88    30     1    NA     100      78      62     100      78\n4    52   100    82    85     1    NA      87      83      89     100      88\n5    59    76    86    64     0    NA     100      93      67      94      79\n6   108    75   100    85     1  2005     100     100     100     100      97\n7   118    92    76    94     0    NA      55      51      51      60      53\n# i 1 more variable: emp_q26 &lt;dbl&gt;",
    "crumbs": [
      "R tutorial",
      "Cleaning"
    ]
  },
  {
    "objectID": "contents/cleaning.html#샘플-r-script",
    "href": "contents/cleaning.html#샘플-r-script",
    "title": "Cleaning",
    "section": "샘플 R script",
    "text": "샘플 R script\n\nlibrary(tidyverse)\n\n# import data\nhelping &lt;- read_csv(\"data/altruism.csv\")\n\n# rename\nhelping &lt;- helping |&gt;\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3)\n\n# delete reponses\nhelping &lt;- helping |&gt;\n  filter(!id == 5)\n\n# scoring\nhelping[\"phone\"] &lt;- helping |&gt;\n  select(ph1:ph3) |&gt;\n  rowMeans(na.rm = TRUE)\n\nhelping[\"persp\"] &lt;- helping |&gt;\n  select(emp_q20, emp_q22, emp_q24:emp_q26) |&gt;\n  rowMeans(na.rm = TRUE)\n\n# substitute anolamies\nhelping &lt;- helping |&gt;\n  mutate(age = ifelse(age &gt; 2004, 2004, ifelse(age &lt; 2002, NA, age)))\n\n# factors and etc.\nhelping &lt;- helping |&gt;\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")),\n    age = 2023 - age\n  )\n\n# select variables\nhelping &lt;- helping |&gt;\n  select(id, sex, age, phone, persp)\n\n정리된 파일로 분석 시작!\n\nhelping |&gt; print()\n\n# A tibble: 119 x 5\n     id sex      age phone persp\n  &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 female    19  95    75  \n2     2 male      20  60    58.4\n3     3 NA        20  66.7  68.8\n4     4 female    19  72.7  71.2\n5     6 male      19  91.7  75  \n6     7 female    19  85.7  82.6\n# i 113 more rows",
    "crumbs": [
      "R tutorial",
      "Cleaning"
    ]
  },
  {
    "objectID": "contents/import.html",
    "href": "contents/import.html",
    "title": "Import",
    "section": "",
    "text": "자세한 데이터 import에 대해서는 링크",
    "crumbs": [
      "R tutorial",
      "Import"
    ]
  },
  {
    "objectID": "contents/import.html#text-files-csv",
    "href": "contents/import.html#text-files-csv",
    "title": "Import",
    "section": "Text files: csv",
    "text": "Text files: csv\nreadr 패키지(tidyverse에 포함)\nread_csv(), write_csv()\n\nR 기본 함수 read.csv()를 개선\n다양한 옵션은 ?read_csv, ?write_csv 참고\n\n\ncsv 파일 읽기\naltruism.csv 파일 링크\n\nlibrary(tidyverse)\n\nhelping &lt;- read_csv(\"data/altruism.csv\")  # tidyverse 패키지의 함수\nhelping |&gt; print()\n\n# A tibble: 120 x 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# i 114 more rows\n# i 1 more variable: emp_q26 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nread_csv()의 자주 사용되는 옵션\nread_csv(\"data/file.csv\", skip = 2) # 첫 2절 스킵\nread_csv(\"data/file.csv\", na = \".\") # 결측치가 .으로 기록된 파일\n\n\n\n\ncsv 파일 쓰기\nwrite_csv(): 단, 쓰기를 하면서 변수 타입 소멸\n\nwrite_csv(helping, file = \"data/helping_new.csv\")",
    "crumbs": [
      "R tutorial",
      "Import"
    ]
  },
  {
    "objectID": "contents/import.html#excel-spreadsheets",
    "href": "contents/import.html#excel-spreadsheets",
    "title": "Import",
    "section": "Excel spreadsheets",
    "text": "Excel spreadsheets\nreadxl package\nread_excel(), read_xlsx(), read_xls()\n\n엑셀 파일 읽기\nstduents.xlsx 파일 링크\n\nlibrary(readxl) # install.packages(\"readxl\")\nstud &lt;- read_xlsx(\"data/students.xlsx\")\n\n# 또는\nstud &lt;- readxl::read_xlsx(\"data/students.xlsx\")\n\nstud |&gt; print()\n\n# A tibble: 1,000 x 93\n  stu_id sch_id sstratid   sex  race ethnic bys42a bys42b bys44a bys44b bys44c\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 124966   1249        1     2     4      1      3      4      2      4      4\n2 124972   1249        1     1     4      1      4      5      1      3      3\n3 175551   1755        1     2     3      0     NA      3      2      3      3\n4 180660   1806        1     1     4      1      2     NA      1      4      4\n5 180672   1806        1     2     4      1      2      3      1      4      3\n6 298885   2988        2     1     3      0      5      4      2      3      3\n# i 994 more rows\n# i 82 more variables: bys44d &lt;dbl&gt;, bys44e &lt;dbl&gt;, bys44f &lt;dbl&gt;, bys44g &lt;dbl&gt;,\n#   bys44h &lt;dbl&gt;, bys44i &lt;dbl&gt;, bys44j &lt;dbl&gt;, bys44k &lt;dbl&gt;, bys44l &lt;dbl&gt;,\n#   bys44m &lt;dbl&gt;, bys48a &lt;dbl&gt;, bys48b &lt;dbl&gt;, bys79a &lt;dbl&gt;, byfamsiz &lt;dbl&gt;,\n#   famcomp &lt;dbl&gt;, bygrads &lt;dbl&gt;, byses &lt;dbl&gt;, byfaminc &lt;dbl&gt;, parocc &lt;dbl&gt;,\n#   bytxrstd &lt;dbl&gt;, bytxmstd &lt;dbl&gt;, bytxsstd &lt;dbl&gt;, bytxhstd &lt;dbl&gt;,\n#   bypared &lt;dbl&gt;, bytests &lt;dbl&gt;, par_inv &lt;dbl&gt;, f1s36a1 &lt;dbl&gt;, ...\n\n\n\n\n\n\n\n\nNote\n\n\n\nSpecify sheet either by position or by name\nread_excel(\"salaries.xlsx\", sheet = 2) # The default is sheet = 1\nread_excel(\"salaries.xlsx\", sheet = \"personnel\")",
    "crumbs": [
      "R tutorial",
      "Import"
    ]
  },
  {
    "objectID": "contents/import.html#statistical-packages",
    "href": "contents/import.html#statistical-packages",
    "title": "Import",
    "section": "Statistical packages",
    "text": "Statistical packages\nSPSS의 데이터: read_sav()\nstudents-shorter.sav 파일 링크\n\nlibrary(haven) # install.packages(\"haven\")\nstud_spss &lt;- read_sav(\"data/students-shorter.sav\")\n\n# 또는\nstud_spss &lt;- haven::read_sav(\"data/students-shorter.sav\")\n\nstud_spss |&gt; print()\n\n# A tibble: 1,000 x 93\n  stu_id    sch_id    sstratid sex     race    ethnic  bys42a   bys42b   bys44a \n  &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt;\n1 124966    1249      1        2 [Fem~ 4 [Whi~ 1 [whi~  3 [2-3~  4 [3-4~ 2 [Agr~\n2 124972    1249      1        1 [Mal~ 4 [Whi~ 1 [whi~  4 [3-4~  5 [4-5~ 1 [Str~\n3 175551    1755      1        2 [Fem~ 3 [Bla~ 0 [blk~ NA        3 [2-3~ 2 [Agr~\n4 180660    1806      1        1 [Mal~ 4 [Whi~ 1 [whi~  2 [1-2~ NA       1 [Str~\n5 180672    1806      1        2 [Fem~ 4 [Whi~ 1 [whi~  2 [1-2~  3 [2-3~ 1 [Str~\n6 298885    2988      2        1 [Mal~ 3 [Bla~ 0 [blk~  5 [4-5~  4 [3-4~ 2 [Agr~\n# i 994 more rows\n# i 84 more variables: bys44b &lt;dbl+lbl&gt;, bys44c &lt;dbl+lbl&gt;, bys44d &lt;dbl+lbl&gt;,\n#   bys44e &lt;dbl+lbl&gt;, bys44f &lt;dbl+lbl&gt;, bys44g &lt;dbl+lbl&gt;, bys44h &lt;dbl+lbl&gt;,\n#   bys44i &lt;dbl+lbl&gt;, bys44j &lt;dbl+lbl&gt;, bys44k &lt;dbl+lbl&gt;, bys44l &lt;dbl+lbl&gt;,\n#   bys44m &lt;dbl+lbl&gt;, bys48a &lt;dbl+lbl&gt;, bys48b &lt;dbl+lbl&gt;, bys79a &lt;dbl+lbl&gt;,\n#   byfamsiz &lt;dbl+lbl&gt;, famcomp &lt;dbl+lbl&gt;, bygrads &lt;dbl+lbl&gt;, byses &lt;dbl+lbl&gt;,\n#   byfaminc &lt;dbl+lbl&gt;, parocc &lt;dbl&gt;, bytxrstd &lt;dbl+lbl&gt;, ...\n\n\n\nstud_spss |&gt;\n  select(ethnic) |&gt;\n  print()\n\n# A tibble: 1,000 x 1\n  ethnic            \n  &lt;dbl+lbl&gt;         \n1 1 [white-asian]   \n2 1 [white-asian]   \n3 0 [blk,namer,hisp]\n4 1 [white-asian]   \n5 1 [white-asian]   \n6 0 [blk,namer,hisp]\n# i 994 more rows\n\n\nlabelled 데이터 참고\n\n# install.packages(\"labelled\")\nlibrary(labelled)\n\n\n# label 확인\nval_labels(stud_spss$race) |&gt; print()\n\nAsian/Pacific islndr             Hispanic   Black not Hispanic \n                   1                    2                    3 \n  White not Hispanic   Amer ind/AK Native              MISSING \n                   4                    5                    8 \n\n\n\n# label 확인\nval_labels(stud_spss$ethnic) |&gt; print()\n\nblk,namer,hisp    white-asian        missing \n             0              1              8 \n\n\n\n# labelled 변수를 factor로 변환\nstud &lt;- stud_spss |&gt;\n  unlabelled()\nstud |&gt; print()\n\n# A tibble: 1,000 x 93\n  stu_id sch_id sstratid sex    race   ethnic bys42a bys42b bys44a bys44b bys44c\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt; \n1 124966   1249        1 Female White~ white~ 2-3 h~ 3-4 h~ Agree  Stron~ Stron~\n2 124972   1249        1 Male   White~ white~ 3-4 h~ 4-5 h~ Stron~ Disag~ Disag~\n3 175551   1755        1 Female Black~ blk,n~ NA     2-3 h~ Agree  Disag~ Disag~\n4 180660   1806        1 Male   White~ white~ 1-2 h~ NA     Stron~ Stron~ Stron~\n5 180672   1806        1 Female White~ white~ 1-2 h~ 2-3 h~ Stron~ Stron~ Disag~\n6 298885   2988        2 Male   Black~ blk,n~ 4-5 h~ 3-4 h~ Agree  Disag~ Disag~\n# i 994 more rows\n# i 82 more variables: bys44d &lt;fct&gt;, bys44e &lt;fct&gt;, bys44f &lt;fct&gt;, bys44g &lt;fct&gt;,\n#   bys44h &lt;fct&gt;, bys44i &lt;fct&gt;, bys44j &lt;fct&gt;, bys44k &lt;fct&gt;, bys44l &lt;fct&gt;,\n#   bys44m &lt;fct&gt;, bys48a &lt;fct&gt;, bys48b &lt;fct&gt;, bys79a &lt;fct&gt;, byfamsiz &lt;fct&gt;,\n#   famcomp &lt;fct&gt;, bygrads &lt;dbl&gt;, byses &lt;dbl&gt;, byfaminc &lt;fct&gt;, parocc &lt;dbl&gt;,\n#   bytxrstd &lt;dbl&gt;, bytxmstd &lt;dbl&gt;, bytxsstd &lt;dbl&gt;, bytxhstd &lt;dbl&gt;,\n#   bypared &lt;fct&gt;, bytests &lt;dbl&gt;, par_inv &lt;dbl&gt;, f1s36a1 &lt;fct&gt;, ...\n\n\n\nstud |&gt; count(race) |&gt; print()\n\n# A tibble: 6 x 2\n  race                     n\n  &lt;fct&gt;                &lt;int&gt;\n1 Asian/Pacific islndr    61\n2 Hispanic               114\n3 Black not Hispanic     100\n4 White not Hispanic     704\n5 Amer ind/AK Native      10\n6 NA                      11\n\n\nLabels 제거하기\n\nstud2 &lt;- stud_spss |&gt;\n  remove_val_labels()\nstud2 |&gt; print()\n\n# A tibble: 1,000 x 93\n  stu_id sch_id sstratid   sex  race ethnic bys42a bys42b bys44a bys44b bys44c\n   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 124966   1249        1     2     4      1      3      4      2      4      4\n2 124972   1249        1     1     4      1      4      5      1      3      3\n3 175551   1755        1     2     3      0     NA      3      2      3      3\n4 180660   1806        1     1     4      1      2     NA      1      4      4\n5 180672   1806        1     2     4      1      2      3      1      4      3\n6 298885   2988        2     1     3      0      5      4      2      3      3\n# i 994 more rows\n# i 82 more variables: bys44d &lt;dbl&gt;, bys44e &lt;dbl&gt;, bys44f &lt;dbl&gt;, bys44g &lt;dbl&gt;,\n#   bys44h &lt;dbl&gt;, bys44i &lt;dbl&gt;, bys44j &lt;dbl&gt;, bys44k &lt;dbl&gt;, bys44l &lt;dbl&gt;,\n#   bys44m &lt;dbl&gt;, bys48a &lt;dbl&gt;, bys48b &lt;dbl&gt;, bys79a &lt;dbl&gt;, byfamsiz &lt;dbl&gt;,\n#   famcomp &lt;dbl&gt;, bygrads &lt;dbl&gt;, byses &lt;dbl&gt;, byfaminc &lt;dbl&gt;, parocc &lt;dbl&gt;,\n#   bytxrstd &lt;dbl&gt;, bytxmstd &lt;dbl&gt;, bytxsstd &lt;dbl&gt;, bytxhstd &lt;dbl&gt;,\n#   bypared &lt;dbl&gt;, bytests &lt;dbl&gt;, par_inv &lt;dbl&gt;, f1s36a1 &lt;dbl&gt;, ...",
    "crumbs": [
      "R tutorial",
      "Import"
    ]
  },
  {
    "objectID": "contents/overview.html",
    "href": "contents/overview.html",
    "title": "Overview",
    "section": "",
    "text": "이번 섹션에서는 통계가 어떻게 활용되는지에 대한 전반적인 landscape을 소개하고자 하며, 이는 다양한 통계적 분석 이론들 속에서 자신이 수행하고 있는 분석의 적절성을 대략 이해하며, 어떤 부분이 부족한지를 파악할 수 있도록 하고자 함.\n여기에서 소개하는 내용을 모두 수업에서 다룬다는 것은 절대 아님!\n통계 분석은 크게 세 가지 주제로 나눌 수 있음.\n통계가 활용되는 방식을 분류하면,",
    "crumbs": [
      "Statistics",
      "Overview"
    ]
  },
  {
    "objectID": "contents/overview.html#descriptive-기술적-분석",
    "href": "contents/overview.html#descriptive-기술적-분석",
    "title": "Overview",
    "section": "Descriptive: 기술적 분석",
    "text": "Descriptive: 기술적 분석\n\n\n\n\n\n\n통계청의 조사 결과와 같이 현상에 대한 기술\n단순한 기술은 자칫 오해의 여지와 호도할 위험이 존재\n예를 들어,\n\n남녀 임금의 차이에 대한 통계치를 제시하는 경우\n\n외국의 경우, 인종별 범죄율에 대한 통계치 등등\n\n만일, 좀 더 자세히 나눠어서, 연령별, 직업군별로 남녀 임금의 차이를 본다면 만족스러운가?\n얼마나 더 상세히 나누어야 하는가?\n그 차이는 의미있는 차이인가?",
    "crumbs": [
      "Statistics",
      "Overview"
    ]
  },
  {
    "objectID": "contents/overview.html#relational-변수들-간의-진실한-관계를-분석",
    "href": "contents/overview.html#relational-변수들-간의-진실한-관계를-분석",
    "title": "Overview",
    "section": "Relational: 변수들 간의 진실한 관계를 분석",
    "text": "Relational: 변수들 간의 진실한 관계를 분석\n\nCase 1\n미혼자에 대한 임금 차별이 있는가? 차별이 의미하는 바는 무엇인가?\n아래 첫번째 그림과 같이 기혼자의 임금이 미혼자에 보다 높은 것으로 나타났다면,\n이는 정말 결혼하지 않은 것이 임금을 책정하는데 영향을 주었는가?\n하지만, 당연하게도 기혼자는 미혼자에 비해 연령이 높으며 (두번째 그림),\n높은 연령은 연차가 높거나 실무능력이 뛰어난 경향으로 인해 임금을 높을 수 있다는 것을 감안하면 (세번째 그림)\n차별처럼 보이는 차이는 차별이라고 볼 수 없을 수도 있음.\n다시 말하면, 연령을 고려한 후에도 기혼자의 임금은 미혼자보다 높은가?\n여전히 높다면, 연령을 고려한 후 혹은 연령을 조정한 후(adjusted for age)의 차이는 얼마라고 봐야하는가?\n연령을 고려한 임금 차이를 조사하는 방법은 무엇이 있겠는가?\n\n연령별로 나누어 비교?\n\nData from the 1985 Current Population Survey\n\n\n\n\n\n\n\n\n\n연령을 고려한 마라톤 기록?\n70세 노인과 20세 청년이 동일하게 2시간 30분의 기록을 세웠다면?\n\n“나이 차이가 큰 두 사람의 기록을 비교하는 것은 공평하지 않아”\n나이를 감안한 마라톤 실력?\n다시 말하면, 나이와는 무관한/독립적인 마라톤 능력에 대해 말하고자 함\n이는 동일한 나이의 사람들로만 제한해서 마라톤 기록을 비교하는 것이 공평한 능력의 비교라고 말하는 것과 같은 이치임\n\n\n\nSource: https://doi.org/10.1186/2052-1847-6-31\n\n\n\nCase 2\n기혼여부에 따른 임금의 차이가 남녀별로 다른가?\n연령이 올라감에 따라 임금이 올라가는 패턴에 차이가 있는가?\n\n\n\n\n\n\n\n\n\n왼편 그림에서 보면, 기혼여부에 따른 임금의 차이가 남녀에 따라 다르게 나타나는 것으로 보임\n이러한 현상을 변수 간에 상호작용(interaction)이 있다고 말함 (moderate라는 표현도 있음)\n말하지면, 기혼여부가 임금에 주는 효과가 성별에 따라 바뀌고, 기혼여부와 성별이 상호작용하여 임금에 영향을 준다라고 표현할 수 있음 (2-way interaction)\n비슷하게, 오른편을 보면, 연령에 따른 임금의 증가 패턴이 남녀에 따라서, 업종에 따라 다르게 나타나는 것으로 보임\n(manag: management, manuf: manufacturing, prof: professional)\n즉, 연령이 임금에 미치는 효과는 성별과 업종에 따라 바뀌고, 연령, 성별, 업종이 상호작용하여 임금에 영향을 준다라고 표현할 수 있음 (3-way interaction)\n\n\n\n\n\n\nWarning\n\n\n\n위의 표현은 모두 효과를 가정한 표현으로 설명을 위해 편의상 그렇게 표현하였음\n또한, 다른 요소들은 단순화를 위해 생략했음. 예를 들어 왼편의 상황에서 나이를 고려하면 다른 양상을 보일 수 있음\n\n\n또 다른 예로는, 나이가 듦(age)에 따라 지구력(endurance)의 감소가 강도 높은 운동을 한 기간(년수)(exercise)에 따라 변화한다는 가설을 테스트한 자료\n\n\n\n\n\n\n\n\n\n이 경우 운동을 한 기간은 앞의 예에서처럼 카테고리 변수가 아니기 때문에 임의로 3구간으로 나누어 살펴 본 것임.\n나이가 지구력에 미치는 부정적 영향이 운동을 한 기간에 따라 변하는 것으로 보임.\n즉, 나이와 운동기간이 상호작용하여 지구력에 영향을 미친다고 표현할 수 있음\n상호작용은 아래와 같이 상호작용하는 두 변수의 위치를 바꿔 살펴볼 수도 있음\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n시각화를 통해 전반적인 패턴을 살펴보는 것은 통계적 모형을 세워 수학적으로 분석하기 전에 하는 보조 수단임.\n앞에 마라톤 기록의 예처럼 실제 분석은 한 변수를 고려한 후 다른 변수의 변화를 계산하는 방식으로 분석을 하는 것이지, 나이별로 자료를 나누어 보지 않듯이, 운동기간을 위에서처럼 구간으로 쪼개어 분석하는 것은 아님.\n\n\n\n\nCase 3\n임금이 증가하면 삶의 만족도가 높아지는가? 아마도?\n\n\n\n\n\n\n\n\n\n\n하지만, 특정 A의 임금이 p 에서 q 로 증가할 때, 트렌드대로 움직이겠는가?\n혹은, 특정 B의 임금이 r 에서 s 로 감소할 때, 트렌드대로 움직이겠는가?\n개인의 변화를 살펴보는 종단연구(logitudinal)로 그 갭을 채울 수 있음\n\n\n\n\n\n\nNote\n\n\n\nLongitudinal (종단) vs. cross-sectional (횡단)\n종단 데이터는 관측의 단위, 예를 들어 개인을 반복측정하여 개개인의 특성을 함께 파악할 수 있는 장점을 가짐. 시간과 비용이 많이 들고, attrition (참여자 탈락) 비율이 높아질 우려가 있어 분석에 걸림돌이 되곤 함. 특히, 노인에 대한 연구는 사망으로 인해 참여자가 주는데, 이런 결측치를 고려한 분석에는 상당한 조심성과 기술이 요함. (missing data analysis)\n분석의 관점에서 보면, 개인을 반복 측정하기 때문에 측정값들 사이의 dependency 문제가 생기는데 이를 분석에 고려하려는 노력임. 참여자 각각의 고유한 특성과 연구자가 측정하고자 하는 특성을 분리하고자 함. 위의 예에서 보면, “임금이 삶의 만족도에 주는 영향”과 “개개인의 고유한 특성이 삶의 만족도에 주는 영향”을 분리시켜야 전자의 효과를 분명히 파악할 수 있음. 이는 이후 언급할 multi-level analysis로도 볼 수 있음.\n반면, 주로 접하게 되는 횡단 데이터는 모든 관측치가 independent, 즉 서로 영향을 받지 않는다고 가정할 수 있는데, 물론 한 가족의 구성원이 참여하는 연구는 그 가정에 위배됨.\n횡단데이터의 문제는 소위 cohort bias가 숨어 있을 수 있음. 예를 들어 다른 나이대의 사람들은 다른 사회적 경험을 통해 다른 특성을 지녔을 수 있으므로, 데이터의 관측치들이 homogenous (동질적) 하지 못함으로 인해 연구자가 보려는 관계에 노이즈를 만들 수 있음.\n\n\n하지만, 그럴지라도 임금으로 “인해” 삶의 만족도가 올라가느냐는 다른 문제임 &gt;&gt; 인과관계의 문제\n\n예를 들어, 연봉의 증가가 삶의 만족도를 올렸다기 보다는 상대적 비교에서 오는 자존감이 증가했기 때문일 수 있음\n연봉이 높은 곳은 직업 특성이 다를 수 있음\n또는, 인맥과 인간관계의 변화에서 오는 차이일 수도 있음\n\n다른 시각에서 보면, 인과 관계를 가정하더라고 개입(intervention)하는 것은 또다른 문제임: 개입은 인과의 매커니즘을 교란시킬 수 있음.\n예를 들어, 현재 A의 연봉 2천만원을 갑자기 4천만으로 올리면 삶의 만족도가 트렌드대로 0.8pt 올라가겠는가?\n\n연봉의 증가는 주변의 시기와 질투를 가져와 인관관계에 영향을 줄 수 있음\n\n본인의 자만은 여러 부정적 결과를 초래할 수 있음\n노력에 의해 얻은 것이 아니라는 점은 다른 부작용을 낳을 수 있음\n\n\n\nPrediction vs. intervention\n\nA의 임금이 올라가면 삶의 만족도가 따라서 올라갈 것이라고 (조심스럽게) 예측할 수는 있으나: association\n\n좀 더 정확히 말하면, 임금이 높은 것은 삶의 만족도가 높은 것과 연관이 있다라고 표현\n“올라가면”이라는 표현은 시간 개념을 포함한 것이라 횡단(cross-sectional) 데이터에서는 부적절\n\nA의 임금을 올리면 삶의 만족도가 올라갈 것이라고 단정할 수 없음: causal\nIntervention이 효과가 있으려면, 적어도 진정한 관계를 파악해야만 하며, 더 나아가 메커니즘을 포함한 인과관계가 만족해야 함.\n진정한 관계의 문제와 인과의 문제는 서로 엮여 있으며 복잡한 문제임.\n\n예를 들어, 오렌지를 섭취하면 괴혈병이 예방되나 사실은 비타민 C의 섭취가 괴혈병을 예방하는 것임\n만약, 장거리 항해에서 상급자(높은 연령)에게만 과일이 제공되었을 때, 나이가 많은 선원들에게서 괴혈병이 덜 생겼다는 현상으로부터 연령과 괴혈병의 관계를 추론해서는 안됨. 하지만 예측은 여전히 유효함.\n\n\n또는, 신앙심이 깊은 노인들의 수명이 더 길다는 현상이 관찰되었을 때, 신앙심 자체가 심리적으로나 신체적으로 긍정적인 효과를 가질 수 있으나, 그 외에도 신앙 활동의 일부로 활동이 늘고 다른 이와의 긍정적 교류가 건강에 영향을 미쳤을 수도 있음.\n\n이 때, 신앙심과 수명과는 진정한 관계가 있다고 볼 수 있으나 (not spurious) 그 인과 관계에 대해서도 좀 더 깊은 논의가 필요함.\n다시 말하면, 어떤 노인에게 신앙을 권유했을 때, 수명이 연장되었을지라도 신앙심 자체가 수명을 연장시킨 것인가는 별개의 논의임.\n\n\n\n\nThe strength of relationships\n변수들간의 관계와 그 관계의 크기(stength)는 중요하게 구별될 필요가 있음\n아래 두 그림은 변수 간의 관계는 동일하나 그 크기에 차이가 있음\n오른쪽 그림에서 연봉으로 그 사람의 삶의 만족도 지수를 더 정확히 예측할 수 있으며, 이를 설명력 \\((R^2)\\)이 높다고 표현\n보통 이 효과의 크기가 클수록 인과관계일 가능성은 높다고 볼 수 있으며,\n왼쪽 박스에서처럼 variability가 높다는 것은 다른 이유가 있을 가능성이 높음\n\n\n\n\n\n\n\n\n\n카테고리 변수에 대해서도 비슷하게 생각할 수 있음.\n이 경우, 두 그룹 간의 차이에 대한 효과의 크기를 말할 수 있고, \\(R^2\\) 이외에도 대표적으로 Cohen’s d로 표현할 수 있음.\n\n\n\n\n\n\n\nNote\n\n\n\n진정한 관계를 탐구하는 것이 어려움에도 불구하고, 관계성을 파악함으로써 통찰을 얻을 수 있음.\n\n\n\n\n복잡한 변수와의 관계를 풀어내려고 노력\nSource: Multiple Regression and Beyond by Timothy Z. Keith\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent variable model (잠재 변수 모형)\n구체적으로 측정한 변수들간의 관계를 넘어서서, 연구자는 좀 더 추상적이고 개념적인 construct에 대해 이론적 논의를 하고자 한다면, 그 construct를 대변해줄 수 있다고 간주되는 측정가능한 요인들로 “잠재 변수”를 구성하여, 그 잠재 변수들 간의 관계를 파악함.\n\n학업성취도에 미치는 요인들\n\nSource: Multiple Regression and Beyond by Timothy Z. Keith\n사회의 보상체계를 결정하는 요인들\n\nSource: Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences by Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. Aiken",
    "crumbs": [
      "Statistics",
      "Overview"
    ]
  },
  {
    "objectID": "contents/overview.html#causal-인과관계의-분석",
    "href": "contents/overview.html#causal-인과관계의-분석",
    "title": "Overview",
    "section": "Causal: 인과관계의 분석",
    "text": "Causal: 인과관계의 분석\n위에서 살펴본 것들은 모두 연구자가 개입하지 않고 관찰만으로 이루어진 분석들임\n논의한 것처럼 관찰된 자료로부터 진실된 관계를 파악하는 것은 매우 정교한 분석이 요구되고 많은 요소들을 고려해야 함.\n좀 더 분명한 관계를 파악하기 위해 실험 연구가 요구되곤 함\n하지만, 많은 경우 실험이 불가능할 뿐 아니라,\n실험이 반드시 최선인 것은 아니며, 실험은 나름데로 큰 약점을 갖고 있음.\n\nConfounding\n\n\n\n\n\n\nConfounding\n\n\n\n일반적으로, 표면적으로 드러난 변수간의 관계가 숨겨진 다른 변수들(lurking third variable)에 의해 매개되어 있어 진실한 관계가 아닌 경우, confounding 혹은 confounder가 존재한다고 함.\n사회과학에서 오래된 가장 핵심적인 문제이나 최근까지도 정확히 정의하기 어려움 개념이었음.\nCausal inference라는 통계와는 별개의 개념으로 발전되어 최근에야 이론적으로 완성이 되어 관심이 높아짐.\n극단적이지만 이해하지 쉬운 예로는\n\n초등학생 발 사이즈 → 독해력\n\n머리 길이 → 우울증\n\n\n\n\n\n\n\n\n\nAnswer!\n\n\n\n\n\n\n\n\n\n\nCommon cause/Fork\n맨 처음 든 예도 마찬가지로   \n올바른 관계를 파악하려면, 동일한 나이에 대해 그 관계를 파악한 후 각 나이에서의 효과를 (weighted) 평균해서 살펴봐야함\n통계에서는 이를 나이를 통제 (control for age)한다고 표현하며, 같은 의미로 다음과 같은 표현을 씀\n나이를 고려했을 때; account for age\n나이를 조정했을 때; adjust for age\n나이를 잔차화했을 때; residualize age\n나이의 변량을 넘어서서; above and beyond age\nSimpson’s paradox\n아래 첫번째 그림은 집단 전체에 대한 플랏이고, 두번째 그림은 나이대별로 나누어 본 플랏\n전체 집단을 보면 운동을 많이 할수록 콜레스테롤이 증가하는 것으로 보이나,\n나이대별로 보면, 상식적으로 운동이 긍정적 효과가 나타남.\n왜 그렇게 나타나는가?\n\nSource: The book of why by Judea Pearl\n마지막 예를 들면,\n은퇴한 노인들을 대상으로 규칙적인 걷기가 사망율을 감소시킬 것이라는 가설을 확인하기 위해 1965년 이후 8000명 가량의 남성들을 추적조사한 데이터의 일부를 이용했는데,\nSource: The book of why by Judea Pearl\n\n12년 후 사망율에서 casual walker(하루 1마일 이하)와 intense walker(하루 2마일 이상)가 각각 43%, 21.5%로 나타났음.\n이 걷기의 효과를 의심케 하는 요소들(confounding)은 무엇인가?\n\n\n\n\n\n\n\nAnswers!\n\n\n\n\n\n\n건강이 나빠 많이 걷지 못했을 수도…\n많이 걷는 사람은 상대적으로 젊을 수도…\n많이 먹는 사람이 덜 걸을 수도…\n술을 많이 먹는 사람이 덜 걸을 수도…\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n무수히 많이 생각해볼 수 있는 confounding 요소들을 다 고려해야 하는가?\nYes and No!\n실제 저자들도 다음과 같이 기술\n“Of course, the effects on longevity of intentional efforts to increase the distance walked per day by physically capable older men cannot be addressed in our study.”\n이러한 조심성은 의미있느나 너무 과장될 필요는 없음\n소위 중요 역할을 할 것으로 의심되는 confounding을 충분히 통계적으로 고려/통제했다면, 충분히 인과관계 혹은 intervention을 제안할 수 있으며,\n그러한 연구는 어떤 요소들을 고려했는지에 대해 밝힘으로써 추후 연구에서 어떤 부분이 더 추가적으로 고려되야 할지 알 수 있게 함.\n\n\n관찰 데이터로부터 진정한 관계를 파악하기 위해서는 이와 같은 인과 추론이라는 좀 더 큰 프레임에서 분석해야 하며, 통계 안에서 해결하기 어려움.\n예를 들어, collider인 경우 통제하면 spurious association이 생길 수 있음.\n\n\nCollider/Immorality\n\n\n운동능력이 뛰어나면 지능이 떨어지는가?\n\n\n미모가 뛰어나면 연기력이 떨어지는가?\n\n\n\n\n\nMediations/Chains(Mechanisms)\n\n1990년대 최악의 시카고 공립학교의 개혁 정책\n고1에서 보충 과목을 없애고, 대학 진학 준비 과목을 수강하도록 함.\n이 중 대수 1 과목(“Algebra for All”)의 경우 3년 간 유의한 성적 개선이 없었음.\nGuanglei Hong(시카고대 인간발달)은 정책의 직접적 효과는 존재한다고 판별했음!\n\n정책이 두 가지 방식으로 (다른 방향으로) 작용했음.\n이후 “Double-Dose Algebra”으로 개선했음.\n\n\n\n학생들의 과제는 성적에 영향을 주는가?\nSource: National Education Longitudinal Study of 1988 (NELS:88)\n\n\n\n\nDirected acyclic graph (DAG)\n인과 관계 다이어그램\n\n\nSource: Causality: Models, Reasoning, and Inference (2000) by Judea Pearl\n\n\n\nSelection Bias\n수집된 데이터의 특성에 따라 인과추론을 방해하거나(confounding); internal validity(내적 타당도)\n일반화할 수 있는 대상의 범위가 제한됨; external validity(외적 타당도)\n\n노인에 관한 데이터: 누가 사망했는가?\n\nSurvival bias: 일종의 collider bias\n예를 들어, 비만이 사망율에 미치는 효과에 대한 과소추정\n\n\n의료 분야에서 발견되는 패러독스\n\n비만은 당뇨 환자에게 이익이 되는가?\n\n과거 기록을 이용?; 수녀들의 자서전 연구\n\n추적조사/종단연구(longitudinal study)\n\n회사 구성원에 대한 조사: 근속년수에 따른 샘플 속성의 변화\n누가 참여(안)했는가? 어떤 방식으로 참여했는가?\n\n관측되지 않은 데이터: 어떤 사람/대상이 왜 누락되었는가?\n어떤 사람들이 설문/실험에 참여했는가? 혹은 어떤 문항에 응답했는가?/하지 않았는가?\n\n어떤 유저들의 데이터인가? 가령, SNS의 기록은 누가 남기는가?\n코호트/특정세대의 특성: 그들만의 특성인가?\n\n\n\nAbraham Wald: “Where are the missing holes?”\n\nSource: War History Online\n\n\n\n\n\nExperimental study\n앞서 살펴본 관찰 연구들이 모두 confounding의 위험을 안고 있기에 결정적인 인과관계를 파악하기 위해, 전통적으로 “통계학”의 시각에서 인과문제에 대해서는 보통 임상테스트에서 실시하는 RCT (randomized controlled trial)라고 부르는 소위 gold standard한 실험 연구를 통해서 해결하고자 했음\n개념적으로는 물리적 통제라고 볼 수 있으며, 두 그룹으로 집단을 randomly assign(무선/무작위 배정/할당)하면 모든 면에서 동질한 성향을 가짐. 예를 들어, 두 집단의 연령이 평균적으로 동일해짐.\n\n\n\nSource: The whats and whys of RCTs\n\n\n\n\n앞서 든 예에서, 걷기가 사망율에 미치는 효과를 검증하려면, 가령 600명을 300명씩 두 그룹으로 무작위로 나눈 후 한쪽은 1마일 이하를 걷도록 하고 나머지는 2마일 이상을 걷게 한 후 12년 후 사망율을 확인해야 함.\n분야마다 효과를 제대로 검증하기 위한 많은 실험 설계들이 발전되었음 &gt;&gt; 연구방법론\n그럼에도 불구하고, 실험 연구는 자체로 한계를 지님\n\n많은 경우 실험이 불가능하거나 완전한 통제가 어려움\n실험에서 처치한 구체적인 상황에서만 유효하고; 어느 지형을 어느 속도로 누구와 어떻게 걸었는지에 대한 실험 통제하에서\n따라서 그 효과 또한 일반화되어 표현하기 어려움\n반대로, 덜 통제된 실험의 경우 어떤 요인의 효과인지 불분명\n완전한 통제를 할수록 더 인위적인 상황이 연출됨; 자연스러운/현실적인 상황에서 적용된다는 보장이 없음\n실험 참여자는 어떻게 왜 참여한 것인가?\n\n\n\nCase 1\nTerror Management Theory (TMT)\nSelf-esteem의 이론적 근거를 밝히고자 함. 왜 인간은 self-esteem을 유지하려는가?\n\nTreatment: 자신의 죽음과 고통에 대해 생각해보고 써보도록 하고\nControl: 자신의 치통에 대한 질문에 답\n측정: 고정관념에 대해 부정적으로 말하는 사람을 어떻게 평가하는가?\n결과: 그들을 더 부정적으로 평가: defences their own culural worldview\n(e.g. Stereotypes and Terror Management: Evidence That Mortality Salience Enhances Stereotypic Thinking and Preferences)\n\n죽음이나 치통에 대한 생각은 모두 두려움을 포함해 부정적 감정을 불러 일으키는데\n그저 두려움에 대한 반응인가? 아니면 정확히 “죽음에 대한 생각”이 효과를 만든 것인가?\n참여자들의 부정적 정서를 실험 마지막에 측정한 후 분석에 고려했음; covariate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n연구 설계시 관심이 있는 효과를 효과적으로 측정하는 것과 동등하게 중요한 것은 어떤 confounding들이 존재할 수 있는지를 다각도로 검토한 후 이를 설계에 반영하는 것임.\n예를 들어, 위의 경우 죽음에 대한 생각 자체의 효과가 아닌 죽음을 생각했을때 발생할 수 있는 부수적인 감정들로 인해 효과가 난 것이 아닌가하는 것들을 고려해서 설계할 수 있음.\n\n\n\n\nCase 2\n마시멜로우 실험, 1960’s\n\nSource: Want To Teach Your Kids Self-Control?\n3-5세 아이들에게 마시멜로우 1개를 놓고 원하면 먹도록 하나, 만약, 5분을 안먹고 기다리면 2개를 먹을 수 있다고 말한 후, 기다리지 못하고 먹는지를 살펴봄\n소위 delay gratification을 self-control을 발휘한 것으로 이해했으며, 먹지 않고 기다린 아이들이 추후에 학업성취도 및 여러면에서 뛰어난 결과를 보고 하였음.\n\n아이들이 참고 기다린 것은 자력에 의한 자기통제력인가?\n어른들 즉, 권위에 대한 복종인가?\n더 많이 먹기 위한 욕심인가?\n눈 앞에 이익을 빨리 취하는 것은 좋은 전략일 수 있지 않은가?\n제3의 common cause가 있을 수 있는가? 지능? 양육 스타일?\n\n혹시 실험을 진행하는 실험자에 따라 다른 효과가 나타날까? (Experimenter effects)\n처치(treatment)의 효과인가 처지가 일어나는 상황이 만든 효과인가?\n\n\n\n\n\n\nImportant\n\n\n\n이 연구에서도 여러 confounding들을 생각해볼 수 있음\n위에서 언급한 것들 외에 어떤 것들이 있을까?\n\n\n적어도 마시멜로우 실험의 경우에서 아이들에게 기다리라고 지시한 experimenter들의 정보를 고려할 필요가 있음.\n그럼, 각 experimenter별로 자료를 분석해야 하는가?\n좀 더 확장하면,\n\n같은 처방을 내린 의사들에 따라 다른 효과가 나타날까?\n\n의사가 속한 병원마다 다른 효과가 나타날까?\n\n특정 수업방식의 효과가 학교마다 선생님마다 다르게 나타날까?\n\n\n\n\n\n\n\nNote\n\n\n\nMulti-level analysis (mixed effect model)\n이는 위에서 언급한 longitudinal (종단) 데이터가 지닌 관측치의 dependency를 고려하는 일반적인 접근임. 관측치들이 군집을 이루면서 군집끼리 비슷한 경향을 보인다면, 이를 고려한 분석이 요구됨. 보통 dependency는 데이터를 어떻게 수집했는지를 알아야 파악할 수 있으며, 데이터 내에서 찾아내기 어려움. (clustering analysis 같은 machine learning 분야에서 개발되는 알고리즘적 분석들이 있음)\n만약, 군집을 이루는 단위가 충분히 많다면,\n예를 들어, 10개의 병원에서 30명의 의사가 각각 50명의 환자에게 새롭게 개발된 처방을 처치하여 그 효과를 볼 때,\n\n병원의 효과 vs. 의사의 효과 vs. 처치의 효과를 분리하여 좀 더 분명한 효과를 찾을 수 있음\n\n또는, 30개의 학교에서 50명의 선생님들이 30명의 학생들에게 특정 수업방식의 효과를 검증할 때,\n\n학교의 효과 vs. 선생님의 효과 vs. 수업의 효과를 분리해 볼 수 있음\n\n분석을 위해 각 선생님 마다 혹은 학교마다 따로 분석하는 것도 아니며, 학교별 혹은 선생님별 특성을 측정하여 고려한다든가 하는 방식이 아님. 자료가 품고 있는 관측치들의 유사성이 통계적으로 파악되어 고려되는 것으로, 모든 샘플을 동시에 이용한 고급 통계 방법\n사회과학 자료에서도 만일 가족단위로 데이터 수집이 이루어진다면, 가족 간의 무언가 톡특한 특성이 연구결과에 반영될 수 밖에 없는데, 가족의 특성을 분리해야 연구자가 살펴보는 관심 변수들 간의 관계를 올바로 파악할 수 있음. 다시 지적하면, 연구에서 가족의 특성을 직접 측정해서 고려한다는 의미가 아니고, 자료가 품고 있는 가족간의 유사성이 통계적으로 파악되어 고려되는 것임.\n\n\n\n\nCase 3\n상담치료 (dialectical behavior therapy)에 대한 효과 검증\n\nZeifman, R. J., Boritz, T., Barnhart, R., Labrish, C., & McMain, S. F. (2020). The independent roles of mindfulness and distress tolerance in treatment outcomes in dialectical behavior therapy skills training. Personality Disorders: Theory, Research, and Treatment, 11(3), 181.\n\n연구 절차\n\n연구 설계\n\n치료 효과에 대한 모형\n\n\n정말 DBT 치료의 효과인가?\n\n아무런 처지도 하지 않은 통제집단은 적절한가?\n\n매개변수의 효과(매커니즘)를 추론할 수 있는가?\n경계성 인격장애의 기준이 문제가 되지 않는가?\n\n경계성 인격 장애의 정도가 치료 효과에 영향을 미치지 않는가?\n이 연구결과는 어떤 대상으로 일반화될 수 있는가?\n\n20주를 다 채우지 않은 참여자들에 대해서 문제가 되는가?\n표본의 수가 충분한가?\n\n\n\nCase 4\n요양원의 노인들을 대상으로, 독립적 행동의 기회 증가가 그들의 정신 건강에 미치는 영향\n\nLanger, E. J., & Rodin, J. (1976). The effects of choice and enhanced personal responsibility for the aged: A field experiment in an institutional setting. Journal of Personality and Social Psychology, 34, 191–198.\n\n\n\n두 층의 노인들의 특성은 동일한가?\n\npretest에서 두 그룹 간의 특성이 유사한지에 대한 체크 문항: 모두 측정할 수는 없음!\n\n간호사 스탭들의 효과?\n\n두 층의 할당된 간호사들의 차이?\n스텝들 자신들도 변화된 요양원의 지침에 반응했는가? 또한 그 변화에 노인들도 반응했는가?\n\n두 층에서 동일하게 활동이나 환경의 변화가 일어났는가? 예, 간호사의 변경\n두 층의 노인들 간의 교류? 오염 요인\n구체적으로 어떤 요인이 효과를 낸 것인가?\n\n“treatment package”\n갑작스러운 변화 자체?\n\n이 요양원에 들어온 노인들의 특성이 있는가?\n\n사회경제적 수준이 높은 노인들의 경우 독립적 생활에 대한 더 긍정적 효과가 발현?\n다른 특성의 요양원의 노인들에게도 적용가능한가?\n\n\n\n\n\n\n\n\nNote\n\n\n\n설문(서베이)을 통한 실험연구도 온라인 서베이 툴이 발전함에 따라 용이해졌음.\n\n가령, 300명의 참여자들이 온라인 설문에 참여했을 때, 참여자의 1/3 각각에 대해 서로 다른 설문 세트 A, B, C가 무작위로 배정되도록 할 수 있으며,\n각 설문 세트에서도 인터랙티브하게 조건에 따라 다른 문항들에 노출되도록 할 수 있음.\n대표적인 서베이 툴: Qualtrics\n온라인 서베이 참여자 풀: M-turk, Prolific",
    "crumbs": [
      "Statistics",
      "Overview"
    ]
  },
  {
    "objectID": "contents/overview.html#uncertainty",
    "href": "contents/overview.html#uncertainty",
    "title": "Overview",
    "section": "Uncertainty",
    "text": "Uncertainty\n관찰자가 관찰한 대상으로부터 얻은 결과를 관찰하지 않은 더 넓은 대상으로 일반화할 수 있는가?\n가령, 다음과 같이 150명에 대해 조사한 “연령이 임금에 미치는 효과”를 일반화 할 수 있는가?\n한 나라의 국민 전체?\n\n\n\n\n\n\n\n\n\nStatistical inference (통계적 추론)\n통계학의 추론(statistical inference)은 작은 샘플(sample)로부터 얻은 분석 결과를 바탕으로 모집단(population)이라고 부르는 전체에 대해 말하고자 하는 시도에서 비롯되었음\n\n어떤 비료가 특정 콩 A의 재배에 어떤 영향을 미치는지 알기 위해 하나의 sample (N=10000: sampe size) 위에서 실험이 이루어지고, 그 결과가 A라는 콩의 종 전체에 얼마나 적용될 수 있을지를 알아보고자 했음\n\n사람에게도 적용될 수 있는가?\n\n사실상 난해한 통계 이론의 상당부분을 차지함.\n하지만, 통계적 추론의 논리는 개념적으로는 다음과 같이 볼 수 있음.\n앞서 논의한 모든 내용은 “특정 샘플” 내에서 변수들 간의 관계에 대한 분석일 뿐 그 샘플을 벗어나서 논의한 것이 아님. 통계적 추론은 수많은 같은 수의 샘플들, 가령 N = 150인 즉, 150명으로 이루어진 샘플들을 반복적으로 관찰한다면 그 샘플들 간의 편차들이 어떠하겠는가에 대한 논의임.\n\n첫번째 그림에서처럼 (알수는 없지만) 어떤 모집단(population)을 가정하는데, 그 모집단에는 남녀 간의 시간당 임금(wage)의 차이에 대한 true relationship이 존재한다고 가정함.\n연구자가 한번에 150명으로 이루어진 표본(sample)을 반복적으로 관찰한다면, 표본마다 남녀 간의 임금 격차는 다르게 나타날 것임 (두번째 그림).\n\n\n\n\n\n\n\n\nSource: The Truthful Art by Albert Cairo.\n\n\n\n\n\n\n\n샘플들로부터 나타나는 임금 차이 값의 분포를 살펴봄으로써 샘플에서 나타날 수 있는 남녀 간의 임금 차이가 어떠한가를 파악할 수 있음.\n\n이 분포를 sampling distribution(표본 분포)이라고 부름\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n이 분포에 따르면 평균이 $2.27이고, 임금 차이 값들의 95%가 $1.47 ~ $3.04 범위에 있음을 알 수 있음.\n다시말하면, 연구자가 관찰한 샘플로부터 연구자는 매우 큰 확신(95%)을 갖고 남녀의 시간당 임금의 차이는 1.47달러에서 3.04달러 사이에 있을 것이라고 말할 수 있음.\n\n\n비슷하게, 어떤 모집단에서 나이(age)와 시간당 임금(wage)의 true relationship이 선형적으로 존재한다고 가정했을 때,\n연구자가 한번에 150명으로 이루어진 sample을 반복적으로 관찰한다면, 샘플마다 age와 wage의 관계는 다르게 나타날 것임 (두번째 그림).\n\n예를 들어, 샘플들로부터 나타나는 기울기들의 분포를 살펴봄으로써 (세번째 그림) 샘플에서 나타날 수 있는 기울기값이 어떠한가를 파악할 수 있음.\n\n이 분포를 sampling distribution(표본 분포)이라고 부름\n이 분포에 따르면 평균이 0.092이고, 기울기 값들의 95%가 0.026 ~ 0.165 범위에 있음을 알 수 있음.\n다시말하면, 연구자가 관찰한 샘플로부터 연구자는 (age와 wage의 선형성을 가정한다면), 매우 큰 확신을 갖고 나이가 10세 늘때마다 시간당 임금의 증가율은 0.26에서 1.65달러 사이에 있을 것이라고 말할 수 있음.\n\n\n\n\n\n\n\n\nSource: The Truthful Art by Albert Cairo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap bca confidence intervals\n\n            Estimate 2.5 % 97.5 %\n(Intercept)    5.375 2.906  7.920\nage            0.092 0.026  0.165\n\n\n\n\n\n\n\n\nNote\n\n\n\n위와 같이 어떤 분포를 가정하고 파라미터(기울기 등등)를 포함해 상정한 모델에 대한 통계적 추정과 추론을 하는데 대한 비판이 오래전부터 있어왔음. 현실의 실제적 현상에 적용할 때는 이론적인 통계의 원리와는 별개의 더 깊은 논의가 필요함.\ne.g:\nBreiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. Basic books.",
    "crumbs": [
      "Statistics",
      "Overview"
    ]
  },
  {
    "objectID": "contents/overview.html#regression-analysis",
    "href": "contents/overview.html#regression-analysis",
    "title": "Overview",
    "section": "Regression analysis",
    "text": "Regression analysis\n앞서 다뤘던 임금과 연령의 관계에 대한 간단한 회귀 분석의 예들 \n\n선형 관계를 가정한 임금과 연령의 관계에 대한 회귀분석 (N=150)\n\n\n\n\n\n\n\n\n\n\nModel: lm(wage ~ age, data = cps)\n\n\n\nMODEL INFO:\nObservations: 150\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(1,148) = 8.755, p = 0.004\nR² = 0.056\nAdj. R² = 0.049 \nStandard errors:OLS\n----------------------------------------------------------\n                     Est.    2.5%   97.5%   t val.       p\n----------------- ------- ------- ------- -------- -------\n(Intercept)         5.375   2.970   7.780    4.417   0.000\nage                 0.092   0.031   0.154    2.959   0.004\n----------------------------------------------------------\n\n\n\n\n\n맨 처음 든 예, 즉 연령을 고려한/통제한 “기혼여부에 따른 임금차이”를 회귀분석하면 (N=465)\n\n\n\n\n\n\n\n\n\n\n우선, 결혼여부에 따른 평균 임금의 차이는 미혼일 때 -0.97 (dollars/hr) 낮음.\n하지만, 모집단에서 그 차이는 (95% 확률로) -1.93에서 -0.02 사이에 있을 것이라고 추정할 수 있음\nModel: lm(wage ~ married, data = cps)\n\n\n\nMODEL INFO:\nObservations: 533\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(1,531) = 8.34, p = 0.00\nR² = 0.02\nAdj. R² = 0.01 \nStandard errors:OLS\n-----------------------------------------------------------\n                       Est.    2.5%   97.5%   t val.      p\n------------------- ------- ------- ------- -------- ------\n(Intercept)            9.40    8.89    9.91    36.07   0.00\nmarriedSingle         -1.28   -2.16   -0.41    -2.89   0.00\n-----------------------------------------------------------\n\n\n\n\n\n\n\n\n\n앞서 논의한데로 나이가 confounding이 될 수 있고,\n이를 통계적으로 통제하면,\n\n\n\n\n\n\nModel: lm(wage ~ married + sex + age + I(age^2), data = cps)\n\n\n\nMODEL INFO:\nObservations: 533\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(4,528) = 23.70, p = 0.00\nR² = 0.15\nAdj. R² = 0.15 \nStandard errors:OLS\n------------------------------------------------------------\n                       Est.     2.5%   97.5%   t val.      p\n------------------- ------- -------- ------- -------- ------\n(Intercept)           -6.43   -10.87   -2.00    -2.85   0.00\nmarriedSingle         -0.17    -1.04    0.70    -0.38   0.70\nsexM                   2.44     1.67    3.22     6.18   0.00\nage                    0.68     0.46    0.91     5.95   0.00\nI(age^2)              -0.01    -0.01   -0.00    -5.26   0.00\n------------------------------------------------------------\n\n\n\n“나이를 고려했을 때”, 미혼이 기혼보다 그 임금이 0.17 (dollars/hr) 낮은데,\n모집단에서 그 차이는 -1.04 ~ 0.70 사이에 있을 확률이 매우 높은 것으로 추론됨. (95% 확률로)\n이는 사실상 임금 차이가 있다고 볼 확신을 거의 갖기 어려움\n결혼여부와 성별이 상호작용하는 것을 고려하고, 임금의 분포를 고려해서 log 변환하면,\nModel2: lm(log_wage ~ married * sex + age + I(age^2), data = cps)\n\n\n\nMODEL INFO:\nObservations: 530\nDependent Variable: log_wage\nType: OLS linear regression \nMODEL FIT:\nF(5,524) = 25.06, p = 0.00\nR² = 0.19\nAdj. R² = 0.19 \nStandard errors:OLS\n----------------------------------------------------------------\n                            Est.    2.5%   97.5%   t val.      p\n------------------------ ------- ------- ------- -------- ------\n(Intercept)                 0.23   -0.23    0.68     0.98   0.33\nmarriedSingle               0.07   -0.05    0.20     1.17   0.24\nsexM                        0.34    0.24    0.43     6.82   0.00\nage                         0.08    0.06    0.11     7.06   0.00\nI(age^2)                   -0.00   -0.00   -0.00    -6.45   0.00\nmarriedSingle:sexM         -0.21   -0.38   -0.05    -2.51   0.01\n----------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n나이와 임금의 관계가 위의 플랏에서 나타났듯이 35세부터 일정하게 유지되는 패턴을 보이므로 그 비선형성을 단순화하여 2차 함수 꼴\\((y=c+b\\cdot age+a\\cdot age^2)\\)로 모델링을 하였으나 원칙적으로는 다른 모형이 필요함",
    "crumbs": [
      "Statistics",
      "Overview"
    ]
  },
  {
    "objectID": "contents/setup.html",
    "href": "contents/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "R 다운로드 및 설치\n\nWindows인 경우: base 설치\nMac인 경우\n\nApple silicon\nolder Intel Macs\n\n\nRStudio 다운로드 및 설치",
    "crumbs": [
      "R tutorial",
      "Setup"
    ]
  },
  {
    "objectID": "contents/setup.html#r-및-rstudio-설치",
    "href": "contents/setup.html#r-및-rstudio-설치",
    "title": "환경설정",
    "section": "",
    "text": "R 다운로드 및 설치\n\nWindows인 경우: base 설치\nMac인 경우\n\nApple silicon\nolder Intel Macs\n\n\nRStudio 다운로드 및 설치",
    "crumbs": [
      "R tutorial",
      "Setup"
    ]
  },
  {
    "objectID": "contents/setup.html#rstudio-소개",
    "href": "contents/setup.html#rstudio-소개",
    "title": "환경설정",
    "section": "RStudio 소개",
    "text": "RStudio 소개\n4개의 패널로 구성\nProject 단위로 분석\n\n시작시 project을 새로 만들거나 불러와서 실행: filename.Rproj 형태로 저장\nFile &gt; New Project 또는 +박스그림 버튼 &gt; New Directory &gt; New Project\n\nDirectory name, Sub directory\n\n\nWorking directory\n\nproject에서 참조하는 최상위 폴더\n하위폴더 지시: 예) data/file.sav\n\nR script 생성, 저장\nRStudio 닫기, 열기\n\nWorkspace 저장 vs. R script 저장\nWorkspace save/load: .Rdata 형태로 저장\n\nSession\n\nRestart R\n\n\n환경설정: Tools &gt; Global Options\n“Save workspace to .RData on exit” 옵션: 종료시 working space 자동 저장\nCode\n\nsoft-wrap R source files\nUse native pipe operator\n\nAppearance\n\nZoom: 전체 보기 줌\nEdiotr font: Cascadia Mono (Win), Menlo (Mac)\nEditor font size: 글자 크기\nTheme: Tomorrow Night??",
    "crumbs": [
      "R tutorial",
      "Setup"
    ]
  },
  {
    "objectID": "contents/setup.html#패키지의-설치",
    "href": "contents/setup.html#패키지의-설치",
    "title": "환경설정",
    "section": "패키지의 설치",
    "text": "패키지의 설치\n\n# 메뉴를 통한 설치\n\n# 명령어를 통한 설치\ninstall.packages(\"name\")\n\n# 수업에서 필요한 기본 패키지\ninstall.packages(\"tidyverse\") # 패키지들의 패키지\n\n## ✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n## ✔ tibble  3.1.7     ✔ dplyr   1.0.9\n## ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n## ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n# 패키지들 간의 함수의 충돌에 대해서... mask\n\n# 추가 패키지\ninstall.packages(c(\"mosaicData\", \"palmerpenguins\")) # c(): combine items\n\n# 패키지 로드: 필요한 패키지는 세션마다 시행해야 함\nlibrary(\"name\")\n    e.g. library(tidyverse)",
    "crumbs": [
      "R tutorial",
      "Setup"
    ]
  },
  {
    "objectID": "contents/setup.html#단축키",
    "href": "contents/setup.html#단축키",
    "title": "환경설정",
    "section": "단축키",
    "text": "단축키\n\n자동완성: tab\n\n현재 라인 실행: Ctrl+Enter (Win)   |   Command+Return (Mac)\nassignment operator (&lt;-) 입력: Alt+- (Win)   |   Option+- (Mac)\npipe operator (%&gt;%) 입력: Ctrl+Shift+M (Win)   |   Shift+Command+M (Mac)\nconsol에서 화살표 키\ncopy, paste\nundo, redo: Ctrl+Z / Ctrl+Shift+Z (Win)   |   Command+Z / Command+Shift+Z (Mac)\nCopy Lines Up/Down: Shift+Alt+Up/Down (Win)   |   Option+Command+Up or Down (Mac)\n\n단축키 변경: Tools &gt;&gt; modify keyboard shortcuts: e.g. pipe operator: Alt+.",
    "crumbs": [
      "R tutorial",
      "Setup"
    ]
  },
  {
    "objectID": "contents/setup.html#도움말",
    "href": "contents/setup.html#도움말",
    "title": "환경설정",
    "section": "도움말",
    "text": "도움말\nhelp() 또는 ?\ne.g. help(factor), ?factor",
    "crumbs": [
      "R tutorial",
      "Setup"
    ]
  }
]