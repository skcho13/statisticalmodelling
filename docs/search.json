[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "CHA Stats in R",
    "section": "",
    "text": "Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\nDefinitions.\n“License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\n“Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\n“Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\n“You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License.\n“Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\n“Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\n“Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\n“Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\n“Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.”\n“Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\nGrant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.\nGrant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.\nRedistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n\nYou must give any other recipients of the Work or Derivative Works a copy of this License; and\nYou must cause any modified files to carry prominent notices stating that You changed the files; and\nYou must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\nIf the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\n\nYou may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\nSubmission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.\nTrademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.\nDisclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\nLimitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\nAccepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\nAPPENDIX: How to apply the Apache License to your work.\n  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\nCopyright [yyyy] [name of copyright owner]\nLicensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n   http://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  {
    "objectID": "contents/tidyverse.html",
    "href": "contents/tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "함수들: print(), glimpse(), summary(), count()\n() 안에 들어가는 것을 argument라고 부름\n\nlibrary(tidyverse)\n\ncps <- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\nprint(cps) # print 생략!\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n\n\n\n\n\nprint()\n\n\n\n강의 노트에서 print()를 쓰는 것은 jupyter notebook에서 data frame을 표시하는 방식때문이므로 무시하셔도 됩니다.\n\n\n보통 print()없이 데이터 프레임을 살펴보지만, print()을 이용하면, 표시되는 방식을 조정해서 볼 수 있음.\n\nprint(cps, n = 3) # 처음 3개 행\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1   9      10 W     M     NH       NS    Married    27 Not      43 const \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales \n# … with 531 more rows\n\n\n\n\n\n\n\n\ntip: print() 옵션\n\n\n\n\n\nprint(tibble, n = 10, width = Inf) # 10개의 rows와 모든 columns\n기본 셋팅을 변경하려면\noptions(tibble.print_min = 10, tibble.width = Inf)\nColumns/변수들이 많은 경우 화면에서 다음과 같이 축약되어 나오는데, 이를 다 보려면\nprint(nycflights13::flights) # nycflights13 패키지의 flights 데이터\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#   <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n# 1  2013     1     1      517         515       2     830     819      11 UA     \n# 2  2013     1     1      533         529       4     850     830      20 UA     \n# 3  2013     1     1      542         540       2     923     850      33 AA     \n# 4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n# 5  2013     1     1      554         600      -6     812     837     -25 DL     \n# 6  2013     1     1      554         558      -4     740     728      12 UA     \n# # … with 336,770 more rows, 9 more variables: flight <int>, tailnum <chr>,\n# #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n# #   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n# #   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nprint(nycflights13::flights, n = 3, width = Inf) # 가로 열의 개수: Inf (모든 열)\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n# 1  2013     1     1      517            515         2      830            819\n# 2  2013     1     1      533            529         4      850            830\n# 3  2013     1     1      542            540         2      923            850\n#   arr_delay carrier flight tailnum origin dest  air_time distance  hour minute\n#       <dbl> <chr>    <int> <chr>   <chr>  <chr>    <dbl>    <dbl> <dbl>  <dbl>\n# 1        11 UA        1545 N14228  EWR    IAH        227     1400     5     15\n# 2        20 UA        1714 N24211  LGA    IAH        227     1416     5     29\n# 3        33 AA        1141 N619AA  JFK    MIA        160     1089     5     40\n#   time_hour          \n#   <dttm>             \n# 1 2013-01-01 05:00:00\n# 2 2013-01-01 05:00:00\n# 3 2013-01-01 05:00:00\n# # … with 336,773 more rows\n\n\n\n많은 변수들을 간략히 보는 방법으로는 glimpse()\n\nglimpse(cps)\n\nRows: 534\nColumns: 11\n$ wage     <dbl> 9.00, 5.50, 3.80, 10.50, 15.00, 9.00, 9.57, 15.00, 11.00, 5.0…\n$ educ     <int> 10, 12, 12, 12, 12, 16, 12, 14, 8, 12, 17, 17, 14, 14, 12, 14…\n$ race     <fct> W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, NW, NW, W,…\n$ sex      <fct> M, M, F, F, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F…\n$ hispanic <fct> NH, NH, NH, NH, NH, NH, NH, NH, NH, NH, Hisp, NH, Hisp, NH, N…\n$ south    <fct> NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, N…\n$ married  <fct> Married, Married, Single, Married, Married, Married, Married,…\n$ exper    <int> 27, 20, 4, 29, 40, 27, 5, 22, 42, 14, 18, 3, 4, 14, 35, 0, 7,…\n$ union    <fct> Not, Not, Not, Not, Union, Not, Union, Not, Not, Not, Not, No…\n$ age      <int> 43, 38, 22, 47, 58, 49, 23, 42, 56, 32, 41, 26, 24, 34, 53, 2…\n$ sector   <fct> const, sales, sales, clerical, const, clerical, service, sale…\n\n\n\n\n\n\n\n\nTip\n\n\n\n엑셀 스프레드시트처럼 보는 방법은\nEnvironment 패널에 보이는 cps 데이터셋 맨 끝에 네모난 마크를 클릭하거나,\nview(cps)\n\n\n변수들에 대한 통계치 요약 summary()\n\nsummary(cps)\n\n      wage             educ       race     sex     hispanic   south   \n Min.   : 1.000   Min.   : 2.00   NW: 67   F:245   Hisp: 27   NS:378  \n 1st Qu.: 5.250   1st Qu.:12.00   W :467   M:289   NH  :507   S :156  \n Median : 7.780   Median :12.00                                       \n Mean   : 9.024   Mean   :13.02                                       \n 3rd Qu.:11.250   3rd Qu.:15.00                                       \n Max.   :44.500   Max.   :18.00                                       \n                                                                      \n    married        exper         union          age             sector   \n Married:350   Min.   : 0.00   Not  :438   Min.   :18.00   prof    :105  \n Single :184   1st Qu.: 8.00   Union: 96   1st Qu.:28.00   clerical: 97  \n               Median :15.00               Median :35.00   service : 83  \n               Mean   :17.82               Mean   :36.83   manuf   : 68  \n               3rd Qu.:26.00               3rd Qu.:44.00   other   : 68  \n               Max.   :55.00               Max.   :64.00   manag   : 55  \n                                                           (Other) : 58  \n\n\n카테고리별 개수를 세주는 count()\nNumber(수)에 대해서도 적용 가능: ex. educ 수준 2, 3, … 18 각각에 대해서\n\ncps |>  # pipe operator: alt + . (option + .)\n    count(sector) |>\n    print() # 생략해도 됨\n\n# A tibble: 8 × 2\n  sector       n\n  <fct>    <int>\n1 clerical    97\n2 const       20\n3 manag       55\n4 manuf       68\n5 other       68\n6 prof       105\n7 sales       38\n8 service     83\n\n\n\ncps |>\n    count(sex, married) |>\n    print()\n\n# A tibble: 4 × 3\n  sex   married     n\n  <fct> <fct>   <int>\n1 F     Married   162\n2 F     Single     83\n3 M     Married   188\n4 M     Single    101\n\n\n\n\n\n\n\n\nPipe operator\n\n\n\n|> 또는 %>% (’then’의 의미로…)\nx |> f(y) # f(x, y),\nx |> f(y) |> g(z) # g(f(x, y), z)\nsummary(cps) 는 다음과 같음\ncps |>\n    summary()\ncount(cps, sector)는 다음과 같음\ncps |> \n    count(sector)"
  },
  {
    "objectID": "contents/tidyverse.html#rows",
    "href": "contents/tidyverse.html#rows",
    "title": "Tidyverse",
    "section": "Rows",
    "text": "Rows\n행에 적용되는 함수들\nfilter(), arrange(), distinct()\n\nfilter()\n조건에 맞는 행을 선택\n\nConditional operators:\n>, >=, <, <=, == (equal to), != (not equal to)\n& (and) | (or)\n! (not)\n%in% (includes)\n\n\n# 임금(wage)가 10이상인 사람들\ncps |>\n    filter(wage >= 10) |>\n    print()\n\n# A tibble: 184 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  15      12 W     M     NH       NS    Married    40 Union    58 const   \n3  15      14 W     M     NH       NS    Single     22 Not      42 sales   \n4  11       8 W     M     NH       NS    Married    42 Not      56 manuf   \n5  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof    \n6  20.4    17 W     M     NH       NS    Single      3 Not      26 prof    \n# … with 178 more rows\n\n\n\n# 임금(wage)가 10이상이고 여성(F)들\ncps |>\n    filter(wage >= 10 & sex == \"F\") |>\n    print()\n\n# A tibble: 62 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  11.2    17 NW    F     NH       NS    Married    32 Not      55 clerical\n3  25.0    17 W     F     NH       NS    Single      5 Not      28 prof    \n4  12.6    17 W     F     NH       NS    Married    13 Not      36 manag   \n5  11.7    16 W     F     NH       NS    Single     42 Not      64 clerical\n6  12.5    15 W     F     NH       NS    Married     6 Not      27 clerical\n# … with 56 more rows\n\n\n\n# 간부급(management)과 전문직(professional)에 종사하는 사람들\ncps |>\n    filter(sector == \"manag\" | sector == \"prof\") |>\n    print()\n\n# A tibble: 160 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# … with 154 more rows\n\n\n다음과 같이 편리하게 %in%을 이용하여 여러 항목을 포함하는, 즉 |와 ==를 합친 조건문을 생성\n즉, include인지 판별\n\n# A shorter way to select sectors for management or professional\ncps |>\n    filter(sector %in% c(\"manag\", \"prof\")) |>\n    print()\n\n# A tibble: 160 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# … with 154 more rows\n\n\n\n\n\n\n\n\nImportant\n\n\n\nfilter()로 얻은 데이터 프레임은 원래 데이터 프레임을 수정하는 것이 아니므로 계속 사용하려면 저장해야 함\n이후 모든 함수들에 대해서도 마찬가지\nprestige <- cps |>\n    filter(sector %in% c(\"manag\", \"prof\"))\n\nprestige\n#    wage  educ race  sex   hispanic south married exper union   age sector\n#   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n# 1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n# 2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n# 3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n# ...\n\n\n\n\n\n\n\n\nTip\n\n\n\n잦은 실수들\ncps |>\n    filter(sex = \"F\") # \"==\" vs. \"=\"\ncps |>\n    filter(sector == \"manage\" | \"prof\") # | 전후 모두 완결된 조건문 필요\n\n\n\n\narrange()\nColumn의 값을 기준으로 row를 정렬\n\n# 교육정도(educ)와 임금(wage)에 따라 오름차순으로 정렬\ncps |>\n    arrange(educ, wage) |>\n    print(n = 10)\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector \n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>  \n 1  3.75     2 W     M     Hisp     NS    Single     16 Not      24 service\n 2  7        3 W     M     Hisp     S     Married    55 Not      64 manuf  \n 3  6        4 W     M     NH       NS    Married    54 Not      64 service\n 4 14        5 W     M     NH       S     Married    44 Not      55 const  \n 5  3        6 W     F     Hisp     NS    Married    43 Union    55 manuf  \n 6  4.62     6 NW    F     NH       S     Single     33 Not      45 manuf  \n 7  5.75     6 W     M     NH       S     Married    45 Not      57 manuf  \n 8  3.35     7 W     M     NH       S     Married    43 Not      56 manuf  \n 9  4.5      7 W     M     Hisp     S     Married    14 Not      27 service\n10  6        7 W     F     NH       S     Married    15 Not      28 manuf  \n# … with 524 more rows\n\n\ndesc()을 이용하면 내림차순으로 정렬\n\n# educ을 내림차순으로 정렬\ncps |>\n    arrange(desc(educ)) |>\n    print(n = 10)\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector\n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n 1 15       18 W     M     NH       NS    Married    12 Not      36 prof  \n 2 14.0     18 W     F     NH       NS    Married    14 Not      38 manag \n 3 13.5     18 W     M     NH       NS    Married    14 Union    38 prof  \n 4 20       18 W     F     NH       NS    Married    19 Not      43 manag \n 5  7       18 W     M     NH       NS    Married    33 Not      57 prof  \n 6 11.2     18 W     M     NH       NS    Married    19 Not      43 prof  \n 7  5.71    18 W     M     NH       NS    Married     3 Not      27 prof  \n 8 18       18 W     M     NH       NS    Married    15 Not      39 prof  \n 9 19       18 W     M     NH       NS    Single     13 Not      37 manag \n10 22.8     18 W     F     NH       NS    Single     37 Not      61 prof  \n# … with 524 more rows\n\n\narrange()와 filter()를 함께 사용하여 좀 더 복잡한 문제를 해결할 수 있음\n\n# 높은 지위의 섹터에서 일하는 사람들 중 임금이 상위에 있는 사람들\ncps |>\n    filter(sector == \"manage\" | sector == \"prof\") |>\n    arrange(desc(wage)) |>\n    print()\n\n# A tibble: 105 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n3  25.0    17 W     M     NH       NS    Married    31 Not      54 prof  \n4  25.0    16 W     F     NH       S     Single      5 Not      27 prof  \n5  23.2    17 NW    F     NH       NS    Married    25 Union    48 prof  \n6  22.8    18 W     F     NH       NS    Single     37 Not      61 prof  \n# … with 99 more rows\n\n\n\n\ndistinct()**\n유티크한 조합들을 리스트\n\ncps |>\n    distinct(sector, sex) |>\n    print()\n\n# A tibble: 15 × 2\n   sector   sex  \n   <fct>    <fct>\n 1 const    M    \n 2 sales    M    \n 3 sales    F    \n 4 clerical F    \n 5 service  F    \n 6 manuf    M    \n 7 prof     M    \n 8 service  M    \n 9 other    M    \n10 clerical M    \n11 manag    M    \n12 prof     F    \n13 manag    F    \n14 manuf    F    \n15 other    F"
  },
  {
    "objectID": "contents/tidyverse.html#columns",
    "href": "contents/tidyverse.html#columns",
    "title": "Tidyverse",
    "section": "Columns",
    "text": "Columns\n열에 적용되는 함수들\nmutate(), select(), rename()\n\nmutate()\nColumns/변수들로부터 값을 계산하여 새로운 변수를 만듦\n\ntips <- as_tibble(reshape::tips) # reshpae 패키지 안에 tips 데이터셋\ntips |> print()\n\n# A tibble: 244 × 7\n  total_bill   tip sex    smoker day   time    size\n       <dbl> <dbl> <fct>  <fct>  <fct> <fct>  <int>\n1       17.0  1.01 Female No     Sun   Dinner     2\n2       10.3  1.66 Male   No     Sun   Dinner     3\n3       21.0  3.5  Male   No     Sun   Dinner     3\n4       23.7  3.31 Male   No     Sun   Dinner     2\n5       24.6  3.61 Female No     Sun   Dinner     4\n6       25.3  4.71 Male   No     Sun   Dinner     4\n# … with 238 more rows\n\n\n\ntips |>\n    mutate(\n        tip_pct = tip / total_bill * 100,\n        tip_pct_per = tip_pct / size\n    ) |>\n    print()\n\n# A tibble: 244 × 9\n  total_bill   tip sex    smoker day   time    size tip_pct tip_pct_per\n       <dbl> <dbl> <fct>  <fct>  <fct> <fct>  <int>   <dbl>       <dbl>\n1       17.0  1.01 Female No     Sun   Dinner     2    5.94        2.97\n2       10.3  1.66 Male   No     Sun   Dinner     3   16.1         5.35\n3       21.0  3.5  Male   No     Sun   Dinner     3   16.7         5.55\n4       23.7  3.31 Male   No     Sun   Dinner     2   14.0         6.99\n5       24.6  3.61 Female No     Sun   Dinner     4   14.7         3.67\n6       25.3  4.71 Male   No     Sun   Dinner     4   18.6         4.66\n# … with 238 more rows\n\n\n\n\nselect()\nColumns/변수를 선택\n\ntips |>\n    select(total_bill, tip, day, time) |>\n    print()\n\n# A tibble: 244 × 4\n  total_bill   tip day   time  \n       <dbl> <dbl> <fct> <fct> \n1       17.0  1.01 Sun   Dinner\n2       10.3  1.66 Sun   Dinner\n3       21.0  3.5  Sun   Dinner\n4       23.7  3.31 Sun   Dinner\n5       24.6  3.61 Sun   Dinner\n6       25.3  4.71 Sun   Dinner\n# … with 238 more rows\n\n\n\n# tip에서 smoker까지, 그리고 size columns 선택\ntips |>\n    select(tip:smoker, size) |>  # select(2:4, 7)처럼 number로 선택가능\n    print()\n\n# A tibble: 244 × 4\n    tip sex    smoker  size\n  <dbl> <fct>  <fct>  <int>\n1  1.01 Female No         2\n2  1.66 Male   No         3\n3  3.5  Male   No         3\n4  3.31 Male   No         2\n5  3.61 Female No         4\n6  4.71 Male   No         4\n# … with 238 more rows\n\n\n\n# sex에서 day까지 columns은 제외하고\ntips |>\n    select(!sex:day) |> # !: not\n    print()\n\n# A tibble: 244 × 4\n  total_bill   tip time    size\n       <dbl> <dbl> <fct>  <int>\n1       17.0  1.01 Dinner     2\n2       10.3  1.66 Dinner     3\n3       21.0  3.5  Dinner     3\n4       23.7  3.31 Dinner     2\n5       24.6  3.61 Dinner     4\n6       25.3  4.71 Dinner     4\n# … with 238 more rows\n\n\n\n# factor 타입의 변수들만 선택: 함수를 이용\ntips |>\n    select(where(is.factor)) |>  # 다른 함수들: is.numeric, is.character\n    print()\n\n# A tibble: 244 × 4\n  sex    smoker day   time  \n  <fct>  <fct>  <fct> <fct> \n1 Female No     Sun   Dinner\n2 Male   No     Sun   Dinner\n3 Male   No     Sun   Dinner\n4 Male   No     Sun   Dinner\n5 Female No     Sun   Dinner\n6 Male   No     Sun   Dinner\n# … with 238 more rows\n\n\n다양한 select()의 선택방법은 ?select로 help참고\n예를 들어, starts_with(\"abc\")는 abc로 시작하는 열의 이름을 가진 열들\n\n\n\n\n\n\nNote\n\n\n\nBase R에서 행과 열의 선택과 비교하면,\ncps[2:5, c(\"wage\", \"married\")] # 2~5행과 wage, married열\n# # A tibble: 4 × 2\n#    wage married\n#   <dbl> <fct>  \n# 1   5.5 Married\n# 2   3.8 Single \n# 3  10.5 Married\n# 4  15   Married\n\ncps |> \n    select(wage, married) |> \n    slice(2:5) # 행을 선택\n\n\n\n\nrename()\nColumns의 이름을 변경\n\ncps |>\n    rename(education = educ, marital = married) |> # new = old\n    print()\n\n# A tibble: 534 × 11\n   wage education race  sex   hispanic south marital exper union   age sector  \n  <dbl>     <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9          10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5        12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8        12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5        12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15          12 W     M     NH       NS    Married    40 Union    58 const   \n6   9          16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n변수를 select할 때 동시에 이름도 바꿀 수 있음\n\ncps |>\n    select(education = educ, marital = married) |> # new = old\n    print()\n\n# A tibble: 534 × 2\n  education marital\n      <int> <fct>  \n1        10 Married\n2        12 Married\n3        12 Single \n4        12 Married\n5        12 Married\n6        16 Married\n# … with 528 more rows"
  },
  {
    "objectID": "contents/tidyverse.html#groups",
    "href": "contents/tidyverse.html#groups",
    "title": "Tidyverse",
    "section": "Groups",
    "text": "Groups\n분석에서는 자주 카테고리별로 데이터를 나누어 통계치를 계산하곤 하는데,\ngroup_by()와 summarise()의 두 함수를 함께 사용하여 가장 자주 사용하게 됨\n\ngroup_by()\n데이터셋을 분석을 위해 의미있는 그룹으로 나눔\n다음은 성별로 데이터셋을 나눈 것인데, 실제 데이터를 수정하는 것은 아니고, 내부적으로 grouping되어 있음.\n맨 위 줄에 보면 Groups:  sex [2]로 표시되어 grouped data frame임을 명시함\n\ncps |>\n    group_by(sex) |> \n    print()\n\n# A tibble: 534 × 11\n# Groups:   sex [2]\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n\nsummarise()\nsummarize()와 동일\ngroup별로 통계치를 구해 하나의 행으로 산출\n\n# 남녀별로 임금의 평균을 구함\ncps |>\n    group_by(sex) |>\n    summarise(\n        avg_wage = mean(wage, na.rm = TRUE),  # mean(): 평균, na.rm: NA를 remove할 것인가\n        n = n()  # n(): 개수\n    ) |>\n    print()\n\n# A tibble: 2 × 3\n  sex   avg_wage     n\n  <fct>    <dbl> <int>\n1 F         7.88   245\n2 M         9.99   289\n\n\n2개 이상의 변수들로 grouping할 수 있음\n\ncps |>\n    group_by(sex, married) |>\n    summarize(\n        ave_wage = mean(wage),\n        sd_wage = sd(wage)) |>\n    print()\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 × 4\n# Groups:   sex [2]\n  sex   married ave_wage sd_wage\n  <fct> <fct>      <dbl>   <dbl>\n1 F     Married     7.68    3.73\n2 F     Single      8.26    6.23\n3 M     Married    10.9     5.35\n4 M     Single      8.35    4.78\n\n\n이때, 결과 데이터 프레임은 sex로 grouping되어 있음.\ngrouping을 해제하려면 ungroup()이 필요함.\n그렇지 않으면, 저 결과는 sex로 grouped data frame임\n\nUseful summary functions\n자세한 사항은 R for Data Science/Data transformation\n\nMeasures of location: mean(), median()\nMeasures of spread: sd(), IQR(), mad()\nMeasures of rank: min(), max(), quantile(x, 0.25)\nMeasures of position: min_rank(), first(), nth(x, 2), last()\nMeasures of count: count(), n_distinct()"
  },
  {
    "objectID": "contents/tidyverse.html#missing",
    "href": "contents/tidyverse.html#missing",
    "title": "Tidyverse",
    "section": "Missing",
    "text": "Missing\nR에서 missing values (결측치)는 NA로 표시\nNaN (not a number)는 주로 계산 결과로 나오는데, 예들 들어 0으로 나눌 때처럼, R에서는 NA로 취급되니 크게 신경쓰지 않아도 됨. 자세한 사항은 R for Data Science/Missing values 참고\nNA는 다음과 같은 성질을 지님\nNA > 5\n#> [1] NA\n10 == NA\n#> [1] NA\nNA + 10\n#> [1] NA\nNA / 2\n#> [1] NA\nNA == NA\n#> [1] NA\n\nx <- NA\nis.na(x)\n#> [1] TRUE\nNA는 filter()는 조건문의 참거짓에 상관없이 모두 제외함 - 실제로 조건문의 결과는 TRUE, FALSE로 이루어지짐\ndf <- tibble(one = c(1, NA, 3, 4, 2, NA), two = c(2, 5, 3, NA, 10, NA), three = c(\"a\", \"a\", \"a\", \"a\", \"b\", \"b\"))\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1     1     2 a    \n# 2    NA     5 a    \n# 3     3     3 a    \n# 4     4    NA a    \n# 5     2    10 b    \n# 6    NA    NA b    \n\nfilter(df, one > 1)\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1     3     3 a    \n# 2     4    NA a    \n# 3     2    10 b\n\n# NA를 포함하고자 할 때,\nfilter(df, one > 1 | is.na(one))\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1    NA     5 a    \n# 2     3     3 a    \n# 3     4    NA a    \n# 4     2    10 b    \n# 5    NA    NA b\n\n# NA를 포함하지 않은 행들만\nfilter(df, !is.na(one))\nfilter(df, !is.na(one) & !is.na(two)) # one, two 열에 모두 NA가 없는 행들만\n\nna.omit(df) # NA가 하나라도 있는 행은 모두 제거, 보통 결측치를 조심스럽게 대체한 후 사용\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1     1     2 a    \n# 2     3     3 a    \n# 3     2    10 b \n\n# 함수 중에 NA를 직접 처리하는 경우들이 많음\nmean(df$one)\n## [1] NA\n\nmean(df$one, na.rm = TRUE) # NA removed\n## [1] 2.5\nna.rm = TRUE로 얻은 계산값에서 몇 개의 데이터로 계산되었는지 알기 위해서는\ndf |> \n    group_by(three) |> \n    summarise(\n        ave = mean(two, na.rm = TRUE), \n        n = n(), \n        n_notna = sum(!is.na(two))  # TRUE는 1로, FALSE는 0으로 계산됨\n    )\n#   three   ave     n n_notna\n#   <chr> <dbl> <int>   <int>\n# 1 a      3.33     4       3\n# 2 b     10        2       1"
  },
  {
    "objectID": "contents/tidyverse.html#summary",
    "href": "contents/tidyverse.html#summary",
    "title": "Tidyverse",
    "section": "Summary",
    "text": "Summary\n다음 dplyr 패키지의 기본 verb 함수들로 데이터를 가공하면서 필요한 통계치를 구함\n\n조건에 맞는 행들(관측치)만 필터링: filter()\n열을 재정렬: arrange()\n변수들의 선택: select()\n변수들과 함수들을 이용하여 새로운 변수를 생성: mutate()\n원하는 요약 통계치를 간추림: summarise()"
  },
  {
    "objectID": "contents/import.html",
    "href": "contents/import.html",
    "title": "Import",
    "section": "",
    "text": "자세한 데이터 import에 대해서는 링크"
  },
  {
    "objectID": "contents/import.html#text-files-csv",
    "href": "contents/import.html#text-files-csv",
    "title": "Import",
    "section": "Text files: csv",
    "text": "Text files: csv\nreadr 패키지(tidyverse에 포함)\nread_csv(), write_csv()\n\nR 기본 함수 read.csv()를 개선\n다양한 옵션은 ?read_csv, ?write_csv 참고\n\n\ncsv 파일 읽기\naltruism.csv 파일 링크\n\nlibrary(tidyverse)\n\nhelping <- read_csv(\"data/altruism.csv\")\nhelping |> print()\n\n# A tibble: 120 × 12\n      id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1   250    95    95    95     1  2004      80      NA      80      80      70\n 2    32    58    62    NA     0  2003      62      58      59      57      56\n 3   109   100    50    50    NA  2003      90      51      51      51      52\n 4   209    77    77    64     1  2004      66      72      88      82      67\n 5    94    77    50    77     1  2003     100     100     100      51      78\n 6   260   100    75   100     0  2004     100      60      70      55      70\n 7   258    77    94    86     1  2004      91      93      85      91      73\n 8   244    90    68    20     0  2004      67      66      31      67      63\n 9   180   100    79    77     0  2003      61      51      30      51      51\n10   182    75    50    64     1  2003      80      80      70      65      70\n# … with 110 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n\n\n\n\n\n\nNote\n\n\n\nread_csv()의 자주 사용되는 옵션\nread_csv(\"data/file.csv\", skip = 2) # 첫 2절 스킵\nread_csv(\"data/file.csv\", na = \".\") # 결측치가 .으로 기록된 파일\n\n\n\n\ncsv 파일 쓰기\nwrite_csv(): 단, 쓰기를 하면서 변수 타입 소멸\n\nwrite_csv(helping, file=\"data/helping_new.csv\")"
  },
  {
    "objectID": "contents/import.html#excel-spreadsheets",
    "href": "contents/import.html#excel-spreadsheets",
    "title": "Import",
    "section": "Excel spreadsheets",
    "text": "Excel spreadsheets\nreadxl package\nread_excel(), read_xlsx(), read_xls()\n\n엑셀 파일 읽기\nstduents.xlsx 파일 링크\n\nlibrary(readxl) # install.packages(\"readxl\")\n\nstud <- read_xlsx(\"data/students.xlsx\")\nstud |> print()\n\n# A tibble: 1,000 × 93\n  stu_id sch_id sstratid   sex  race ethnic bys42a bys42b bys44a bys44b bys44c\n   <dbl>  <dbl>    <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 124966   1249        1     2     4      1      3      4      2      4      4\n2 124972   1249        1     1     4      1      4      5      1      3      3\n3 175551   1755        1     2     3      0     NA      3      2      3      3\n4 180660   1806        1     1     4      1      2     NA      1      4      4\n5 180672   1806        1     2     4      1      2      3      1      4      3\n6 298885   2988        2     1     3      0      5      4      2      3      3\n# … with 994 more rows, and 82 more variables: bys44d <dbl>, bys44e <dbl>,\n#   bys44f <dbl>, bys44g <dbl>, bys44h <dbl>, bys44i <dbl>, bys44j <dbl>,\n#   bys44k <dbl>, bys44l <dbl>, bys44m <dbl>, bys48a <dbl>, bys48b <dbl>,\n#   bys79a <dbl>, byfamsiz <dbl>, famcomp <dbl>, bygrads <dbl>, byses <dbl>,\n#   byfaminc <dbl>, parocc <dbl>, bytxrstd <dbl>, bytxmstd <dbl>,\n#   bytxsstd <dbl>, bytxhstd <dbl>, bypared <dbl>, bytests <dbl>,\n#   par_inv <dbl>, f1s36a1 <dbl>, f1s36a2 <dbl>, f1s36b1 <dbl>, …\n\n\n\n\n\n\n\n\nNote\n\n\n\nSpecify sheet either by position or by name\nread_excel(\"salaries.xlsx\", sheet = 2) # The default is sheet = 1\nread_excel(\"salaries.xlsx\", sheet = \"personnel\")"
  },
  {
    "objectID": "contents/import.html#statistical-packages",
    "href": "contents/import.html#statistical-packages",
    "title": "Import",
    "section": "Statistical packages",
    "text": "Statistical packages\nSPSS의 데이터: read_sav()\nstudents-shorter.sav 파일 링크\n\nlibrary(haven) # install.packages(\"haven\")\n\nstud_spss <- read_sav(\"data/students-shorter.sav\")\nstud_spss |> print()\n\n# A tibble: 1,000 × 93\n  stu_id    sch_id    sstratid sex     race    ethnic  bys42a   bys42b   bys44a \n  <dbl+lbl> <dbl+lbl> <dbl+lb> <dbl+l> <dbl+l> <dbl+l> <dbl+lb> <dbl+lb> <dbl+l>\n1 124966    1249      1        2 [Fem… 4 [Whi… 1 [whi…  3 [2-3…  4 [3-4… 2 [Agr…\n2 124972    1249      1        1 [Mal… 4 [Whi… 1 [whi…  4 [3-4…  5 [4-5… 1 [Str…\n3 175551    1755      1        2 [Fem… 3 [Bla… 0 [blk… NA        3 [2-3… 2 [Agr…\n4 180660    1806      1        1 [Mal… 4 [Whi… 1 [whi…  2 [1-2… NA       1 [Str…\n5 180672    1806      1        2 [Fem… 4 [Whi… 1 [whi…  2 [1-2…  3 [2-3… 1 [Str…\n6 298885    2988      2        1 [Mal… 3 [Bla… 0 [blk…  5 [4-5…  4 [3-4… 2 [Agr…\n# … with 994 more rows, and 84 more variables: bys44b <dbl+lbl>,\n#   bys44c <dbl+lbl>, bys44d <dbl+lbl>, bys44e <dbl+lbl>, bys44f <dbl+lbl>,\n#   bys44g <dbl+lbl>, bys44h <dbl+lbl>, bys44i <dbl+lbl>, bys44j <dbl+lbl>,\n#   bys44k <dbl+lbl>, bys44l <dbl+lbl>, bys44m <dbl+lbl>, bys48a <dbl+lbl>,\n#   bys48b <dbl+lbl>, bys79a <dbl+lbl>, byfamsiz <dbl+lbl>, famcomp <dbl+lbl>,\n#   bygrads <dbl+lbl>, byses <dbl+lbl>, byfaminc <dbl+lbl>, parocc <dbl>,\n#   bytxrstd <dbl+lbl>, bytxmstd <dbl+lbl>, bytxsstd <dbl+lbl>, …\n\n\n\nstud_spss |>\n    select(ethnic) |>\n    print()\n\n# A tibble: 1,000 × 1\n  ethnic            \n  <dbl+lbl>         \n1 1 [white-asian]   \n2 1 [white-asian]   \n3 0 [blk,namer,hisp]\n4 1 [white-asian]   \n5 1 [white-asian]   \n6 0 [blk,namer,hisp]\n# … with 994 more rows\n\n\nLabels 제거하기\n\nlibrary(labelled) # install.packages(\"labelled\")\nstud <- stud_spss |>\n    remove_val_labels()\nstud |> print()\n\n# A tibble: 1,000 × 93\n  stu_id sch_id sstratid   sex  race ethnic bys42a bys42b bys44a bys44b bys44c\n   <dbl>  <dbl>    <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 124966   1249        1     2     4      1      3      4      2      4      4\n2 124972   1249        1     1     4      1      4      5      1      3      3\n3 175551   1755        1     2     3      0     NA      3      2      3      3\n4 180660   1806        1     1     4      1      2     NA      1      4      4\n5 180672   1806        1     2     4      1      2      3      1      4      3\n6 298885   2988        2     1     3      0      5      4      2      3      3\n# … with 994 more rows, and 82 more variables: bys44d <dbl>, bys44e <dbl>,\n#   bys44f <dbl>, bys44g <dbl>, bys44h <dbl>, bys44i <dbl>, bys44j <dbl>,\n#   bys44k <dbl>, bys44l <dbl>, bys44m <dbl>, bys48a <dbl>, bys48b <dbl>,\n#   bys79a <dbl>, byfamsiz <dbl>, famcomp <dbl>, bygrads <dbl>, byses <dbl>,\n#   byfaminc <dbl>, parocc <dbl>, bytxrstd <dbl>, bytxmstd <dbl>,\n#   bytxsstd <dbl>, bytxhstd <dbl>, bypared <dbl>, bytests <dbl>,\n#   par_inv <dbl>, f1s36a1 <dbl>, f1s36a2 <dbl>, f1s36b1 <dbl>, …"
  },
  {
    "objectID": "contents/cleaning.html",
    "href": "contents/cleaning.html",
    "title": "Cleaning",
    "section": "",
    "text": "select(), mutate(), filter(), rename() : 기본 tidyverse verbs\n\nrowSums(), rowMeans() : composite 변수들의 합 또는 평균을 구함\n\nfactor() : 카테고리 변수의 변환\n\n\nlibrary(tidyverse)\n\n# import data\nhelping <- read_csv(\"data/altruism.csv\")\nhelping |> print()\n\n# A tibble: 120 × 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# … with 114 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n\n\nrename()\n\nhelping |>\n    rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3) |>\n    print()\n\n# A tibble: 120 × 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# … with 114 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n변형 후에는 꼭 변수에 assign!\n\nhelping <-     # 원래 데이터에 overwrite\n    helping |>\n    rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3)\n\nhelping |> print()\n\n# A tibble: 120 × 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# … with 114 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n\n\n\nrowSums(row, na.rm = TRUE) 함수를 이용하는 것이 직접 덧셈보다 더 적절함\nph1, ph2, ph3 세 문항을 더하려면,\n\n# 먼저 문항을 선택/확인\nhelping |>\n  select(ph1:ph3) |> # position!\n  print()\n\n# A tibble: 120 × 3\n    ph1   ph2   ph3\n  <dbl> <dbl> <dbl>\n1    95    95    95\n2    58    62    NA\n3   100    50    50\n4    77    77    64\n5    NA    NA    NA\n6   100    75   100\n# … with 114 more rows\n\n\n\nhelping |>\n  select(ph1:ph3) |>\n  rowSums(na.rm = TRUE) |>\n  print()\n\n  [1] 285 120 200 218   0 275 257 178 256 189 215 226 209 246 159 197 205 225\n [19] 150 195  44   0   0 125 225 211 270 176 241 205   0 220  98  79 143 165\n [37]  49 294 300 292 101 285 208 230 255 150 299 188 208 205 138 267 187 300\n [55] 195 300 236  59 226 193 213 250  32 228 250 300 300 190 230 281 196 268\n [73] 240 250  39 233 211 198 199 234 300 215 240   9 261 209 281 201 270 255\n [91] 177 235 161   0 242 151 182 170   3 222 172 194 300 300 293 238 243 260\n[109] 197 294 280 195 255   1 162 278 176 262 300 164\n\n\n\nhelping[\"phone\"] <-    # \"phone\"이라는 새로운 변수에 assign!\n  helping |>\n  select(ph1:ph3) |>\n  rowSums(na.rm = TRUE)\n\nhelping |> print(width = Inf)\n\n# A tibble: 120 × 13\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone\n    <dbl> <dbl>\n1      70   285\n2      59   120\n3     100   200\n4      69   218\n5      NA     0\n6      90   275\n# … with 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n다음과 같이 직접 더하는 것은 부적절\nhelping |>\n  mutate(phone = ph1 + ph2 + ph3) \n#      id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n#   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n# 1     1    95    95    95     1  2004      80      NA      80      80      70\n# 2     2    58    62    NA     0  2003      62      58      59      57      56\n# 3     3   100    50    50    NA  2003      90      51      51      51      52\n# 4     4    77    77    64     1  2004      66      72      88      82      67\n# 5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n# 6     6   100    75   100     0  2004     100      60      70      55      70\n#   emp_q26 phone\n#     <dbl> <dbl>\n# 1      70   285\n# 2      59    NA\n# 3     100   200\n# 4      69   218\n# 5      NA    NA\n# 6      90   275\n# # … with 114 more rows\n\n\n\n\n\nrowMeans(row, na.rm = TRUE) 함수를 이용하는 것이 적절함\n\n# 먼저, 평균을 낼 문항을 선택/확인\nhelping |>\n  select(emp_q20, emp_q22:emp_q26) |>  # \":\" operator와 \",\" 섞어써도 무방\n  print()\n\n# A tibble: 120 × 6\n  emp_q20 emp_q22 emp_q23 emp_q24 emp_q25 emp_q26\n    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1      80      NA      80      80      70      70\n2      62      58      59      57      56      59\n3      90      51      51      51      52     100\n4      66      72      88      82      67      69\n5      NA      NA      NA      NA      NA      NA\n6     100      60      70      55      70      90\n# … with 114 more rows\n\n\n\nhelping[\"persp\"] <- helping |>    # \"persp\"라는 새로운 변수에 assign!\n  select(emp_q20, emp_q22:emp_q26) |>\n  rowMeans(na.rm = TRUE)\n\nhelping |> print(width = Inf)\n\n# A tibble: 120 × 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone persp\n    <dbl> <dbl> <dbl>\n1      70   285  76  \n2      59   120  58.5\n3     100   200  65.8\n4      69   218  74  \n5      NA     0 NaN  \n6      90   275  74.2\n# … with 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nTidyverse에서 row-wise operation을 하려면,\nhelping |>\n    rowwise() |>\n    mutate(persp = mean(c(emp_q20, c_across(emp_q22:emp_q26)), na.rm = TRUE)) |>\n    ungroup()\n참고: column-wise operation\n\n\n\n\n\n카테고리 변수는 R의 factor 타입으로 바꾸어 분석하는 것이 유리함.\n간단한 연산은 직접 계산.\n\nhelping |>\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")),  # factor 타입의 변수로 변환\n    age = 2023 - age  # 출생년도로부터 나이 계산\n  ) |>\n  print(width = Inf)\n\n# A tibble: 120 × 14\n     id   ph1   ph2   ph3 sex      age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <fct>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95 female    19      80      NA      80      80      70\n2     2    58    62    NA male      20      62      58      59      57      56\n3     3   100    50    50 NA        20      90      51      51      51      52\n4     4    77    77    64 female    19      66      72      88      82      67\n5     5    NA    NA    NA NA        NA      NA      NA      NA      NA      NA\n6     6   100    75   100 male      19     100      60      70      55      70\n  emp_q26 phone persp\n    <dbl> <dbl> <dbl>\n1      70   285  75  \n2      59   120  58.4\n3     100   200  68.8\n4      69   218  71.2\n5      NA     0 NaN  \n6      90   275  75  \n# … with 114 more rows\n\n\n\n\n\nfilter()를 활용\n예를 들어, 5번째 행을 지우려면\n\nhelping |>\n    filter(!id == 5) |> # !는 not의 의미\n    print()\n\n# 다시 helping에 assign 해야 수정됨!\n\n# A tibble: 119 × 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     6   100    75   100     0  2004     100      60      70      55      70\n6     7    77    94    86     1  2004      91      93      85      91      73\n# … with 113 more rows, and 3 more variables: emp_q26 <dbl>, phone <dbl>,\n#   persp <dbl>\n\n\n여러 행을 지우려면?\n%in% 응용\n\nhelping |>\n    filter(!id %in% c(1, 3, 5)) |> # !는 not의 의미\n    print()\n\n# A tibble: 117 × 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     2    58    62    NA     0  2003      62      58      59      57      56\n2     4    77    77    64     1  2004      66      72      88      82      67\n3     6   100    75   100     0  2004     100      60      70      55      70\n4     7    77    94    86     1  2004      91      93      85      91      73\n5     8    90    68    20     0  2004      67      66      31      67      63\n6     9   100    79    77     0  2003      61      51      30      51      51\n# … with 111 more rows, and 3 more variables: emp_q26 <dbl>, phone <dbl>,\n#   persp <dbl>\n\n\n\n\n\nselect() 활용\nemp_q23, emp_q25 두 열을 삭제\n\nhelping |>\n    select(-emp_q23, -emp_q25) |>\n    print()\n\n# A tibble: 120 × 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q24 emp_q26 phone\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n1     1    95    95    95     1  2004      80      NA      80      70   285\n2     2    58    62    NA     0  2003      62      58      57      59   120\n3     3   100    50    50    NA  2003      90      51      51     100   200\n4     4    77    77    64     1  2004      66      72      82      69   218\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA     0\n6     6   100    75   100     0  2004     100      60      55      90   275\n# … with 114 more rows, and 1 more variable: persp <dbl>\n\n\nemp_q23부터 emp_q26 열을 삭제 (위치의 의미로)\n\nhelping |>\n    select(-(emp_q23:emp_q26)) |>  # () 꼭 필요\n    print()\n\n# A tibble: 120 × 10\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 phone persp\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl> <dbl> <dbl>\n1     1    95    95    95     1  2004      80      NA   285  75  \n2     2    58    62    NA     0  2003      62      58   120  58.4\n3     3   100    50    50    NA  2003      90      51   200  68.8\n4     4    77    77    64     1  2004      66      72   218  71.2\n5     5    NA    NA    NA    NA    NA      NA      NA     0 NaN  \n6     6   100    75   100     0  2004     100      60   275  75  \n# … with 114 more rows"
  },
  {
    "objectID": "contents/cleaning.html#이상치-발견",
    "href": "contents/cleaning.html#이상치-발견",
    "title": "Cleaning",
    "section": "이상치 발견",
    "text": "이상치 발견\nOutliers을 찾는 방법은 다양하고 복잡한 테크닉을 요하기도 하는데, 앞으로 점차 익히게 될 것임\n예를 들어, age에 잘못 기입한 경우가 있는데\n\nhelping <- read_csv(\"data/altruism.csv\")\n\nhelping |>\n    ggplot(aes(x = age)) +\n    geom_histogram()\n\n\n\n\nage는 출생년도를 물어봤으나 다른 답을 한 경우들이 있음\n값은 2002 ~ 2004 사이가 정상이므로 filter()를 써서 확인해 볼 수 있음\n\nhelping |>\n    filter(age < 2002 | age > 2004) |>\n    print()\n\n# A tibble: 7 × 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1    11    65    94    56     1   203      62      86      58      47      62\n2    21    17    10    17     1 20004       0       6       1       0       4\n3    43    90    88    30     1   507     100      78      62     100      78\n4    52   100    82    85     1   723      87      83      89     100      88\n5    59    76    86    64     0   709     100      93      67      94      79\n6   108    75   100    85     1  2005     100     100     100     100      97\n7   118    92    76    94     0  1108      55      51      51      60      53\n# … with 1 more variable: emp_q26 <dbl>"
  },
  {
    "objectID": "contents/cleaning.html#샘플-r-script",
    "href": "contents/cleaning.html#샘플-r-script",
    "title": "Cleaning",
    "section": "샘플 R script",
    "text": "샘플 R script\n\nlibrary(tidyverse)\n\n# import data\nhelping <- read_csv(\"data/altruism.csv\")\n\n# rename\nhelping <- helping |>\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3) \n\n# delete reponses\nhelping <- helping |>\n  filter(!id == 5)\n\n# scoring\nhelping[\"phone\"] <- helping |>\n  select(ph1:ph3) |>\n  rowMeans(na.rm = TRUE)\n\nhelping[\"persp\"] <- helping |> \n  select(emp_q20, emp_q22, emp_q24:emp_q26) |>\n  rowMeans(na.rm = TRUE)\n\n# factors and etc.\nhelping <- helping |>\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")),\n    age = 2023 - age\n  )\n\n# select variables\nhelping <- helping |>\n  select(id, sex, age, phone, persp)\n\n정리된 파일로 분석 시작!\n\nhelping |> print()\n\n# A tibble: 119 × 5\n     id sex      age phone persp\n  <dbl> <fct>  <dbl> <dbl> <dbl>\n1     1 female    19  95    75  \n2     2 male      20  60    58.4\n3     3 NA        20  66.7  68.8\n4     4 female    19  72.7  71.2\n5     6 male      19  91.7  75  \n6     7 female    19  85.7  82.6\n# … with 113 more rows"
  },
  {
    "objectID": "contents/inspection.html",
    "href": "contents/inspection.html",
    "title": "Inspecting",
    "section": "",
    "text": "tibble/dataframe 살펴보기 명령어들\nhead(tibble, 20) tail(tibble, 20) view(tibble) # in tidyverse, R에서는 대문자 View()\nglimpse(tibble) slice(tibble, 5:20) # row numbers\nstr() # structure\n\n\npipe operator 이용\nex. iris2 %>% glimpse() # ctrl + enter"
  },
  {
    "objectID": "contents/setup.html",
    "href": "contents/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "R 다운로드 및 설치\n\nWindows인 경우 > Download R for Windows > base > Download R-4.2.2 for Windows\n\n다운로드 링크\n\nMac인 경우 > Download R for macOS > R-4.2.2.pkg 또는 R-4.2.2-arm64.pkg (Apple silicon)\n\n다운로드 링크 일반\n\n다운로드 링크 for Apple silicon\n\n\nRStudio 다운로드 및 설치\n\n2: Install RStudio"
  },
  {
    "objectID": "contents/setup.html#rstudio-소개",
    "href": "contents/setup.html#rstudio-소개",
    "title": "환경설정",
    "section": "RStudio 소개",
    "text": "RStudio 소개\n4개의 패널로 구성\nProject 단위로 분석\n\n시작시 project을 새로 만들거나 불러와서 실행: filename.Rproj 형태로 저장\nFile > New Project or +R 버튼 > New Directory > New Project\n\nDirectory name, Sub directory\n\n\nWorking directory\n\nproject에서 참조하는 최상위 폴더\n하위폴더 지시: 예) data/file.sav\n\nR script 생성, 저장\nRStudio 닫기, 열기\n\nWorkspace 저장 vs. R script 저장\nWorkspace save/load: .Rdata 형태로 저장\n\nSession\n\nRestart R\n\n\n환경설정: Tools > Global Options\nSave workspace to .RData on exit: working space 자동 저장\nCode\n\nsoft-wrap R source files\nUse native pipe operator\n\nAppearance\n\nZoom: 전체 보기 줌\nEdiotr font: Cascadia Mono (Win), Menlo (Mac)\nEditor font size: 글자 크기\ntheme: Tomorrow Night??"
  },
  {
    "objectID": "contents/setup.html#패키지의-설치",
    "href": "contents/setup.html#패키지의-설치",
    "title": "환경설정",
    "section": "패키지의 설치",
    "text": "패키지의 설치\n\n# 메뉴를 통한 설치\n\n# 명령어를 통한 설치\ninstall.packages(\"name\")\n\n# 수업에서 필요한 기본 패키지\ninstall.packages(\"tidyverse\") # 패키지들의 패키지\n\n## ✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n## ✔ tibble  3.1.7     ✔ dplyr   1.0.9\n## ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n## ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n# 패키지들 간의 함수의 충돌에 대해서... mask\n\n# 추가 패키지\ninstall.packages(c(\"mosaicData\", \"palmerpenguins\")) # c(): combine items\n\n# 패키지 로드: 필요한 패키지는 세션마다 시행해야 함\nlibrary(\"name\")\n    e.g. library(tidyverse)"
  },
  {
    "objectID": "contents/setup.html#단축키",
    "href": "contents/setup.html#단축키",
    "title": "환경설정",
    "section": "단축키",
    "text": "단축키\n\n자동완성: tab\n\n현재 라인 실행: Ctrl+Enter (Win)   |   Command+Return (Mac)\nassignment operator (<-) 입력: Alt+- (Win)   |   Option+- (Mac)\npipe operator (%>%) 입력: Ctrl+Shift+M (Win)   |   Shift+Command+M (Mac)\nconsol에서 화살표 키\ncopy, paste\nundo, redo: Ctrl+Z / Ctrl+Shift+Z (Win)   |   Command+Z / Command+Shift+Z (Mac)\nCopy Lines Up/Down: Shift+Alt+Up/Down (Win)   |   Option+Command+Up or Down (Mac)\n\n단축키 변경: Tools >> modify keyboard shortcuts: e.g. pipe operator: Alt+."
  },
  {
    "objectID": "contents/setup.html#도움말",
    "href": "contents/setup.html#도움말",
    "title": "환경설정",
    "section": "도움말",
    "text": "도움말\nhelp() 또는 ?\ne.g. help(factor), ?factor"
  },
  {
    "objectID": "contents/case3_sol.html#national-education-longitudinal-study-of-1988-nels88",
    "href": "contents/case3_sol.html#national-education-longitudinal-study-of-1988-nels88",
    "title": "Case Study 3",
    "section": "National Education Longitudinal Study of 1988 (NELS:88)",
    "text": "National Education Longitudinal Study of 1988 (NELS:88)\nSource: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n연구주제: 학생들의 과제는 성적에 영향을 주는가? 준다면 그 영향력의 크기는 어떠한가?\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels <- read_csv(\"data/nels88_sample.csv\")\nnels <- nels |> \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# A tibble: 300 × 5\n   grades pared hw_in hw_out  prev\n    <dbl> <dbl> <dbl>  <dbl> <dbl>\n 1   4.33     3     1      0  56.4\n 2   8        5     1      2  58.4\n 3   6.5      4     0      2  44.4\n 4   7.33     6     3      2  67.4\n 5   6        2     3      2  50.7\n 6   4        3     1     NA  46.0\n 7   6.5      6     1      7  62.4\n 8   4.33     2     1      2  46.0\n 9   3.5      2     3      1  46.3\n10   6.5      3     7      5  62.4\n# ℹ 290 more rows\n\n# summarize data\nsummary(nels)\n\n     grades          pared           hw_in           hw_out     \n Min.   :1.333   Min.   :1.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:4.500   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  \n Median :5.750   Median :3.000   Median :2.000   Median :2.000  \n Mean   :5.610   Mean   :3.197   Mean   :2.135   Mean   :2.554  \n 3rd Qu.:6.750   3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:4.000  \n Max.   :8.000   Max.   :6.000   Max.   :7.000   Max.   :7.000  \n NA's   :20                      NA's   :25      NA's   :24     \n      prev      \n Min.   :29.34  \n 1st Qu.:43.79  \n Median :50.81  \n Mean   :50.86  \n 3rd Qu.:57.06  \n Max.   :69.96  \n NA's   :12     \n\n# count values\nnels |> count(pared)\n\n# A tibble: 6 × 2\n  pared     n\n  <dbl> <int>\n1     1    31\n2     2    47\n3     3   123\n4     4    53\n5     5    23\n6     6    23\n\nnels |> count(hw_out)\n\n# A tibble: 9 × 2\n  hw_out     n\n   <dbl> <int>\n1      0    17\n2      1    75\n3      2    78\n4      3    31\n5      4    33\n6      5    17\n7      6    11\n8      7    14\n9     NA    24\n\n\n\n\n변수들 간의 관계 탐색\n\nlowerCor(nels)\nlibrary(corrgram)\nnels |> \n  corrgram(upper.panel = panel.cor, lower.panel = panel.pie)\n\n\n\n       grads pared hw_in hw_ot prev\ngrades 1.00                        \npared  0.39  1.00                  \nhw_in  0.15  0.02  1.00            \nhw_out 0.37  0.27  0.28  1.00      \nprev   0.51  0.50  0.18  0.30  1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 <- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)\n\n\n\n\n\n\n세 개의 독립변수로 예측\n\nB1. 인과모형 A: 부분 회귀 계수들\n\n\n\n\n\n\n\n\n\n\n\nmod1 <- lm(grades ~ pared + hw_in + hw_out, data = nels)\nsummary(mod1)\n\n\nCall:\nlm(formula = grades ~ pared + hw_in + hw_out, data = nels)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5760 -0.9737  0.1006  0.9497  2.8618 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.76892    0.24369  15.466  < 2e-16 ***\npared        0.36326    0.06365   5.707 3.13e-08 ***\nhw_in        0.05066    0.05014   1.010    0.313    \nhw_out       0.22884    0.04752   4.816 2.49e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.299 on 260 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2377,    Adjusted R-squared:  0.2289 \nF-statistic: 27.02 on 3 and 260 DF,  p-value: 3.032e-15\n\n\n\nmod2 <- lm(hw_out ~ pared, data = nels)\nsummary(mod2)\n\n\nCall:\nlm(formula = hw_out ~ pared, data = nels)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8260 -1.4548 -0.4548  1.1740  5.2874 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.34143    0.28227   4.752 3.25e-06 ***\npared        0.37114    0.08016   4.630 5.66e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.746 on 274 degrees of freedom\n  (24 observations deleted due to missingness)\nMultiple R-squared:  0.07255,   Adjusted R-squared:  0.06917 \nF-statistic: 21.44 on 1 and 274 DF,  p-value: 5.658e-06\n\n\n\n\nD: 표준화 계수 및 부분 상관 계수\n\n# beta: standardized coefficients\ncoef(lm.beta::lm.beta(mod1)) |> print()\n\n(Intercept)       pared       hw_in      hw_out \n         NA  0.31961944  0.05707121  0.28071933 \n\n\n\nsumm(mod1, part.corr=TRUE, model.info=FALSE, model.fit=FALSE)\n\n\n\n\n\n\n\n\nEst.\n\n\nS.E.\n\n\nt val.\n\n\np\n\n\npartial.r\n\n\npart.r\n\n\n\n\n\n\n(Intercept)\n\n\n3.77\n\n\n0.24\n\n\n15.47\n\n\n0.00\n\n\nNA\n\n\nNA\n\n\n\n\npared\n\n\n0.36\n\n\n0.06\n\n\n5.71\n\n\n0.00\n\n\n0.33\n\n\n0.31\n\n\n\n\nhw_in\n\n\n0.05\n\n\n0.05\n\n\n1.01\n\n\n0.31\n\n\n0.06\n\n\n0.05\n\n\n\n\nhw_out\n\n\n0.23\n\n\n0.05\n\n\n4.82\n\n\n0.00\n\n\n0.29\n\n\n0.26\n\n\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\nE: 간접효과의 크기와 검증\n\n\nsummary(mediate(grades ~ pared + (hw_out), data = nels))\n\n\n\n\nCall: mediate(y = grades ~ pared + (hw_out), data = nels)\n\nDirect effect estimates (traditional regression)    (c') X + M on Y \n          grades   se     t  df     Prob\nIntercept   3.90 0.21 18.39 297 6.04e-51\npared       0.35 0.06  5.66 297 3.61e-08\nhw_out      0.24 0.04  5.33 297 1.90e-07\n\nR = 0.47 R2 = 0.22   F = 41.42 on 2 and 297 DF   p-value:  1.36e-16 \n\n Total effect estimates (c) (X on Y) \n          grades   se     t  df     Prob\nIntercept   4.22 0.21 19.85 298 1.78e-56\npared       0.43 0.06  7.06 298 1.20e-11\n\n 'a'  effect estimates (X on M) \n          hw_out   se    t  df     Prob\nIntercept   1.36 0.27 5.10 298 6.09e-07\npared       0.37 0.08 4.85 298 2.00e-06\n\n 'b'  effect estimates (M on Y controlling for X) \n       grades   se    t  df    Prob\nhw_out   0.24 0.04 5.33 297 1.9e-07\n\n 'ab'  effect estimates (through all  mediators)\n      grades boot   sd lower upper\npared   0.09 0.09 0.03  0.04  0.14\n\n\n\n\n\n변수의 추가: 4개의 독립변수로 예측\n\nB2. 인과모형 B: 부분 회귀 계수들\n\n\nmod3 <- lm(grades ~ pared + hw_out, data = nels)\nmod4 <- lm(grades ~ pared + hw_out + prev, data = nels)\n\n\n\nF: 모형의 비교\n\nexport_summs(mod3, mod4, error_format = \"({p.value})\") |> print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)            3.80 ***         0.94 *    \n                                      (0.00)           (0.05)     \n                pared                  0.37 ***         0.20 **   \n                                      (0.00)           (0.00)     \n                hw_out                 0.24 ***         0.17 ***  \n                                      (0.00)           (0.00)     \n                prev                                    0.07 ***  \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                    270              258         \n                R2                     0.23             0.35      \n              ────────────────────────────────────────────────────\n                *** p < 0.001; ** p < 0.01; * p < 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n\n\n\nG: 표준화 계수 및 부분 상관 계수\n\n# beta: standardized coefficients\ncoef(lm.beta::lm.beta(mod4)) |> print()\n\n(Intercept)       pared      hw_out        prev \n         NA   0.1723538   0.2039104   0.3867412 \n\n\n\nsumm(mod4, part.corr=TRUE, model.info=FALSE, model.fit=FALSE)\n\n\n\n\n\n\n\n\nEst.\n\n\nS.E.\n\n\nt val.\n\n\np\n\n\npartial.r\n\n\npart.r\n\n\n\n\n\n\n(Intercept)\n\n\n0.94\n\n\n0.48\n\n\n1.97\n\n\n0.05\n\n\nNA\n\n\nNA\n\n\n\n\npared\n\n\n0.20\n\n\n0.07\n\n\n2.96\n\n\n0.00\n\n\n0.18\n\n\n0.15\n\n\n\n\nhw_out\n\n\n0.17\n\n\n0.05\n\n\n3.81\n\n\n0.00\n\n\n0.23\n\n\n0.19\n\n\n\n\nprev\n\n\n0.07\n\n\n0.01\n\n\n6.61\n\n\n0.00\n\n\n0.38\n\n\n0.33\n\n\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\n\n추가 분석\n\nH: Howework에 영향을 주는 요소들 분석\n\n\nmod5 <- lm(hw_out ~ scale(pared), data = nels)\nmod6 <- lm(hw_out ~ scale(pared) + scale(prev), data = nels)\n\nexport_summs(mod5, mod6, error_format = \"({p.value})\") |> print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)            2.53 ***         2.50 ***  \n                                      (0.00)           (0.00)     \n                scale(pared)           0.49 ***         0.33 **   \n                                      (0.00)           (0.01)     \n                scale(prev)                             0.38 **   \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                    276              264         \n                R2                     0.07             0.12      \n              ────────────────────────────────────────────────────\n                *** p < 0.001; ** p < 0.01; * p < 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n\n\nmod5 <- lm(hw_out ~ pared, data = nels)\nmod6 <- lm(hw_out ~ pared + scale(prev), data = nels)\n\nexport_summs(mod5, mod6, error_format = \"({p.value})\") |> print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)            1.34 ***         1.69 ***  \n                                      (0.00)           (0.00)     \n                pared                  0.37 ***         0.25 **   \n                                      (0.00)           (0.01)     \n                scale(prev)                             0.38 **   \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                    276              264         \n                R2                     0.07             0.12      \n              ────────────────────────────────────────────────────\n                *** p < 0.001; ** p < 0.01; * p < 0.05.           \n\nColumn names: names, Model 1, Model 2"
  },
  {
    "objectID": "contents/overview.html",
    "href": "contents/overview.html",
    "title": "Overview",
    "section": "",
    "text": "이번 섹션에서는 통계가 어떻게 활용되는지에 대한 전반적인 landscape을 소개하고자 하며, 이는 다양한 통계적 분석 이론들 속에서 자신이 수행하고 있는 분석의 적절성을 대략 이해하며, 어떤 부분이 부족한지를 파악할 수 있도록 도움을 주고자 함.\n여기에서 소개하는 내용을 모두 수업에서 다룬다는 것은 절대 아님!\n시작하면,\n통계가 활용되는 방식은 크게 3가지로 나누어 볼 수 있음"
  },
  {
    "objectID": "contents/overview.html#descriptive-기술적-분석",
    "href": "contents/overview.html#descriptive-기술적-분석",
    "title": "Overview",
    "section": "Descriptive: 기술적 분석",
    "text": "Descriptive: 기술적 분석\n\n\n\n통계청의 조사 결과와 같이 현상에 대한 기술 \n단순한 기술은 자칫 오해의 여지와 호도할 위험이 존재\n예를 들어,\n- 남녀 임금의 차이에 대한 통계치를 제시하는 경우\n- 외국의 경우, 인종별 범죄율에 대한 통계치 등등 \n만일, 좀 더 자세히 나눠어서, 연령별, 직업군별로 남녀 임금의 차이를 본다면 만족스러운가?\n얼마나 더 상세히 나누어야 하는가?\n그 차이는 의미있는 차이인가?"
  },
  {
    "objectID": "contents/overview.html#relational-변수들-간의-진실한-관계를-분석",
    "href": "contents/overview.html#relational-변수들-간의-진실한-관계를-분석",
    "title": "Overview",
    "section": "Relational: 변수들 간의 진실한 관계를 분석",
    "text": "Relational: 변수들 간의 진실한 관계를 분석\n\nCase 1\n미혼자에 대한 임금 차별이 있는가? 차별이 의미하는 바는 무엇인가?\n아래 첫번째 그림과 같이 기혼자의 임금이 미혼자에 보다 높은 것으로 나타났다면,\n이는 정말 결혼하지 않은 것이 임금을 책정하는데 영향을 주었는가?\n하지만, 당연하게도 기혼자는 미혼자에 비해 연령이 높으며 (두번째 그림),\n높은 연령은 연차가 높거나 실무능력이 뛰어난 경향으로 인해 임금을 높을 수 있다는 것을 감안하면 (세번째 그림)\n차별처럼 보이는 차이는 차별이라고 볼 수 없을 수도 있음.\n다시 말하면, 연령을 고려한 후에도 기혼자의 임금은 미혼자보다 높은가?\n여전히 높다면, 연령을 고려한 후 혹은 연령을 조정한 후(adjusted for age)의 차이는 얼마라고 봐야하는가?\n연령을 고려한 임금 차이를 조사하는 방법은 무엇이 있겠는가?\n\n연령별로 나누어 비교?\n\nData from the 1985 Current Population Survey\n\n\n\n\n\n연령을 고려한 마라톤 기록?\n70세 노인의 기록 2시간 30분과 20세 청년의 2시간 30분은 마라톤 실력이라는 관점에서 다르게 볼 수도 있음\n예를 들어, “나이 차이가 큰 두 사람의 기록을 비교하는 것은 공평하지 않아”라는 주장에 대해서, 70세 노인의 기록은 “나이를 감안하면 2시간 10분에 해당한다”고 답변할 수 있음\n다시 말하면, 나이와는 무관한/독립적인 마라톤 능력에 대해 말할 수 있음\n이는 동일한 나이의 사람들로만 제한해서 마라톤 기록을 비교하는 것이 공평한 능력의 비교라고 말하는 것과 것이 같은 이치임\n\nSource: https://doi.org/10.1186/2052-1847-6-31\n\n\nCase 2\n기혼여부에 따른 임금의 차이가 남녀별로 다른가?\n연령이 올라감에 따라 임금이 올라가는 패턴에 차이가 있는가?\n\n\n\n\n\n왼편 그림에서 보면, 기혼여부에 따른 임금의 차이가 남녀에 따라 다르게 나타나는 것으로 보임\n이러한 현상을 변수 간에 상호작용(interaction)이 있다고 말함 (moderate라는 표현도 있음)\n말하지면, 기혼여부가 임금에 주는 효과가 성별에 따라 바뀌고, 기혼여부와 성별이 상호작용하여 임금에 영향을 준다라고 표현할 수 있음 (2-way interaction)\n비슷하게, 오른편을 보면, 연령에 따른 임금의 증가 패턴이 남녀에 따라서, 업종에 따라 다르게 나타나는 것으로 보임\n(manag: management, manuf: manufacturing, prof: professional)\n즉, 연령이 임금에 미치는 효과는 성별과 업종에 따라 바뀌고, 연령, 성별, 업종이 상호작용하여 임금에 영향을 준다라고 표현할 수 있음 (3-way interaction)\n\n\n\n\n\n\nWarning\n\n\n\n위의 표현은 모두 효과를 가정한 표현으로 설명을 위해 편의상 그렇게 표현하였음\n또한, 다른 요소들은 단순화를 위해 생략했음. 예를 들어 왼편의 상황에서 나이를 고려하면 다른 양상을 보일 수 있음\n\n\n또 다른 예로는, 나이가 듦(age)에 따라 지구력(endurance)의 감소가 강도 높은 운동을 한 기간(년수)(exercise)에 따라 변화한다는 가설을 테스트한 자료\n\n\n\n\n\n이 경우 운동을 한 기간은 앞의 예에서처럼 카테고리 변수가 아니기 때문에 임의로 3구간으로 나누어 살펴 본 것임.\n나이가 지구력에 미치는 부정적 영향이 운동을 한 기간에 따라 변하는 것으로 보임.\n즉, 나이와 운동기간이 상호작용하여 지구력에 영향을 미친다고 표현할 수 있음\n상호작용은 아래와 같이 상호작용하는 두 변수의 위치를 바꿔 살펴볼 수도 있음\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n시각화를 통해 전반적인 패턴을 살펴보는 것은 통계적 모형을 세워 수학적으로 분석하기 전에 하는 보조 수단임.\n앞에 마라톤 기록의 예처럼 실제 분석은 한 변수를 고려한 후 다른 변수의 변화를 계산하는 방식으로 분석을 하는 것이지, 나이별로 자료를 나누어 보지 않듯이, 운동기간을 위에서처럼 구간으로 쪼개어 분석하는 것은 아님.\n\n\n\n\nCase 3\n임금이 증가하면 삶의 만족도가 높아지는가? 아마도?\n\n\n\n\n\n\n하지만, 특정 A의 임금이 p 에서 q 로 증가할 때, 트렌드대로 움직이겠는가?\n혹은, 특정 B의 임금이 r 에서 s 로 감소할 때, 트렌드대로 움직이겠는가?\n개인의 변화를 살펴보는 종단연구(logitudinal)로 그 갭을 채울 수 있음\n\n\n\n\n\n\nNote\n\n\n\nLongitudinal (종단) vs. cross-sectional (횡단)\n종단 데이터는 관측의 단위, 예를 들어 개인을 반복측정하여 개개인의 특성을 함께 파악할 수 있는 장점을 가짐. 시간과 비용이 많이 들고, attrition (참여자 탈락) 비율이 높아질 우려가 있어 분석에 걸림돌이 되곤 함. 특히, 노인에 대한 연구는 사망으로 인해 참여자가 주는데, 이런 결측치를 고려한 분석에는 상당한 조심성과 기술이 요함. (missing data analysis)\n분석의 관점에서 보면, 개인을 반복 측정하기 때문에 측정값들 사이의 dependency 문제가 생기는데 이를 분석에 고려하려는 노력임. 참여자 각각의 고유한 특성과 연구자가 측정하고자 하는 특성을 분리하고자 함. 위의 예에서 보면, “임금이 삶의 만족도에 주는 영향”과 “개개인의 고유한 특성이 삶의 만족도에 주는 영향”을 분리시켜야 전자의 효과를 분명히 파악할 수 있음. 이는 이후 언급할 multi-level analysis로도 볼 수 있음.\n반면, 주로 접하게 되는 횡단 데이터는 모든 관측치가 independent, 즉 서로 영향을 받지 않는다고 가정할 수 있는데, 물론 한 가족의 구성원이 참여하는 연구는 그 가정에 위배됨.\n횡단데이터의 문제는 소위 cohort bias가 숨어 있을 수 있음. 예를 들어 다른 나이대의 사람들은 다른 사회적 경험을 통해 다른 특성을 지녔을 수 있으므로, 데이터의 관측치들이 homogenous (동질적) 하지 못함으로 인해 연구자가 보려는 관계에 노이즈를 만들 수 있음.\n\n\n하지만, 그럴지라도 임금으로 “인해” 삶의 만족도가 올라가느냐는 다른 문제임 >> 인과관계의 문제\n\n예를 들어, 연봉의 증가가 삶의 만족도를 올렸다기 보다는 상대적 비교에서 오는 자존감이 증가했기 때문일 수 있음\n연봉이 높은 곳은 직업 특성이 다를 수 있음\n또는, 인맥과 인간관계의 변화에서 오는 차이일 수도 있음\n\n다른 시각에서 보면,\n현재 A의 연봉 2천만원을 갑자기 4천만으로 올리면 삶의 만족도가 트렌드대로 0.8pt 올라가겠는가?\n\n연봉의 증가는 주변의 시기와 질투를 가져와 인관관계에 영향을 줄 수 있음\n\n본인의 자만은 여러 부정적 결과를 초래할 수 있음\n\n\nPrediction vs. intervention\n\nA의 임금이 올라가면 삶의 만족도가 따라서 올라갈 것이라고 (조심스럽게) 예측할 수는 있으나: association\n\n좀 더 정확히 말하면, 임금이 높은 것은 삶의 만족도가 높은 것과 연관이 있다라고 표현\n“올라가면”이라는 표현은 시간 개념을 포함한 것이라 횡단(cross-sectional) 데이터에서는 부적절\n\nA의 임금을 올리면 삶의 만족도가 올라갈 것이라고 단정할 수 없음: causal\nIntervention이 효과가 있으려면, 적어도 진정한 관계를 파악해야만 하며, 더 나아가 인과관계가 만족해야 함.\n진정한 관계의 문제와 인과의 문제는 서로 엮여 있으며 복잡한 문제임.\n\n예를 들어, 오렌지를 섭취하면 괴혈병이 예방되나 사실은 비타민 C의 섭취가 괴혈병을 예방하는 것임\n만약, 장거리 항해에서 상급자(높은 연령)에게만 과일이 제공되었을 때, 나이가 많은 선원들에게서 괴혈병이 덜 생겼다는 현상으로부터 연령과 괴혈병의 관계를 추론해서는 안됨. 하지만 예측은 여전히 유효함.\n\n\n또는, 신앙심이 깊은 노인들의 수명이 더 길다는 현상이 관찰되었을 때, 신앙심 자체가 심리적으로나 신체적으로 긍정적인 효과를 가질 수 있으나, 그 외에도 신앙 활동의 일부로 활동이 늘고 다른 이와의 긍정적 교류가 건강에 영향을 미쳤을 수도 있음.\n\n이 때, 신앙심과 수명과는 진정한 관계가 있다고 볼 수 있으나 (not spurious) 그 인과 관계에 대해서도 좀 더 깊은 논의가 필요함.\n다시 말하면, 어떤 노인에게 신앙을 권유했을 때, 수명이 연장되었을지라도 신앙심이 수명을 연장시킨 것인가는 별개의 논의임.\n\n\n\n\nThe strength of relationships\n변수들간의 관계와 그 관계의 크기(stength)는 중요하게 구별될 필요가 있음\n아래 두 그림은 변수 간의 관계는 동일하나 그 크기에 차이가 있음\n오른쪽 그림에서 연봉으로 그 사람의 삶의 만족도 지수를 더 정확히 예측할 수 있으며, 이를 설명력 \\((R^2)\\)이 높다고 표현\n보통 이 효과의 크기가 클수록 인과관계일 가능성은 높다고 볼 수 있으며,\n왼쪽 박스에서처럼 variability가 높다는 것은 다른 이유가 있을 가능성이 높음\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n진정한 관계를 탐구하는 것이 어려움에도 불구하고, 관계성을 파악함으로써 통찰을 얻을 수 있음.\n\n\n\n\n복잡한 변수와의 관계를 풀어내려고 노력\nSource: Multiple Regression and Beyond by Timothy Z. Keith"
  },
  {
    "objectID": "contents/overview.html#causal-인과관계의-분석",
    "href": "contents/overview.html#causal-인과관계의-분석",
    "title": "Overview",
    "section": "Causal: 인과관계의 분석",
    "text": "Causal: 인과관계의 분석\n위에서 살펴본 것들은 모두 연구자가 개입하지 않고 관찰만으로 이루어진 분석들임\n논의한 것처럼 관찰된 자료로부터 진실된 관계를 파악하는 것은 매우 정교한 분석이 요구되고 많은 요소들을 고려해야 함.\n좀 더 분명한 관계를 파악하기 위해 실험 연구가 요구되곤 함\n하지만, 많은 경우 실험이 불가능할 뿐 아니라,\n실험이 반드시 최선인 것은 아니며, 실험은 나름데로 큰 약점을 갖고 있음.\n\n\n\n\n\n\nConfounding\n\n\n\n일반적으로, 표면적으로 드러난 변수간의 관계가 숨겨진 다른 변수(lurking third variable)에 의해 매개되어 있어 진실한 관계가 아닌 경우, confounding 혹은 confounder가 존재한다고 함.\n사회과학에서 오래된 가장 핵심적인 문제이나 최근까지도 정확히 정의하기 어려움 개념이었음.\nCausal analysis라는 통계와는 별개의 개념으로 발전되어 최근에야 이론적으로 완성이 되어 관심이 높아짐.\n극단적이지만 이해하지 쉬운 예로는\n\n초등학생 발 사이즈 → 독해력\n\n머리 길이 → 우울증\n\n\n\n\n\n\n\n\n\nAnswer!\n\n\n\n\n\n\n\n\n\n맨 처음 든 예도 마찬가지로   \n올바른 관계를 파악하려면, 동일한 나이에 대해 그 관계를 파악한 후 각 나이에서의 효과를 (weighted) 평균해서 살펴봐야함\n통계에서는 이를 나이를 통제 (control for age)한다고 표현하며, 같은 의미로 다음과 같은 표현을 씀\n나이를 고려했을 때; account for age\n나이를 조정했을 때; adjust for age\n나이를 잔차화했을 때; residualize age\n나이의 변량을 넘어서서; above and beyond age\nSimpson’s paradox\n아래 첫번째 그림은 집단 전체에 대한 플랏이고, 두번째 그림은 나이대별로 나누어 본 플랏\n전체 집단을 보면 운동을 많이 할수록 콜레스테롤이 증가하는 것으로 보이나,\n나이대별로 보면, 상식적으로 운동이 긍정적 효과가 나타남.\n왜 그렇게 나타나는가?\n\nSource: The book of why by Judea Pearl\n관찰 데이터로부터 진정한 관계를 파악하기 위해서는 이와 같은 통계적인 통제를 통해 혹은 인과분석이라는 좀 더 큰 프레임에서 분석해야 하며, 깊은 논의가 필요함\n마지막 예를 들면,\n은퇴한 노인들을 대상으로 규칙적인 걷기가 사망율을 감소시킬 것이라는 가설을 확인하기 위해 1965년 이후 8000명 가량의 남성들을 추적조사한 데이터의 일부를 이용했는데,\nSource: The book of why by Judea Pearl\n\n12년 후 사망율에서 casual walker(하루 1마일 이하)와 intense walker(하루 2마일 이상)가 각각 43%, 21.5%로 나타났음.\n이 걷기의 효과를 의심케 하는 요소들(confounding)은 무엇인가?\n\n\n\n\n\n\n\nAnswers!\n\n\n\n\n\n\n건강이 나빠 많이 걷지 못했을 수도…\n많이 걷는 사람은 상대적으로 젊을 수도…\n많이 먹는 사람이 덜 걸을 수도…\n술을 많이 먹는 사람이 덜 걸을 수도…\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n무수히 많이 생각해볼 수 있는 confounding 요소들을 다 고려해야 하는가?\nYes and No!\n실제 저자들도 다음과 같이 기술\n“Of course, the effects on longevity of intentional efforts to increase the distance walked per day by physically capable older men cannot be addressed in our study.”\n이러한 조심성은 의미있느나 너무 과장될 필요는 없음\n소위 중요 역할을 할 것으로 의심되는 confounding을 충분히 통계적으로 고려/통제했다면, 충분히 인과관계 혹은 intervention을 제안할 수 있으며,\n그러한 연구는 어떤 요소들을 고려했는지에 대해 밝힘으로써 추후 연구에서 어떤 부분이 더 추가적으로 고려되야 할지 알 수 있게 함.\n\n\n앞서 살펴본 관찰 연구들이 모두 confounding의 위험을 안고 있기에 결정적인 인과관계를 파악하기 위해, 전통적으로 “통계학”의 시각에서 인과문제에 대해서는 보통 임상테스트에서 실시하는 RCT (randomized controlled trial)라고 부르는 소위 gold standard한 실험 연구를 통해서 해결하고자 했음\n개념적으로는 물리적 통제라고 볼 수 있으며, 두 그룹으로 집단을 randomly assign(무선/무작위 배정/할당)하면 모든 면에서 동질한 성향을 가짐. 예를 들어, 두 집단의 연령이 평균적으로 동일해짐.\n\n\nSource: The whats and whys of RCTs\n앞서 든 예에서, 걷기가 사망율에 미치는 효과를 검증하려면, 가령 600명을 300명씩 두 그룹으로 무작위로 나눈 후 한쪽은 1마일 이하를 걷도록 하고 나머지는 2마일 이상을 걷게 한 후 12년 후 사망율을 확인해야 함.\n분야마다 효과를 제대로 검증하기 위한 많은 실험 설계들이 발전되었음 >> 연구방법론\n그럼에도 불구하고, 실험 연구는 자체로 한계를 지님\n\n많은 경우 실험이 불가능하며\n실험에서 처치한 구체적인 상황에서만 유효하고\n그 효과는 어떻게 표현할 것인가?\n실험 참여자는 어떻게 왜 참여한 것인가?\n\n\nCase 1\nTerror Management Theory (TMT)\nSelf-esteem의 이론적 근거를 밝히고자 함. 왜 인간은 self-esteem을 유지하려는가?\n\nTreatment: 자신의 죽음과 고통에 대해 생각해보고 써보도록 하고\nControl: 자신의 치통에 대한 질문에 답\n측정: 고정관념에 대해 부정적으로 말하는 사람을 어떻게 평가하는가?\n결과: 그들을 더 부정적으로 평가: defences their own culural worldview\n(e.g. Stereotypes and Terror Management: Evidence That Mortality Salience Enhances Stereotypic Thinking and Preferences)\n\n죽음이나 치통에 대한 생각은 모두 두려움을 포함해 부정적 감정을 불러 일으키는데\n그저 두려움에 대한 반응인가? 아니면 정확히 “죽음에 대한 생각”이 효과를 만든 것인가?\n참여자들의 부정적 정서를 실험 마지막에 측정한 후 분석에 고려했음\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n연구 설계시 관심이 있는 효과를 효과적으로 측정하는 것과 동등하게 중요한 것은 어떤 confounding들이 존재할 수 있는지를 다각도로 검토한 후 이를 설계에 반영하는 것임.\n예를 들어, 위의 경우 죽음에 대한 생각 자체의 효과가 아닌 죽음을 생각했을때 발생할 수 있는 부수적인 감정들로 인해 효과가 난 것이 아닌가하는 것들을 고려해서 설계할 수 있음.\n\n\n\n\nCase 2\n마시멜로우 실험, 1960’s\n\nSource: Want To Teach Your Kids Self-Control?\n3-5세 아이들에게 마시멜로우 1개를 놓고 원하면 먹도록 하나, 만약, 5분을 안먹고 기다리면 2개를 먹을 수 있다고 말한 후, 기다리지 못하고 먹는지를 살펴봄\n소위 delay gratification을 self-control을 발휘한 것으로 이해했으며, 먹지 않고 기다린 아이들이 추후에 학업성취도 및 여러면에서 뛰어난 결과를 보고 하였음.\n\n아이들이 참고 기다린 것은 자력에 의한 자기통제력인가?\n어른들 즉, 권위에 대한 복종인가?\n더 많이 먹기 위한 욕심인가?\n눈 앞에 이익을 빨리 취하는 것은 좋은 전략일 수 있지 않은가?\n\n혹시 실험을 진행하는 실험자에 따라 다른 효과가 나타날까? (Experimenter effects)\n처치(treatment)의 효과인가 처지가 일어나는 상황이 만든 효과인가?\n\n\n\n\n\n\nImportant\n\n\n\n이 연구에서도 여러 confounding들을 생각해볼 수 있음\n위에서 언급한 것들 외에 어떤 것들이 있을까?\n\n\n적어도 마시멜로우 실험의 경우에서 아이들에게 기다리라고 지시한 experimenter들의 정보를 고려할 필요가 있음.\n그럼, 각 experimenter별로 자료를 분석해야 하는가?\n좀 더 확장하면,\n\n같은 처방을 내린 의사들에 따라 다른 효과가 나타날까?\n\n의사가 속한 병원마다 다른 효과가 나타날까?\n\n특정 수업방식의 효과가 학교마다 선생님마다 다르게 나타날까?\n\n\n\n\n\n\n\nNote\n\n\n\nMulti-level analysis (mixed effect model)\n이는 위에서 언급한 longitudinal (종단) 데이터가 지닌 관측치의 dependency를 고려하는 일반적인 접근임. 관측치들이 군집을 이루면서 군집끼리 비슷한 경향을 보인다면, 이를 고려한 분석이 요구됨. 보통 dependency는 데이터를 어떻게 수집했는지를 알아야 파악할 수 있으며, 데이터 내에서 찾아내기 어려움. (clustering analysis 같은 machine learning 분야에서 개발되는 알고리즘적 분석들이 있음)\n만약, 군집을 이루는 단위가 충분히 많다면,\n예를 들어, 10개의 병원에서 30명의 의사가 각각 50명의 환자에게 새롭게 개발된 처방을 처치하여 그 효과를 볼 때,\n\n병원의 효과 vs. 의사의 효과 vs. 처치의 효과를 분리하여 좀 더 분명한 효과를 찾을 수 있음\n\n또는, 30개의 학교에서 50명의 선생님들이 30명의 학생들에게 특정 수업방식의 효과를 검증할 때,\n\n학교의 효과 vs. 선생님의 효과 vs. 수업의 효과를 분리해 볼 수 있음\n\n분석을 위해 각 선생님 마다 혹은 학교마다 따로 분석하는 것도 아니며, 학교별 혹은 선생님별 특성을 측정하여 고려한다든가 하는 방식이 아님. 자료가 품고 있는 관측치들의 유사성이 통계적으로 파악되어 고려되는 것으로, 모든 샘플을 동시에 이용한 고급 통계 방법\n사회과학 자료에서도 만일 가족단위로 데이터 수집이 이루어진다면, 가족 간의 무언가 톡특한 특성이 연구결과에 반영될 수 밖에 없는데, 가족의 특성을 분리해야 연구자가 살펴보는 관심 변수들 간의 관계를 올바로 파악할 수 있음. 다시 지적하면, 연구에서 가족의 특성을 직접 측정해서 고려한다는 의미가 아니고, 자료가 품고 있는 가족간의 유사성이 통계적으로 파악되어 고려되는 것임."
  },
  {
    "objectID": "contents/overview.html#uncertainty",
    "href": "contents/overview.html#uncertainty",
    "title": "Overview",
    "section": "Uncertainty",
    "text": "Uncertainty\n관찰자가 관찰한 대상으로부터 얻은 결과를 관찰하지 않은 더 넓은 대상으로 일반화할 수 있는가?\n가령, 다음과 같이 150명에 대해 조사한 “연령이 임금에 미치는 효과”를 일반화 할 수 있는가?\n한 나라의 국민 전체?\n\n\n\n\n\nStatistical inference (통계적 추론)\n통계학의 추론(statistical inference)은 작은 샘플(sample)로부터 얻은 분석 결과를 바탕으로 모집단(population)이라고 부르는 전체에 대해 말하고자 하는 시도에서 비롯되었음\n\n어떤 비료가 특정 콩 A의 재배에 어떤 영향을 미치는지 알기 위해 하나의 sample (N=10000: sampe size) 위에서 실험이 이루어지고, 그 결과가 A라는 콩의 종 전체에 얼마나 적용될 수 있을지를 알아보고자 했음\n\n사람에게도 적용될 수 있는가?\n\n사실상 난해한 통계 이론의 상당부분을 차지함.\n하지만, 통계적 추론의 논리는 개념적으로는 다음과 같이 볼 수 있음.\n앞서 논의한 모든 내용은 “특정 샘플” 내에서 변수들 간의 관계에 대한 분석일 뿐 그 샘플을 벗어나서 논의한 것이 아님. 통계적 추론은 수많은 같은 수의 샘플들, 가령 N = 150인 즉, 150명으로 이루어진 샘플들을 반복적으로 관찰한다면 그 샘플들 간의 편차들이 어떠하겠는가에 대한 논의임.\n\n첫번째 그림에서처럼 (알수는 없지만) 어떤 population을 가정하는데, 그 모집단에는 age와 wage의 true relationship이 선형적으로 존재한다고 가정함. 연구자가 한번에 150명으로 이루어진 sample을 반복적으로 관찰한다면, 샘플마다 age와 wage의 관계는 다르게 나타날 것임 (두번째 그림).\n예를 들어, 그 기울기에 관심이 있다면, 샘플들로부터 나타나는 기울기들의 분포를 살펴봄으로써 (세번째 그림) 샘플에서 나타날 수 있는 기울기값이 어떠한가를 파악할 수 있음.\n\n이 분포를 sampling distribution이라고 부름\n이 분포에 따르면 평균이 0.066이고, 기울기 값들의 95%가 0.005 ~ 0.140 범위에 있음을 알 수 있음.\n다시말하면, 연구자가 관찰한 샘플로부터 연구자는 (age와 wage의 선형성을 가정한다면), 매우 큰 확신을 갖고 나이가 10세 늘때마다 시간당 임금의 증가율은 0.05에서 1.4달러 사이에 있을 것이라고 말할 수 있음.\n확신이 커지려면 임금증가율의 범위가 넓어져야 함. 예를 들어, 99%의 확신을 갖고 나이가 10세 늘때 시간당 임금의 증가율은 -0.18에서 1.67달러 사이에 있을 것이라고 말할 수 있음. 별로 의미없는 발언이 될 수 있음.\n반대로, 확신에 대해서는 양보하는 대신 임금증가율에 대한 범위폭을 줄일 수 있음. 예를 들어 90%의 조금 낮은 확신을 갖고 임금증가율은 0.14에서 1.3달러 사이에 있을 것이라고 말할 수 있음\n\n\n\n\n\nSource: The Truthful Art by Albert Cairo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap bca confidence intervals\n\n            Estimate 2.5 % 97.5 %\n(Intercept)    6.563 3.926  8.908\nage            0.066 0.005  0.140\n\n\n\n\n\n\n\n\nNote\n\n\n\n위와 같이 어떤 분포를 가정하고 파라미터(기울기 등등)를 포함해 상정한 모델에 대한 통계적 추정과 추론을 하는데 대한 비판이 오래전부터 있어왔음. 현실의 실제적 현상에 적용할 때는 이론적인 통계의 원리와는 별개의 더 깊은 논의가 필요함.\ne.g:\nBreiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. Basic books."
  },
  {
    "objectID": "contents/overview.html#regression-analysis",
    "href": "contents/overview.html#regression-analysis",
    "title": "Overview",
    "section": "Regression analysis",
    "text": "Regression analysis\n앞서 다뤘던 임금과 연령의 관계에 대한 간단한 회귀 분석의 예들 \n\n선형 관계를 가정한 임금과 연령의 관계에 대한 회귀분석 (N=150)\n\n\n\n\n\n\nModel: lm(wage ~ age, data = cps)\n\n\n\nMODEL INFO:\nObservations: 150\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(1,148) = 8.755, p = 0.004\nR<U+00B2> = 0.056\nAdj. R<U+00B2> = 0.049 \nStandard errors: OLS\n----------------------------------------------------------\n                     Est.    2.5%   97.5%   t val.       p\n----------------- ------- ------- ------- -------- -------\n(Intercept)         5.375   2.970   7.780    4.417   0.000\nage                 0.092   0.031   0.154    2.959   0.004\n----------------------------------------------------------\n\n\n\n\n\n맨 처음 든 예, 즉 연령을 고려한/통제한 “기혼여부에 따른 임금차이”를 회귀분석하면 (N=465)\n\n\n\n\n\n\n우선, 결혼여부에 따른 평균 임금의 차이는 미혼일 때 -0.97 (dollars/hr) 낮음.\n하지만, 모집단에서 그 차이는 (95% 확률로) -1.93에서 -0.02 사이에 있을 것이라고 추정할 수 있음\nModel: lm(wage ~ married, data = cps)\n\n\n\nMODEL INFO:\nObservations: 533\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(1,531) = 8.34, p = 0.00\nR<U+00B2> = 0.02\nAdj. R<U+00B2> = 0.01 \nStandard errors: OLS\n-----------------------------------------------------------\n                       Est.    2.5%   97.5%   t val.      p\n------------------- ------- ------- ------- -------- ------\n(Intercept)            9.40    8.89    9.91    36.07   0.00\nmarriedSingle         -1.28   -2.16   -0.41    -2.89   0.00\n-----------------------------------------------------------\n\n\n\n\n\n\n앞서 논의한데로 나이가 confounding이 될 수 있고,\n이를 통계적으로 통제하면,\n\n\n\n\n\n\nModel: lm(wage ~ married + sex + age + I(age^2), data = cps)\n\n\n\nMODEL INFO:\nObservations: 533\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(4,528) = 23.70, p = 0.00\nR<U+00B2> = 0.15\nAdj. R<U+00B2> = 0.15 \nStandard errors: OLS\n------------------------------------------------------------\n                       Est.     2.5%   97.5%   t val.      p\n------------------- ------- -------- ------- -------- ------\n(Intercept)           -6.43   -10.87   -2.00    -2.85   0.00\nmarriedSingle         -0.17    -1.04    0.70    -0.38   0.70\nsexM                   2.44     1.67    3.22     6.18   0.00\nage                    0.68     0.46    0.91     5.95   0.00\nI(age^2)              -0.01    -0.01   -0.00    -5.26   0.00\n------------------------------------------------------------\n\n\n\n“나이를 고려했을 때”, 미혼이 기혼보다 그 임금이 0.17 (dollars/hr) 낮은데,\n모집단에서 그 차이는 -1.04 ~ 0.70 사이에 있을 확률이 매우 높은 것으로 추론됨. (95% 확률로)\n이는 사실상 임금 차이가 있다고 볼 확신을 거의 갖기 어려움\n결혼여부와 성별이 상호작용하는 것을 고려하고, 임금의 분포를 고려해서 log 변환하면,\nModel2: lm(log_wage ~ married * sex + age + I(age^2), data = cps)\n\n\n\nMODEL INFO:\nObservations: 530\nDependent Variable: log_wage\nType: OLS linear regression \nMODEL FIT:\nF(5,524) = 25.06, p = 0.00\nR<U+00B2> = 0.19\nAdj. R<U+00B2> = 0.19 \nStandard errors: OLS\n----------------------------------------------------------------\n                            Est.    2.5%   97.5%   t val.      p\n------------------------ ------- ------- ------- -------- ------\n(Intercept)                 0.23   -0.23    0.68     0.98   0.33\nmarriedSingle               0.07   -0.05    0.20     1.17   0.24\nsexM                        0.34    0.24    0.43     6.82   0.00\nage                         0.08    0.06    0.11     7.06   0.00\nI(age^2)                   -0.00   -0.00   -0.00    -6.45   0.00\nmarriedSingle:sexM         -0.21   -0.38   -0.05    -2.51   0.01\n----------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n나이와 임금의 관계가 위의 플랏에서 나타났듯이 35세부터 일정하게 유지되는 패턴을 보이므로 그 비선형성을 단순화하여 2차 함수 꼴\\((y=c+b\\cdot age+a\\cdot age^2)\\)로 모델링을 하였으나 원칙적으로는 다른 모형이 필요함"
  },
  {
    "objectID": "contents/copilot.html",
    "href": "contents/copilot.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "acad0 <- read_csv(\"data/c0301dt.csv\")\n\n\nacad0\n\n\n\nA spec_tbl_df: 15 × 3\n\n    timepubssalary\n    <dbl><dbl><dbl>\n\n\n    31851876\n    6 354511\n    3 253425\n    81761863\n    ⋮⋮⋮\n     62147047\n     71039115\n    112759677\n    183761458\n\n\n\n\n\n# create a linear model with time as the predictor time, and the outcome being the salary\n# the model is called mod1\nmod1 <- lm(salary ~ time, data = acad0)\n\n# print the model\nmod1\n\n# print the model summary\nsummary(mod1)\n\n\nCall:\nlm(formula = salary ~ time, data = acad0)\n\nCoefficients:\n(Intercept)         time  \n      43659         1224  \n\n\n\nCall:\nlm(formula = salary ~ time, data = acad0)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13114.3  -3964.4     51.4   4025.1   8409.3 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  43658.6     2978.0  14.660 1.83e-09 ***\ntime          1224.4      336.5   3.639    0.003 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5763 on 13 degrees of freedom\nMultiple R-squared:  0.5046,    Adjusted R-squared:  0.4665 \nF-statistic: 13.24 on 1 and 13 DF,  p-value: 0.003\n\n\n\n# r squared of mod1 and round to 2 decimal places\nround(summary(mod1)$r.squared, 2)\n\n0.5\n\n\n\n# correlation between all variables in acad0 with corr.test\n# corr.test is a function from the psych package\nlibrary(psych)\ncorr.test(acad0)\n\nCall:corr.test(x = acad0)\nCorrelation matrix \n       time pubs salary\ntime   1.00 0.66   0.71\npubs   0.66 1.00   0.59\nsalary 0.71 0.59   1.00\nSample Size \n[1] 15\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n       time pubs salary\ntime   0.00 0.02   0.01\npubs   0.01 0.00   0.02\nsalary 0.00 0.02   0.00\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\n\n# buile a linear model with time an pubs as the predictor and salary as the outcome with interaction terms between time and pubs\nmod2 <- lm(salary ~ time + pubs + time:pubs, data = acad0)\n\n# visualize the interaction between time and pubs\nggplot(acad0, aes(x = time, y = pubs, fill = salary)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  labs(x = \"Time\", y = \"Pubs\", fill = \"Salary\") +\n  theme_minimal()\n\n# visualize the interaction between time and pubs with a package visreg\nlibrary(visreg)\nvisreg(mod2, \"time\", \"pubs\")\n\n# visualize the interaction between time and pubs with a package car using effects function\nlibrary(car)\neffects(mod2, \"time\", \"pubs\")\n\n\n\n\nERROR: Error in if (set.sign) {: argument is not interpretable as logical\n\n\n\n\n\n\n# regression diagnostics for mod2\nlibrary(car)\n\n# plot the residuals against the fitted values\nplot(mod2)\n\n# plot the residuals against the fitted values with a package car\nlibrary(car)\nresidualPlots(mod2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n           Test stat Pr(>|Test stat|)\ntime         -0.9563           0.3615\npubs          0.6334           0.5407\nTukey test   -1.1784           0.2386\n\n\n\n\n\n\nhelping <- read_csv(\"data/altruism.csv\")\n\n\n# summary of helping\nsummary(helping)\n\n       id             pho_1            pho_2            pho_3       \n Min.   :  1.00   Min.   :  0.00   Min.   :  0.00   Min.   :  0.00  \n 1st Qu.: 30.75   1st Qu.: 60.50   1st Qu.: 62.50   1st Qu.: 50.00  \n Median : 60.50   Median : 76.00   Median : 77.00   Median : 66.50  \n Mean   : 60.50   Mean   : 70.89   Mean   : 70.25   Mean   : 61.58  \n 3rd Qu.: 90.25   3rd Qu.: 94.50   3rd Qu.: 91.50   3rd Qu.: 84.25  \n Max.   :120.00   Max.   :100.00   Max.   :100.00   Max.   :100.00  \n                  NA's   :1        NA's   :1        NA's   :2       \n      sex             age           emp_q20          emp_q22      \n Min.   :0.000   Min.   :  203   Min.   :  0.00   Min.   :  6.00  \n 1st Qu.:0.000   1st Qu.: 2003   1st Qu.: 62.50   1st Qu.: 65.25  \n Median :1.000   Median : 2003   Median : 80.00   Median : 80.00  \n Mean   :0.678   Mean   : 2100   Mean   : 78.24   Mean   : 78.27  \n 3rd Qu.:1.000   3rd Qu.: 2004   3rd Qu.: 91.50   3rd Qu.: 93.00  \n Max.   :1.000   Max.   :20004   Max.   :100.00   Max.   :100.00  \n NA's   :2       NA's   :3       NA's   :1        NA's   :2       \n    emp_q23          emp_q24          emp_q25          emp_q26     \n Min.   :  0.00   Min.   :  0.00   Min.   :  4.00   Min.   :  2.0  \n 1st Qu.: 56.50   1st Qu.: 60.00   1st Qu.: 64.50   1st Qu.: 59.5  \n Median : 70.00   Median : 71.00   Median : 74.00   Median : 75.0  \n Mean   : 67.49   Mean   : 73.98   Mean   : 74.46   Mean   : 73.5  \n 3rd Qu.: 85.00   3rd Qu.: 90.50   3rd Qu.: 88.00   3rd Qu.: 91.0  \n Max.   :100.00   Max.   :100.00   Max.   :100.00   Max.   :100.0  \n NA's   :1        NA's   :1        NA's   :1        NA's   :1      \n\n\n\n# rename the column pho_1 to pho1, pho_2 to pho2, pho_3 to pho3\nhelping <- helping %>% rename(pho1 = pho_1, pho2 = pho_2, pho3 = pho_3)\n\n# add a column pho to helping that is the average of pho1, pho2, and pho3 with na.rm = TRUE\nhelping <- helping %>% mutate(pho = mean(c(pho1, pho2, pho3), na.rm = TRUE))\n\n\nhelping[\"pho_mean2\"] <- rowMeans(helping[, c(\"pho1\", \"pho2\", \"pho3\")], na.rm = TRUE)\nhelping\n\n\n\nA tibble: 120 × 14\n\n    idpho1pho2pho3sexageemp_q20emp_q22emp_q23emp_q24emp_q25emp_q26phopho_mean2\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    1 959595 1200480NA808070 7067.5898995.00000\n    2 5862NA 020036258595756 5967.5898960.00000\n    31005050NA2003905151515210067.5898966.66667\n    4 777764 120046672888267 6967.5898972.66667\n    ⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮\n    117 50 50 760200352100 026 484567.58989 58.66667\n    118 92 76 940110855 515160 536467.58989 87.33333\n    1191001001000200468 755572 756367.58989100.00000\n    120 60 78 260200486 50 5501009067.58989 54.66667\n\n\n\n\n\nhelping[\"pho_mean3\"] <-    # \"phone\"이라는 새로운 변수에 assign!\n  helping |>\n  select(pho1:pho3) |>\n  rowMeans(na.rm = TRUE)\n\n\nhelping\n\n\n\nA tibble: 120 × 15\n\n    idpho1pho2pho3sexageemp_q20emp_q22emp_q23emp_q24emp_q25emp_q26phopho_mean2pho_mean3\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    1 959595 1200480NA808070 7067.5898995.0000095.00000\n    2 5862NA 020036258595756 5967.5898960.0000060.00000\n    31005050NA2003905151515210067.5898966.6666766.66667\n    4 777764 120046672888267 6967.5898972.6666772.66667\n    ⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮\n    117 50 50 760200352100 026 484567.58989 58.66667 58.66667\n    118 92 76 940110855 515160 536467.58989 87.33333 87.33333\n    1191001001000200468 755572 756367.58989100.00000100.00000\n    120 60 78 260200486 50 5501009067.58989 54.66667 54.66667\n\n\n\n\n\n# load a dataset penguins from the palmerpenguins package\nlibrary(palmerpenguins)\n\n# print the first 6 rows of penguins\nhead(penguins)\n\n\n\nA tibble: 6 × 8\n\n    speciesislandbill_length_mmbill_depth_mmflipper_length_mmbody_mass_gsexyear\n    <fct><fct><dbl><dbl><int><int><fct><int>\n\n\n    AdelieTorgersen39.118.71813750male  2007\n    AdelieTorgersen39.517.41863800female2007\n    AdelieTorgersen40.318.01953250female2007\n    AdelieTorgersen  NA  NA NA  NANA    2007\n    AdelieTorgersen36.719.31933450female2007\n    AdelieTorgersen39.320.61903650male  2007\n\n\n\n\n\n# draw a scatterplot of flipper length and body mass with penguins with a facet wrap of species, with a number of columns of 2\npenguins %>% ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + geom_point() + facet_wrap(~species, ncol = 2)\n\n\n\n\n\n# Tukey's multiple comparison test of flipper length between species\nTukeyHSD(aov(flipper_length_mm ~ species, data = penguins))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = flipper_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr       upr p adj\nChinstrap-Adelie  5.869887  3.586583  8.153191     0\nGentoo-Adelie    27.233349 25.334376 29.132323     0\nGentoo-Chinstrap 21.363462 19.000841 23.726084     0\n\n\n\n# Tukey's multiple comparison test of flipper length between species using multicomp package, glht function\nlibrary(multcomp)\nglht(aov(flipper_length_mm ~ species, data = penguins), linfct = mcp(species = \"Tukey\"))\n\n# summary of the Tukey's multiple comparison test of flipper length between species using multicomp package, glht function\nsummary(glht(aov(flipper_length_mm ~ species, data = penguins), linfct = mcp(species = \"Tukey\")))\n\n# Tukey's multiple comparison test of flipper length between species using emmeans package\nlibrary(emmeans)\nemmeans(aov(flipper_length_mm ~ species, data = penguins), \"species\")\n\n\n\n     General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nLinear Hypotheses:\n                        Estimate\nChinstrap - Adelie == 0     5.87\nGentoo - Adelie == 0       27.23\nGentoo - Chinstrap == 0    21.36\n\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = flipper_length_mm ~ species, data = penguins)\n\nLinear Hypotheses:\n                        Estimate Std. Error t value Pr(>|t|)    \nChinstrap - Adelie == 0   5.8699     0.9699   6.052 1.06e-08 ***\nGentoo - Adelie == 0     27.2333     0.8067  33.760  < 1e-08 ***\nGentoo - Chinstrap == 0  21.3635     1.0036  21.286  < 1e-08 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n(Adjusted p values reported -- single-step method)\n\n\n species   emmean    SE  df lower.CL upper.CL\n Adelie       190 0.540 339      189      191\n Chinstrap    196 0.805 339      194      197\n Gentoo       217 0.599 339      216      218\n\nConfidence level used: 0.95 \n\n\n\n# import the data from the file \"data/students-shorter.sav\" using haven package\nlibrary(haven)\nstudents <- read_spss(\"data/students-shorter.sav\")\n\n# print the first 6 rows of students\nhead(students)\n\n\n\nA tibble: 6 × 93\n\n    stu_idsch_idsstratidsexraceethnicbys42abys42bbys44abys44b⋯f1s83ffugradf1cncpt1f1cncpt2f1locus1f1locus2f1txrstdf1txmstdf1txsstdf1txhstd\n    <dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl>⋯<dbl+lbl><dbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl>\n\n\n    12496612491241 3 424⋯35.25-0.33-0.10 0.03-0.1448.2963.6157.7361.71\n    12497212491141 4 513⋯33.00-0.33-0.45-0.43-0.5836.0547.6553.3646.98\n    17555117551230NA 323⋯22.50 0.42 0.33-0.45-0.5955.1343.4446.3950.48\n    18066018061141 2NA14⋯26.50 0.43-0.02 0.03 0.0742.5456.1940.1456.48\n    18067218061241 2 314⋯24.25 0.02-0.09-0.88-0.8552.9647.3646.0155.32\n    29888529882130 5 423⋯26.00-0.33-0.28 0.03 0.0744.2445.2541.8839.67"
  },
  {
    "objectID": "contents/regression2.html#measures-of-association",
    "href": "contents/regression2.html#measures-of-association",
    "title": "Multiple Regression",
    "section": "Measures of Association",
    "text": "Measures of Association\n\n\n\n\\(R\\): Multiple correlation coefficient\n\n\\(Y\\) 와 \\(\\widehat Y\\) 의 correlation 즉, Y와 회귀모형이 예측한 값의 (선형적) 상관 관계의 정도; 회귀모형의 예측의 정확성\n\n다시말하면, 예측변수들의 최적의 선형 조합과 Y의 상관 관계의 정도.\n\n\\(R^2\\): (평면의) 선형모형에 의해 설명된 Y 변량의 비율:\n또는 예측변수들의 최적의 선형 조합에 의해 설명된 Y 변량의 비율.\n즉, \\(\\displaystyle\\frac{V(\\widehat{Y})}{V(Y)}\\) 또는 \\(\\displaystyle 1 - \\frac{V(e)}{V(Y)}\\)\n\n\n\n\n\n\n\nPartial Associations\n\nPartial correlation (pr)\nSemi-partial correlation (sr)\n\n\n\n\n\n\n\n\n\n\n\n\\(pr^2\\) : “연차로 설명되지 않는 연봉”의 변량 중 “연차로 설명되지 않는 논문수”의 변량으로 설명되는 비율\n즉, 연차를 연봉과 논문수에서 모두 partial out 시켰을 때 남은(residualized) 연봉의 변량과 논문수의 변량의 중복 정도.\n\\(sr^2\\) : 연봉의 변량 중 “연차로 설명되지 않는 논문수”의 변량으로 설명되는 비율\n즉, 연차를 논문수에서만 partial out 시켰을 때 남은(residualized) 논문수의 변량과 연봉의 변량의 중복 정도.\n\nsumm(mod3, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |> print()\n\nStandard errors: OLS\n---------------------------------------------------------------------------\n                        Est.      S.E.   t val.      p   partial.r   part.r\n----------------- ---------- --------- -------- ------ ----------- --------\n(Intercept)         43082.39   3099.49    13.90   0.00                     \ntime                  982.87    452.06     2.17   0.05        0.53     0.43\npubs                  121.80    149.70     0.81   0.43        0.23     0.16\n---------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nCorrelations tables\n\n\n\n\n\nlibrary(psych)\npartial.r(acad0, c(\"salary\", \"time\"), \"pubs\")\n# partial correlations \n#        salary time\n# salary   1.00 0.53\n# time     0.53 1.00\n\npartial.r(acad0, c(\"salary\", \"pubs\"), \"time\")\n# partial correlations \n#        salary pubs\n# salary   1.00 0.23\n# pubs     0.23 1.00\n\ncor2(acad0[c(\"time\", \"pubs\")], acad0[\"salary\"])\n#      salary\n# time   0.71\n# pubs   0.59\n\n\n\nCorrelations with salary\n\n\n\n\n\n\n\n\\(r\\) (simple)\n\\(pr\\) (partial)\n\\(sr\\) (semi-partial)\n\n\n\n\ntime\n0.71\n0.53\n0.43\n\n\npubs\n0.59\n0.23\n0.16\n\n\n\n\n\n \n\n\n\n\n\n\n\\(r^2\\)\n\\(pr^2\\)\n\\(sr^2\\)\n\n\n\n\ntime\n0.50\n0.28\n0.18\n\n\npubs\n0.35\n0.05\n0.03\n\n\n\n\n\n\n\nSummarizing the results for the running example, we found \\(sr^2\\) = .1850, \\(pr^2\\) = .2826 and \\(sr^2\\) = .0258, \\(pr^2\\) = .0522. Whichever base we use, it is clear that number of publications (\\(X_2\\)) has virtually no unique relationship to salary, that is, no relationship beyond what can be accounted for by time since doctorate (\\(X_1\\)). On the other hand, time since doctorate (\\(X_1\\)) is uniquely related to salary (\\(sr_1\\)) and to salary holding publications constant (\\(pr_1\\)) to a quite substantial degree. (p.75)\n\n\n회귀계수의 상대적 중요성\n참고: Chapter 8. Assessing the Importance of Regressors,\nin Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n모든 상황에 적용할 수 있는 하나의 방법은 없으며,\n연구 내용과 측정 변수들의 특성에 따라 적절한 방법을 선택. (여전히 논쟁 중이며, 연구 중)\n\n표준화 회귀계수 (standardized regression coefficient)\nSemi-partial correlation coefficient (sr) **\nSemi-partial correlation squared (\\(sr^2\\)) (by David C. Howell)\nDominance analysis\n\n\n표준화 회귀계수 (\\(\\beta\\))\nStandardized regression coefficient\n\n표준화하여 각 변수들의 단위가 1sd로 같아져 계수들 간에 비교가 용이하나\n표준화에 (심각하게) 반대하는 의견도 있음.\n\n현 표본의 특성을 반영하여, 샘플들마다 계수값이 크게 달라질 수 있음. (특히, 변수들간의 상관이 큰 경우)\n표준화가 무의미한 변수들도 존재하며; ex. 성별\n인과적 의미를 지니려면 원 단위로 표현하는 것이 더 적절함. (1sd 만큼 늘어났다는 것이 의미가 있을까?)\n\nSimple regression의 경우, \\(\\beta = r\\) 즉, 표준화 회귀계수는 상관계수와 같음.\n\n\\(b = r\\),   (\\(b=r \\frac{sd_Y}{sd_X}\\))\n\\(b_i = \\beta_i \\frac{sd_Y}{sd_i}\\)\n\n\nR에서 표준화 계수를 구하는 방식: scale(), summ()\n\nscale() 함수로 각 변수들을 직접 표준화\n참고: 표준화 한 후 estimate한 방식 vs. estimate한 후 표준화한 방식\n\n\nacad0 <- acad0 |> \n  mutate(\n    time_std = scale(time),\n    pubs_std = scale(pubs),\n    salary_std = scale(salary)\n  )\n\n또는 formula에서 직접 처리\n\nbroom::tidy(lm(scale(salary) ~ scale(time) + scale(pubs), data = acad0))\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept) 2.37e-16     0.191  1.24e-15  1.00  \n2 scale(time) 5.70e- 1     0.262  2.17e+ 0  0.0504\n3 scale(pubs) 2.13e- 1     0.262  8.14e- 1  0.432 \n\n\n\nsumm() 함수의 옵션 scale, transform.response을 이용\n\n\n선별적으로 표준화할 변수를 지정할 수 없어서 부적절한 경우 존재\n\n\nsumm(mod3, scale = TRUE, transform.response = TRUE, model.info = FALSE, model.fit = FALSE) |> print()\n\nStandard errors: OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.00   0.19     0.00   1.00\ntime                0.57   0.26     2.17   0.05\npubs                0.21   0.26     0.81   0.43\n-----------------------------------------------\n\nContinuous variables are mean-centered and scaled by 1 s.d.\n\n\nmod3에서 연봉에 미치는 연차와 논문수의 상대적 중요성에 대한 지표 비교\n\n\n\n\n\n\n\n\\(\\beta\\)\n\\(sr\\)\n\\(sr^2\\)\n\n\n\n\ntime\n0.57\n0.43\n0.18\n\n\npubs\n0.21\n0.16\n0.03\n\n\n\n\n\n \n\n\n\n\n\n\nModel Comparison\n\nmod1 vs. mod3: nested model\n\n\nmod1 <- lm(salary ~ time, data = acad0)\nmod3 <- lm(salary ~ time + pubs, data = acad0)\n\n\n\n\n\n연차로 연봉의 변량을 설명한 모형에 논문 수가 예측변수로 추가되었을 때, 추가로 연봉의 변량을 얼마나 설명하는가?\n\\(R^2\\)의 증가량을 통해 파악할 수 있음.\n\\(\\Delta R^2\\) = 0.530 - 0.505 = 0.025\n\\(sr^2\\) 과 동일 (semi-partial squared)\n\n\n\n\n\n\n\n\nglance(mod1)  # library(broom)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.505         0.466 5763.      13.2 0.00300     1  -150.  306.  308.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\nglance(mod3)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.530         0.452 5839.      6.78  0.0107     2  -150.  307.  310.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\n\\(\\Delta R^2\\) 가 통계적으로 유의한지, 즉 유의하지 증가했는지를 확인\n\nanova(mod1, mod3)\n\n# A tibble: 2 × 6\n  Res.Df        RSS    Df `Sum of Sq`      F `Pr(>F)`\n   <dbl>      <dbl> <dbl>       <dbl>  <dbl>    <dbl>\n1     13 431731655.    NA         NA  NA       NA    \n2     12 409159359.     1   22572295.  0.662    0.432\n\n\n 2. mod2 vs. mod3: nested model\n\nmod2 <- lm(salary ~ pubs, data = acad0)\nmod3 <- lm(salary ~ time + pubs, data = acad0)\n\n\n\n\n\n논문수로 연봉의 변량을 설명한 모형에 연차가 예측변수로 추가되었을 때, 추가로 연봉의 변량을 얼마나 설명하는가?\n\\(R^2\\)의 증가량을 통해 파악할 수 있음.\n\\(\\Delta R^2\\) = 0.530 - 0.346 = 0.184\n\\(sr^2\\) 과 동일 (semi-partial squared)\n\n\n\n\n\n\n\n\nglance(mod2)  # library(broom)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.346         0.295 6624.      6.86  0.0212     1  -152.  310.  312.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\nglance(mod3)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.530         0.452 5839.      6.78  0.0107     2  -150.  307.  310.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\n\\(\\Delta R^2\\) 가 통계적으로 유의한지, 즉 유의하지 증가했는지를 확인\n\nanova(mod2, mod3)\n\n# A tibble: 2 × 6\n  Res.Df        RSS    Df `Sum of Sq`     F `Pr(>F)`\n   <dbl>      <dbl> <dbl>       <dbl> <dbl>    <dbl>\n1     13 570340401.    NA         NA  NA     NA     \n2     12 409159359.     1  161181042.  4.73   0.0504"
  },
  {
    "objectID": "contents/regression2.html#patterns-of-association",
    "href": "contents/regression2.html#patterns-of-association",
    "title": "Multiple Regression",
    "section": "Patterns of Association",
    "text": "Patterns of Association\n\nDirect and Indirect Effects\n만약, 다음과 같은 인과모형을 세운다면,\n\n\n연차가 연봉에 미치는 효과가 두 경로로 나뉘어지고,\n연차 \\(\\rightarrow\\) 연봉: 직접효과 $983\n연차 \\(\\rightarrow\\) 논문 \\(\\rightarrow\\) 연봉: 간접효과 1.98 x $122 = $241.56\n두 효과를 더하면: $983 + $241.56 = $1224.56 = 논문수를 고려하지 않았을 때 연차의 효과\n\n즉, 연차가 1년 늘때 연봉이 $1224 증가하는 것은 연차 자체의 효과($983)와 논문의 증가에 따른 효과($241)가 합쳐져 나온 결과라고 말할 수 있음.\n\n이 때, 논문의 수가 연차와 연봉의 관계를 (부분) 매개한다고 표현. (mediation)\n\n만약, 연차의 효과 $1224이 논문수를 고려했을 때 줄어든($983) 수준을 훨씬 넘어 통계적으로 유의하지 않을 정도로 0에 가까워진다면, 연차의 효과는 모두 논문의 효과를 거쳐 나타나는 것이라고 말할 수 있음. 이 때, 완전 매개 (fully mediate)한다고 표현함.\n\n매개효과의 통계적 분석 절차는 여러 방식이 제시되고 있으나, 일반적인 절차는 부트스랩핑(bootstraping)을 통해 추정.\n\nlibrary(psych)\nmod_med <- mediate(salary ~ time + (pubs), data = acad0)\n\n\n\nsummary(mod_med)\n\nCall: mediate(y = salary ~ time + (pubs), data = acad0)\n\nDirect effect estimates (traditional regression)    (c') X + M on Y \n            salary      se     t df     Prob\nIntercept 43082.39 3099.49 13.90 12 9.26e-09\ntime        982.87  452.06  2.17 12 5.04e-02\npubs        121.80  149.70  0.81 12 4.32e-01\n\nR = 0.73 R2 = 0.53   F = 6.78 on 2 and 12 DF   p-value:  0.0107 \n\n Total effect estimates (c) (X on Y) \n            salary      se     t df     Prob\nIntercept 43658.59 2978.02 14.66 13 1.83e-09\ntime       1224.39  336.48  3.64 13 3.00e-03\n\n 'a'  effect estimates (X on M) \n          pubs   se    t df    Prob\nIntercept 4.73 5.59 0.85 13 0.41300\ntime      1.98 0.63 3.14 13 0.00783\n\n 'b'  effect estimates (M on Y controlling for X) \n     salary    se    t df  Prob\npubs  121.8 149.7 0.81 12 0.432\n\n 'ab'  effect estimates (through all  mediators)\n     salary   boot     sd   lower upper\ntime 241.53 229.28 283.68 -308.58 779.9\n\n\n\n\n\nSpurious Relationships\n사실, 위에서 다룬 데이터(N=15)로만 보자면,\n논문수(pubs)와 연봉(salary)의 관계는 spurious한 관계라고 잠정적으로 말할 수 있음.\n\n연차(time)가 “통계적으로 통제” 혹은 “partial out” 되었을 때,\npartial correlation \\(pr\\) = 0.23 이며, 그 제곱 \\(pr^2\\) = 0.05\n뿐만 아니라, not significant\n\n연차(time)를 논문수와 연봉의 common cause 라고 말하며, confounding이 되어 논문수와 연봉의 인과관계는 실제로 없을 수 있음을 암시함.\n\n\n\n\nCausal Relations\n세 변수 간의 일반적인 인과관계의 형태에 대해서 분류해보면, (p.76, p.458)\n\n흔히 나타나는 partial redundancy인 Model B의 예를 보면,\n\nModerators (조절변수): interaction effects\nex. 연령(X)에 따라 지구력(Y)이 감소하는 관계가 운동한 기간(Z)에 따라 변화"
  },
  {
    "objectID": "contents/reports.html",
    "href": "contents/reports.html",
    "title": "Reports",
    "section": "",
    "text": "acad0 <- read_csv(\"data/c0301dt.csv\")\n\nmod1 <- lm(salary ~ time, data = acad0)\nmod2 <- lm(salary ~ pubs, data = acad0)\n\nmod3 <- lm(salary ~ time + pubs, data = acad0)\n\n\nlibrary(jtools)\nsumm(mod3)  # library(jtools)\n\n\n\n\n\n\n  \n    Observations \n    15 \n  \n  \n    Dependent variable \n    salary \n  \n  \n    Type \n    OLS linear regression \n  \n\n \n\n  \n    F(2,12) \n    6.78 \n  \n  \n    R² \n    0.53 \n  \n  \n    Adj. R² \n    0.45 \n  \n\n \n \n  \n      \n    Est. \n    S.E. \n    t val. \n    p \n  \n \n\n  \n    (Intercept) \n    43082.39 \n    3099.49 \n    13.90 \n    0.00 \n  \n  \n    time \n    982.87 \n    452.06 \n    2.17 \n    0.05 \n  \n  \n    pubs \n    121.80 \n    149.70 \n    0.81 \n    0.43 \n  \n\n\n Standard errors: OLS\n\n\n\n\n\n\nsumm(mod3, scale = TRUE, transform.response = TRUE)\n\n\n\n\n\n\n  \n    Observations \n    15 \n  \n  \n    Dependent variable \n    salary \n  \n  \n    Type \n    OLS linear regression \n  \n\n \n\n  \n    F(2,12) \n    6.78 \n  \n  \n    R² \n    0.53 \n  \n  \n    Adj. R² \n    0.45 \n  \n\n \n \n  \n      \n    Est. \n    S.E. \n    t val. \n    p \n  \n \n\n  \n    (Intercept) \n    0.00 \n    0.19 \n    0.00 \n    1.00 \n  \n  \n    time \n    0.57 \n    0.26 \n    2.17 \n    0.05 \n  \n  \n    pubs \n    0.21 \n    0.26 \n    0.81 \n    0.43 \n  \n\n\n Standard errors: OLS; Continuous variables are mean-centered and scaled by 1 s.d.\n\n\n\n\n\n\nlibrary(sjPlot)\ntab_model(mod3, show.std = TRUE)\n\n\n\n\n\n\n \nsalary\n\n\nPredictors\nEstimates\nstd. Beta\nCI\nstandardized CI\np\n\n\n(Intercept)\n43082.39\n0.00\n36329.18 – 49835.61\n-0.42 – 0.42\n<0.001\n\n\ntime\n982.87\n0.57\n-2.08 – 1967.81\n-0.00 – 1.14\n0.050\n\n\npubs\n121.80\n0.21\n-204.36 – 447.97\n-0.36 – 0.78\n0.432\n\n\nObservations\n15\n\n\nR2 / R2 adjusted\n0.530 / 0.452\n\n\n\n\n\n\n\n\n\ntab_model(mod2, mod3)\n\n\n\n\n\n\n \nsalary\nsalary\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n46357.45\n39719.22 – 52995.68\n<0.001\n43082.39\n36329.18 – 49835.61\n<0.001\n\n\npubs\n335.53\n58.85 – 612.20\n0.021\n121.80\n-204.36 – 447.97\n0.432\n\n\ntime\n\n\n\n982.87\n-2.08 – 1967.81\n0.050\n\n\nObservations\n15\n15\n\n\nR2 / R2 adjusted\n0.346 / 0.295\n0.530 / 0.452\n\n\n\n\n\n\n\n\n\nlibrary(modelsummary)\nmodelsummary(mod3)\n\n\n\n\n\n \n  \n      \n     (1) \n  \n \n\n  \n    (Intercept) \n    43082.394 \n  \n  \n     \n    (3099.493) \n  \n  \n    time \n    982.867 \n  \n  \n     \n    (452.057) \n  \n  \n    pubs \n    121.801 \n  \n  \n     \n    (149.699) \n  \n  \n    Num.Obs. \n    15 \n  \n  \n    R2 \n    0.530 \n  \n  \n    R2 Adj. \n    0.452 \n  \n  \n    AIC \n    307.4 \n  \n  \n    BIC \n    310.2 \n  \n  \n    Log.Lik. \n    −149.696 \n  \n  \n    RMSE \n    5222.77 \n  \n\n\n\n\n\n\n\n\nlibrary(gtsummary)\n\n# summarize the data with our package\ntbl_summary(trial, include = c(age, grade, response))\ntbl_regression(mod3)\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 2001\n    \n  \n  \n    Age\n47 (38, 57)\n        Unknown\n11\n    Grade\n\n        I\n68 (34%)\n        II\n68 (34%)\n        III\n64 (32%)\n    Tumor Response\n61 (32%)\n        Unknown\n7\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    time\n983\n-2.1, 1,968\n0.050\n    pubs\n122\n-204, 448\n0.4\n  \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "contents/regression1.html",
    "href": "contents/regression1.html",
    "title": "Correlation/Simple Regression",
    "section": "",
    "text": "통계에서 데이터의 타입은 대략 다음과 같이 나누어짐"
  },
  {
    "objectID": "contents/regression1.html#linear-correlation의-계산",
    "href": "contents/regression1.html#linear-correlation의-계산",
    "title": "Correlation/Simple Regression",
    "section": "Linear correlation의 계산",
    "text": "Linear correlation의 계산\n교수의 연봉(salary), 학위를 받은 후 지난 시간(time since Ph.D.), 출판물의 수(pubs)의 관계\nData: c0301dt.csv\n\n\n# A tibble: 15 x 3\n    time  pubs salary\n   <dbl> <dbl>  <dbl>\n 1     3    18  51876\n 2     6     3  54511\n 3     3     2  53425\n 4     8    17  61863\n 5     9    11  52926\n 6     6     6  47034\n 7    16    38  66432\n 8    10    48  61100\n 9     2     9  41934\n10     5    22  47454\n11     5    30  49832\n12     6    21  47047\n13     7    10  39115\n14    11    27  59677\n15    18    37  61458\n\n\nThe formula for Pearson’s correlation coefficient; the product moment correlation coefficient\n\\(X, Y\\)에 대한 standardize (Z score); \\(\\displaystyle z_X = \\frac{X-M_X}{sd_X}, \\thinspace z_Y = \\frac{Y-M_Y}{sd_Y}\\)\n\\(r_{XY} = \\displaystyle 1 - \\frac{\\sum{(z_X - z_Y)^2}}{2n}\\)   \\(z_X, z_Y\\) : 각각 standardized \\(X, Y\\)\n\\(r_{XY} = \\displaystyle\\frac{\\sum_{i=1}^{n}{(x_i - \\bar x)(y_i - \\bar y)}}{\\sqrt{\\sum_{i=1}^{n}{(x_i - \\bar x)^2}} \\sqrt{\\sum_{i=1}^{n}{(y_i - \\bar y)^2}}}\\)   \\(\\bar x : X\\) 의 평균,   \\(\\bar y :Y\\) 의 평균\n\ndf <- acad0 |>\n    mutate(\n        z_time = (time - mean(time)) / sd(time),\n        z_pubs = (pubs - mean(pubs)) / sd(pubs),\n        diff = z_time - z_pubs,\n        squared = diff^2\n    ) |>\n    print()\n\n# A tibble: 15 × 7\n    time  pubs salary  z_time  z_pubs   diff squared\n   <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>   <dbl>\n 1     3    18  51876 -1.02   -0.140  -0.880  0.774 \n 2     6     3  54511 -0.364  -1.23    0.861  0.741 \n 3     3     2  53425 -1.02   -1.30    0.278  0.0772\n 4     8    17  61863  0.0728 -0.212   0.285  0.0812\n 5     9    11  52926  0.291  -0.646   0.938  0.879 \n 6     6     6  47034 -0.364  -1.01    0.644  0.415 \n 7    16    38  66432  1.82    1.31    0.514  0.264 \n 8    10    48  61100  0.510   2.03   -1.52   2.31  \n 9     2     9  41934 -1.24   -0.791  -0.447  0.200 \n10     5    22  47454 -0.583   0.150  -0.732  0.536 \n11     5    30  49832 -0.583   0.728  -1.31   1.72  \n12     6    21  47047 -0.364   0.0772 -0.441  0.195 \n13     7    10  39115 -0.146  -0.719   0.573  0.328 \n14    11    27  59677  0.728   0.511   0.217  0.0471\n15    18    37  61458  2.26    1.23    1.02   1.05  \n\n\n\nprint(1 - sum(df$squared) / (2 * 14))\n\n[1] 0.6566546\n\n\n\ncor(acad0) |>\n    round(2) |>  # 반올림 함수\n    print()\n\n       time pubs salary\ntime   1.00 0.66   0.71\npubs   0.66 1.00   0.59\nsalary 0.71 0.59   1.00\n\n\n상관계수 크기에 대한 guidline\n\n\\(| \\thinspace r\\thinspace|<0.3\\): weak\n\\(0.3\\le|\\thinspace r\\thinspace|<0.5\\): moderate\n\\(|\\thinspace r\\thinspace|>0.5\\) : strong relationship\n\n상관계수를 제곱한 \\(r^2\\) 는 변량의 설명 정도를 나타내주는 계수; 결정계수 (\\(R^2\\), \\(R\\) squared)\n이는 좀 더 해석가능한 값이 되고, strength of association를 나타내는 주요한 지표임.\n뒤에서 자세히 다룸.\n\n\n\n\n\n\nTip\n\n\n\n# Base R의 cor()의 옵션들\ncor(acad0, use = \"pairwise.complete.obs\") # NA의 처리: pairwise deletion\n\n# psych 패키지의 corr.test() 또는 lowerCor()이용\nlibrary(psych) \ncorr.test(acad0) # NA를 pairwise deletion으로 처리해줌\n\n## Correlation matrix \n##        time pubs salary\n## time   1.00 0.66   0.71\n## pubs   0.66 1.00   0.59\n## salary 0.71 0.59   1.00\n\n## Sample Size \n## [1] 15\n## Probability values (Entries above the diagonal are adjusted for multiple tests.) \n##        time pubs salary\n## time   0.00 0.02   0.01\n## pubs   0.01 0.00   0.02\n## salary 0.00 0.02   0.00\n## \n##  To see confidence intervals of the correlations, print with the short=FALSE option\n\nlowerCor(acad0)\n##        time pubs salary\n## time   1.00 \n## pubs   0.66 1.00\n## salary 0.71 0.59   1.00"
  },
  {
    "objectID": "contents/regression1.html#시각화를-통한-상관계수",
    "href": "contents/regression1.html#시각화를-통한-상관계수",
    "title": "Correlation/Simple Regression",
    "section": "시각화를 통한 상관계수",
    "text": "시각화를 통한 상관계수\ncorrgram(), ggpairs()\nvignette for corrgram\n\nlibrary(corrgram)\ncorrgram(acad0,\n         order = TRUE,  # 상관계수가 높은 변수들을 가까이 위치시킴\n         upper.panel = panel.cor,   # 상관계수\n         lower.panel = panel.pie,  # 파이 차트\n)\n\n\n\n\n\n\n\n\n\n\ntip: use a function\n\n\n\n\n\ncorgrm <- function(df, order = TRUE){\n    corrgram(df,\n         order = order,  # 상관계수가 높은 변수들을 가까이 위치시킴\n         upper.panel = panel.cor,   # 상관계수\n         lower.panel = panel.pie,  # 파이 차트\n    )\n}\n\ncorgrm(acad0)\ncorgrm(acad0, order = FALSE)\n\n\n\nData from the 1985 Current Population Survey (CPS85)\n임금, 교육수준, 연차, 나이, 성별 간의 상관관계\n\ncps <- mosaicData::CPS85\n\ncps |>\n    select(wage, educ, exper, age, sex) |>\n    mutate(sex = as.numeric(sex)) |>   # factor를 숫자로 변환: 1, 2, ...\n    corrgram(\n         order = TRUE, \n         upper.panel = panel.cor, \n         lower.panel = panel.pie, \n    )\n\n\n\n\n\ncorrgram(acad0,\n         order = FALSE,\n         lower.panel = panel.pts,\n         upper.panel = panel.cor,\n         diag.panel = panel.density\n)\n\n\n\n\n\n# GGally 패키지의 ggpairs()\nGGally::ggpairs(acad0)\n\n\n\n\n\n\n\n\n\n\nTip: includes fitted lines\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .6) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"skyblue\", ...)\n}\n\nggpairs(acad0, columns = 1:3, lower = list(continuous = trendlines))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n명목변수인 경우에도 measure of association을 계산하는 방법이 있는데, 자세한 사항은 Measures of Association - How to Choose? 참조\nR에서 계산은 psych::corr.test()의 옵션 method를 “pearson”, “spearman”, “kendall” 중 선택\n명목변수의 예\n\n한 변수가 binary 인 경우: 물건의 가격 ~ 구매 여부\n두 변수가 모두 binary 인 경우: 남녀 ~ 합격 여부\n두 변수가 rank(ordinal) 인 경우: 다이아몬드 투명도(clarity)와 컬러(color)\n\nbinary인 경우: 0, 1로 코딩\nrank인 경우: 1, 2, 3… 로 코딩"
  },
  {
    "objectID": "contents/regression1.html#simple-linearregression-models",
    "href": "contents/regression1.html#simple-linearregression-models",
    "title": "Correlation/Simple Regression",
    "section": "Simple linear/regression models",
    "text": "Simple linear/regression models\n단순한 상관관계를 넘어서서,\nY가 X에 의해 영향을 받거나 X에 의해 예측되는 변수라는 연구자의 가정이 있음.\n\nY: 종속변수 (dependent variable), regressand, response\n\nX: 독립변수 (independent variable), regressor, 예측변수 (predictor)\n\n선형관계임을 가정하고, 데이터에 가장 근접한 직선을 구함\n이 직선을 주어진 데이터로부터 두 변수 간의 관계를 가장 잘 represent하는 model (모형)이라고 말함.\n이는 확장된 의미에서 물리법칙에서 변수 간의 관계를 수학식으로 표현하고, 자연현상을 모델링한 것으로 이해할 수 있는 것과 같음.\n예를 들어, 다음과 같이 x와 y의 관계가 나타난 경우,\n\n패턴: 강한 선형 관계\n\n\n\n\n\n\nx와 y의 관계에 대한 모형을 세우는데, 모형은 두 부분으로 나눌 수 있음.\n\nA family of models를 정의: generic 패턴을 표현해 줄 수 있는 모델 타입\n예를 들어,\n\n만약, 선형적인 관계라면 선형 모델인 \\(y = a_2 x + a_1\\)\n곡선 관계라면 가령, \\(y = a_3 x^2 + a_2 x + a_1\\)\n\\(a_1, a_2, a_3\\)는 패턴을 잡아 낼수 있도록 변하는 파라미터\n\nA fitted model을 생성: 데이터에 가장 가까운(적합한) 파라미터에 해당하는 특정 모델을 선택;\n”fit a model to data”\n예를 들어,\n\n\\(y = 3x+7\\)\n\\(y = 2x^2 - 4x + 1\\)\n\nA fitted model은 a family of models 중에 데이터에 가장 가까운 모델임\n\n이는 소위 “best” model일 뿐\n“good” model임을 뜻하지 않고, “true” model임을 뜻하는 것은 더더욱 아님\n\n\n이제 위의 예를 보면, 선형성을 가정하고\n\n선형 모델 family인   \\(y = a_2 x + a_1\\)을 세울 수 있음\n무수히 많은 \\(a_1, a_2\\)의 값들 중 위 데이터에 가장 가까운 값을 찾음\n\n이를 “fit a model to data”라고 하고, 그 특정 모델을 fitted model이라고 함\n\n가깝다는 것을 정의하기 위해 데이터와 모델과의 거리를 정의해야 함; \\(d =|~data - model~|\\)\n대표적으로 모델과 데이터의 수직 차이 (잔차; residuals)의 총체로 거리를 정의할 수 있음\n최적의 모델은 이 거리를 최소로 함\n\n     \n\n\n\n\n\n\n\nNote\n\n\n\n\n특히, 다음과 같은 RMSE (root-mean-square deviation)을 기본적인 거리로 정의하고\n\n    \\(RMSE = \\displaystyle\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}{(Y_i -\\hat Y_i)^2}},\\)   \\(Y_i -\\hat Y_i\\) : residual (잔차)\n\n\nMean absolute error: \\(MAE = \\displaystyle\\frac{1}{n} \\sum_{i=1}^{n}{|~Y_i -\\hat Y_i~|}\\)\n\n이상치에 덜 민감함\n\n\n\n\n\n이 거리를 이용해서 모델의 파라미터를 추정하는 것을 ordinary least square (OLS) esimate이라고 함\n\n이 때, 잔차의 합은 0;   \\(\\displaystyle \\sum_{i=1}^{n}{(Y_i -\\hat Y_i)} = 0\\)\n\n이제, 위 예제의 데이터와 꽤 가까운 임의의 20개의 선형 모델을 그려보면 다음과 같고, 이 중 거리가 최소인 모델이 fitted model이 됨\n\n이 때, fitted model의 기울기는 2.05, y절편은 4.22임\n\n\n\n\n\n\nR은 여러 형태의 a family of models을 구성할 수 있는 효율적인 툴을 제공\n\nLinear (regression) models: \\(Y = a_0 + a_1 X_1 + a_2 X_2 + ~... ~ + a_n X_n\\)\n\n앞의 예는 \\(n=1\\) 에 해당하며, \\(Y =a_0 +a_1X_1\\)에 대해서 다음과 같이 편리하게 적용할 수 있음\nsim1_mod <- lm(y ~ x, data = sim1)\n\ncoef(sim1_mod) # 모델의 parameter 즉, coefficients를 내줌\n#> (Intercept)           x \n#>    4.220822    2.051533   # 위에서 구한 파라미터값과 동일함\n\n즉, 앞의 데이터에 최적인 선형 모형은 \\(Y = 4.22 + 2.05X\\)\n\nlm()은 formula y ~ x를 \\(Y =a_0 +a_1X\\) 로 변환해 줌; Y 절편은 formula에서 생략\nLinear models의 경우 위에서 처럼 수치 을 이용하지 않고 방정식의 해를 구하듯 exact form으로 최소값을 구함\n\n\\(n=2\\) 인 경우인 두 변수 \\(X_1\\), \\(X_2\\)로 \\(Y\\)를 예측하는 경우,\nlm(y ~ x1 + x2, data = df)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis formula notation is called “Wilkinson-Rogers notation”, and was initially described in Symbolic Description of Factorial Models for Analysis of Variance by G. N. Wilkinson and C. E. Rogers\n위에서 y ~ x라는 formula는 x, y라는 변수를 바로 evaluate하지 않고, \\(Y = a_0 + a_1X\\)로 해석되어 함수로 전환됨"
  },
  {
    "objectID": "contents/regression1.html#visualising-models",
    "href": "contents/regression1.html#visualising-models",
    "title": "Correlation/Simple Regression",
    "section": "Visualising models",
    "text": "Visualising models\nFitted models을 이해하기 위해 모델이 예측하는 부분(prediction)과 모델이 놓친 부분(residuals)을 시각화해서 보는 것이 유용함\n\nPredictions: the pattern that the model has captured\nResiduals: what the model has missed; 통계 분석의 핵심 요소\n앞서 구한 모형 \\(Y = 4.22 + 2.05X\\) 을 데이터와 함께 그려보면,\n\n\n\n\n\n\n이 모형에 의한 예측값들(pred)과 잔차(resid)들은\n\n\n# A tibble: 30 × 4\n      x     y  pred  resid\n  <int> <dbl> <dbl>  <dbl>\n1     1  4.20  6.27 -2.07 \n2     1  7.51  6.27  1.24 \n3     1  2.13  6.27 -4.15 \n4     2  8.99  8.32  0.665\n5     2 10.2   8.32  1.92 \n6     2 11.3   8.32  2.97 \n7     3  7.36 10.4  -3.02 \n8     3 10.5  10.4   0.130\n# … with 22 more rows\n\n\nResiduals의 분포를 시각화해서 살펴보면,\n\nresiduals의 평균은 항상 0\nresiduals의 분포는 predictions이 관측치로부터 전반적으로 얼마나 벗어났는지에 평가할 수 있음\n\n\n\n\n\n\n예측 변수와 residuals의 관계를 시각화해서 보면,\n\n이 residuals은 특별한 패턴을 보이지 않아야 모델이 데이터의 패턴을 잘 잡아낸 것으로 판단할 수 있음\n또한 어떤 부분에서 예측이 벗어났는지도 판별할 수 있음\n\n\n\n\n\n\n\nResiduals에 패턴이 보이는 경우: 모형을 수정!"
  },
  {
    "objectID": "contents/regression1.html#case-1",
    "href": "contents/regression1.html#case-1",
    "title": "Correlation/Simple Regression",
    "section": "Case 1",
    "text": "Case 1\n교수의 연봉(salary)이 학위를 받은 후 지난 시간(time since Ph.D.)과 출판물의 수(pubs)에 의해 어떻게 영향을 받는가? \n\n\n\n# A tibble: 15 × 3\n   time  pubs salary\n  <dbl> <dbl>  <dbl>\n1     3    18  51876\n2     6     3  54511\n3     3     2  53425\n4     8    17  61863\n5     9    11  52926\n6     6     6  47034\n# … with 9 more rows\n\n\n\n\n\n\n\n\n모형 세우기\n선형모형: lm(y ~ x)\n\n\\(\\hat{Y} = a_0 + a_1X\\),   (\\(\\hat{Y}\\): 예측치)\n또는 \\(Y = a_0 + a_1X +e\\),   (\\(Y\\): 관측치, \\(e\\): 잔차, 에러)\n\\(a_1\\): 기울기 (\\(X\\)가 1 증가할 때, \\(Y\\)의 증가량),   \\(a_0\\): 절편 (\\(X\\)가 0일 때, \\(Y\\)의 값)\n\n\nmod1 <- lm(salary ~ time, data = acad0): \\(\\widehat{salary} = a_0 + a_1time\\)\nmod2 <- lm(salary ~ pubs, data = acad0): \\(\\widehat{salary} = a_0 + a_1pubs\\)\n\n\nFit a model to data\n데이터에 가장 근접한 모델\n\nmod1 <- lm(salary ~ time, data = acad0)\nmod2 <- lm(salary ~ pubs, data = acad0)\n\ncoef(mod1)\n## (Intercept)        time \n##   43658.594    1224.392\ncoef(mod2)\n## (Intercept)        pubs \n##   46357.449     335.526\n\n\nModel 1: \\(\\widehat{salary} = \\$43,659 + \\$1,224\\:time\\)\n\\(a_1\\): 학위를 받은 후 1년이 지날 때마다, 연봉은 $1,224 오름 (표현에 주의!)\n\\(a_0\\): 학위를 받은 후 0년일 때, 연봉은 $43,658; 0년이 의미있는가?\nModel 2 : \\(\\widehat{salary} = \\$46,357 + \\$336\\:pubs\\)\n\\(a_1\\): 출판물 1편을 추가로 발표하면, 연봉은 $336 오름 (표현에 주의!)\n\\(a_0\\): 출판물이 0편일 때, 연봉은 $46,357\n\n\n\n\n\n\n\n\n\n\n\n연봉(salary)을 연차(time)로 예측하는 모델(mod1)에 대해서 prediction과 residuals 값을 구해보면\n단, 간편한 계산을 위해 salary를 1000으로 나누었으며, 51.876는 $51,876을 의미\n\n아래 테이블에서 가령, 6년차인 교수의 연봉은 모형에 의해 $51,000로 예측되고,\n2번째 교수의 경우 그 예측이 $3,510 정도 낮게 예측되었으며,\n6번째 교수의 경우는 $3,9700 정도 높게 예측되었음\n예측이 틀린 정도, 즉 잔차는 왜 생기는가? …\n\n\n\n\n\n\nImportant\n\n\n\n모형의 분석은 예측/설명되는 부분과 예측/설명되지 않는 부분으로 쪼개어 보는 것이 기본적인 시각\n예들 들어, 연차로 연봉을 설명할 수는 있는 부분 vs. 연차로 연봉이 설명되지 않는 부분!\n\n\n\n\n\n   time salary  pred  resid (pred-m)^2 resid^2 (salary-m)^2\n1     3  51.88 47.33   4.54      32.65   20.65         1.37\n2     6  54.51 51.00   3.51       4.16   12.29         2.15\n3     3  53.42 47.33   6.09      32.65   37.13         0.14\n4     8  61.86 53.45   8.41       0.17   70.72        77.75\n5     9  52.93 54.68  -1.75       2.67    3.07         0.01\n6     6  47.03 51.00  -3.97       4.16   15.77        36.14\n7    16  66.43 63.25   3.18     104.11   10.13       179.20\n8    10  61.10 55.90   5.20       8.16   27.01        64.87\n9     2  41.93 46.11  -4.17      48.14   17.42       123.47\n10    5  47.45 49.78  -2.33      10.66    5.41        31.27\n11    5  49.83 49.78   0.05      10.66    0.00        10.33\n12    6  47.05 51.00  -3.96       4.16   15.67        35.98\n13    7  39.12 52.23 -13.11       0.67  171.99       194.06\n14   11  59.68 57.13   2.55      16.66    6.50        43.98\n15   18  61.46 65.70  -4.24     160.07   17.97        70.77\n\n\n\n\n\n\n\n\ngraphical representation\n\n\n\n\n\n\n\n\n\nColumn별로 더하면\n\n\n  time salary   pred resid (pred-m)^2 resid^2 (salary-m)^2\n1  115 795.68 795.68     0     439.75  431.73       871.48\n\n\n우선, 연봉의 합 \\(\\sum{Y}\\) = 예측값의 합 \\(\\sum{\\hat{Y}}\\)  : \\(X\\) 의 평균은 모형에 의해 Y의 평균으로 예측됨\n\n\n\n\n\n\nImportant\n\n\n\nPartitioning of variances\n\\(\\sum{(\\hat{Y}-m)^2}=439.75\\) : 연차의 변량 (variation)으로 모형에 의해 설명되는 (attribute/acount for) 연봉의 변량\n\\(\\sum{(Y-\\hat{Y})^2}=431.73\\) : 연차의 변량 (variation)으로 모형에 의해 설명될 수 없는 (not attribute) 연봉의 변량\n\\(\\sum{(Y-m)^2}=871.48\\) : 연봉의 변량\n이 세 값의 관계는 \\(\\sum{(\\hat{Y}-m)^2} + \\sum{(Y-\\hat{Y})^2} = \\sum{(Y-m)^2}\\)\n\nSum of squares (SS)로 부르며,\n\nSSR, SSE, SSY (각각 sum of squares of Regression, Error, Y)\n\n\n\n위 값을 다시 N(=15)으로 나누면, 즉 column별 평균은\n\n\n  time salary  pred resid (pred-m)^2 resid^2 (salary-m)^2\n1 7.67  53.05 53.05     0      29.32   28.78         58.1\n\n\n위의 관계는 variance (분산)으로 보면,\n  \\(V(predictions) + V(residuals) = V(Y)\\)\n이렇게 간결하게 쪼개지는 것은 predictions과 residuals이 서로 독립(\\(r=0\\))이 되기 때문으로 이해할 수 있음\n\npredictions \\(\\hat{Y}\\) 은 \\(X\\) 의 일차 함수식으로 얻어진 것이므로 \\(X\\) 와 \\(r=1\\) 이 되고,\nresiduals \\(Y-\\hat{Y}=Y-T(X)\\) 과 \\(\\hat{Y}\\)이 상관이 있다면, \\(X\\) 와 \\(Y-\\hat{Y}\\) 과의 상관이 존재해야하는데, 이는 OLS estimate에 어긋남\n# correlations with residuals\n#         pred time salary\n# resid  0.00 0.00  0.704\n# salary 0.71 0.71  1.000\n\n다시 위의 식에서 \\(V(Y)\\) 로 양변을 나누면\n  \\(\\displaystyle\\frac{V(predictions)}{V(Y)} + \\frac{V(residuals)}{V(Y)} = 1\\)\n\n\n\n\n\n\nImportant\n\n\n\n즉, “모형에 의해 설명되는 \\(Y\\) 변량의 비율” + “모형에 의해 설명되지 않는 \\(Y\\) 변량의 비율” = 1\n첫 항을 \\(R^2\\) 라고 하고, 결정계수 혹은 R squared라고 부름\n따라서, \\(1-R^2\\) 는 설명되지 않는 변량의 비율이라고 할 수 있음\n\n\n\\(R^2\\) 를 제곱근하면 \\(R\\) 이 나오고, 이는 Pearson’s correlation coefficient와 동일함;\n\n\\(R = cor(Y, X) = cor(Y, \\hat{Y}=aX+b), ~a = r_{XY} \\frac{sd_Y}{sd_X}\\)\n\\(R\\) 은 예측의 정확성에 대한 지표라고 이해할 수 있음\n\nOverlap in variance of correlated variables\n\n\n\n\n\n\n\nANOVA\n\n\n\n모형 자체에 대한 분석으로 ANOVA 결과는 anova()함수를 써서 볼 수 있음\n모집단에 대한 추론: 모형의 설명력이 모집단에서 0은 아닐 것이라는 추론;\n\nNull 모형 대비 주어진 모형이 잔차를 얼마나 줄였는가를 테스트함으로써 주어진 모형의 설명력이 0은 아님을 보임\n\nNull 모형: y ~ 1 (예측변수가 없는 모형, 설명력 0)\n\n잔차 변량(SSE) 대비 예측 변량(SSR)이 얼마나 큰가를 F분포를 이용해 통계적 추론이 이루어짐\n\n[주어진 모형의 잔차 변량 (SSE)] - [null 모형의 잔차 변량] = SSE - SSY = SSR\n즉, 추가된 예측 변수에 의해 설명되는 변량 정도가 sampling error, 즉 표본 추출에 따른 우연성에 의해 나타날 수 있을 확률을 계산\n\n\nanova(mod1)\n# Analysis of Variance Table\n\n# Response: salary\n#           Df Sum Sq Mean Sq F value Pr(>F)   \n# time       1 439.75  439.75  13.241  0.003 **\n# Residuals 13 431.73   33.21                  \n# ---\n# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n대략, (예측변수로 설명되지 않는 Y인) 잔차의 평균 변량: \\(\\sqrt{mean~of~SSE} = \\sqrt{33.21} = 5.763\\)\n\n대략 말하면, 모형이 예측한 연봉과 실제 연봉의 차이는 평균 $5,763 정도 된다는 것을 의미함\n\n\n\n\n모형 \\(\\widehat{salary} = a_0 + a_1time\\) 에 대한\nSPSS 결과 테이블:\n\n\nsummary(mod1)\n\n\nCall:\nlm(formula = salary ~ time, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1143  -3.9644   0.0514   4.0251   8.4093 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  43.6586     2.9780  14.660 1.83e-09 ***\ntime          1.2244     0.3365   3.639    0.003 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.763 on 13 degrees of freedom\nMultiple R-squared:  0.5046,    Adjusted R-squared:  0.4665 \nF-statistic: 13.24 on 1 and 13 DF,  p-value: 0.003\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\\(R^2\\) 는 모형이 predictor들로부터 Y의 변량을 얼마나 예측/설명해주는지에 대한 지표로서 가장 널리 쓰임.\n다음의 두 경우는 1년의 연차가 $1,224의 연봉 증가로 나타나는 동일한 관계를 보여주지만, 그 strength of association에는 큰 차이가 있음\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n출판물의 수(pubs)가 연봉(salary)에 어떻게 영향을 미치는지 살펴보세요."
  },
  {
    "objectID": "contents/regression1.html#case-2",
    "href": "contents/regression1.html#case-2",
    "title": "Correlation/Simple Regression",
    "section": "Case 2",
    "text": "Case 2\n다음 데이터는 the Octogenarian Twin Study of Aging에서 나타나는 패턴을 기반으로 생성한 데이터\n출처: Longitudinal Analysis: Modeling Within-Person Fluctuation and Change by Lesa Hoffman\n\nincludes 550 older adults age 80 to 97 years.\nCognition was assessed by the Information Test, a measure of general world knowledge (i.e., crystallized intelligence; range = 0 to 44)\ndemgroup 1: those who will not be diagnosed with dementia (none group = 1; 72.55%),\ndemgroup 2: those who will eventually be diagnosed with dementia later in the study (future group = 2; 19.82%)\ndemgroup 3: those who already have been diagnosed with dementia (current group = 3; 7.64%)\n\nspss_chapter2.csv\n\ncognition <- read_csv(\"data/spss_chapter2.csv\")\ncognition |> print()\n\n# A tibble: 550 x 6\n  PersonID cognition   age  grip sexMW demgroup\n     <dbl>     <dbl> <dbl> <dbl> <dbl>    <dbl>\n1        1        23  92.6     9     1        1\n2        2        24  91.8    11     0        2\n3        3        29  92.6    12     0        1\n4        4        16  94.4     6     1        1\n5        5        27  85.8     9     1        1\n6        6        37  83.1    11     0        1\n# i 544 more rows\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .6) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"skyblue\", ...)\n}\n\nggpairs2 <- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\nggpairs2(cognition, columns = 2:6)\n\n\n\n\n\n\n\n\n\nlibrary(psych)\ncorr.test(cognition[-1])$r |>  # r만 선택, inference부분 제외\n    round(2) |>\n    print()\n\n          cognition   age  grip sexMW demgroup\ncognition      1.00 -0.17  0.24 -0.24    -0.41\nage           -0.17  1.00 -0.18  0.05     0.01\ngrip           0.24 -0.18  1.00 -0.40     0.04\nsexMW         -0.24  0.05 -0.40  1.00     0.01\ndemgroup      -0.41  0.01  0.04  0.01     1.00\n\n\n\n\n\n\n\n\nTip\n\n\n\ncognition |>\n    select(cognition, age, grip) |>\n    corr.test()\n          cognition   age  grip\n# cognition      1.00 -0.17  0.24\n# age           -0.17  1.00 -0.18\n# grip           0.24 -0.18  1.00\n\ncorr.test(cognition[\"cognition\"], cognition[c(\"age\", \"grip\")])\n# Correlation matrix \n#             age grip\n# cognition -0.17 0.24\n\n\n\ncognition |>\n    ggplot(aes(x = grip, y = cognition)) +\n    geom_point(alpha=.5) +\n    geom_smooth()\n\n\n\n\n\nmod_cog <- lm(cognition ~ grip, data = cognition)\nsummary(mod_cog)\n\n\nCall:\nlm(formula = cognition ~ grip, data = cognition)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-27.3941  -7.1578   0.3877   8.8377  22.8422 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  16.7033     1.4640  11.409  < 2e-16 ***\ngrip          0.8909     0.1527   5.834 9.24e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.67 on 548 degrees of freedom\nMultiple R-squared:  0.05848,   Adjusted R-squared:  0.05677 \nF-statistic: 34.04 on 1 and 548 DF,  p-value: 9.244e-09\n\n\n\n기울기 0.89를 의미있게 해석할 수 있는가?\n\n절편 16.7은?\n\\(R^2\\) = 0.058; 악력의 변량으로 인지능력 변량의 5.8%가 설명됨\n\n\n\n\n\n\n\nTip: summ()\n\n\n\n\n\nlibrary(jtools)\nsumm(mod_cog)\n\n# MODEL INFO:\n# Observations: 550\n# Dependent Variable: cognition\n# Type: OLS linear regression \n\n# MODEL FIT:\n# F(1,548) = 34.04, p = 0.00\n# R<U+00B2> = 0.06\n# Adj. R<U+00B2> = 0.06 \n\n# Standard errors: OLS\n# ------------------------------------------------\n#                      Est.   S.E.   t val.      p\n# ----------------- ------- ------ -------- ------\n# (Intercept)         16.70   1.46    11.41   0.00\n# grip                 0.89   0.15     5.83   0.00\n# ------------------------------------------------\n\n\n\n\n변수의 표준화\nstandardize/normalize:   \\(\\displaystyle z = \\frac{x-m}{sd}; ~ax+b\\) : zoom + translate\n\n변수를 표준화하면 평균이 0이고, 표준편차가 1로 변환\n변수가 대략적으로 정규분포(normal distribution)을 따를 때,\n내재적인 단위가 없는 측정치들의 경우 그 값을 표준화시키면 해석이 용이하며,\n표준편차(sd)가 그 눈금/단위가 됨으로써 변수에 상관없이 동일한 눈금을 갖게 되어, 변수들 간의 비교가 가능해짐\n\n즉, 표준화된 변수의 1은 1sd를 의미\n\n또한, 평균이 0이 됨으로써 선형모형에서 용이한 trick을 제공해 줌\n변수를 표준화해도 사실상 중요한 통계치는 변화하지 않음; 상관계수, \\(R^2\\), \\(p\\) value 등\n\n좀 더 일반적으로 linear transform에 의해서 변하지 않음; 온도 C/F\n\n반면, 주어진 샘플의 평균과 표준편차를 사용하므로 샘플마다 변동이 생길 수 있음을 인지해야 함.\n\n\n cognition <- cognition |>\n     select(cog_std = cognition, grip_std = grip) |>\n     scale() |>  # standardize 함수\n     bind_cols(cognition)  # column bind: 열 방향으로 두 데이터프레임을 붙힘\n\ncognition |> print()\n\n# A tibble: 550 x 8\n  cog_std grip_std PersonID cognition   age  grip sexMW demgroup\n    <dbl>    <dbl>    <dbl>     <dbl> <dbl> <dbl> <dbl>    <dbl>\n1 -0.166   -0.0378        1        23  92.6     9     1        1\n2 -0.0748   0.633         2        24  91.8    11     0        2\n3  0.380    0.968         3        29  92.6    12     0        1\n4 -0.803   -1.04          4        16  94.4     6     1        1\n5  0.198   -0.0378        5        27  85.8     9     1        1\n6  1.11     0.633         6        37  83.1    11     0        1\n# i 544 more rows\n\n\n\ncognition |>\n    ggplot(aes(x = grip_std, y = cog_std)) +\n    geom_point(alpha=.5) +\n    geom_smooth(method=lm)\n\ncognition |>\n    ggplot(aes(x = grip, y = cognition)) +\n    geom_point(alpha=.5) + \n    geom_smooth(method=lm)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggpubr)\ncognition |>\n    ggplot(aes(x = cognition, y = after_stat(density))) +\n    geom_freqpoly(binwidth=2) +\n    stat_overlay_normal_density(color = \"red\")\n\ncognition |>\n    ggplot(aes(x = grip, y = after_stat(density))) +\n    geom_freqpoly(binwidth=1) +\n    stat_overlay_normal_density(color = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nNormal distribution 정규 분포; 사실상 sd만으로 결정되는 분포 곡선\n\n  Source: The Truthful Art by Albert Cairo\n\nmod_cog_std <- lm(cog_std ~ grip_std, data = cognition)\nsummary(mod_cog_std) |> print(digits = 2)\n\n\nCall:\nlm(formula = cog_std ~ grip_std, data = cognition)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.493 -0.651  0.035  0.804  2.079 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.2e-16    4.1e-02     0.0        1    \ngrip_std     2.4e-01    4.1e-02     5.8    9e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.97 on 548 degrees of freedom\nMultiple R-squared:  0.058, Adjusted R-squared:  0.057 \nF-statistic:  34 on 1 and 548 DF,  p-value: 9.2e-09\n\n\n\n\n\\(R^2\\) 와 p values는 변함이 없으며, y intercept (y 절편)은 0\n기울기 0.24는 두 변수 간의 Pearson’s 상관계수와 같음\n\n\n\n\n\n\n\nTip: summ(df, scale = TRUE, transform.response = TRUE)\n\n\n\n\n\nlibrary(jtools)\n\n# scale: predictors 표준화, transform.response: response 표준화\nsumm(mod_cog_std, scale = TRUE, transform.response = TRUE)  # digits = 3, center = TRUE\n\n# ------------------------------------------------\n#                      Est.   S.E.   t val.      p\n# ----------------- ------- ------ -------- ------\n# (Intercept)         -0.00   0.04    -0.00   1.00\n# grip_std             0.24   0.04     5.83   0.00\n# ------------------------------------------------\n\n# Continuous variables are mean-centered and scaled by 1 s.d."
  },
  {
    "objectID": "contents/regression1.html#case-3",
    "href": "contents/regression1.html#case-3",
    "title": "Correlation/Simple Regression",
    "section": "Case 3",
    "text": "Case 3\n성별에 따라 인지능력(cognition)에 차이가 있는가?\n성별에 따라 악력(grip)에 차이가 있는가?\n\ncognition <- cognition |>\n    mutate(sex = factor(sexMW, levels = c(0, 1), labels = c(\"male\", \"female\")))\ncognition |> print()\n\n# A tibble: 550 x 9\n  cog_std grip_std PersonID cognition   age  grip sexMW demgroup sex   \n    <dbl>    <dbl>    <dbl>     <dbl> <dbl> <dbl> <dbl>    <dbl> <fct> \n1 -0.166   -0.0378        1        23  92.6     9     1        1 female\n2 -0.0748   0.633         2        24  91.8    11     0        2 male  \n3  0.380    0.968         3        29  92.6    12     0        1 male  \n4 -0.803   -1.04          4        16  94.4     6     1        1 female\n5  0.198   -0.0378        5        27  85.8     9     1        1 female\n6  1.11     0.633         6        37  83.1    11     0        1 male  \n# i 544 more rows\n\n\n\n\nCode\np1 <- cognition |>\n    ggplot(aes(x = sex, y = cognition)) +\n    geom_jitter(width = .1, alpha = .3) +\n    stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\") +\n    labs(title=\"Cognition predicted by sex\")\n\np2 <- cognition |>\n    ggplot(aes(x = sex, y = cognition)) +\n    geom_boxplot() +\n    stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\")\n\nlibrary(patchwork)\np1 + p2\n\n\n\n\n\n\n\nCode\np1 <- cognition |>\n    ggplot(aes(x = sex, y = grip)) +\n    geom_jitter(width = .1, alpha = .3) +\n    stat_summary(fun = mean, geom = \"point\", color = \"red\", size = 3) +\n    stat_summary(aes(x = as.numeric(sex)), fun = mean, geom = \"line\", color = \"red\") +\n    labs(title = \"Grip predicted by sex\")\n\np2 <- cognition |>\n    ggplot(aes(x = sex, y = grip)) +\n    geom_boxplot() +\n    stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\")\n\np3 <- cognition |>\n    ggplot(aes(x = grip, color = sex)) +\n    geom_density(alpha = .6, bw = 1.5)\n\nlibrary(patchwork)\np1 + p2 + p3 + plot_layout(nrow = 2)\n\n\n\n\n\n성별(sex)로 악력(grip)을 예측하는 모형을 세우면,\n\nlibrary(jtools)\nmod_grip <- lm(grip ~ sex, data = cognition)\nsumm(mod_grip, model.info = FALSE)\n\n\nMODEL FIT:\nF(1,548) = 106.41, p = 0.00\nR<U+00B2> = 0.16\nAdj. R<U+00B2> = 0.16 \nStandard errors: OLS\n------------------------------------------------\n                     Est.   S.E.   t val.      p\n----------------- ------- ------ -------- ------\n(Intercept)         10.55   0.18    58.16   0.00\nsexfemale           -2.44   0.24   -10.32   0.00\n------------------------------------------------\n\n\n\nModel: \\(\\widehat{grip} = -2.44\\cdot sexfemale + 10.55\\)\n우선, 잔차의 합이 0이므로 \\(\\displaystyle \\sum_{i=1}^{n}{(y_i - \\hat{y})} = 0,~~ \\hat{y} = \\frac{\\sum_{i=1}^{n}{y_i}}{n}\\) for each \\(x\\)\n즉, 각 카테고리 값에 대해서 모형은 평균으로 예측\n\n기울기 -2.44는 남성과 여성의 평균 악력 차이를 의미함; 남성(0)에서 여성(1)로 1증가할 때, 악력의 증가량\n절편 10.55는 남성(0)일 때의 평균 악력을 의미함.\n따라서, 여성의 평균 약력은 -2.44 * (1) + 10.55 = 8.11\n\\(R^2\\)= 0.16; 성별로 악력의 변량의 16%를 설명할 수 있음.\n\n\n\n# A tibble: 550 x 5\n    grip sex    sexfemale  pred  resid\n   <dbl> <fct>      <dbl> <dbl>  <dbl>\n 1     9 female         1  8.11  0.895\n 2    11 male           0 10.5   0.454\n 3    12 male           0 10.5   1.45 \n 4     6 female         1  8.11 -2.11 \n 5     9 female         1  8.11  0.895\n 6    11 male           0 10.5   0.454\n 7    10 female         1  8.11  1.89 \n 8     9 male           0 10.5  -1.55 \n 9    11 male           0 10.5   0.454\n10    10 male           0 10.5  -0.546\n# i 540 more rows\n\n\n\nanova(mod_grip) |> print()\n\nAnalysis of Variance Table\n\nResponse: grip\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nsex         1  794.3  794.33  106.41 < 2.2e-16 ***\nResiduals 548 4090.7    7.46                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmodel_matrix(cognition, formula = grip ~ sex) |> print()\n\n# A tibble: 550 x 2\n  `(Intercept)` sexfemale\n          <dbl>     <dbl>\n1             1         1\n2             1         0\n3             1         0\n4             1         1\n5             1         1\n6             1         0\n# i 544 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n전통적으로 카테고리 변수에 대한 분석은 ANOVA 프레임워크에서 실시되었음.\n특히, 위의 경우와 같이 두 집단 간의 차이, 즉 남성과 여성의 약력의 평균 차이를 분석할 때 t-test를 실시.\nt.test(grip ~ sex, data = cognition, var.equal = TRUE)  # varance가 동일하다는 가정\n\n#   Two Sample t-test\n\n# data:  grip by sex\n# t = 10.316, df = 548, p-value < 2.2e-16\n# alternative hypothesis: true difference in means between group male and group female is not equal to 0\n# 95 percent confidence interval:\n#  1.976174 2.905811\n# sample estimates:\n#   mean in group male mean in group female \n#            10.546256             8.105263 \n\n\n\n\n\n\n\n\nNote\n\n\n\nFormula는 factor/카테고리 변수가 predictor인 경우 카테고리 값(levels)들을 수치화해줌.\n여러 방식이 있느나, 기본은 dummy coding으로, 각 카테고리를 0과 1로 표현하며, memership으로 이해하는 것이 적절함.\n그 값을 새로운 변수인 dummy variable/indicator variable로 만드는데, 1에 해당하는 level을 변수명에 표시함.\n예를 들어, 다음과 같이 female에 속하면(membership) 1, female에 속하지 않으면 0\nlibrary(modelr)\nmodel_matrix(cognition, formula = grip ~ sex) |> print()\n# # A tibble: 550 x 2\n#   `(Intercept)` sexfemale\n#           <dbl>     <dbl>\n# 1             1         1\n# 2             1         0\n# 3             1         0\n# 4             1         1\n# 5             1         1\n# 6             1         0\n# # i 544 more rows\nCoding을 어떠한 방식으로 하느냐에 따라 회귀 계수의 의미가 달라짐.\n예를 들어, effect coding의 경우 (female: -1, male: 1)\n\\(\\displaystyle b_0 = \\frac{\\overline{Y}_1 + \\overline{Y}_2}{2},~~ b_1 = \\overline{Y}_1 - \\frac{\\overline{Y}_1 + \\overline{Y}_2}{2}\\)\nSequential coding, Helmert coding, effect coding 등등 여러 다른 coding 방식에 대해서는 책을 참고.\n10.1 Alternative Coding Systems in Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n\n\nFactor의 levels을 formula 안에서 간단히 변경하려면, fct_relevel()\n\nmod_grip2 <- lm(grip ~ fct_relevel(sex, \"female\"), data = cognition)\n# 또는 relevel(sex, ref = \"female\")\n\nmodel_matrix(cognition, mod_grip2) |> print()\n\n# A tibble: 550 x 2\n  `(Intercept)` `relevel(sex, ref = \"female\")male`\n          <dbl>                              <dbl>\n1             1                                  0\n2             1                                  1\n3             1                                  1\n4             1                                  0\n5             1                                  0\n6             1                                  1\n# i 544 more rows"
  },
  {
    "objectID": "contents/notice.html",
    "href": "contents/notice.html",
    "title": "Notice",
    "section": "",
    "text": "기본적으로 모두 대면으로 하겠습니다. 비대면시 따로 공지하겠습니다."
  },
  {
    "objectID": "contents/notice.html#과제",
    "href": "contents/notice.html#과제",
    "title": "Notice",
    "section": "과제",
    "text": "과제"
  },
  {
    "objectID": "contents/notice.html#중간고사-대체-과제-5.11목-700pm",
    "href": "contents/notice.html#중간고사-대체-과제-5.11목-700pm",
    "title": "Notice",
    "section": "중간고사 대체 과제 5.11(목) 7:00pm",
    "text": "중간고사 대체 과제 5.11(목) 7:00pm\nSimple regression 섹션 마지막 연습문제 R script 파일로 LMS에 제출하세요."
  },
  {
    "objectID": "contents/notice.html#기말시험-6.15",
    "href": "contents/notice.html#기말시험-6.15",
    "title": "Notice",
    "section": "기말시험 6.15",
    "text": "기말시험 6.15"
  },
  {
    "objectID": "contents/notice.html#개별-프로젝트",
    "href": "contents/notice.html#개별-프로젝트",
    "title": "Notice",
    "section": "개별 프로젝트",
    "text": "개별 프로젝트"
  },
  {
    "objectID": "contents/notice.html#강의-계획-tentative",
    "href": "contents/notice.html#강의-계획-tentative",
    "title": "Notice",
    "section": "강의 계획 (tentative)",
    "text": "강의 계획 (tentative)\n1주 ~ 4주: R tutorial\n5주 ~ 6주: 통계 전반적 소개 - Statistics/overview\n7주: correlation\n8주: simple linear regression\n9주: multiple regression\n10주: multiple regression: residualize & parial correlations\n11주: multiple regression: measures & patterns of association\n12주: interaction effect 1\n13주: interaction effect 2\n14주: diagnosis of assumptions 1\n15주: diagnosis of assumptions 2\n16주: final exam"
  },
  {
    "objectID": "contents/categories.html",
    "href": "contents/categories.html",
    "title": "Categorical IVs",
    "section": "",
    "text": "Let us consider a fictitious investigation of background factors and altruism. The researchers have hypothesized that there are influences of population density on altruism, and have drawn samples of residents of a city and the surrounding area outside the city (noncity). (p. 344)"
  },
  {
    "objectID": "contents/visualize.html",
    "href": "contents/visualize.html",
    "title": "Visualize",
    "section": "",
    "text": "데이터 시각화는 탐색적 분석에 더 초점이 맞춰져 있음.\n\n소위 data mining이라고 부르는 데이터 내의 숨겨진 패턴을 찾고 분석하는 탐색적 분석은 전통적인 통계에서 discouraging되어 왔음.\n\n확률에 근거한 통계 이론은 데이터를 수집하기 전에 가설을 세우고 그 가설을 confirm하는 방식을 취함.\n\n논란의 여지가 있지만, 원칙적으로 가설에 근거해 수집한 자료가 가설과 일치하는지를 확인하는 작업에서는 자료를 두 번 이상 들여다 보지 않아야 함.\n\n그럼에도 불구하고, 탐색적 분석은 behind doors에서 이루어지거나 새로운 가설을 세우기 위한 방편으로 이용되었음.\n\n또한, 매우 엄격한 잣대를 적용하는 상황에서도 통계 이론의 특성으로 인해 기본적인 탐색적 분석은 반드시 선행되어야 함.\n\n연구 가설의 진위를 탐구할 때, 탐색적 분석에서 쉽게 빠질 수 있는 편향성(bias)는 항상 조심할 필요가 있고, 확신을 위해서는 새로이 자료를 수집해서 가설을 재검증할 필요가 있음.\n\n탐색적 분석을 위해서는 다양한 시각화 기술이 요하나, 일반적인 통계 분석을 위해서 필요로하는 최소한으로 제한하고자 함.\n또한, 복잡한 통계치를 살펴볼 때, 직접 시각화를 하기보다는 패키지가 알아서 시각화를 해주기 때문에 자세히 알지 못해도 무방함.\n좀 더 상세한 내용에 대해서는\n\nR for Data Science/Visualize\nggplot2 book\nggplot2 extensions\n통계치 표현: ggstatsplot, ggpubr\nData Visualization with R by Rob Kabacoff : 적절한 밸런스\nggplot2 cheatsheet : pdf 다운로드\n\n\n\n\n\n\n\nNote\n\n\n\n충분히 큰 데이터의 경우, 일정량의 데이터 가령 1/4을 따로 떼어놓고, 3/4만으로 탐색적 분석을 통해 모델을 만든 후, 따로 떼어놓은 1/4로 (가설)검증을 하는 cross-validation 방법이 있는데, machine leanring분야에서는 기본적인 process.\nCross-validation 방식에는 여러 변형들이 있음; e.g. 데이터를 4등분하여 각각 4번 위의 방식을 반복하여 합치는 방식, 3가지 (training, validation, test sets)로 나누어 분석"
  },
  {
    "objectID": "contents/visualize.html#basics",
    "href": "contents/visualize.html#basics",
    "title": "Visualize",
    "section": "Basics",
    "text": "Basics\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\npenguins |>\n    print() # 무시\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n  <fct>   <fct>              <dbl>         <dbl>       <int>   <int> <fct> <int>\n1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n4 Adelie  Torgersen           NA            NA            NA      NA NA     2007\n5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n6 Adelie  Torgersen           39.3          20.6         190    3650 male   2007\n# … with 338 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#   ²​body_mass_g\n\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nVariabels:\n\nspecies: a penguin’s species (Adelie, Chinstrap, or Gentoo).\n\nflipper_length_mm: length of a penguin’s flipper, in millimeters.\n\nbody_mass_g: body mass of a penguin, in grams.\n\n더 자세한 사항은 ?penguins\nggplot을 이용한 시각화는 주로 3가지 성분으로 나뉨\n\ndata: 사용할 데이터\n\nmapping: data의 변수들을 어떤 특성에 mapping할 것인지 specify\n\ngeom: 어떤 시각화 개체(graphical objects)로 데이터를 표현할 것인지 specify\n\n\n# x, y축에 변수를 mapping\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\n\n# point로 데이터를 표시: scatterplot\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#> Warning: Removed 2 rows containing missing values (`geom_point()`).\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n실제로 is.na()함수를 이용해 missing을 확인해보면,\npenguins |>\n  select(species, flipper_length_mm, body_mass_g) |>\n  filter(is.na(body_mass_g) | is.na(flipper_length_mm))  # true, false의 boolean type\n#> # A tibble: 2 × 3\n#>   species flipper_length_mm body_mass_g\n#>   <fct>               <int>       <int>\n#> 1 Adelie                 NA          NA\n#> 2 Gentoo                 NA          NA\n\n\n\nAdding aesthetics and layers\n\n# spcies에 color (aesthetics)를 mapping\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n위에서 species마다 다른 색을 입혀서 다른 패턴이 나타나는지 확인해 볼 수 있음\nggplot2는 + 기호로 연결하여 계속 layer를 추가할 수 있음.\n다음은 trendline 혹은 fitted line이라고 부르는 경향성을 확인해 볼 수 있는 라인의 layer를 추가함\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nData에 fitted curve를 구하는 방식에는 여러 방법이 있음\n\nLinear fit: 1차 함수형태인 직선으로 fit\nSmoothing fit\n\nPolynominal fit: n차 다항함수형태로 fit\nLoess/lowess: locally estimated/weighted scatterplot smoothing\nGAM: generalized additive model\nSpine: piece-wise polynominal regression\n\n\n나중에 좀 더 자세히 알아봄\n\n\nggplot2는 플랏의 대상에 다음과 같은 속성을 부여할 수 있음\ncolor, size, shape, fill, alpha\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species, shape = island)\n) +\n  geom_point() \n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n어떤 속성을 어떤 변수에 할당하는 것이 적절한지를 선택하는 것이 기술\n\n\n\n\nCategorical vs. continuous\ncolor와 같은 속성은 카테고리 변수가 좀 더 적절하나, 연속변수에서도 적용될 수 있음\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = bill_length_mm)\n) +\n  geom_point() \n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n반대로, x, y에 카테고리 변수를 mapping하여 scatterplot을 그리면 다음과 같은 overploting의 문제가 생김\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_point() \n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\nOverplotting\nOverplotting의 문제를 해결하는 방식은 주로\n\nalpha(투명도)를 조정하거나 랜덤하게 흐뜨려그리는 geom_jitter()를 사용\n\n애초에 겹치지 않게 그리는 방법도 있음: e.g. beeswarm plot\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_jitter(width = .2) # jitter의 정도: width, height\n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_jitter(width = .2, alpha = .5) # alpha: 투명도 0 ~ 1\n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "contents/visualize.html#geometric-objects",
    "href": "contents/visualize.html#geometric-objects",
    "title": "Visualize",
    "section": "Geometric objects",
    "text": "Geometric objects\nggplot2는 40가지 넘는 geom objects를 제공함.\n주로 통계를 위해 쓰일 geom들은\n\ngeom_point, geom_smooth()\ngeom_boxplot()\ngeom_histogram(), geom_freqploy(), geom_density()\n\nGlobal vs. local mapping\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) + # color mapping은 geom_point에만 적용\n  geom_smooth() # 맨 위의 mapping에 있는 global mapping을 inherit\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_smooth(mapping = aes(linetype = sex), se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\n\n\n\n\n\n\nggplot(\n    data = penguins,\n    mapping = aes(x = bill_depth_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +  # color mapping은 geom_point에만 \n  geom_smooth(method = lm)  # 맨 위의 mapping에 있는 global mapping을 inherit, method: fitted line의 종류\n\n\n\n\n\nggplot(\n    data = penguins,\n    mapping = aes(x = bill_depth_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = lm) +  # 맨 위의 mapping에 있는 global mapping을 inherit\n  geom_smooth(mapping = aes(color = species), method = lm) # color mapping 추가\n\n\n\n\naes() 내부, 외부에서의 mapping\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(mapping = aes(color = species)) # aesthetic color에 변수를 mapping\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(color = \"skyblue\") + # geom의 color 속성에 색을 지정\n    geom_smooth(color = \"orangered\")"
  },
  {
    "objectID": "contents/visualize.html#statistical-transformations",
    "href": "contents/visualize.html#statistical-transformations",
    "title": "Visualize",
    "section": "Statistical transformations",
    "text": "Statistical transformations\nggplot2는 편의를 위해 통계치를 구해 표시해주는데,\n경우에 따라 직접 통계치를 계산 후 새로 얻는 데이터로 그리는 것이 유리함\n\nDistribution\ngeom_histogram(), geom_freqploy(), geom_density()\n\n# y축에 표시되는 통계치들이 계산됨\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 100) # binwidth vs. bins\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, colour = sex)) +\n  geom_freqpoly(binwidth = 100)\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, colour = sex)) +\n  geom_density(bw = 100) # bw: band width\n\n\n\n\n\n\n\n\nBoxplot\nBoxplot은 분포에 대한 정보은 줄어드나, 카테고리별로 간결하게 비교되는 장점\nboxplot()\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n    geom_boxplot()\n\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_boxplot()`).”\n\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n    geom_boxplot() +\n    geom_jitter(alpha = .6)\n\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_boxplot()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\ncps <- as_tibble(mosaicData::CPS85)\ncps |>\n    filter(wage < 30) |> \n    ggplot(aes(x = as.factor(educ), y = wage)) +  # as.factor(): numeric을 factor로 변환\n    geom_boxplot()\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g, fill = sex)) + # color는 box의 테두리 색, fill은 내부색\n  geom_boxplot()\n\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_boxplot()`).”\n\n\n\n\n\n\n\nBarplot\nBarplot은 여러방식으로 쓸 수 있는데, 문법이 조금 복잡하고, 수업에서 거의 사용하지 않을 예정이므로 웹사이트를 참조\nR for Data Science/Layers/Statistical transformations\n\nggplot(data = penguins) + \n  geom_bar(mapping = aes(x = species)) # 개수\n\n\n\n\n\n\nDiscretize\n연속 변수를 임의의 구간으로 나누어 카테고리처럼 적용하기 할 수 있음\ncut_width(), cut_number(), cut_interval()\n\ncut_width(): 구간의 길이를 정함\ncut_number(): 동일한 갯수의 관측값을 갖는 n개의 그룹\ncut_interval(): 동일한 길이의 n개의 그룹\n\n\nggplot(\n  data = penguins,\n  mapping = aes(\n      x = bill_length_mm, y = bill_depth_mm,\n      color = cut_interval(body_mass_g, 3) # body_mass_g의 값을 3개의 동일한 길이의 구간으로 나눔\n  )\n) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) # span: smoothing 정도 조절\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "contents/visualize.html#facets",
    "href": "contents/visualize.html#facets",
    "title": "Visualize",
    "section": "Facets",
    "text": "Facets\n카테고리 변수들이 지니는 카테고리들(레벨)로 나누어 그리기\nfacet_wrap(), facet_grid()\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~species) # species의 레벨로 나뉘어짐\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\nfacet_wrap()은 레벨이 많아지면 다음의 facet_grid()와는 다르게 화면크기에 맞춰 다음 줄로 넘어감\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_grid(sex ~ species)  # 행과 열에 각각 sex, species\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\nggplot(\n  data = penguins, \n  aes(x = body_mass_g, y = flipper_length_mm, color = sex) # color 추가\n) +\n  geom_point(alpha = .6) +\n  facet_grid(island ~ species)  # 행과 열에 각각 sex, species\n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFacet과 color 중 어떤 방식으로 표현하는 것이 유리한가? 밸런스를 잘 선택!\n\n\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~species)\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm, color = species)) +\n  geom_point()\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "contents/visualize.html#labels",
    "href": "contents/visualize.html#labels",
    "title": "Visualize",
    "section": "Labels",
    "text": "Labels\nlabs() 안에 각 요소별로 지정\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = island)) +\n  geom_smooth() +\n  labs(\n    title = \"Body mass and flipper length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Flipper length (mm)\", y = \"Body mass (g)\",\n    color = \"Species\", shape = \"Island\"\n  )\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n앞으로는 pipe operator와 함께, 축약 형태로\n\ndata = 대신 첫번째 argument 위치에 data frame이 위치\nmapping = 은 두번째 argument 위치에 aes()을 위치\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n은 다음과 같이\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\nPipe operator로 다음과 연결될 수 있음\n\npenguins |>\n    filter(!is.na(sex) & island != \"Torgersen\") |>  # 성별이 missing이 아니고, Torgersen섬은 제외\n    ggplot(aes(x = body_mass_g, y = flipper_length_mm, color = sex)) +\n    geom_point() +\n    geom_smooth() +\n    facet_wrap(~island)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "contents/visualize.html#examples",
    "href": "contents/visualize.html#examples",
    "title": "Visualize",
    "section": "Examples",
    "text": "Examples\n이전에 다뤘던 CPS85 데이터로 보면,\n\ncps <- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\ncps |>\n   print() # 생략!\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\ncps |>\n    ggplot(aes(x = wage, color = married)) +\n    geom_freqpoly(binwidth=1)\n\n\n\n\n\ncps |>\n    ggplot(aes(x = wage, color = married)) +\n    geom_freqpoly(binwidth = 1) +\n    facet_wrap(~sex)\n\n\n\n\n\ncps |>\n  ggplot(aes(x = married, y = wage)) +\n  geom_boxplot(width = .2) +\n  geom_jitter(width = .2, alpha = .2, color = \"red\") +\n  scale_y_continuous(label = scales::label_dollar())  # y축 scale의 변경\n\n\n\n\n\ncps |>\n  ggplot(aes(x = married, y = wage, fill = sex)) +\n  geom_boxplot()\n  \n\n\n\n\n\ncps |>\n    filter(wage < 30) |> \n    ggplot(aes(x = sector, y = wage, fill = sex)) +\n    geom_boxplot()\n\n\n\n\n\ncps |>\n    filter(wage < 30) |>\n    ggplot(aes(x = sector, y = wage, fill = sex)) +\n    geom_boxplot() +\n    facet_grid(married ~ .) \n\n\n\n\n\nplot <- cps |>\n  filter(wage < 30) |>\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .6) +\n  geom_smooth()\nplot\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n확대, 축소 혹은 제한된 범위에서 보려면 다음 2가지를 구분해야 함\ncoord_cartesian() vs. xlim() or ylim()\n\n\n\nplot + coord_cartesian(xlim = c(18, 40)) # zoom in\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nplot + xlim(18, 40) # data crop\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 181 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 181 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\ncps |>\n    filter(wage < 30 & sector %in% c(\"manag\", \"manuf\", \"prof\", \"sales\")) |>\n    ggplot(aes(x = age, y = wage, color = sex)) +\n    geom_point() +\n    geom_smooth(se = FALSE, span = 1) +\n    facet_wrap(~sector)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "contents/case4.html",
    "href": "contents/case4.html",
    "title": "Salary",
    "section": "",
    "text": "연봉에 미치는 영향에 대한 full model (p.461)\n\n다음과 같이 회귀계수들과 여러 연관된 값들을 직접 구해보세요."
  },
  {
    "objectID": "contents/anova.html",
    "href": "contents/anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "data(CO2)\nw1b1 <- CO2 |> filter(Treatment == \"chilled\") |> select(-Treatment)\n\n\nw1b1 |> print()\n\n   Plant        Type conc uptake\n1    Qc1      Quebec   95   14.2\n2    Qc1      Quebec  175   24.1\n3    Qc1      Quebec  250   30.3\n4    Qc1      Quebec  350   34.6\n5    Qc1      Quebec  500   32.5\n6    Qc1      Quebec  675   35.4\n7    Qc1      Quebec 1000   38.7\n8    Qc2      Quebec   95    9.3\n9    Qc2      Quebec  175   27.3\n10   Qc2      Quebec  250   35.0\n11   Qc2      Quebec  350   38.8\n12   Qc2      Quebec  500   38.6\n13   Qc2      Quebec  675   37.5\n14   Qc2      Quebec 1000   42.4\n15   Qc3      Quebec   95   15.1\n16   Qc3      Quebec  175   21.0\n17   Qc3      Quebec  250   38.1\n18   Qc3      Quebec  350   34.0\n19   Qc3      Quebec  500   38.9\n20   Qc3      Quebec  675   39.6\n21   Qc3      Quebec 1000   41.4\n22   Mc1 Mississippi   95   10.5\n23   Mc1 Mississippi  175   14.9\n24   Mc1 Mississippi  250   18.1\n25   Mc1 Mississippi  350   18.9\n26   Mc1 Mississippi  500   19.5\n27   Mc1 Mississippi  675   22.2\n28   Mc1 Mississippi 1000   21.9\n29   Mc2 Mississippi   95    7.7\n30   Mc2 Mississippi  175   11.4\n31   Mc2 Mississippi  250   12.3\n32   Mc2 Mississippi  350   13.0\n33   Mc2 Mississippi  500   12.5\n34   Mc2 Mississippi  675   13.7\n35   Mc2 Mississippi 1000   14.4\n36   Mc3 Mississippi   95   10.6\n37   Mc3 Mississippi  175   18.0\n38   Mc3 Mississippi  250   17.9\n39   Mc3 Mississippi  350   17.9\n40   Mc3 Mississippi  500   17.9\n41   Mc3 Mississippi  675   18.9\n42   Mc3 Mississippi 1000   19.9\n\n\n\nw1b1 <- w1b1 |>\n    mutate(\n        conc = factor(conc),\n        Plant = factor(Plant, ordered = FALSE)\n    )\n\n\nw1b1 |> pivot_wider(names_from = \"conc\", values_from = \"uptake\")\n\n\n\nA tibble: 6 x 9\n\n    PlantType951752503505006751000\n    <fct><fct><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    Qc1Quebec     14.224.130.334.632.535.438.7\n    Qc2Quebec      9.327.335.038.838.637.542.4\n    Qc3Quebec     15.121.038.134.038.939.641.4\n    Mc1Mississippi10.514.918.118.919.522.221.9\n    Mc2Mississippi 7.711.412.313.012.513.714.4\n    Mc3Mississippi10.618.017.917.917.918.919.9\n\n\n\n\n\nfit <- aov(uptake ~ conc*Type + Error(Plant/conc), w1b1)\nsummary(fit)\n\n\nError: Plant\n          Df Sum Sq Mean Sq F value  Pr(>F)   \nType       1 2667.2  2667.2   60.41 0.00148 **\nResiduals  4  176.6    44.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Plant:conc\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nconc       6 1472.4  245.40   52.52 1.26e-12 ***\nconc:Type  6  428.8   71.47   15.30 3.75e-07 ***\nResiduals 24  112.1    4.67                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(ez)\nw1b1_aov <- ezANOVA(\n    data = w1b1,\n    dv = uptake,\n    wid = Plant,\n    # between = Type,\n    within = conc,\n    # detailed = TRUE,\n    type = 3,\n    # return_aov = TRUE\n)\nw1b1_aov\n\n\n$ANOVA = \nA data.frame: 1 x 7\n\n    EffectDFnDFdFpp<.05ges\n    <chr><dbl><dbl><dbl><dbl><chr><dbl>\n\n\n    2conc63013.60882.09137e-07*0.3031357\n\n\n\n\n\nlmer(uptake ~ conc + (1 | Plant), data = w1b1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: uptake ~ conc + (1 | Plant)\n   Data: w1b1\nREML criterion at convergence: 230.3504\nRandom effects:\n Groups   Name        Std.Dev.\n Plant    (Intercept) 8.870   \n Residual             4.246   \nNumber of obs: 42, groups:  Plant, 6\nFixed Effects:\n(Intercept)      conc175      conc250      conc350      conc500      conc675  \n     11.233        8.217       14.050       14.967       15.417       16.650  \n   conc1000  \n     18.550  \n\n\n\nw1b1 |>\n    ggplot(aes(x = conc, y = uptake, fill = Type)) +\n    geom_boxplot()\n\n\n\n\n\nw1b1\n\n\n\nA data.frame: 42 x 4\n\n    PlantTypeconcuptake\n    <ord><fct><fct><dbl>\n\n\n    1Qc1Quebec95 14.2\n    2Qc1Quebec17524.1\n    3Qc1Quebec25030.3\n    4Qc1Quebec35034.6\n    ...............\n    39Mc3Mississippi350 17.9\n    40Mc3Mississippi500 17.9\n    41Mc3Mississippi675 18.9\n    42Mc3Mississippi100019.9\n\n\n\n\n\nw1b1 |>\n    ggplot(aes(x = conc, y = uptake, color = Type)) +\n    geom_jitter(width = .2) +\n    facet_wrap(~Plant)\n\n\n\n\n\nw1b1 |>\n    ggplot(aes(x = Plant, y = uptake)) +\n    geom_jitter(width = .1)"
  },
  {
    "objectID": "contents/anova.html#blog",
    "href": "contents/anova.html#blog",
    "title": "ANOVA",
    "section": "blog",
    "text": "blog\nhttps://yury-zablotski.netlify.app/post/rma/#introduction\n\n# load(url(\"http://coltekin.net/cagri/R/data/newborn.rda\"))\nnewborn <- read.csv(\"data/newborn.csv\")\nnewborn\n\n\n\nA data.frame: 60 x 3\n\n    participantlanguagerate\n    <int><chr><dbl>\n\n\n    1native 29.01\n    1foreign20.06\n    2native 29.49\n    2foreign31.60\n    .........\n    29native 28.62\n    29foreign20.28\n    30native 16.56\n    30foreign14.68\n\n\n\n\n\nggplot(newborn, aes(language, rate))+\n  geom_violin()+\n  geom_dotplot(binaxis='y', stackdir='center', dotsize=.5)\n\n\n\n\n\nnewborn\n\n\n\nA data.frame: 60 x 3\n\n    participantlanguagerate\n    <fct><fct><dbl>\n\n\n    1native 29.01\n    1foreign20.06\n    2native 29.49\n    2foreign31.60\n    .........\n    29native 28.62\n    29foreign20.28\n    30native 16.56\n    30foreign14.68\n\n\n\n\n\nnewborn |>\n    ggplot(aes(x = language, y = rate, group = participant, color = as.numeric(participant))) +\n    geom_line() +\n    facet_wrap(~participant)\n\n\n\n\n\nnewborn_wide <- newborn |>\n    pivot_wider(names_from = \"language\", values_from = \"rate\") |>\n    mutate(diff = native - foreign)\nnewborn_wide |> print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  <fct>        <dbl>   <dbl>  <dbl>\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# ... with 24 more rows\n\n\n\nt.test(rate ~ language, data = newborn)\n\n\n    Welch Two Sample t-test\n\ndata:  rate by language\nt = -1.7074, df = 57.994, p-value = 0.0931\nalternative hypothesis: true difference in means between group foreign and group native is not equal to 0\n95 percent confidence interval:\n -9.8271059  0.7797726\nsample estimates:\nmean in group foreign  mean in group native \n             31.84367              36.36733 \n\n\n\nsummary(lm(rate ~ language, data = newborn))\n\n\nCall:\nlm(formula = rate ~ language, data = newborn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.8837  -7.4548   0.8927   6.5913  21.8863 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      31.844      1.873  16.997   <2e-16 ***\nlanguagenative    4.524      2.649   1.707   0.0931 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.26 on 58 degrees of freedom\nMultiple R-squared:  0.04786,   Adjusted R-squared:  0.03144 \nF-statistic: 2.915 on 1 and 58 DF,  p-value: 0.0931\n\n\n\nt.test(rate ~ language, data = newborn, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  rate by language\nt = -5.3138, df = 29, p-value = 1.06e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -6.264775 -2.782559\nsample estimates:\nmean difference \n      -4.523667 \n\n\n\nezANOVA(data = newborn, \n                dv = rate, \n                wid = participant,, \n                within = language, \n                detailed = TRUE, \n                type = 3,\n                return_aov = TRUE)\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd        F            p p<.05\n1 (Intercept)   1  29 69791.1078 5791.737 349.4534 1.015654e-17     *\n2    language   1  29   306.9534  315.251  28.2367 1.060479e-05     *\n         ges\n1 0.91953700\n2 0.04785722\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 34.1055\n\nStratum 1: participant\n\nTerms:\n                Residuals\nSum of Squares   5791.737\nDeg. of Freedom        29\n\nResidual standard error: 14.13206\n\nStratum 2: participant:language\n\nTerms:\n                language Residuals\nSum of Squares  306.9534  315.2511\nDeg. of Freedom        1        29\n\nResidual standard error: 3.297078\nEstimated effects are balanced\n\n\n\nlibrary(lme4)\nmodel_lmer <- lmer(rate ~ language + (1 | participant), data = newborn)\nsummary(model_lmer)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: rate ~ language + (1 | participant)\n   Data: newborn\n\nREML criterion at convergence: 394.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.79385 -0.50665 -0.03044  0.42331  2.00234 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n participant (Intercept) 94.42    9.717   \n Residual                10.87    3.297   \nNumber of obs: 60, groups:  participant, 30\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     31.8437     1.8734  16.997\nlanguagenative   4.5237     0.8513   5.314\n\nCorrelation of Fixed Effects:\n            (Intr)\nlanguagentv -0.227\n\n\n\nlibrary(report)\nreport(model_lmer) |> print()\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict rate with language (formula: rate ~ language). The model included\nparticipant as random effect (formula: ~1 | participant). The model's total\nexplanatory power is substantial (conditional R2 = 0.90) and the part related\nto the fixed effects alone (marginal R2) is of 0.05. The model's intercept,\ncorresponding to language = foreign, is at 31.84 (95% CI [28.09, 35.60], t(56)\n= 17.00, p < .001). Within this model:\n\n  - The effect of language [native] is statistically significant and positive\n(beta = 4.52, 95% CI [2.82, 6.23], t(56) = 5.31, p < .001; Std. beta = 0.43,\n95% CI [0.27, 0.60])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\nreport(model_lmer) |>\n    table_long() |>\n    print()\n\nERROR: Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': could not find function \"table_long\"\n\n\n\nlibrary(broom)\nlibrary(emmeans)\nemmeans(model_lmer, pairwise ~ language, adjust = \"bonferroni\")\n\n$emmeans\n language emmean   SE   df lower.CL upper.CL\n foreign    31.8 1.87 32.1     28.0     35.7\n native     36.4 1.87 32.1     32.6     40.2\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n$contrasts\n contrast         estimate    SE df t.ratio p.value\n foreign - native    -4.52 0.851 29  -5.314  <.0001\n\nDegrees-of-freedom method: kenward-roger \n\n\n\n# install.packages(\"TMB\", type = \"source\")\nplot_model(model_lmer, type = \"diag\")\n\n\n\n\n\n\n\n[[1]]\n\n[[2]]\n[[2]]$participant\n\n\n[[3]]\n\n[[4]]\n\n\n\n\n\n\n\n\n\ncar::influencePlot(model_lmer)\n\n\n\nA data.frame: 4 x 3\n\n    StudResHatCookD\n    <dbl><dbl><dbl>\n\n\n    1 0.71894960.49035830.2486654\n    2-1.16158950.49035830.6491183\n    25 2.80482230.49035833.7846806\n    26-2.51277390.49035833.0375634\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_model(model_lmer)\n\n\nlibrary(effects)\nplot(allEffects(model_lmer))\n\n\n\n\n\nlibrary(sjPlot)\ntab_model(model_lmer, p.style = \"scientific\")"
  },
  {
    "objectID": "contents/anova.html#appendix-mlm",
    "href": "contents/anova.html#appendix-mlm",
    "title": "ANOVA",
    "section": "Appendix MLM",
    "text": "Appendix MLM\n\nOBrienKaiser <- carData::OBrienKaiser\nOBrienKaiser\n\n\n\nA data.frame: 16 x 17\n\n    treatmentgenderpre.1pre.2pre.3pre.4pre.5post.1post.2post.3post.4post.5fup.1fup.2fup.3fup.4fup.5\n    <fct><fct><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    1controlM124213253223244\n    2controlM445342235345641\n    3controlM565774575476976\n    4controlF547542235344534\n    ......................................................\n    13BF556864668677 8108\n    14BF223125675267 8 63\n    15BF223446679777 8 67\n    16BF45754778677810 87\n\n\n\n\n\nphase <- factor(rep(c(\"pretest\", \"posttest\", \"followup\"), c(5, 5, 5)),\n    levels=c(\"pretest\", \"posttest\", \"followup\"))\nhour <- ordered(rep(1:5, 3))\nidata <- data.frame(phase, hour)\nidata\n\n\n\nA data.frame: 15 x 2\n\n    phasehour\n    <fct><ord>\n\n\n    pretest1\n    pretest2\n    pretest3\n    pretest4\n    ......\n    followup2\n    followup3\n    followup4\n    followup5\n\n\n\n\n\nOBrien.long <- reshape(OBrienKaiser,\n    varying=c(\"pre.1\", \"pre.2\", \"pre.3\", \"pre.4\", \"pre.5\",\n        \"post.1\", \"post.2\", \"post.3\", \"post.4\", \"post.5\",\n        \"fup.1\", \"fup.2\", \"fup.3\",  \"fup.4\", \"fup.5\"),\n    v.names=\"score\",\n    timevar=\"phase.hour\", direction=\"long\")\nOBrien.long$phase <- ordered(\n      c(\"pre\", \"post\", \"fup\")[1 + ((OBrien.long$phase.hour - 1) %/% 5)],\n    levels=c(\"pre\", \"post\", \"fup\"))\nOBrien.long$hour <- ordered(1 + ((OBrien.long$phase.hour - 1) %% 5))\n\n\nOBrien.long\n\n\n\nA data.frame: 240 x 7\n\n    treatmentgenderphase.hourscoreidphasehour\n    <fct><fct><int><dbl><int><ord><ord>\n\n\n    1.1controlM111pre1\n    2.1controlM142pre1\n    3.1controlM153pre1\n    4.1controlF154pre1\n    ........................\n    13.15BF15813fup5\n    14.15BF15314fup5\n    15.15BF15715fup5\n    16.15BF15716fup5\n\n\n\n\n\nmod.ok <- lm(cbind(pre.1, pre.2, pre.3, pre.4, pre.5,\n                     post.1, post.2, post.3, post.4, post.5,\n                     fup.1, fup.2, fup.3, fup.4, fup.5) ~  treatment*gender,\n                data=OBrienKaiser)\nmod.ok\n\n\nCall:\nlm(formula = cbind(pre.1, pre.2, pre.3, pre.4, pre.5, post.1, \n    post.2, post.3, post.4, post.5, fup.1, fup.2, fup.3, fup.4, \n    fup.5) ~ treatment * gender, data = OBrienKaiser)\n\nCoefficients:\n                    pre.1       pre.2       pre.3       pre.4       pre.5     \n(Intercept)          3.903e+00   4.278e+00   5.431e+00   4.611e+00   4.139e+00\ntreatment1           1.181e-01   1.389e-01  -7.639e-02   1.806e-01   1.944e-01\ntreatment2          -2.292e-01  -3.333e-01  -1.458e-01  -7.083e-01  -6.667e-01\ngender1             -6.528e-01  -7.778e-01  -1.806e-01  -1.111e-01  -6.389e-01\ntreatment1:gender1  -4.931e-01  -3.889e-01  -5.486e-01  -1.806e-01  -1.944e-01\ntreatment2:gender1   6.042e-01   5.833e-01   2.708e-01   7.083e-01   1.167e+00\n                    post.1      post.2      post.3      post.4      post.5    \n(Intercept)          5.028e+00   5.542e+00   6.917e+00   6.361e+00   4.833e+00\ntreatment1           7.639e-01   8.958e-01   8.333e-01   7.222e-01   9.167e-01\ntreatment2           2.917e-01   1.875e-01  -2.500e-01   8.333e-02  -2.047e-17\ngender1             -8.611e-01  -4.583e-01  -4.167e-01  -5.278e-01  -1.000e+00\ntreatment1:gender1  -6.806e-01  -6.042e-01  -3.333e-01  -5.556e-01  -5.000e-01\ntreatment2:gender1   9.583e-01   6.875e-01   2.500e-01   9.167e-01   1.250e+00\n                    fup.1       fup.2       fup.3       fup.4       fup.5     \n(Intercept)          6.014e+00   6.153e+00   7.778e+00   6.167e+00   5.347e+00\ntreatment1           9.236e-01   1.035e+00   1.097e+00   9.583e-01   8.819e-01\ntreatment2          -6.250e-02  -6.250e-02  -1.250e-01   1.250e-01   2.292e-01\ngender1             -5.972e-01  -9.028e-01  -7.778e-01  -8.333e-01  -4.306e-01\ntreatment1:gender1  -2.153e-01  -1.597e-01  -3.472e-01  -4.167e-02  -1.736e-01\ntreatment2:gender1   6.875e-01   1.187e+00   8.750e-01   1.125e+00   3.958e-01\n\n\n\nlibrary(car)\n(av.ok <- Anova(mod.ok, idata=idata, idesign=~phase*hour, type=3))\n\n\nType III Repeated Measures MANOVA Tests: Pillai test statistic\n                            Df test stat approx F num Df den Df    Pr(>F)    \n(Intercept)                  1   0.96736  296.389      1     10 9.241e-09 ***\ntreatment                    2   0.44075    3.940      2     10 0.0547069 .  \ngender                       1   0.26789    3.659      1     10 0.0848003 .  \ntreatment:gender             2   0.36350    2.855      2     10 0.1044692    \nphase                        1   0.81363   19.645      2      9 0.0005208 ***\ntreatment:phase              2   0.69621    2.670      4     20 0.0621085 .  \ngender:phase                 1   0.06614    0.319      2      9 0.7349696    \ntreatment:gender:phase       2   0.31060    0.919      4     20 0.4721498    \nhour                         1   0.93286   24.315      4      7 0.0003345 ***\ntreatment:hour               2   0.31634    0.376      8     16 0.9183275    \ngender:hour                  1   0.33922    0.898      4      7 0.5129764    \ntreatment:gender:hour        2   0.57022    0.798      8     16 0.6131884    \nphase:hour                   1   0.56043    0.478      8      3 0.8202673    \ntreatment:phase:hour         2   0.66238    0.248     16      8 0.9915531    \ngender:phase:hour            1   0.71151    0.925      8      3 0.5894907    \ntreatment:gender:phase:hour  2   0.79277    0.328     16      8 0.9723693    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "contents/repeated.html",
    "href": "contents/repeated.html",
    "title": "Repeated ANOVA",
    "section": "",
    "text": "newborn <- read.csv(\"data/newborn.csv\")\nnewborn <- newborn |>\n    mutate(\n        participant = factor(participant),\n        language = factor(language)\n    )\nnewborn |>\n    as_tibble() |>\n    print()\n\n# A tibble: 60 x 3\n  participant language  rate\n  <fct>       <fct>    <dbl>\n1 1           native    29.0\n2 1           foreign   20.1\n3 2           native    29.5\n4 2           foreign   31.6\n5 3           native    50.9\n6 3           foreign   53.7\n# i 54 more rows\n\n\n\n# wide format\nnewborn_wide <- newborn |>\n    pivot_wider(names_from = \"language\", values_from = \"rate\") |>\n    mutate(diff = native - foreign)\nnewborn_wide |> print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  <fct>        <dbl>   <dbl>  <dbl>\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# i 24 more rows\n\n\n\n\nAssuming the newborn data came from two independent groups of babies (no baby is tested twice), test whether the babies respond diﬀerently to their native language and the foreign language.\nTwo normal Q-Q plots, one for each language, and var.test() testing for equivalence of variances would be ways to test for normality and homogeneity of variance assumptions. A boxplot() is also useful for visualizing the distributions of both groups.\n\nnewborn |>\n    ggplot(aes(x = language, y = rate)) +\n    geom_boxplot(fill = \"white\") +\n    geom_jitter(width = .2)\n\n\n\n\n\nnewborn |>\n    ggplot(aes(x = language, y = rate, group = participant, color = as.numeric(participant))) +\n    geom_line() +\n    facet_wrap(~participant)\n\n\n\n\n\nlibrary(broom)\n\nmod_ind <- lm(rate ~ language, data = newborn)  # assumes independence\ntidy(mod_ind) |> print(digits = 2)\n\n# A tibble: 2 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)       31.8       1.87     17.0  3.39e-24\n2 languagenative     4.52      2.65      1.71 9.31e- 2\n\n\n\nt.test(rate ~ language, data = newborn)  # assumes independence\n\n\n    Welch Two Sample t-test\n\ndata:  rate by language\nt = -1.7074, df = 57.994, p-value = 0.0931\nalternative hypothesis: true difference in means between group foreign and group native is not equal to 0\n95 percent confidence interval:\n -9.8271059  0.7797726\nsample estimates:\nmean in group foreign  mean in group native \n             31.84367              36.36733 \n\n\n\nlibrary(car)\nqqPlot(mod_ind)\n\n\n654\n\n\n\n\n\n\nresidualPlots(mod_ind)\n\n\n\n\n\nvar.test(rate ~ language, data = newborn)\n\n\n    F test to compare two variances\n\ndata:  rate by language\nF = 0.98053, num df = 29, denom df = 29, p-value = 0.9581\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.4666972 2.0600871\nsample estimates:\nratio of variances \n         0.9805289 \n\n\n\n\n\nPerform a paired t test. Compare your results and to the independent-samples t test you have just performed.\n\nt.test(rate ~ language, data = newborn, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  rate by language\nt = -5.3138, df = 29, p-value = 1.06e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -6.264775 -2.782559\nsample estimates:\nmean difference \n      -4.523667 \n\n\n\nnewborn_wide |> print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  <fct>        <dbl>   <dbl>  <dbl>\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# i 24 more rows\n\n\n\nnewborn_wide |>\n    ggplot(aes(x = diff)) +\n    geom_freqpoly(binwidth = 2)\n\n\n\n\n\nqqPlot(newborn_wide$diff)\n\n\n1322\n\n\n\n\n\n\n\nIn this case, we tell aov() that the response corresponding to every level of language is measured for each participant. The speciﬁcation of the error term could be confusing at ﬁrst sight. Within the Error() term, the part before the slash ‘/’ speciﬁes the ‘case’ or ‘subject’ variable. The part after the slash speciﬁes the ‘within subject’ variable(s).\nHowever, aov() does not run any diagnostics or present corrected results in case of violation of the assumptions, does not report any eﬀect size, cannot handle unbalanced designs or missing data.\nWe will only present an example using ezANOVA() from the package ez. However, when things are not perfectly balanced, and neat, the repeated-measures ANOVA becomes diﬃcult to interpret. One reasonable course of action when ANOVA design becomes too complicated, or assumptions are violated at some level is to switch to so-called mixed-eﬀect models which also oﬀer some other beneﬁts.\n\nm <- aov(rate ~ language + Error(participant / language), data = newborn)\nsummary(m)\n\n\nError: participant\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals 29   5792   199.7               \n\nError: participant:language\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nlanguage   1  306.9  306.95   28.24 1.06e-05 ***\nResiduals 29  315.2   10.87                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(ez)\n# The ez package defaults to the “median-centered” ANOVA, which is usually more robust then “mean-centered”.\n# The ez package also defaults to the “Satterthwaite” approximation for the degrees of freedom, which is usually more robust than the “Kenward-Roger” approximation.\nezANOVA(data = newborn, \n                dv = rate, \n                wid = participant,, \n                within = language, \n                detailed = TRUE, \n                type = 3,\n                return_aov = TRUE)\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd        F            p p<.05\n1 (Intercept)   1  29 69791.1078 5791.737 349.4534 1.015654e-17     *\n2    language   1  29   306.9534  315.251  28.2367 1.060479e-05     *\n         ges\n1 0.91953700\n2 0.04785722\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 34.1055\n\nStratum 1: participant\n\nTerms:\n                Residuals\nSum of Squares   5791.737\nDeg. of Freedom        29\n\nResidual standard error: 14.13206\n\nStratum 2: participant:language\n\nTerms:\n                language Residuals\nSum of Squares  306.9534  315.2511\nDeg. of Freedom        1        29\n\nResidual standard error: 3.297078\nEstimated effects are balanced\n\n\n\nlibrary(lme4)\nmodel_lmer <- lmer(rate ~ language + (1 | participant), data = newborn)\nsummary(model_lmer)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: rate ~ language + (1 | participant)\n   Data: newborn\n\nREML criterion at convergence: 394.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.79385 -0.50665 -0.03044  0.42331  2.00234 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n participant (Intercept) 94.42    9.717   \n Residual                10.87    3.297   \nNumber of obs: 60, groups:  participant, 30\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     31.8437     1.8734  16.997\nlanguagenative   4.5237     0.8513   5.314\n\nCorrelation of Fixed Effects:\n            (Intr)\nlanguagentv -0.227\n\n\n\nlibrary(effects)\nplot(allEffects(model_lmer))"
  },
  {
    "objectID": "contents/repeated.html#exercise-5.8.",
    "href": "contents/repeated.html#exercise-5.8.",
    "title": "Repeated ANOVA",
    "section": "Exercise 5.8.",
    "text": "Exercise 5.8.\nPerform a repeated measures ANOVA that tests the eﬀect of language and age on mlu in the bilingual data set\n\nlibrary(ez)\n# The ez package defaults to the “median-centered” ANOVA, which is usually more robust then “mean-centered”.\n# The ez package also defaults to the “Satterthwaite” approximation for the degrees of freedom, which is usually more robust than the “Kenward-Roger” approximation.\n\n\nmod_bilingual <- ezANOVA(\n        data = bilingual,\n        dv = mlu,\n        wid = .(subj),\n        within = .(language, age),\n        between = gender,\n        type = 3,\n        # detailed = TRUE, \n        # return_aov = TRUE\n)\nmod_bilingual |> print(digits = 2)\n\n$ANOVA\n               Effect DFn DFd       F       p p<.05     ges\n2              gender   1  18 2.9e-04 9.9e-01       0.00001\n3            language   1  18 6.8e+00 1.8e-02     * 0.03377\n5                 age   2  36 1.7e+01 5.1e-06     * 0.14702\n4     gender:language   1  18 2.0e-01 6.6e-01       0.00102\n6          gender:age   2  36 6.5e-01 5.3e-01       0.00636\n7        language:age   2  36 3.1e+00 5.9e-02       0.01659\n8 gender:language:age   2  36 1.4e+00 2.5e-01       0.00776\n\n$`Mauchly's Test for Sphericity`\n               Effect    W    p p<.05\n5                 age 0.99 0.95      \n6          gender:age 0.99 0.95      \n7        language:age 0.99 0.92      \n8 gender:language:age 0.99 0.92      \n\n$`Sphericity Corrections`\n               Effect  GGe   p[GG] p[GG]<.05 HFe   p[HF] p[HF]<.05\n5                 age 0.99 5.4e-06         * 1.1 5.1e-06         *\n6          gender:age 0.99 5.3e-01           1.1 5.3e-01          \n7        language:age 0.99 5.9e-02           1.1 5.9e-02          \n8 gender:language:age 0.99 2.5e-01           1.1 2.5e-01          \n\n\n\n\nlibrary(lme4)\nmlm <- lmer(data = bilingual, mlu ~ age*language + (1|subj))\n\n\nsummary(mlm)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: mlu ~ age * language + (1 | subj)\n   Data: bilingual\n\nREML criterion at convergence: 360.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.48540 -0.54268 -0.04216  0.55965  2.27307 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subj     (Intercept) 0.9997   0.9999  \n Residual             0.8344   0.9135  \nNumber of obs: 120, groups:  subj, 20\n\nFixed effects:\n                              Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)                     3.8880     0.3028 45.8663  12.839  < 2e-16 ***\nagefirstgrade                   0.3625     0.2889 95.0000   1.255  0.21262    \nagesecondgrade                  0.9106     0.2889 95.0000   3.152  0.00217 ** \nlanguageschool                  0.1336     0.2889 95.0000   0.462  0.64482    \nagefirstgrade:languageschool    0.2541     0.4085 95.0000   0.622  0.53538    \nagesecondgrade:languageschool   0.8145     0.4085 95.0000   1.994  0.04903 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) agfrst agscnd lnggsc agfrs:\nagefirstgrd -0.477                            \nagesecndgrd -0.477  0.500                     \nlanguagschl -0.477  0.500  0.500              \nagfrstgrd:l  0.337 -0.707 -0.354 -0.707       \nagscndgrd:l  0.337 -0.354 -0.707 -0.707  0.500\n\n\n\nlibrary(report)\nreport(mlm) |> print()\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict mlu with age and language (formula: mlu ~ age * language). The model\nincluded subj as random effect (formula: ~1 | subj). The model's total\nexplanatory power is substantial (conditional R2 = 0.62) and the part related\nto the fixed effects alone (marginal R2) is of 0.17. The model's intercept,\ncorresponding to age = preschool and language = home.only, is at 3.89 (95% CI\n[3.29, 4.49], t(112) = 12.84, p < .001). Within this model:\n\n  - The effect of age [firstgrade] is statistically non-significant and positive\n(beta = 0.36, 95% CI [-0.21, 0.93], t(112) = 1.25, p = 0.212; Std. beta = 0.25,\n95% CI [-0.14, 0.64])\n  - The effect of age [secondgrade] is statistically significant and positive\n(beta = 0.91, 95% CI [0.34, 1.48], t(112) = 3.15, p = 0.002; Std. beta = 0.62,\n95% CI [0.23, 1.01])\n  - The effect of language [school] is statistically non-significant and positive\n(beta = 0.13, 95% CI [-0.44, 0.71], t(112) = 0.46, p = 0.645; Std. beta = 0.09,\n95% CI [-0.30, 0.48])\n  - The interaction effect of language [school] on age [firstgrade] is\nstatistically non-significant and positive (beta = 0.25, 95% CI [-0.56, 1.06],\nt(112) = 0.62, p = 0.535; Std. beta = 0.17, 95% CI [-0.38, 0.73])\n  - The interaction effect of language [school] on age [secondgrade] is\nstatistically significant and positive (beta = 0.81, 95% CI [5.10e-03, 1.62],\nt(112) = 1.99, p = 0.049; Std. beta = 0.56, 95% CI [3.49e-03, 1.11])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "contents/case1.html#leerkes-and-crockenberg-1999의-육아에-대한-효능감-연구",
    "href": "contents/case1.html#leerkes-and-crockenberg-1999의-육아에-대한-효능감-연구",
    "title": "Case Study 1",
    "section": "Leerkes and Crockenberg (1999)의 육아에 대한 효능감 연구",
    "text": "Leerkes and Crockenberg (1999)의 육아에 대한 효능감 연구\nSource: Statistical Methods for Psychology (8e) by Dave C. Howell\n\n\n\n\n5개월의 아기를 양육하는 92명의 어머니를 대상\n본인이 아이였을 때 어머니에게 받은 양육(maternal care) 정도가 자신이 어머니가 되었을 때 아이를 향한 양육효능감으로 이전될 것이라는 가설\n매개변수로 maternal care로부터 영향을 받은 자존감(self-esteem)을 고려.\n데이터: maternal_care.sav\n\n\n\n\n\n\n\n\nlibrary(haven)\nmaternal <- read_spss(\"howell/maternal_care.sav\")\nmaternal\n\n# A tibble: 92 × 4\n   FAMID Esteem MatCare Efficacy\n   <dbl>  <dbl>   <dbl>    <dbl>\n 1     1   3.83    2.58      3.7\n 2     2   3.5     2.83      3.4\n 3     4   4       3.17      3.8\n 4     8   4       3.75      3.9\n 5     9   4       3.58      3.9\n 6    11   3.33    3.67      3.7\n 7    12   3.5     3.25      3.8\n 8    13   3.67    3.75      3.5\n 9    15   1.83    3.17      3.1\n10    16   2.83    2.67      3.5\n# ℹ 82 more rows\n\n# correlations\n# library(psych)\nlowerCor(maternal[-1])  # lowerCor(maternal[2:4])과 동일 \n\n         Estem MatCr Effcc\nEsteem   1.00             \nMatCare  0.40  1.00       \nEfficacy 0.38  0.27  1.00 \n\n\n\nGGally::ggpairs(maternal[-1])\n\n\n\n\n\nmod1 <- lm(Efficacy ~ MatCare, data = maternal)\nmod2 <- lm(Efficacy ~ MatCare + Esteem, data = maternal)\n\n\n# compare models\n# library(jtools)\nexport_summs(mod1, mod2, error_format = \"(p = {p.value})\") |> print()\n\n\n\n                ───────────────────────────────────────────────\n                                   Model 1         Model 2     \n                              ─────────────────────────────────\n                  (Intercept)        3.27 ***        2.94 ***  \n                                (p = 0.00)      (p = 0.00)     \n                  MatCare            0.11 *          0.06      \n                                (p = 0.01)      (p = 0.20)     \n                  Esteem                             0.15 **   \n                                                (p = 0.00)     \n                              ─────────────────────────────────\n                  N                 92              92         \n                  R2                 0.07            0.16      \n                ───────────────────────────────────────────────\n                  *** p < 0.001; ** p < 0.01; * p <            \n                  0.05.                                        \n\nColumn names: names, Model 1, Model 2\n\n\n\n\n\nsumm(mod2, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |> print()\n\nStandard errors: OLS\n--------------------------------------------------------------------\n                    Est.   S.E.   t val.      p   partial.r   part.r\n----------------- ------ ------ -------- ------ ----------- --------\n(Intercept)         2.94   0.17    16.95   0.00                     \nMatCare             0.06   0.04     1.30   0.20        0.14     0.13\nEsteem              0.15   0.05     3.02   0.00        0.31     0.29\n--------------------------------------------------------------------\n\n\n\n\n\n\n\n\n# test for mediation\nsummary(mediate(Efficacy ~ MatCare + (Esteem), data = maternal)) # library(psych)\n\n\n\n\nCall: mediate(y = Efficacy ~ MatCare + (Esteem), data = maternal)\n\nDirect effect estimates (traditional regression)    (c') X + M on Y \n          Efficacy   se     t df     Prob\nIntercept     2.94 0.17 16.95 89 1.30e-29\nMatCare       0.06 0.04  1.30 89 1.98e-01\nEsteem        0.15 0.05  3.02 89 3.28e-03\n\nR = 0.4 R2 = 0.16   F = 8.34 on 2 and 89 DF   p-value:  0.000479 \n\n Total effect estimates (c) (X on Y) \n          Efficacy   se     t df     Prob\nIntercept     3.27 0.14 23.24 90 8.31e-40\nMatCare       0.11 0.04  2.63 90 1.00e-02\n\n 'a'  effect estimates (X on M) \n          Esteem   se    t df     Prob\nIntercept   2.26 0.29 7.69 90 1.79e-11\nMatCare     0.36 0.09 4.18 90 6.82e-05\n\n 'b'  effect estimates (M on Y controlling for X) \n       Efficacy   se    t df    Prob\nEsteem     0.15 0.05 3.02 89 0.00328\n\n 'ab'  effect estimates (through all  mediators)\n        Efficacy boot   sd lower upper\nMatCare     0.05 0.05 0.02  0.02   0.1"
  },
  {
    "objectID": "contents/case3.html#national-education-longitudinal-study-of-1988-nels88",
    "href": "contents/case3.html#national-education-longitudinal-study-of-1988-nels88",
    "title": "Case Study 3",
    "section": "National Education Longitudinal Study of 1988 (NELS:88)",
    "text": "National Education Longitudinal Study of 1988 (NELS:88)\nSource: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n연구주제: 학생들의 과제는 성적에 영향을 주는가? 준다면 그 영향력의 크기는 어떠한가?\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels <- read_csv(\"data/nels88_sample.csv\")\nnels <- nels |> \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# summarize data\nsummary(nels)\n\n# count values\nnels |> count(pared)\nnels |> count(hw_out)\n\n\n\n변수들 간의 관계 탐색\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 <- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)\n\n\n\n세 개의 독립변수로 예측\n\nB1. 인과모형 A: 부분 회귀 계수들\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD: 표준화 계수 및 부분 상관 계수\n\n\n\n\n\n\n\n\nE: 간접효과의 크기와 검증\n\n\n\n\n\n\n\n변수의 추가: 4개의 독립변수로 예측\n\nB2. 인과모형 B: 부분 회귀 계수들\n\n\n\n\n\n\nF: 모형의 비교\n\n\n\n\n\nG: 표준화 계수 및 부분 상관 계수\n\n\n\n\n\n\n\n\n\n추가 분석\n\nH: Howework에 영향을 주는 요소들 분석"
  },
  {
    "objectID": "contents/report.html",
    "href": "contents/report.html",
    "title": "Report",
    "section": "",
    "text": "acad3 <- read_csv('Cohen/data/c0904dt.csv') |>  \n    rename_with(str_to_lower) |>  \n    mutate(depart = factor(depart, labels = c(\"psych\", \"soc\", \"hist\")),\n           sex = factor(sex, labels = c(\"male\", \"female\")))\nacad3\n\n# A tibble: 150 × 5\n   depart   pub  time salary sex   \n   <fct>  <dbl> <dbl>  <dbl> <fct> \n 1 psych     16     3 56465. female\n 2 psych     25     7 92044. male  \n 3 psych     16     2 48980. female\n 4 psych     24     1 53239. female\n 5 psych     24     8 98948. male  \n 6 psych     26    14 64782. male  \n 7 psych     39     5 91652. male  \n 8 psych     16     1 32833. male  \n 9 psych     26    10 79231. male  \n10 psych     23    11 77154. female\n# ℹ 140 more rows\n\n\n\nmod1 <- lm(salary ~ time, data = acad3)\nmod2 <- lm(salary ~ pub, data = acad3)\nmod3 <- lm(salary ~ time + pub, data = acad3)\nmod4 <- lm(salary ~ time + pub + sex, data = acad3)\nmod5 <- lm(salary ~ time + pub * depart + sex, data = acad3)\n\nlibrary(jtools)\nsumm(mod3, part.corr = TRUE)\n\n\n\n\n  \n    Observations \n    150 \n  \n  \n    Dependent variable \n    salary \n  \n  \n    Type \n    OLS linear regression \n  \n\n \n\n  \n    F(2,147) \n    24.85 \n  \n  \n    R² \n    0.25 \n  \n  \n    Adj. R² \n    0.24 \n  \n\n \n \n  \n      \n    Est. \n    S.E. \n    t val. \n    p \n    partial.r \n    part.r \n  \n \n\n  \n    (Intercept) \n    45132.42 \n    3176.66 \n    14.21 \n    0.00 \n    NA \n    NA \n  \n  \n    time \n    1351.08 \n    235.81 \n    5.73 \n    0.00 \n    0.43 \n    0.41 \n  \n  \n    pub \n    520.26 \n    164.55 \n    3.16 \n    0.00 \n    0.25 \n    0.23 \n  \n\n\n Standard errors: OLS\n\n\nsumm(mod3, part.corr = TRUE, scale = TRUE, transform.response = TRUE)\n\n\n\n\n  \n    Observations \n    150 \n  \n  \n    Dependent variable \n    salary \n  \n  \n    Type \n    OLS linear regression \n  \n\n \n\n  \n    F(2,147) \n    24.85 \n  \n  \n    R² \n    0.25 \n  \n  \n    Adj. R² \n    0.24 \n  \n\n \n \n  \n      \n    Est. \n    S.E. \n    t val. \n    p \n    partial.r \n    part.r \n  \n \n\n  \n    (Intercept) \n    0.00 \n    0.07 \n    0.00 \n    1.00 \n    NA \n    NA \n  \n  \n    time \n    0.41 \n    0.07 \n    5.73 \n    0.00 \n    0.43 \n    0.41 \n  \n  \n    pub \n    0.23 \n    0.07 \n    3.16 \n    0.00 \n    0.25 \n    0.23 \n  \n\n\n Standard errors: OLS; Continuous variables are mean-centered and scaled by 1 s.d.\n\n\nexport_summs(mod3, mod4, mod5) # scale = TRUE, transform.response = TRUE\n\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)45132.42 ***46910.49 ***35238.47 ***\n\n(3176.66)   (3401.42)   (4931.36)   \n\ntime1351.08 ***1382.07 ***1187.98 ***\n\n(235.81)   (235.98)   (243.09)   \n\npub520.26 ** 501.73 ** 1054.65 ***\n\n(164.55)   (164.48)   (242.60)   \n\nsexfemale       -3483.65    -4265.57    \n\n       (2438.77)   (2468.58)   \n\ndepartsoc              21818.27 ** \n\n              (8323.12)   \n\ndeparthist              18498.52 ** \n\n              (6753.95)   \n\npub:departsoc              -926.27    \n\n              (470.67)   \n\npub:departhist              -836.34    \n\n              (434.34)   \n\nN150       150       150       \n\nR20.25    0.26    0.32    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\nexport_summs(mod3, mod4, mod5, error_format = \"({conf.low}, {conf.high})\")\n\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)45132.42 ***46910.49 ***35238.47 ***\n\n(38854.59, 51410.24)   (40188.10, 53632.88)   (25490.11, 44986.84)   \n\ntime1351.08 ***1382.07 ***1187.98 ***\n\n(885.06, 1817.10)   (915.69, 1848.45)   (707.43, 1668.53)   \n\npub520.26 ** 501.73 ** 1054.65 ***\n\n(195.07, 845.44)   (176.66, 826.80)   (575.07, 1534.23)   \n\nsexfemale       -3483.65    -4265.57    \n\n       (-8303.50, 1336.19)   (-9145.49, 614.36)   \n\ndepartsoc              21818.27 ** \n\n              (5365.03, 38271.51)   \n\ndeparthist              18498.52 ** \n\n              (5147.24, 31849.79)   \n\npub:departsoc              -926.27    \n\n              (-1856.70, 4.16)   \n\npub:departhist              -836.34    \n\n              (-1694.95, 22.27)   \n\nN150       150       150       \n\nR20.25    0.26    0.32    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\nlibrary(parameters)\nmodel_parameters(mod5)\n\nParameter           | Coefficient |      SE |               95% CI | t(142) |      p\n------------------------------------------------------------------------------------\n(Intercept)         |    35238.47 | 4931.36 | [25490.11, 44986.84] |   7.15 | < .001\ntime                |     1187.98 |  243.09 | [  707.43,  1668.53] |   4.89 | < .001\npub                 |     1054.65 |  242.60 | [  575.07,  1534.23] |   4.35 | < .001\ndepart [soc]        |    21818.27 | 8323.12 | [ 5365.03, 38271.51] |   2.62 | 0.010 \ndepart [hist]       |    18498.52 | 6753.95 | [ 5147.24, 31849.79] |   2.74 | 0.007 \nsex [female]        |    -4265.57 | 2468.58 | [-9145.49,   614.36] |  -1.73 | 0.086 \npub × depart [soc]  |     -926.27 |  470.67 | [-1856.70,     4.16] |  -1.97 | 0.051 \npub × depart [hist] |     -836.34 |  434.34 | [-1694.95,    22.27] |  -1.93 | 0.056 \n\ncompare_models(mod4, mod5)\n\nParameter           |                          mod4 |                          mod5\n-----------------------------------------------------------------------------------\n(Intercept)         | 46910.49 (40188.10, 53632.88) | 35238.47 (25490.11, 44986.84)\ntime                |  1382.07 (  915.69,  1848.45) |  1187.98 (  707.43,  1668.53)\npub                 |   501.73 (  176.66,   826.80) |  1054.65 (  575.07,  1534.23)\nsex (female)        | -3483.65 (-8303.50,  1336.19) | -4265.57 (-9145.49,   614.36)\ndepart (soc)        |                               | 21818.27 ( 5365.03, 38271.51)\ndepart (hist)       |                               | 18498.52 ( 5147.24, 31849.79)\npub × depart (soc)  |                               |  -926.27 (-1856.70,     4.16)\npub × depart (hist) |                               |  -836.34 (-1694.95,    22.27)\n-----------------------------------------------------------------------------------\nObservations        |                           150 |                           150\n\ncompare_parameters(mod4, mod5)\n\nParameter           |                          mod4 |                          mod5\n-----------------------------------------------------------------------------------\n(Intercept)         | 46910.49 (40188.10, 53632.88) | 35238.47 (25490.11, 44986.84)\ntime                |  1382.07 (  915.69,  1848.45) |  1187.98 (  707.43,  1668.53)\npub                 |   501.73 (  176.66,   826.80) |  1054.65 (  575.07,  1534.23)\nsex (female)        | -3483.65 (-8303.50,  1336.19) | -4265.57 (-9145.49,   614.36)\ndepart (soc)        |                               | 21818.27 ( 5365.03, 38271.51)\ndepart (hist)       |                               | 18498.52 ( 5147.24, 31849.79)\npub × depart (soc)  |                               |  -926.27 (-1856.70,     4.16)\npub × depart (hist) |                               |  -836.34 (-1694.95,    22.27)\n-----------------------------------------------------------------------------------\nObservations        |                           150 |                           150\n\n\n\ntidy(mod5)\n\n# A tibble: 8 × 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      35238.     4931.      7.15 4.30e-11\n2 time              1188.      243.      4.89 2.73e- 6\n3 pub               1055.      243.      4.35 2.61e- 5\n4 departsoc        21818.     8323.      2.62 9.71e- 3\n5 departhist       18499.     6754.      2.74 6.95e- 3\n6 sexfemale        -4266.     2469.     -1.73 8.62e- 2\n7 pub:departsoc     -926.      471.     -1.97 5.10e- 2\n8 pub:departhist    -836.      434.     -1.93 5.62e- 2\n\nlibrary(sjPlot)\ntab_model(mod5)\n\n\n\n\n \nsalary\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n35238.47\n25490.11 – 44986.84\n<0.001\n\n\ntime\n1187.98\n707.43 – 1668.53\n<0.001\n\n\npub\n1054.65\n575.07 – 1534.23\n<0.001\n\n\ndepart [soc]\n21818.27\n5365.03 – 38271.51\n0.010\n\n\ndepart [hist]\n18498.52\n5147.24 – 31849.79\n0.007\n\n\nsex [female]\n-4265.57\n-9145.49 – 614.36\n0.086\n\n\npub × depart [soc]\n-926.27\n-1856.70 – 4.16\n0.051\n\n\npub × depart [hist]\n-836.34\n-1694.95 – 22.27\n0.056\n\n\nObservations\n150\n\n\nR2 / R2 adjusted\n0.316 / 0.282"
  },
  {
    "objectID": "contents/baser.html",
    "href": "contents/baser.html",
    "title": "Base R",
    "section": "",
    "text": "90년대에 통계 분석을 위해 개발된 R 언어와 대비하여, 좀 더 직관적이고 효율적인 데이터 분석을 위해 새로운 문법이 R내의 패키지 형태로 구현되었는데 이 새로운 생태계 안의 패키지들의 모임이 Tidyverse라는 이름하에 발전하고 있음: Tidyverse\n이 패키지들은 design philosophy, grammar, data structures를 공유하며 유기적으로 작동됨.\n기존 R의 문법과는 상당한 차이가 있어 단점도 지적되고 있고, 소위 base-R을 고수하는 사람들과 tidyverse를 기본으로 사용하는 사람들이 나뉘어 있다고 알려져 있음.\n아마도 빠르게 발전하고 있는 tidyverse/tidymodel 생태계의 언어들이 기본으로 자리잡지 않을까 함.\n본 강의에서는 주로 tidyverse의 언어로만 분석하고자 함."
  },
  {
    "objectID": "contents/baser.html#r의-데이터-구조와-변수-타입",
    "href": "contents/baser.html#r의-데이터-구조와-변수-타입",
    "title": "Base R",
    "section": "R의 데이터 구조와 변수 타입",
    "text": "R의 데이터 구조와 변수 타입\n주로 vector (벡터)와 data frame (데이터프레임)을 다룸\n\nSource: R in Action by Rob Kabacoff\nData frame의 예\n\n각 column이 하나의 variable (변수)를 구성하고, 한가지 타입의 데이터로 이루어짐\n\n각 Row가 하나의 observation (관측치)을 구성함.\n\n이러한 형태를 갖춘 데이터를 tidy라고도 부르며, 이를 벗어난 형태의 경우 가공이 필요함.\nex. “m23”: male이고 23세임을 나타내는 표기도 있음\n\n\nlibrary(tidyverse)\n\ncps <- mosaicData::CPS85 # mosaicData package의 CPS85 데이터셋\ncps # data.frame\n\n\ncps <- as_tibble(cps) # tibble vs. data.frame\nprint(cps) # print는 생략해도 됨\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n# Dataset의 설명\nhelp(CPS85, package=\"mosaicData\") # 또는\n?mosaicData::CPS85"
  },
  {
    "objectID": "contents/baser.html#vector",
    "href": "contents/baser.html#vector",
    "title": "Base R",
    "section": "Vector",
    "text": "Vector\n한 가지 타입으로만 구성: 숫자 (numeric), 문자 (character), 논리형 (logical), factor, etc\n\nvar <- c(1, 2, 5, 3, 6, -2, 4) # 변수에 assign: '=' 대신 '<-'\nnm <- c(\"one\", \"two\", \"three\")\ntf <- c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)\n\n# 타입 확인\nclass(var)\n## [1] \"numeric\"\n\nclass(nm)\n## [1] \"character\"\n\nclass(tf)\n## [1] \"logical\"\n\n\n원소의 추출 및 대체\n다음은 원소를 추출, 대체하는 R의 native한 방식임\n수업에서는 뒤에서 다룰 tidyverse 문법을 주로 활용할 것임\nVector의 경우\n\nvar\n## [1]  1  2  5  3  6 -2  4\n\nvar[3]\n## [1] 5\n\nvar[c(1, 3, 5)]\n## [1] 1 5 6\n\nvar[2:6] # \":\"\" slicing: c(2, 3, 4, 5, 6)\n## [1]  2  5  3  6 -2\n\nvar[c(1, 3:5)] # 혼합\n## [1] 1 5 3 6\n\nvar[-c(1, 3)] # \"-\"는 제외라는 의미\n## [1]  2  3  6 -2  4\n\nc(10, var, 100, 101) # 추가\n##  [1]  10   1   2   5   3   6  -2   4 100 101\n\nvar[2] <- 55 # 대체\n## var\n## [1]  1 55  5  3  6 -2  4\n\nvar[c(2, 5)] <- c(200, 500) # 대체\n## var\n## [1]   1 200   5   3 500  -2   4\n\n# numeric 벡터의 연산: recycling rule\n1:5 * 2\n## [1]  2  4  6  8 10\n\nc(1, 3, 5) - 5\n## [1] -4 -2  0\n\nc(2, 4, 6) / 2\n## [1] 1 2 3\n\nc(1, 3) * c(2, 4)\n## [1]  2 12\n\nc(1, 3) - c(2, 4)\n## [1] -1 -1"
  },
  {
    "objectID": "contents/baser.html#factor",
    "href": "contents/baser.html#factor",
    "title": "Base R",
    "section": "Factor",
    "text": "Factor\nVector로서 명목변수(카테고리)를 다룸\npatientID <- c(1, 2, 1, 3)\ndiabetes <- c(\"Type1\", \"Type2\", \"Type1\", \"Type1\")\nstatus <- c(\"Poor\", \"Improved\", \"Excellent\", \"Poor\")\n\n# factor로 변환: 알파벳 순서로 levels의 순서가 정해짐\nfactor(patientID)\n## [1] 1 2 1 3\n## Levels: 1 2 3\n\nfactor(diabetes)\n## [1] Type1 Type2 Type1 Type1\n## Levels: Type1 Type2\n\nfactor(status, order = TRUE) # order를 표시\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Excellent < Improved < Poor\n\n# 구체적으로 표시하는 것을 추천: 지정한 성분 순서대로 levels의 순서가 정해짐\nfactor(status, levels = c(\"Poor\", \"Improved\", \"Excellent\"),\n                                         order = TRUE)\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Poor < Improved < Excellent\n\n# order가 없을시\nfactor(status, levels = c(\"Poor\", \"Improved\", \"Excellent\"))\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Poor Improved Excellent\n\n# 대표적으로 성별을 코딩할 때: 숫자대신 레이블로 표시\nsex <- c(1, 2, 1, 1, 1, 2, 2, 1)\nfactor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\n## [1] Male   Female Male   Male   Male   Female Female Male  \n## Levels: Male Female\n\nsex_fct <- factor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\n\nlevels(sex) # 레벨 확인\n## NULL\nlevels(sex_fct) # 레벨 확인\n## [1] \"Male\"   \"Female\"\n\nsex\n## [1] 1 2 1 1 1 2 2 1\nsex_fct\n## [1] Male   Female Male   Male   Male   Female Female Male  \n## Levels: Male Female"
  },
  {
    "objectID": "contents/baser.html#data-frame",
    "href": "contents/baser.html#data-frame",
    "title": "Base R",
    "section": "Data Frame",
    "text": "Data Frame\n\n데이터 프레임의 구성\n# 벡터들로부터 데이터 프레임 구성\npatientID <- c(1, 2, 3, 4)\nage <- c(25, 34, 28, 52)\ndiabetes <- c(\"Type1\", \"Type2\", \"Type1\", \"Type1\")\nstatus <- c(\"Poor\", \"Improved\", \"Excellent\", \"Poor\")\n\npatientdata <- data.frame(patientID, age, diabetes, status)\n\npatientdata\n##   patientID age diabetes    status\n## 1         1  25    Type1      Poor\n## 2         2  34    Type2  Improved\n## 3         3  28    Type1 Excellent\n## 4         4  52    Type1      Poor\n\nmidterm <- data.frame(english = c(90, 80, 60, 70),\n                      math = c(50, 60, 100, 20),\n                      class = c(1, 1, 2, 2))\nmidterm\n##   english math class\n## 1      90   50     1\n## 2      80   60     1\n## 3      60  100     2\n## 4      70   20     2\n\n\n원소의 추출 및 대체\n# 원소의 추출\npatientdata[1:2] # 변수의 열을 지정\n##   patientID age\n## 1         1  25\n## 2         2  34\n## 3         3  28\n## 4         4  52\n\npatientdata[c(\"diabetes\", \"status\")] # 열 이름을 지정\n##   diabetes    status\n## 1    Type1      Poor\n## 2    Type2  Improved\n## 3    Type1 Excellent\n## 4    Type1      Poor\n\npatientdata[c(1, 3), c(\"age\", \"status\")] # 행과 열을 모두 지정\n##   age    status\n## 1  25      Poor\n## 3  28 Excellent\n\npatientdata[c(1, 3), c(2, 4)]\n##   age    status\n## 1  25      Poor\n## 3  28 Excellent\n\npatientdata[, 1:2] # patientdata[1:2]과 동일, 빈칸은 모든 행을 의미\n##   patientID age\n## 1         1  25\n## 2         2  34\n## 3         3  28\n## 4         4  52\n\npatientdata[1:2, ] # 빈칸은 모든 열을 의미\n##   patientID age diabetes   status\n## 1         1  25    Type1     Poor\n## 2         2  34    Type2 Improved\n\npatientdata[-1] # 열 제외\n##   age diabetes    status\n## 1  25    Type1      Poor\n## 2  34    Type2  Improved\n## 3  28    Type1 Excellent\n## 4  52    Type1      Poor\n\npatientdata[-c(1, 3)] # 열 제외\n##   age    status\n## 1  25      Poor\n## 2  34  Improved\n## 3  28 Excellent\n## 4  52      Poor\n\npatientdata[-c(1:2), 2:4] # 행 제외 & 열 선택\n##   age diabetes    status\n## 3  28    Type1 Excellent\n## 4  52    Type1      Poor\n\n\n# 변수/열의 성분을 벡터로 추출: $ 또는 [[ ]]을 이용\npatientdata$age # $를 이용\n## [1] 25 34 28 52\n\nclass(patientdata$age) # numeric vector임을 확인\n## [1] \"numeric\"\n\npatientdata[[\"age\"]] # patientdata$age과 동일, [[ ]] doule bracket을 이용해 벡터로 추출\n## [1] 25 34 28 52\n\npatientdata[[2]] # 열의 위치를 이용해도 동일한 추출\n## [1] 25 34 28 52\n\npatientdata[\"age\"] # [ ] single bracket은 열을 선택하는 것으로 데이터 프레임으로 추출\n##   age\n## 1  25\n## 2  34\n## 3  28\n## 4  52\n\npatientdata[2] # 2번째 열을 추출; patientdata[\"age\"]과 동일\n##   age\n## 1  25\n## 2  34\n## 3  28\n## 4  52\n\n\n데이터의 추가 및 대체\n# 데이터 추가\npatientdata$gender <- c(1, 1, 2, 2) \n\npatientdata\n##   patientID age diabetes    status gender\n## 1         1  25    Type1      Poor      1\n## 2         2  34    Type2  Improved      1\n## 3         3  28    Type1 Excellent      2\n## 4         4  52    Type1      Poor      2\n\n# 데이터 대체\npatientdata[c(1,3), \"age\"] # 혼동: 원칙적으로 데이터프레임으로 추출되어야하나 벡터로 추출됨\n## [1] 25 28\n\npatientdata[c(1,3), \"age\"] <- c(88, 99)\npatientdata\n##   patientID age diabetes    status gender\n## 1         1  88    Type1      Poor      1\n## 2         2  34    Type2  Improved      1\n## 3         3  99    Type1 Excellent      2\n## 4         4  52    Type1      Poor      2\n\n\n# 참고\nrow.names(patientdata) # 데이터 프레임의 행 이름\n## [1] \"1\" \"2\" \"3\" \"4\"\n\nrow.names(patientdata) <- c(\"a\", \"b\", \"c\", \"d\")\npatientdata\n##   patientID age diabetes    status gender\n## a         1  88    Type1      Poor      1\n## b         2  34    Type2  Improved      1\n## c         3  99    Type1 Excellent      2\n## d         4  52    Type1      Poor      2"
  },
  {
    "objectID": "contents/baser.html#tibble",
    "href": "contents/baser.html#tibble",
    "title": "Base R",
    "section": "Tibble",
    "text": "Tibble\n기존 data.frame의 단점을 보안한 tidyverse에서 기본이 되는 데이터 형식\n\nData frame vs. tibble\nPrinting의 차이\ncps <- mosaicData::CPS85 # data.frame\ncps\n#   wage educ race sex hispanic south married exper union age   sector\n# 1  9.0   10    W   M       NH    NS Married    27   Not  43    const\n# 2  5.5   12    W   M       NH    NS Married    20   Not  38    sales\n# 3  3.8   12    W   F       NH    NS  Single     4   Not  22    sales\n# 4 10.5   12    W   F       NH    NS Married    29   Not  47 clerical\n# 5 15.0   12    W   M       NH    NS Married    40 Union  58    const\n# 6  9.0   16    W   F       NH    NS Married    27   Not  49 clerical\n...\n\ncps_tibble <- as_tibble(cps)\ncps_tibble\n# # A tibble: 534 × 11\n#    wage  educ race  sex   hispanic south married exper union   age sector  \n#   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n# 1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n# 2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n# 3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n# 4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n# 5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n# 6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# # … with 528 more rows\n그 외의 차이는 R for Data Science/10.3 Tibbles vs. data.frame을 참고"
  },
  {
    "objectID": "contents/case2.html#guber-1999의-sat-점수와-주states의-교육지출-사이의-관계",
    "href": "contents/case2.html#guber-1999의-sat-점수와-주states의-교육지출-사이의-관계",
    "title": "Case Study 2",
    "section": "Guber (1999)의 SAT 점수와 주(states)의 교육지출 사이의 관계",
    "text": "Guber (1999)의 SAT 점수와 주(states)의 교육지출 사이의 관계\nSource: Statistical Methods for Psychology (8e) by Dave C. Howell\n\n\n\n\n각 주에서 집행되는 교육지출이 미국 학생의 SAT 점수에 미치는 효과를 알아보고자 함.\nSAT를 치르는 학생들의 비율이 주마다 상이함.\nData: ACT.csv\n\n\n\n\n\n\n\n\nact <- read_csv(\"howell/ACT.csv\")\nact\n\n# A tibble: 50 × 12\n      id State   Expend PTratio Salary PctSAT Verbal  Math   SAT PctACT   ACT\n   <dbl> <chr>    <dbl>   <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl>\n 1     1 Alabama   4.40    17.2   31.1      8    491   538  1029     61  20.2\n 2     2 Alaska    8.96    17.6   48.0     47    445   489   934     32  21  \n 3     3 Arizona   4.78    19.3   32.2     27    448   496   944     27  21.1\n 4     4 Ark       4.46    17.1   28.9      6    482   523  1005     66  20.3\n 5     5 Calif     4.99    24     41.1     45    417   485   902     11  21  \n 6     6 Col       5.44    18.4   34.6     29    462   518   980     62  21.5\n 7     7 Conn      8.82    14.4   50.0     81    431   477   908      3  21.7\n 8     8 Del       7.03    16.6   39.1     68    429   468   897      3  21  \n 9     9 Florida   5.72    19.1   32.6     48    420   469   889     36  20.7\n10    10 Georgia   5.19    16.3   32.3     65    406   448   854     16  20.2\n# ℹ 40 more rows\n# ℹ 1 more variable: LogPctSAT <dbl>\n\n\nA. 변수들 간의 관계 탐색\n\nlowerCor(act[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")])\nlibrary(corrgram)\nact[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")] |> \n  corrgram(upper.panel = panel.cor, lower.panel = panel.pie)\n\n\n\n          SAT   Expnd LPSAT Salry\nSAT        1.00                  \nExpend    -0.38  1.00            \nLogPctSAT -0.93  0.56  1.00      \nSalary    -0.44  0.87  0.61  1.00\n\n\n\n\n\n\n\n\nGGally::ggpairs(act[c(\"SAT\", \"Expend\", \"LogPctSAT\", \"Salary\")])\n\n\n\n\n\nact |> ggplot(aes(x = PctSAT, y = SAT)) + geom_point() + geom_smooth()\nact |> ggplot(aes(x = LogPctSAT, y = SAT)) + geom_point() + geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\nB1. 부분 회귀 계수들\n\nmod1 <- lm(SAT ~ Expend, data = act)\nmod2 <- lm(SAT ~ Expend + LogPctSAT, data = act)\n\n\n\nexport_summs(mod1, mod2, error_format = \"({p.value})\") |> print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)         1089.29 ***      1147.10 ***  \n                                      (0.00)           (0.00)     \n                Expend               -20.89 **         11.13 **   \n                                      (0.01)           (0.00)     \n                LogPctSAT                             -78.20 ***  \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                     50               50         \n                R2                     0.14             0.89      \n              ────────────────────────────────────────────────────\n                *** p < 0.001; ** p < 0.01; * p < 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n# beta: standardized coefficients\ncoef(lm.beta::lm.beta(mod2)) |> print()\n\n(Intercept)      Expend   LogPctSAT \n         NA    0.202704   -1.039937 \n\n\n\n\n\n\n\nB2. 부분 회귀 계수들\n\nmod1 <- lm(SAT ~ LogPctSAT, data = act)\nmod2 <- lm(SAT ~ LogPctSAT + Expend, data = act)\n\n\nexport_summs(mod1, mod2, error_format = \"({p.value})\") |> print()\n\n              ────────────────────────────────────────────────────\n                                    Model 1          Model 2      \n                               ───────────────────────────────────\n                (Intercept)         1185.83 ***      1147.10 ***  \n                                      (0.00)           (0.00)     \n                LogPctSAT            -69.65 ***       -78.20 ***  \n                                      (0.00)           (0.00)     \n                Expend                                 11.13 **   \n                                                       (0.00)     \n                               ───────────────────────────────────\n                N                     50               50         \n                R2                     0.86             0.89      \n              ────────────────────────────────────────────────────\n                *** p < 0.001; ** p < 0.01; * p < 0.05.           \n\nColumn names: names, Model 1, Model 2\n\n\nC. 부분 상관 계수들\n\nlowerCor(act[c(\"SAT\", \"Expend\", \"LogPctSAT\")])\n\n          SAT   Expnd LPSAT\nSAT        1.00            \nExpend    -0.38  1.00      \nLogPctSAT -0.93  0.56  1.00\n\nsumm(mod2, part.corr = TRUE, model.info = FALSE, model.fit = FALSE) |> print()\n\nStandard errors: OLS\n------------------------------------------------------------------------\n                       Est.    S.E.   t val.      p   partial.r   part.r\n----------------- --------- ------- -------- ------ ----------- --------\n(Intercept)         1147.10   16.70    68.68   0.00                     \nLogPctSAT            -78.20    4.47   -17.49   0.00       -0.93    -0.86\nExpend                11.13    3.26     3.41   0.00        0.45     0.17\n------------------------------------------------------------------------\n\n\nSummary\n\n\n\n\n\n\n\n\\(r\\)\n\\(\\beta\\)\n\\(pr\\)\n\\(sr\\)\n\n\n\n\nExpend\n-0.38\n0.20\n0.45\n0.17\n\n\nLogPctSAT\n-0.93\n-1.04\n-0.93\n-0.86\n\n\n\n\n\n \n\n\n\n\n\n\n\\(r^2\\)\n\\(\\beta^2\\)\n\\(pr^2\\)\n\\(sr^2\\)\n\n\n\n\nExpend\n0.14\n0.04\n0.20\n0.03\n\n\nLogPctSAT\n0.86\n1.08\n0.86\n0.74\n\n\n\n\n\n\nD. 예측변수의 추가\n예측변수가 3개인 경우\n\n\n\n\n\nmod3 <- lm(SAT ~ Salary, data = act)\nmod4 <- lm(SAT ~ Salary + Expend, data = act)\nmod5 <- lm(SAT ~ Salary + Expend + LogPctSAT, data = act)\n\nexport_summs(mod0, mod2, mod3, mod4, mod5, model.names = c(\"mod0\", \"mod2\", \"mod3\", \"mod4\", \"mod5\")) |> print()\n\n\n\n───────────────────────────────────────────────────────────────────────────────\n                  mod0         mod2         mod3         mod4         mod5     \n             ──────────────────────────────────────────────────────────────────\n  (Intercept      1089.29      1147.10      1158.86      1159.35      1133.11  \n  )                   ***          ***          ***          ***          ***  \n               (44.39)      (16.70)      (57.66)      (60.22)      (22.73)     \n  Expend       -20.89 **     11.13 **                   0.47         7.10      \n                (7.33)       (3.26)                   (14.58)       (5.50)     \n  LogPctSAT                 -78.20 ***                             -79.51 ***  \n                             (4.47)                                 (4.71)     \n  Salary                                  -5.54 **     -5.63         1.20      \n                                          (1.63)       (3.34)       (1.32)     \n             ──────────────────────────────────────────────────────────────────\n  N             50           50           50           50           50         \n  R2             0.14         0.89         0.19         0.19         0.89      \n───────────────────────────────────────────────────────────────────────────────\n  *** p < 0.001; ** p < 0.01; * p < 0.05.                                      \n\nColumn names: names, mod0, mod2, mod3, mod4, mod5\n\n\n\n\n\nmcPlots(mod4, overlaid = FALSE)\n\n\n\navPlots(mod5) # library(car)\n\n\n\n\nQ: Salary와 Expend 중 하나는 제거해야 되나???\n\n상관관계가 높은 변수들은 서로 partial out되어 남은 잔차들의 변량이 줄어 Y와의 관계를 온전히 테스트하기 어려워짐\n구체적으로는 standard error를 높여서 회귀계수에 대한 모집단에 대한 신뢰도를 낮춤\n이를 다중공선성(multicollinearity)이라고 함\n이들을 하나의 “묶음”(set)으로 취급해도 무방함"
  },
  {
    "objectID": "contents/interaction.html#continuous-vs.-continuous",
    "href": "contents/interaction.html#continuous-vs.-continuous",
    "title": "Interaction Effects",
    "section": "Continuous vs. Continuous",
    "text": "Continuous vs. Continuous\n\n예제 1\n나이가 듦(age)에 따른 지구력(endurance)의 감소가 운동을 한 기간(exercise)에 따라 변화하는가? (p.275)\nData: c07e01dt\nendurance: the number of minutes of sustained jogging on a treadmill\nexercise: the number of years of vigorous physical exercise\n\n\n연구자의 관심변수에 따라 다르게 표현될 수 있음.\n나이가 지구력에 미치는 부정적 영향을 운동이 완화시키는지 관심.\n이 때, 운동이 moderator로 작용하는 moderating effect (조절효과)를 가지는지 검증.\n통계적으로는 나이과 운동기간이 서로 상호작용(interact)하여 지구력에 영향을 미치는 것으로 나타남.\n\n\n\n\nacad2 <- read_csv('cohen/data/c07e01dt.csv')\nacad2\n\n# A tibble: 245 × 3\n     age exercise endurance\n   <dbl>    <dbl>     <dbl>\n 1    60       10        18\n 2    40        9        36\n 3    29        2        51\n 4    47       10        18\n 5    48        9        23\n 6    42        6        30\n 7    55        8         8\n 8    43       19        40\n 9    39        9        28\n10    51       14        15\n# ℹ 235 more rows\n\n\n\nlibrary(psych)\nlowerCor(acad2)\n\n          age   exrcs endrn\nage        1.00            \nexercise   0.28  1.00      \nendurance -0.13  0.34  1.00\n\n\n\n\n\n\n\nacad2 %>% \n  ggplot(aes(x = age, y = endurance)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\n\n\n\n\nacad2 %>% \n  ggplot(aes(x = exercise, y = endurance)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\n\n\n\n\n\n나이와 지구력의 관계가 운동기간에 따라 다른가를 보기 위해, 운동기간을 3구간으로 나눔.\n\n# 편의상 운동기간을 3구간으로 나눔\nacad2 %>% \n  mutate(exercise_cat = cut_number(exercise, 3)) %>% \n  ggplot(aes(x = age, y = endurance, color = exercise_cat)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) +\n  facet_wrap(~exercise_cat)\n\n\n\n# 편의상 나이를 3구간으로 나눔\nacad2 %>% \n  mutate(age_cat = cut_number(age, 3)) %>% \n  ggplot(aes(x = exercise, y = endurance, color = age_cat)) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) +\n  facet_wrap(~age_cat)\n\n\n\n\n두 변수, 나이와 운동기간으로 지구력을 예측하는 모형을 세우면,\n\nmod_s1 <- lm(endurance ~ age, data = acad2)\nmod_s2 <- lm(endurance ~ exercise, data = acad2)\nmod <- lm(endurance ~ age + exercise, data = acad2)\nexport_summs(mod_s1, mod_s2, mod)\n\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)33.16 ***18.39 ***29.40 ***\n\n(3.42)   (1.60)   (3.21)   \n\nage-0.13 *         -0.26 ***\n\n(0.07)          (0.07)   \n\nexercise       0.76 ***0.92 ***\n\n       (0.14)   (0.14)   \n\nN245       245       245       \n\nR20.02    0.11    0.17    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\nInteraction term을 추가해서 모형을 세우면\n\\(\\displaystyle \\widehat{endurance} = b_1\\cdot age + b_2\\cdot exercise + b_3\\cdot age \\cdot exercise + b_0\\)\n      \\(\\displaystyle = (b_1 + b_3 \\cdot exercise)\\cdot age + b_2\\cdot exercise + b_0\\)\n이제 age의 기울기가 exercise의 값에 따라 변할 수 있음.\n\n\n\n\n\n\n\n\n\n\n\nmod_interact <- lm(endurance ~ age * exercise, data = acad2)  \n# 동일: endurance ~ age + exercise + age:exercise\nS(mod_interact) # library(car)\n\nCall: lm(formula = endurance ~ age * exercise, data = acad2)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  53.17896    7.52661   7.065 1.71e-11 ***\nage          -0.76596    0.15980  -4.793 2.87e-06 ***\nexercise     -1.35095    0.66626  -2.028 0.043694 *  \nage:exercise  0.04724    0.01359   3.476 0.000604 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.7 on 241 degrees of freedom\nMultiple R-squared: 0.2061\nF-statistic: 20.86 on 3 and 241 DF,  p-value: 4.764e-12 \n    AIC     BIC \n1814.57 1832.07 \n\n\n\\(\\displaystyle \\widehat{endurance} = -0.766\\cdot age -1.350\\cdot exercise + 0.047\\cdot age \\cdot exercise + 53.18\\)\n      \\(\\displaystyle = (-0.766 + 0.047 \\cdot exercise)\\cdot age -1.350\\cdot exercise + 53.18\\)\n\nage의 기울기는 exercise의 값에 따라 변함\n운동기간이 0년인 경우, 지구력에 미치는 나이의 효과: \\((-0.766+0.047*0)\\cdot age = -0.766\\cdot age\\)\n운동기간이 10년인 경우, 지구력에 미치는 나이의 효과: \\((-0.766+0.047*10)\\cdot age = -0.30\\cdot age\\)\n\n각 회귀계수의 의미는 다른 변수의 값이 0일 때의 기울기/효과임\n\nage: -0.766은 운동기간이 0년일 때의 나이의 효과\nexercise: -1.350은 나이가 0살일 때의 운동기간의 효과\nage:exercise: 0.047는 두 변수의 joint effect\n절편 53.18: 운동기간이 0년인 0세의 지구력\n\n회귀계수를 용이하게 해석하기 위해 변수를 centering하거나 standardizing하는 것이 좋음.\n\n0의 의미가 있는 특별한 경우가 아니면 centering을 기본적으로 함.\n예를 들어, 언어발달 ~ 나이 * 형제자매 수 + 부모의 교육수준\n\n형제자매의 수 0은 의미가 있음.\n\n위의 경우 age와 exercise의 단위가 의미가 있으므로, 표준화보다는 centering\np-value들은 모두 바뀐 의미의 회귀계수에 대한 영가설 검정\n\n\n# jtools의 center()함수를 이용하거나 데이터셋에서 미리 변환\nmod_interact_c <- lm(endurance ~ center(age) * center(exercise), data = acad2)\nS(mod_interact_c)\n\nCall: lm(formula = endurance ~ center(age) * center(exercise), data = acad2)\n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  25.88872    0.64662  40.037  < 2e-16 ***\ncenter(age)                  -0.26169    0.06406  -4.085 6.01e-05 ***\ncenter(exercise)              0.97272    0.13653   7.124 1.20e-11 ***\ncenter(age):center(exercise)  0.04724    0.01359   3.476 0.000604 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.7 on 241 degrees of freedom\nMultiple R-squared: 0.2061\nF-statistic: 20.86 on 3 and 241 DF,  p-value: 4.764e-12 \n    AIC     BIC \n1814.57 1832.07 \n\n\n\n나이에 대한 회귀계수 -0.26: 운동기간이 평균(10.67년)일 때의 나이의 효과\n운동기간에 대한 회귀계수 0.97: 나이가 평균(49.18세)일 때의 운동기간의 효과\n\n\npsych::describe(acad2)\n\n          vars   n  mean    sd median trimmed   mad min max range skew kurtosis\nage          1 245 49.18 10.11     48   49.11 10.38  20  82    62 0.15    -0.08\nexercise     2 245 10.67  4.78     11   10.56  4.45   0  26    26 0.27     0.23\nendurance    3 245 26.53 10.82     27   26.39 10.38   0  55    55 0.11    -0.30\n            se\nage       0.65\nexercise  0.31\nendurance 0.69\n\n\n\nlibrary(effects)\nplot(predictorEffects(mod_interact, ~age, xlevels = 3))  # centering하지 않은 모형\n\n\n\nplot(predictorEffect(\"age\", mod_interact, xlevels = 3))  # centering하지 않은 모형\n\n\n\nm <- mean(acad2$exercise, na.rm = TRUE) |> round(2)\nsd <- sd(acad2$exercise, na.rm = TRUE) |> round(2)\n\nplot(predictorEffects(mod_interact, ~age, xlevels = list(exercise = c(m-sd, m, m+sd))))\n\n\n\n\n평균보다 1 표준편차 만큼 오래 운동한 경우: m + 1sd = 10.67 + 4.78 = 15.45년\n\n나이에 따른 지구력 감소가 거의 없는가?\n\n\nmod_interact_t <- lm(endurance ~ age * I(exercise - 15.45), data = acad2)\nS(mod_interact_t)  # car\n\nCall: lm(formula = endurance ~ age * I(exercise - 15.45), data = acad2)\n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             32.30671    4.72744   6.834 6.71e-11 ***\nage                     -0.03602    0.09027  -0.399 0.690184    \nI(exercise - 15.45)     -1.35095    0.66626  -2.028 0.043694 *  \nage:I(exercise - 15.45)  0.04724    0.01359   3.476 0.000604 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 9.7 on 241 degrees of freedom\nMultiple R-squared: 0.2061\nF-statistic: 20.86 on 3 and 241 DF,  p-value: 4.764e-12 \n    AIC     BIC \n1814.57 1832.07 \n\nConfint(mod_interact_t) |> print(digits = 2)  # car\n\n                        Estimate 2.5 % 97.5 %\n(Intercept)               32.307 22.99 41.619\nage                       -0.036 -0.21  0.142\nI(exercise - 15.45)       -1.351 -2.66 -0.039\nage:I(exercise - 15.45)    0.047  0.02  0.074\n\n\n\n\n\n\n\n\nInteraction의 패턴\n\n\n\n\nSynergistic or enhancing interaction\n\n\n상호작용 효과가 원래 효과들과 같은 방향으로 작용하는 경우\n삶의 만족도(Y)가 직업 스트레스(X)와 부정적인 관계에 있고, 부부관계의 문제(Z)와도 부정적인 관계에 있는 경우\n이 둘의 상호작용이 부정적이라면, 직업 스트레스와 부부관계의 문제가 동시에 증가하면 각각의 sum이 예측하는 것보다 더 낮은 삶의 만족도가 예측됨.\n\n\nBuffering interaction\n\n\n두 변수가 반대 방향으로 Y에 작용하고 있을 때, 한 변수가 다른 변수의 효과를 감소시키는 경우\n즉, 한 변수의 impact가 다른 변수의 impact를 줄여주는 경우\n건강보건에 대한 연구에서, 한 변수가 질병의 위험요인이고 다른 변수가 질병의 위험을 줄여주는 보호요인인 경우\n위의 예에서처럼, 나이(X)는 지구력 감소의 위험요인이고, 운동기간(Z)은 지구력 보호요인인 경우\n\n\nInterference or antagonistic interactionin\n\n\n두 변수가 같은 방향으로 Y에 작용하고 있을 때, 상호작용은 반대 방향으로 작용하는 경우\n대학생의 학업성취도(Y)에 대하여, 학업동기(X)와 학업능력(Z)이 모두 학업성취도(Y)에 긍정적인 영향을 미치나 이 두 변수는 서로 보완적인 효과를 가지고 있음.\n즉, 성취도에 대한 학업능력의 중요성은 높은 학업동기에 의해 낮아질 수 있음.\n반대로, 학업동기에 대한 중요성은 높은 학업능력에 의해 낮아질 수 있음.\n\n\n\n\n\n예제 2\nSource: p.551, Statistical Methods for Psychology (8e) by Dave C. Howell\n오리엔테이션에 참석한 대학 신입생을 대상으로, 스트레스 받은 일(hassles)이 많을 수록 여러 증상들(symptoms)을 더 경험하는데, 주위의 지지(support)가 많을 수록 그 증상들이 감소한다는 것을 알아보고자 설문 조사. (Wagner, Compas, and Howell (1988))\n\nhassles: 소소한 일상적인 스트레스를 경험한 횟수\nsupport: 본인이 인지하는 주위의 지지 정도\nsymptoms: 증상에 대한 checklist로 나타난 증상의 개수\n\nData: hassles.csv\n\n\nhassles <- read_csv(\"data/hassles.csv\")\nhassles\n\n# A tibble: 56 × 3\n   hassles support symptoms\n     <dbl>   <dbl>    <dbl>\n 1     176      10       73\n 2     379      50       88\n 3     126      45      118\n 4     193      40       79\n 5     229      40      127\n 6     153      39       73\n 7     214      38       93\n 8     164      37       99\n 9     143      36       81\n10      27      36       64\n# ℹ 46 more rows\n\ncar::scatterplotMatrix(hassles)\n\n\n\nhassles |> \n  lowerCor()  # library(psych)\n\n         hssls spprt sympt\nhassles   1.00            \nsupport  -0.17  1.00      \nsymptoms  0.58 -0.13  1.00\n\nhassles <- hassles |> \n  mutate(\n    hassles_c = center(hassles),  # library(jtools)\n    support_c = center(support),\n    symptom_c = center(symptoms),\n  )\n\nmod <- lm(symptom_c~ hassles_c * support_c, data = hassles)\nS(mod)  # library(car)\n\nCall: lm(formula = symptom_c ~ hassles_c * support_c, data = hassles)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -0.843632   2.291503  -0.368   0.7143    \nhassles_c            0.085942   0.019213   4.473 4.22e-05 ***\nsupport_c            0.146358   0.305244   0.479   0.6336    \nhassles_c:support_c -0.005065   0.002363  -2.144   0.0368 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 16.89 on 52 degrees of freedom\nMultiple R-squared: 0.3885\nF-statistic: 11.01 on 3 and 52 DF,  p-value: 1.046e-05 \n   AIC    BIC \n481.39 491.51 \n\n\n\nhassles |> ggplot(aes(x = support_c)) + geom_freqpoly()\n\n\n\n\n\nlibrary(effects)\n# 임의의 3 levels 선택\npredictorEffects(mod, xlevels = 3) |>  # 임의의 3 levels 선택\n  plot(lines = list(multiline = TRUE)) # 3개의 선을 함께 그림\n\n\n\n\n\n# 특정 3 levels 선택: -10(평균-10), 0(평균), 10(평균+10)\npredictorEffects(mod, ~ hassles_c, \n                 xlevels = list(support_c = c(-10, 0, 10))) |>  # 특정 3 levels 선택\n  plot(lines = list(multiline = TRUE))  # 3개의 선을 함께 그림\n\n\n\n\nsupport_c가 10일 때, hassels의 기울기는 통계적으로 유의한가를 테스트\n\nmod_probe <- lm(symptom_c ~ hassles_c * I(support_c - 10), data = hassles)\nS(mod_probe)  # library(car)\n\nCall: lm(formula = symptom_c ~ hassles_c * I(support_c - 10), data = hassles)\n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)  \n(Intercept)                  0.619943   3.697199   0.168   0.8675  \nhassles_c                    0.035293   0.034034   1.037   0.3045  \nI(support_c - 10)            0.146358   0.305244   0.479   0.6336  \nhassles_c:I(support_c - 10) -0.005065   0.002363  -2.144   0.0368 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 16.89 on 52 degrees of freedom\nMultiple R-squared: 0.3885\nF-statistic: 11.01 on 3 and 52 DF,  p-value: 1.046e-05 \n   AIC    BIC \n481.39 491.51 \n\n\n모든 moderator의 값에 대한 통계적 유의도를 계산\n\n# Johnson-Neyman intervals \nlibrary(interactions)\njohnson_neyman(mod, pred = \"hassles_c\", modx = \"support_c\")\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen support_c is OUTSIDE the interval [6.25, 297.50], the slope of\nhassles_c is p < .05.\n\nNote: The range of observed values of support_c is [-18.96, 21.04]\n\n\n\n\n\n회귀모형에 대한 진단\n\navPlots(mod)\n\n\n\ninfluenceIndexPlot(mod)\n\n\n\nmod_update <- update(mod, subset = -52) # 52번째 관측치 제거\navPlots(mod_update)\n\n\n\nS(mod_update)\n\nCall: lm(formula = symptom_c ~ hassles_c * support_c, data = hassles, subset =\n         -52)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -1.288549   2.156778  -0.597 0.552856    \nhassles_c            0.070908   0.018801   3.772 0.000423 ***\nsupport_c            0.125998   0.286624   0.440 0.662089    \nhassles_c:support_c -0.001655   0.002524  -0.656 0.515015    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 15.86 on 51 degrees of freedom\nMultiple R-squared: 0.2291\nF-statistic: 5.053 on 3 and 51 DF,  p-value: 0.00385 \n   AIC    BIC \n465.93 475.97"
  },
  {
    "objectID": "contents/interaction.html#continuous-vs.-categorical",
    "href": "contents/interaction.html#continuous-vs.-categorical",
    "title": "Interaction Effects",
    "section": "Continuous vs. Categorical",
    "text": "Continuous vs. Categorical\n\n성별 이나 실험조건/통제조건 같이 두 개의 범주를 가지는 변수와의 상호작용\n직업군과 같이 세 개 이상의 범주를 가지는 변수와의 상호작용\n\n\nBinary 변수와의 상호작용\n예제 1: Data from the 1985 Current Population Survey (CPS85)\n교육수준(educ)에 따른 임금(wage)의 증가량이 직업군에 따라 다른가?\n\ncps <- mosaicData::CPS85 |> as_tibble()\ncps\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector  \n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n 1  9       10 W     M     NH       NS    Married    27 Not      43 const   \n 2  5.5     12 W     M     NH       NS    Married    20 Not      38 sales   \n 3  3.8     12 W     F     NH       NS    Single      4 Not      22 sales   \n 4 10.5     12 W     F     NH       NS    Married    29 Not      47 clerical\n 5 15       12 W     M     NH       NS    Married    40 Union    58 const   \n 6  9       16 W     F     NH       NS    Married    27 Not      49 clerical\n 7  9.57    12 W     F     NH       NS    Married     5 Union    23 service \n 8 15       14 W     M     NH       NS    Single     22 Not      42 sales   \n 9 11        8 W     M     NH       NS    Married    42 Not      56 manuf   \n10  5       12 W     F     NH       NS    Married    14 Not      32 sales   \n# ℹ 524 more rows\n\n\n편의상 management와 professonal을 prof로 합치고, 나머지 sector들은 others로 합침\n\ncps <- cps |> \n  mutate(sector2 = ifelse(sector %in% c(\"manag\", \"prof\"), \"prof\", \"others\")) |> \n  filter(educ > 8 & wage < 30)\n\n\ncps |> ggplot(aes(x = educ, y = wage, color = sector2)) + geom_point() + geom_smooth(method=lm)\n\n\n\n\n\nmod <- lm(wage ~ educ * sector2, data = cps)\nS(mod)\n\nCall: lm(formula = wage ~ educ * sector2, data = cps)\n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)   \n(Intercept)        4.8011     1.8351   2.616  0.00916 **\neduc               0.2400     0.1461   1.642  0.10115   \nsector2prof       -6.9405     3.1148  -2.228  0.02631 * \neduc:sector2prof   0.6855     0.2190   3.130  0.00185 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.413 on 502 degrees of freedom\nMultiple R-squared: 0.2111\nF-statistic: 44.79 on 3 and 502 DF,  p-value: < 2.2e-16 \n    AIC     BIC \n2944.32 2965.46 \n\npredictorEffects(mod) |> plot()\n\n\n\n\n예제 2: 상대방의 사회적 지위에 따른 이타성의 차이\n\n실험조건: 수혜자의 사회적 지위가 high status vs. low status\n통제변수: 돕는 사람의 공감능력\n\n\nhelping <- read_csv(\"data/altru.csv\")\nhelping\n\n# A tibble: 170 × 3\n   helping empathy status\n     <dbl>   <dbl> <chr> \n 1   45.5     58.1 low   \n 2   73.4     43.9 high  \n 3   73.6     76.8 high  \n 4    5.43    42.6 low   \n 5   29.5     80.6 high  \n 6   24.2     44.2 low   \n 7   68.6     77.6 low   \n 8   46.5     94.2 low   \n 9    3.76    87.3 high  \n10   36.0     57.9 high  \n# ℹ 160 more rows\n\n\n\nmod <- lm(helping ~ empathy * status, data = helping)\nS(mod)\n\nCall: lm(formula = helping ~ empathy * status, data = helping)\n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)   \n(Intercept)         8.6270    11.2547   0.767  0.44445   \nempathy             0.5022     0.1568   3.203  0.00163 **\nstatuslow         -29.6046    15.8479  -1.868  0.06352 . \nempathy:statuslow   0.5187     0.2161   2.401  0.01748 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 21.97 on 166 degrees of freedom\nMultiple R-squared: 0.2845\nF-statistic:    22 on 3 and 166 DF,  p-value: 4.787e-12 \n    AIC     BIC \n1538.84 1554.52 \n\nmod_std <- lm(scale(helping) ~ scale(empathy) * status, data = helping)\nS(mod_std)\n\nCall: lm(formula = scale(helping) ~ scale(empathy) * status, data = helping)\n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)   \n(Intercept)              -0.15510    0.09089  -1.706  0.08979 . \nscale(empathy)            0.30706    0.09585   3.203  0.00163 **\nstatuslow                 0.29387    0.13167   2.232  0.02696 * \nscale(empathy):statuslow  0.31710    0.13209   2.401  0.01748 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.8535 on 166 degrees of freedom\nMultiple R-squared: 0.2845\nF-statistic:    22 on 3 and 166 DF,  p-value: 4.787e-12 \n   AIC    BIC \n434.53 450.20 \n\ndescribe(helping)\n\n        vars   n  mean    sd median trimmed   mad   min max  range  skew\nhelping    1 170 48.61 25.74  48.25   48.82 27.47  0.00 100 100.00 -0.03\nempathy    2 170 71.66 15.74  73.94   72.38 17.65 13.08 100  86.92 -0.45\nstatus*    3 170  1.48  0.50   1.00    1.47  0.00  1.00   2   1.00  0.09\n        kurtosis   se\nhelping    -0.73 1.97\nempathy    -0.05 1.21\nstatus*    -2.00 0.04\n\nplot(predictorEffects(mod, ~status, xlevels = list(empathy = c(71.6-15.7, 71.6, 1+15.7))))\n\n\n\n\n\n\n3개 이상의 범주를 가지는 변수와의 상호작용\nData: c0904dt2.csv\n\nacad3 <- read_csv(\"data/c0904dt2.csv\")\nacad3\n\n# A tibble: 150 × 5\n   depart    pub  time salary sex   \n   <chr>   <dbl> <dbl>  <dbl> <chr> \n 1 anthrop    16     3 56465. female\n 2 anthrop    25     7 92044. male  \n 3 anthrop    16     2 48980. female\n 4 anthrop    24     1 53239. female\n 5 anthrop    24     8 98948. male  \n 6 anthrop    26    14 64782. male  \n 7 anthrop    39     5 91652. male  \n 8 anthrop    16     1 32833. male  \n 9 anthrop    26    10 79231. male  \n10 anthrop    23    11 77154. female\n# ℹ 140 more rows\n\n\n\nacad3 <- acad3 |> mutate(pub_c = center(pub), time_c = center(time))\nacad3 |> \n  ggplot(aes(x = pub, y = salary, color = depart)) +\n  geom_point() + geom_smooth(method=lm) + facet_wrap(~depart)\n\n\n\n\n\nmod <- lm(salary ~ pub_c * depart, data = acad3)\nS(mod)\n\nCall: lm(formula = salary ~ pub_c * depart, data = acad3)\n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       56917.9     2207.4  25.785  < 2e-16 ***\npub_c              1372.9      252.5   5.438 2.25e-07 ***\ndeparthist         9796.1     3615.1   2.710  0.00755 ** \ndepartsoc          9672.8     3235.2   2.990  0.00328 ** \npub_c:departhist   -961.0      466.2  -2.061  0.04109 *  \npub_c:departsoc   -1115.0      495.4  -2.251  0.02592 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 15670 on 144 degrees of freedom\nMultiple R-squared: 0.1892\nF-statistic: 6.722 on 5 and 144 DF,  p-value: 1.167e-05 \n    AIC     BIC \n3331.44 3352.51 \n\nplot(predictorEffects(mod, ~depart, xlevels = 3))\n\n\n\nplot(predictorEffects(mod, ~pub_c))\n\n\n\n\n연차의 효과를 통제?\n\nmod2 <- lm(salary ~ (time_c + pub_c) * depart, data = acad3)"
  },
  {
    "objectID": "contents/interaction.html#categorical-vs.-categorical",
    "href": "contents/interaction.html#categorical-vs.-categorical",
    "title": "Interaction Effects",
    "section": "Categorical vs. Categorical",
    "text": "Categorical vs. Categorical\nANOVA: factorical design\n\n실험연구의 예\n실험연구 분석에 대한 더 논의가 필요함…\nData: C0901DT.csv\n\nrats <- read_csv(\"data/C0901DT.csv\")\nrats <- rats |> rename_with(str_to_lower)  # 변수명 소문자로 변경\nrats |> sample_n(6)\n\n# A tibble: 6 × 5\n     ya    yb     yc lesion drug   \n  <dbl> <dbl>  <dbl> <chr>  <chr>  \n1  5.03  5.03  3.03  SHAM   ACTIVE \n2  6.72 10.7   8.72  SHAM   PLACEBO\n3  1.83  1.83  0.826 SHAM   ACTIVE \n4  2.83  2.83  0.829 SHAM   ACTIVE \n5  9.84 13.8  11.8   SHAM   PLACEBO\n6  3.12  3.12  1.12  SHAM   ACTIVE \n\nrats |> group_by(lesion, drug) |> summarise(yc_mean = mean(yc))\n\n# A tibble: 4 × 3\n  lesion  drug    yc_mean\n  <chr>   <chr>     <dbl>\n1 SHAM    ACTIVE     2.00\n2 SHAM    PLACEBO    9.99\n3 SURGERY ACTIVE     8.02\n4 SURGERY PLACEBO   12.0 \n\nmod <- lm(yb ~ lesion * drug, data = rats)\nS(mod)\n\nCall: lm(formula = yb ~ lesion * drug, data = rats)\n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 3.9965     0.1524   26.23   <2e-16 ***\nlesionSURGERY              10.0251     0.2302   43.55   <2e-16 ***\ndrugPLACEBO                 8.0141     0.2056   38.98   <2e-16 ***\nlesionSURGERY:drugPLACEBO -12.0336     0.3256  -36.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.9758 on 147 degrees of freedom\nMultiple R-squared: 0.9401\nF-statistic: 768.6 on 3 and 147 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n427.07 442.15 \n\npredictorEffects(mod, ~drug) |> plot()\n\n\n\n\nData: C0902DT.csv\n\ntreat <- read_csv(\"data/C0902DT.csv\")\ntreat <- treat |> rename_with(str_to_lower) # 변수명 소문자로 변경\ntreat |> head(5)\n\n# A tibble: 5 × 3\n  hospital treatmen     y\n     <dbl>    <dbl> <dbl>\n1        1        1  66.8\n2        1        1  42.4\n3        1        1  20.7\n4        1        1  46.4\n5        1        1  54.3\n\ntreat <- treat |> \n  mutate(hospital = factor(hospital), treatmen = factor(treatmen))\nmod <- lm(y ~ hospital * treatmen, data = treat)\npredictorEffects(mod, ~treatmen) |> plot()\n\n\n\n\n\n\n관찰연구의 예\n성별과 결혼 여부에 따른 임금차이\n\ncps <- mosaicData::CPS85 |> as_tibble()\ncps |> head(5)\n\n# A tibble: 5 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n\nmod <- lm(wage ~ sex * married, data = cps)\nS(mod)\n\nCall: lm(formula = wage ~ sex * married, data = cps)\n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          7.6838     0.3898  19.711  < 2e-16 ***\nsexM                 3.1923     0.5319   6.002 3.62e-09 ***\nmarriedSingle        0.5759     0.6697   0.860  0.39026    \nsexM:marriedSingle  -3.0972     0.9073  -3.414  0.00069 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.962 on 530 degrees of freedom\nMultiple R-squared: 0.07314\nF-statistic: 13.94 on 3 and 530 DF,  p-value: 9.234e-09 \n    AIC     BIC \n3232.05 3253.45 \n\npredictorEffects(mod) |> plot()\n\n\n\n\n관찰연구의 경우 confounding이 될만한 통제 변수를 충분히 고려해야 하고, 나이가 성별과 결혼 여부와 상관관계가 있으므로 통제 변수로 포함.\n\ncps |> select(age, sex, married) |> lowerCor()\n\n         age   sex*  mrrd*\nage       1.00            \nsex*     -0.08  1.00      \nmarried* -0.28  0.01  1.00\n\n# age와 wage의 관계는 비선형적: spline regression (piecewise polynomial) fit을 고려할 필요있음\nmod2 <- lm(wage ~ sex * married + age + I(age^2), data = cps)  \npredictorEffects(mod2, ~ sex + married) |> plot()\n\n\n\nS(mod2)\n\nCall: lm(formula = wage ~ sex * married + age + I(age^2), data = cps)\n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        -5.147951   2.391631  -2.152  0.03181 *  \nsexM                3.152425   0.516297   6.106 1.98e-09 ***\nmarriedSingle       1.321511   0.662608   1.994  0.04662 *  \nage                 0.608443   0.121565   5.005 7.62e-07 ***\nI(age^2)           -0.006630   0.001483  -4.470 9.60e-06 ***\nsexM:marriedSingle -2.617902   0.887868  -2.949  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.816 on 528 degrees of freedom\nMultiple R-squared: 0.1301\nF-statistic:  15.8 on 5 and 528 DF,  p-value: 1.649e-14 \n    AIC     BIC \n3202.17 3232.13 \n\n\n결혼 유무에 따른 임금의 차이는 여성의 경우 미혼이 $1.32(p = 0.047) 높음.\n남성의 경우는 아래와 같이 factor level을 변경해서 보면, 남성인 경우 미혼이 $1.29(p = 0.041) 낮음.\n\nmod2_m <- lm(wage ~ fct_relevel(sex, \"M\") * married + age + I(age^2), data = cps)\nS(mod2_m)\n\nCall: lm(formula = wage ~ fct_relevel(sex, \"M\") * married + age + I(age^2),\n         data = cps)\n\nCoefficients:\n                                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                          -1.995525   2.393324  -0.834  0.40478    \nfct_relevel(sex, \"M\")F               -3.152425   0.516297  -6.106 1.98e-09 ***\nmarriedSingle                        -1.296391   0.632255  -2.050  0.04082 *  \nage                                   0.608443   0.121565   5.005 7.62e-07 ***\nI(age^2)                             -0.006630   0.001483  -4.470 9.60e-06 ***\nfct_relevel(sex, \"M\")F:marriedSingle  2.617902   0.887868   2.949  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 4.816 on 528 degrees of freedom\nMultiple R-squared: 0.1301\nF-statistic:  15.8 on 5 and 528 DF,  p-value: 1.649e-14 \n    AIC     BIC \n3202.17 3232.13"
  },
  {
    "objectID": "contents/categorical.html",
    "href": "contents/categorical.html",
    "title": "Categorical IVs",
    "section": "",
    "text": "범주형 변수가 예측변수가 되는 경우, 범주형 변수는 숫자로 변환시켜 분석 가능\n범주가 실험 조건이 되는 경우, 예를 들어 통제집단과 처치집단에 대해서 그 차이를 보는 경우, 실험연구의 전통을 가진 ANOVA 프레임워크에서 다루어져 왔고 다양한 용어(ANCOVA, fatorial ANOVA, repeated ANOVA, MANOVA 등등)와 분석 방식이 행해져왔으나, 관찰연구의 전통을 가진 회귀분석의 프레임워크 안에서 통합될 수 있음.\n범주를 숫자로 변환시키는 방식은 연구의 목적에 따라 여러 방식으로 coding할 수 있는데, 예를 들어 sequential coding, Helmert coding, effect coding 등등에 대해서는 책을 참고.\n10.1 Alternative Coding Systems in Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n앞서, 범주가 2개인 성별의 경우: 남자는 0, 여자는 1로 변형시키는 dummy coding으로 indicator variable을 만들어 사용했음"
  },
  {
    "objectID": "contents/categorical.html#attitude-toward-abortion-ata",
    "href": "contents/categorical.html#attitude-toward-abortion-ata",
    "title": "Categorical IVs",
    "section": "Attitude toward abortion (ATA)",
    "text": "Attitude toward abortion (ATA)\n종교에 따른 낙태에 대한 (긍정적) 태도의 차이\n종교: 개신교, 카톡릭, 유대교, 기타\nData: c08e01dt.csv\n\n\n\nata <- read_csv(\"data/c08e01dt.csv\")\nata\n\n# A tibble: 36 × 2\n   rel          ata\n   <chr>      <dbl>\n 1 Catholic      61\n 2 Other         78\n 3 Protestant    47\n 4 Catholic      65\n 5 Catholic      45\n 6 Other        106\n 7 Protestant   120\n 8 Catholic      49\n 9 Other         45\n10 Other         62\n# ℹ 26 more rows\n\n\n\nggplot(ata, aes(x = rel, y = ata)) +\n    geom_boxplot(fill = \"white\") +\n    geom_jitter(width= .1, size = 2, color = \"orangered\")\n\n\n\n\n\n\n다음은 dummy coding을 하는데 기준이 되는 범주(reference group)를 무엇으로 하느냐에 따른 차이를 보여줌\n일반적으로 범주가 N개이면 N-1개의 dummy variable이 필요함.\n각각의 dummy variable은 membership를 나타내며, 해당 범주에 속하는 경우 1, 아닌 경우 0으로 coding됨.\n\n여기서는 Protestant를 reference로 하는 B번을 사용하는데\n\\(C_1\\) : Catholic인지 아닌지\n\\(C_2\\) : Jewish인지 아닌지\n\\(C_3\\) : Other인지 아닌지\n\n\n   p.304\n\n회귀 계수\n우선, 명목변수를 R의 factor 타입으로 변환\n\nrel을 factor로 변환; 순서를 고려해서\nProtestant를 reference group으로 지정하기 위해 첫번째 level로 지정\n\n\nata <- ata |> \n    mutate(rel = factor(rel, levels = c(\"Protestant\", \"Catholic\", \"Jewish\", \"Other\")))\n\nR에서 기본적으로 factor는 dummy coding으로 변환\n실제 내부적으로 어떻게 변환되는지 확인해보면,\n\nmodel.matrix(~ rel, data = ata) |> bind_cols(ata[\"rel\"]) # bind two columns\n\n# A tibble: 36 × 5\n   `(Intercept)` relCatholic relJewish relOther rel       \n           <dbl>       <dbl>     <dbl>    <dbl> <fct>     \n 1             1           1         0        0 Catholic  \n 2             1           0         0        1 Other     \n 3             1           0         0        0 Protestant\n 4             1           1         0        0 Catholic  \n 5             1           1         0        0 Catholic  \n 6             1           0         0        1 Other     \n 7             1           0         0        0 Protestant\n 8             1           1         0        0 Catholic  \n 9             1           0         0        1 Other     \n10             1           0         0        1 Other     \n# ℹ 26 more rows\n\n\n이전과 같은 방식으로 선형회귀모형을 세워 분석하면,\nModel: ata ~ rel\n\\(\\widehat{ata} = b_1 \\cdot relCatholic + b_2 \\cdot relJewish + b_3 \\cdot relOther + b_0\\)\n\nmod <- lm(ata ~ rel, data = ata) \nS(mod, brief = TRUE)  # S()는 summmary() 대체 (car 패키지)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   93.308      6.495  14.366 1.66e-15 ***\nrelCatholic  -32.641     10.155  -3.214  0.00298 ** \nrelJewish     10.192     11.558   0.882  0.38444    \nrelOther     -23.183     10.523  -2.203  0.03491 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 23.42 on 32 degrees of freedom\nMultiple R-squared: 0.3549\nF-statistic: 5.869 on 3 and 32 DF,  p-value: 0.002599 \n   AIC    BIC \n334.98 342.89 \n\n\nFitted model:\n\\(\\widehat{ata} = -32.6 \\cdot relCatholic + 10.2 \\cdot relJewish - 23.2 \\cdot relOther + 93.3\\)\n각 회귀계수의 의미는 실제 dummy variable의 값을 대입함으로써 추론할 수 있음.\nProtestant:    \\(\\widehat{ata} = b_1(0) + b_2(0) + b_3(0) + b_0 = b_0 = 93.3 = M_{Protestant}~(reference ~group)\\)\n    Catholic:    \\(\\widehat{ata} = b_1(1) + b_2(0) + b_3(0) + b_0 = b_1 + b_0 = -32.6 + 93.3 = M_{Catholic}\\)\n   Jewish:    \\(\\widehat{ata} = b_1(0) + b_2(1) + b_3(0) + b_0 = b_2 + b_0 = 10.2 + 93.3 = M_{Jewish}\\)\n   Other:    \\(\\widehat{ata} = b_1(0) + b_2(0) + b_3(1) + b_0 = b_3 + b_0 = -23.2 + 93.3 = M_{Other}\\)\n따라서, 각 회귀계수는 기울기로 (마찬가지로) 해석해서 0에서 1로 증가할 때의 변화량으로 해석할 수 있음. 즉,\n\n\\(b_1 = -32.6\\) 은 카톡릭 신자는 개신교도(\\(b_0\\))에 비해 32.6 정도 낙태에 대한 부정적인 태도를 나타냈음.\n\\(b_2 = 10.2\\) 는 유대교도는 개신교도(\\(b_0\\))에 비해 10.2 정도 낙태에 대한 긍정적인 태도를 나타냈음.\n\\(b_3 = -23.2\\) 는 기타 종교는 개신교도(\\(b_0\\))에 비해 23.2 정도 낙태에 대한 부정적인 태도를 나타냈음.\n\n각 범주에 대한 예측값은 해당 범주의 평균과 같음.\nGraphical representation of the model\n\n\n\n\n\n\n\n\n\n회귀계수에 대한 가설검정\n\n각 회귀계수에 대한 가설검정은 해당 범주와 reference group의 평균이 같은지에 대한 테스트\n다른 범주간의 평균 차이에 대한 가설검정은 reference group을 바꿔 테스트\n\n\nS(mod, brief = TRUE)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   93.308      6.495  14.366 1.66e-15 ***\nrelCatholic  -32.641     10.155  -3.214  0.00298 ** \nrelJewish     10.192     11.558   0.882  0.38444    \nrelOther     -23.183     10.523  -2.203  0.03491 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 23.42 on 32 degrees of freedom\nMultiple R-squared: 0.3549\nF-statistic: 5.869 on 3 and 32 DF,  p-value: 0.002599 \n   AIC    BIC \n334.98 342.89 \n\n\nReference group를 잠시 변경하고자 한다면, fct_relevel() 함수를 사용\n\nmod_Catholic <- lm(ata ~ fct_relevel(rel, \"Catholic\"), data = ata)  # Catholic을 첫번째 level로 변경\nS(mod_Catholic, brief = TRUE)\n\nCoefficients:\n                                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                              60.667      7.806   7.772  7.3e-09 ***\nfct_relevel(rel, \"Catholic\")Protestant   32.641     10.155   3.214  0.00298 ** \nfct_relevel(rel, \"Catholic\")Jewish       42.833     12.342   3.470  0.00151 ** \nfct_relevel(rel, \"Catholic\")Other         9.458     11.379   0.831  0.41202    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 23.42 on 32 degrees of freedom\nMultiple R-squared: 0.3549\nF-statistic: 5.869 on 3 and 32 DF,  p-value: 0.002599 \n   AIC    BIC \n334.98 342.89 \n\n\n만약, 여러 조합에 대한 가설검증을 한번에 하고자 한다면, multiple test의 문제를 고려한 다양한 방식이 존재\nChapter 11. Multiple Test 참고, Regression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\n\nBonferroni correction: 비교하는 조합의 수로 나누어서 유의수준을 보정\nex. 3개라면 3으로 p-value를 곱한 후 0.05보다 작은지 확인 (95% 유의수준에서)\n\nemmeans 패키지의 emmeans() 함수는 적절한 방식으로 multiple test를 수행\n\n아래는 모든 조합 (all pairwise)에 대한 가설검정 결과\n\nlibrary(emmeans)\nemmeans(mod, pairwise ~ rel)  # all pairwise\n\n$emmeans\n rel        emmean   SE df lower.CL upper.CL\n Protestant   93.3 6.50 32     80.1    106.5\n Catholic     60.7 7.81 32     44.8     76.6\n Jewish      103.5 9.56 32     84.0    123.0\n Other        70.1 8.28 32     53.3     87.0\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast              estimate   SE df t.ratio p.value\n Protestant - Catholic    32.64 10.2 32   3.214  0.0150\n Protestant - Jewish     -10.19 11.6 32  -0.882  0.8142\n Protestant - Other       23.18 10.5 32   2.203  0.1441\n Catholic - Jewish       -42.83 12.3 32  -3.470  0.0078\n Catholic - Other         -9.46 11.4 32  -0.831  0.8393\n Jewish - Other           33.38 12.6 32   2.639  0.0585\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\n\nThe second part of the output shows all possible pairwise differences of adjusted means and provides p-values for t-tests adjusted for multiple comparisons using, in this instance, Tukey’s HSD (“honestly significant difference”) method (Bretz, Hothorn, & Westfall, 2011, Section 4.2). The emmeans () function chooses an appropriate multiple-comparison method depending on the problem.\nAn R Companion to Applied Regression by John Fox \n\n아래는 reference group과의 차이에 대한 가설검정 결과\n\ndummy coding한 회귀 분석과 같은 비교 단, 보정된 p-value\n\n\nemmeans(mod, trt.vs.ctrl ~ rel)  # treatment vs. control 용어에서 유래\n\n$emmeans\n rel        emmean   SE df lower.CL upper.CL\n Protestant   93.3 6.50 32     80.1    106.5\n Catholic     60.7 7.81 32     44.8     76.6\n Jewish      103.5 9.56 32     84.0    123.0\n Other        70.1 8.28 32     53.3     87.0\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast              estimate   SE df t.ratio p.value\n Catholic - Protestant    -32.6 10.2 32  -3.214  0.0084\n Jewish - Protestant       10.2 11.6 32   0.882  0.6926\n Other - Protestant       -23.2 10.5 32  -2.203  0.0910\n\nP value adjustment: dunnettx method for 3 tests \n\n\n\n\nMeasure of association\n각 더미 변수들과 낙태에 대한 태도와의 고유한 상관계수인 partial correlation에 대해서 논의하는 것은 복잡하나, 원래의 의미를 유지하고 있음.\n더 중요한 관심은 종교라는 변수를 3개의 더미 변수들의 set으로 보고, 3개의 변수들이 합쳐서 낙태에 대한 태도를 얼마나 설명해주는지에 대해 말할 수 있음.\n\n즉, \\(R^2\\)를 보면 0.35로 종교 변수는 낙태에 대한 태도 변량의 35%를 설명해준다고 해석할 수 있음.\n그 상관계수 \\(R = \\sqrt{0.35} = 0.60\\) 은 종교과 낙태에 대한 태도와의 상관 정도(association)를 말해 줌.\n주의! 각 범주의 비율이 상정한 모집단과 어느 정도 일치해야지 모집단에 대한 추정이 의미가 있음.\n\nANOVA 프레임워크에서 effect size를 뜻하는 \\(\\eta^2\\)는 \\(R^2\\)와 동일하며\n보정된 값들인 \\(\\epsilon^2,~ \\omega^2\\)에 대해서 \\(\\epsilon^2 = R^2_{adj}\\)\n\nAdjusted (shrunken) \\(R^2\\) 는 표본에서 biased된 통계치인 \\(R^2\\)를 보정한 값으로, 모집단에서의 true \\(R^2\\)을 추정하기 위한 노력.\n\n참고: Effect Sizes for ANOVAs\n예를 들어,\n\n\n\neta_squared(mod)  # library(effectsize)\n\n# A tibble: 1 × 5\n  Parameter  Eta2    CI CI_low CI_high\n  <chr>     <dbl> <dbl>  <dbl>   <dbl>\n1 rel       0.355  0.95  0.105       1\n\n\n\nomega_squared(mod)  # library(effectsize)\n\n# A tibble: 1 × 5\n  Parameter Omega2    CI CI_low CI_high\n  <chr>      <dbl> <dbl>  <dbl>   <dbl>\n1 rel        0.289  0.95 0.0492       1\n\n\n\n\n\nepsilon_squared(mod)  # library(effectsize)\n\n# A tibble: 1 × 5\n  Parameter Epsilon2    CI CI_low CI_high\n  <chr>        <dbl> <dbl>  <dbl>   <dbl>\n1 rel          0.294  0.95 0.0537       1"
  },
  {
    "objectID": "contents/categorical.html#effect-size",
    "href": "contents/categorical.html#effect-size",
    "title": "Categorical IVs",
    "section": "Effect size",
    "text": "Effect size\n효과의 크기를 표현하기 위해 다양한 방식이 존재하며, 이는 연구의 성격과 전달하고자 하는 바에 맞춰 선택.\n크게 두 클래스로 나눌 수 있는데,\n 1. r-family (correlation-based)\n앞서 전개한 r(R), parital r, semi-partial r, (adjusted) R squared 등을 통해 종속변수와 독립변수들의 관계의 크기를 구현함.\nANOVA 프레임워크에서는 \\(\\eta^2, ~\\epsilon^2,~ \\omega^2\\) 로 표현됨.\n\n임금의 변량이 성별에 의해 50% 설명된다면, 즉 \\(R^2\\) = .5 라면, 임금에 미치는 성별의 효과의 크기를 0.5로 표현할 수 있고,\n또는 임금과 성별이 \\(R\\) = .7 정도의 상관을 갖는다고 그 효과를 표현할 수 있음.\n앞서 예에서는 종교가 낙태에 대한 태도를 36% 설명하므로, 종교가 낙태에 대한 생각에 미치는 효과의 크기는 0.36 정도라고 혹은 \\(R\\)을 이용해 0.6 정도 라고 말할 수 있음.\n\n 2. d-family (difference-based)\n두 집단의 평균 차이 혹은 비율을 표현하는데, 보통 표준편차의 단위로 표현. 즉, 표준화된 차이(standardized difference)\n대표적으로 Cohen’s d (Hedges’ g, Glass’s delta)\n\n|d|<0.2 “negligible”, |d|<0.5 “small”, |d|<0.8 “medium”, 그 외 “large”\n예를 들어, 어떤 회사의 남녀의 연봉 차이가 $8000일 때, 그 자체로 연봉에 미치는 성별의 효과로 말할 수 있으나\n표준편차의 단위로 표현하는 것이 더 적절할 수 있음. 예를 들어 그 회사의 연봉의 편차가 $2000일 때와 $4,000일 때 남녀 연봉의 차이가 실제 주는 의미가 다름. 즉, $8000/$2000 = 4와 $8000/$4000 = 2가 되어 표준편차의 단위로 표현하면 더 의미가 있음. (또는 남녀 각각의 표준편차의 (weighted) 평균 (pooled standard deviation)으로 나눔)\n이 때, 어떤 표준편차로 나눌지는 연구내용에 맞춰 효과의 크기가 잘 전달되도록 선택.\n\n참고:\nCohen, J. (1992). A power primer. Psychological Bulletin, 112, 155-159.\nDavid C. Howell (2011). Confidence Intervals on Effect Size\nR에서 d-family 효과 크기를 계산하는 한 방법\n구체적 계산식은 help(cohens_d) 참고\n\n\n\ncohens_d(ata ~ rel,  # library(effectsize)\n    data = filter(ata, \n        rel %in% c(\"Protestant\", \"Catholic\")))\n\n# A tibble: 1 × 4\n  Cohens_d    CI CI_low CI_high\n     <dbl> <dbl>  <dbl>   <dbl>\n1     1.37  0.95  0.404    2.30\n\n\n\ncohens_d(ata ~ rel, \n    data = filter(ata, \n        rel %in% c(\"Protestant\", \"Jewish\")))\n\n# A tibble: 1 × 4\n  Cohens_d    CI CI_low CI_high\n     <dbl> <dbl>  <dbl>   <dbl>\n1   -0.365  0.95  -1.34   0.615"
  },
  {
    "objectID": "contents/categorical.html#simpler-model",
    "href": "contents/categorical.html#simpler-model",
    "title": "Categorical IVs",
    "section": "Simpler model",
    "text": "Simpler model\n예제: 이타적인 성향이 인구밀도에 영향을 받을 것이라는 가설 하에 도시지역(city)과 그 주변도시(noncity)의 주민들을 조사 (p. 344)\nData: c08e02dt.csv\n이 때, 연구자는 인구밀도에 따른 이타성의 차이는 그저 두 지역의 neuroticism의 차이를 반영할 뿐일 수 있음을 의심한다고 하면,\n\n\n\n\naltruism <- read_csv(\"data/c08e02dt.csv\")\naltruism\n\n# A tibble: 150 × 5\n   altruism   ses neuroticism area       city    \n      <dbl> <dbl>       <dbl> <chr>      <chr>   \n 1     69.1  66.7        61.0 small_town non-city\n 2     56.2  58.0        73.6 small_town non-city\n 3     65.6  36.3        41.2 small_town non-city\n 4     65.8  63.8        55.9 small_town non-city\n 5     63.1  46.1        46.4 small_town non-city\n 6     50.6  42.2        58.2 small_town non-city\n 7     63.5  54.4        54.6 small_town non-city\n 8     69.1  26.2        47.5 small_town non-city\n 9     69.9  50.6        59.0 small_town non-city\n10     49.0  31.9        49.0 small_town non-city\n# ℹ 140 more rows\n\n\n\naltruism |> \n  ggplot(aes(x = city, y = altruism)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = city, y = neuroticism)) +\n  geom_boxplot()\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = neuroticism, y = altruism)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\naltruism |> group_by(city) |> \n  summarise(\n    mean_altruism = mean(altruism), sd_altruism = sd(altruism),\n    mean_neuroticism = mean(neuroticism), sd_neuroticism = sd(neuroticism)\n  )\n\n# A tibble: 2 × 5\n  city     mean_altruism sd_altruism mean_neuroticism sd_neuroticism\n  <chr>            <dbl>       <dbl>            <dbl>          <dbl>\n1 city              34.8        10.9             58.4          10.4 \n2 non-city          53.2        11.8             55.0           9.10\n\n\n위 플랏에서 확인해 볼 수 있으며, 아래 상관계수를 통해서도 세 변수들 간의 상관관계가 있음을 확인할 수 있음.\n\n# factor로 변환; label도 함께 지정\naltruism <- altruism |>\n    mutate(\n        city = factor(city,\n            levels = c(\"non-city\", \"city\"),\n            labels = c(\"noncity\", \"city\")\n        )\n    )\n\n일반적으로 dummy variable과의 상관계수는 해석이 어려우나, 다음과 같은 방식으로 살펴볼 수 있음.\n\naltruism_dummy <- fastDummies::dummy_cols(altruism, \"city\")\nlowerCor(altruism_dummy)\n\n             altrs ses   nrtcs area* city* cty_n cty_c\naltruism      1.00                                    \nses          -0.02  1.00                              \nneuroticism  -0.25  0.12  1.00                        \narea*         0.68 -0.20 -0.20  1.00                  \ncity*        -0.61  0.28  0.17 -0.87  1.00            \ncity_noncity  0.61 -0.28 -0.17  0.87 -1.00  1.00      \ncity_city    -0.61  0.28  0.17 -0.87  1.00 -1.00  1.00\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = neuroticism, y = altruism, color = city)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n\n\naltruism |> \n  mutate(neurotic_cat = cut_interval(neuroticism, 3)) |>\n  ggplot(aes(x = city, y = altruism, fill = neurotic_cat)) +\n  geom_boxplot()\n\n\n\n\n\n\n이제 neuroticism을 통계적으로 통제(control for, hold it constant, partial the effect of)한 선형회귀모형을 세우면,\n(ANOVA 프레임워크에서 ANCOVA라고도 함; analysis of covariance)\n\n\n\n\n\n\nImportant\n\n\n\n아래 선형모형의 중요한 전제는 city와 altruism의 관계가 neuroticism 정도에 따라 변하지 않을 것이라는 것임.\n위 플랏으로부터 어느 정도 정당화될 수 있고, 추가적으로 통계적 검정를 통해 확인할 수 있음.\n\n\n\nmod <- lm(altruism ~ city + neuroticism, data = altruism)\nS(mod)\n\nCall: lm(formula = altruism ~ city + neuroticism, data = altruism)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  65.23452    5.45529  11.958  < 2e-16 ***\ncitycity    -17.62565    1.94617  -9.057 7.63e-16 ***\nneuroticism  -0.21939    0.09684  -2.266   0.0249 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 11.32 on 147 degrees of freedom\nMultiple R-squared: 0.3972\nF-statistic: 48.44 on 2 and 147 DF,  p-value: < 2.2e-16 \n    AIC     BIC \n1158.63 1170.68 \n\n\n\\(\\widehat Y = -17.62 \\cdot city - .22 \\cdot neuroticism + 59.731\\)\nneuroticism을 centering한 후, 선형회귀모형을 세우면,\n\nlibrary(jtools) # for center()\nmod <- lm(altruism ~ city + center(neuroticism), data = altruism)\nS(mod)\n\nCall: lm(formula = altruism ~ city + center(neuroticism), data = altruism)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          52.88494    1.16772  45.289  < 2e-16 ***\ncitycity            -17.62565    1.94617  -9.057 7.63e-16 ***\ncenter(neuroticism)  -0.21939    0.09684  -2.266   0.0249 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 11.32 on 147 degrees of freedom\nMultiple R-squared: 0.3972\nF-statistic: 48.44 on 2 and 147 DF,  p-value: < 2.2e-16 \n    AIC     BIC \n1158.63 1170.68 \n\n\n\\(\\widehat Y = -17.62 \\cdot city - .22 \\cdot neuroticism_C + 52.88\\)\nAdjusted mean: predicted means for each group\n\n절편 52.88은 도시에 살지 않는 사람들(non city: 0)의 이타성의 adjusted mean (neuroticism을 통제했다는 의미에서)\n기울기 -17.62는 도시인과 아닌 사람간의 이타성의 adjusted mean 차이 (adjusted mean difference)\n도시인들에 대한 이타성의 adjusted mean = -17.62(1) -.22(0) + 52.88 = 35.26\n비도시인들에 대한 이타성의 adjusted mean = -17.62(0) -.22(0) + 52.88 = 52.88\n\n즉, neuroticism의 효과가 제거되었을 때 (partial out), 혹은 그 효과만큼 city가 조정받은 후 (adjusted for), 도시인과 아닌 사람들의 이타성은 각각 35.26, 52.88로 추정됨.\n\nlibrary(emmeans)\nemmeans(mod, pairwise ~ city)  # all pairwise\n\n$emmeans\n city    emmean   SE  df lower.CL upper.CL\n noncity   52.9 1.17 147     50.6     55.2\n city      35.3 1.54 147     32.2     38.3\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast       estimate   SE  df t.ratio p.value\n noncity - city     17.6 1.95 147   9.057  <.0001\n\n\nPlot으로 표현하면: effect plot\n\nlibrary(effects)\nplot(predictorEffects(mod))\n\n\n\n\nneuroticism의 효과가 partial된 실제 값에 대해 플랏을 그리면: add-variable plot\n\nmcPlots(mod, terms = \"city\", overlaid = FALSE)\n\n\n\n\n위의 선형모형 \\(\\widehat Y = -17.62 \\cdot city - .22 \\cdot neuroticism_C + 52.88\\)이 예측하는 값을 플랏에 추가하면,\n\n두 라인의 기울기는 -.22로 “동일”하며, (동일해야 함!)\n그 간격은 도시인이 17.62 낮음\n\n\naltruism |> \n  ggplot(aes(x = center(neuroticism), y = altruism, color = city)) +\n  geom_point() +\n  geom_smooth(se = FALSE, size = .3) +\n  geom_line(aes(y = mod$fitted.values), size = 1) # 모형의 예측값들\n\n\n\n\nneuroticism이 평균일 때의 adjusted mean은\n\\(\\widehat{Y}_{city} = -(17.62)(1) - (.22)(0.0) + 52.88 = adjusted ~ M_{city}\\) \\(\\widehat{Y}_{noncity} = -(17.62)(0) - (.22)(0.0) + 52.88 = adjusted ~ M_{noncity}\\)\n만약, centering하지 않은 식이라면 neuroticism의 평균값을 대입.\nPartial association\narea의 고유한 설명력을 파악하기 위해 partial association 대해 알아보는 방식은\n\n모형의 비교를 통해 \\(R^2\\)의 변화를 살펴보는 방식: semi-partial (squared)\nSet correlation을 통해 partial out된 상관계수를 계산하는 방식: partial (squared)\nANOVA 프레임워크에서 partial eta-squared를 계산하는 방식: semi-paritl, partial (squared)\n\n\n\nmod_reduced <- lm(altruism ~ center(neuroticism), data = altruism) # reduced model\n\n\n\n\nexport_summs(mod_reduced, mod, \n    error_format = \"({p.value})\")\n\n\n\n\nModel 1Model 2\n\n(Intercept)46.42 ***52.88 ***\n\n(0.00)   (0.00)   \n\ncenter(neuroticism)-0.37 ** -0.22 *  \n\n(0.00)   (0.02)   \n\ncitycity       -17.63 ***\n\n       (0.00)   \n\nN150       150       \n\nR20.06    0.40    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\n\n\n\n\n\n\\(\\Delta R^2\\) = 0.40 - 0.06 = 0.34 : semi-partical correlation squared\nANOVA의 프레임워크에서 neuroticism의 효과가 partial out된 \\(\\eta^2\\)\n참고: Effect Sizes for ANOVAs\n\neta_squared(car::Anova(mod), partial = TRUE)  # partial correlation squared\n\n# Effect Size for ANOVA (Type II)\n\nParameter           | Eta2 (partial) |       95% CI\n---------------------------------------------------\ncity                |           0.36 | [0.26, 1.00]\ncenter(neuroticism) |           0.03 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nSet correlation을 통해 partial out된 상관계수\n\n# 우선 dummy variable을 생성\naltruism_dummy <- fastDummies::dummy_cols(altruism, \"city\")\naltruism_dummy |> head(3)\n\n# A tibble: 3 × 7\n  altruism   ses neuroticism area       city    city_noncity city_city\n     <dbl> <dbl>       <dbl> <chr>      <fct>          <int>     <int>\n1     69.1  66.7        61.0 small_town noncity            1         0\n2     56.2  58.0        73.6 small_town noncity            1         0\n3     65.6  36.3        41.2 small_town noncity            1         0\n\n# neuroticism partialled out!\nsetCor(altruism ~ city_city - neuroticism, data = altruism_dummy)\n\n\n\n\nCall: setCor(y = altruism ~ city_city - neuroticism, data = altruism_dummy)\n\nMultiple Regression from raw data \nThe following variables were partialed out: neuroticism \n and are included in the calculation of df1 and df2\n\n DV =  altruism* \n             slope   se     t       p lower.ci upper.ci VIF Vy.x\n(Intercept)*  0.00 0.06  0.00 1.0e+00    -0.13     0.13   1 0.00\ncity_city*   -0.59 0.06 -9.06 7.6e-16    -0.72    -0.46   1 0.36\n\nResidual Standard Error =  0.78  with  147  degrees of freedom\n\n Multiple Regression\n           R   R2  Ruw R2uw Shrunken R2 SE of R2 overall F df1 df2        p\naltruism 0.6 0.36 0.61 0.38        0.35     0.06     82.02   1 147 7.63e-16\n\n\n즉, partial correlation = 0.60, partial correlation squared = 0.36 (=\\(\\eta^2\\))"
  },
  {
    "objectID": "contents/categorical.html#full-model",
    "href": "contents/categorical.html#full-model",
    "title": "Categorical IVs",
    "section": "Full model",
    "text": "Full model\n이타적인 성향이 인구밀도에 영향을 받을 것이라는 가설하에, 세 지역 (도시, 교외, 시골)의 주민들을 조사하는데, neuroticism 뿐만 아니라 사회경제적 상태(SES)도 이타성과 관련이 있음을 고려하면,\n\n\n\n\naltruism |> \n  ggplot(aes(x = area, y = altruism)) +\n  geom_boxplot()\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = ses, y = altruism)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = area, y = neuroticism)) +\n  geom_boxplot()\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = ses, y = neuroticism)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = area, y = ses)) +\n  geom_boxplot()\n\n\n\n\n\n\n위 플랏에서 확인해 볼 수 있으며, 아래 상관계수를 통해서도 상관관계가 있음을 확인할 수 있음.\n일반적으로 dummy variable과의 상관계수는 해석이 어려우나, 다음과 같은 방식으로 살펴볼 수 있음.\n\n# factor로 변환; label도 함께 지정\naltruism <- altruism |>\n    mutate(\n        area = factor(area,\n            levels = c(\"small_town\", \"rural\", \"city\"),\n            labels = c(\"small\", \"rural\", \"city\")\n        )\n    )\n\naltruism_dummy <- fastDummies::dummy_cols(altruism, \"area\")\nlowerCor(altruism_dummy)\n\n            altrs ses   nrtcs area* city* ar_sm ar_rr ar_ct\naltruism     1.00                                          \nses         -0.02  1.00                                    \nneuroticism -0.25  0.12  1.00                              \narea*       -0.68  0.20  0.20  1.00                        \ncity*       -0.61  0.28  0.17  0.87  1.00                  \narea_small   0.55 -0.05 -0.17 -0.84 -0.45  1.00            \narea_rural   0.12 -0.23 -0.01 -0.10 -0.59 -0.46  1.00      \narea_city   -0.61  0.28  0.17  0.87  1.00 -0.45 -0.59  1.00\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = neuroticism, y = altruism, color = area)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n\n\naltruism |> \n  mutate(neurotic_cat = cut_interval(neuroticism, 3)) |>\n  ggplot(aes(x = area, y = altruism, fill = neurotic_cat)) +\n  geom_boxplot()\n\n\n\n\n\n\n\naltruism |> \n  ggplot(aes(x = ses, y = altruism, color = area)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n\n\naltruism |> \n  mutate(ses_cat = cut_interval(ses, 3)) |>\n  ggplot(aes(x = area, y = altruism, fill = ses_cat)) +\n  geom_boxplot()\n\n\n\n\n\n\n이제 neuroticism과 ses을 통계적으로 통제(control for, hold it constant, partial the effect of) 한 선형회귀모형을 세우면, (ANCOVA라고도 함; analysis of covariance)\n\n\n\n\n\n\nImportant\n\n\n\n아래 선형모형의 중요한 전제는 area와 altruism의 관계가 neuroticism 또는 ses정도에 따라 변하지 않을 것이라는 것임.\n위 플랏으로부터 어느 정도 정당화될 수 있고, 추가적으로 통계적 검정를 통해 확인할 수 있음.\n\n\n\nmod_full <- lm(altruism ~ area + neuroticism + ses, data = altruism)\nS(mod_full)\n\nCall: lm(formula = altruism ~ area + neuroticism + ses, data = altruism)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.82541    6.12678   9.928  < 2e-16 ***\narearural   -10.21356    2.18807  -4.668 6.87e-06 ***\nareacity    -24.96670    2.24895 -11.102  < 2e-16 ***\nneuroticism  -0.19045    0.08967  -2.124   0.0354 *  \nses           0.19643    0.08333   2.357   0.0197 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 10.38 on 145 degrees of freedom\nMultiple R-squared: 0.4997\nF-statistic:  36.2 on 4 and 145 DF,  p-value: < 2.2e-16 \n    AIC     BIC \n1134.69 1152.76 \n\n\nCentering한 모형\n\nmod_full_c <- lm(altruism ~ area + center(neuroticism) + center(ses), data = altruism)\nS(mod_full_c)\n\nCall: lm(formula = altruism ~ area + center(neuroticism) + center(ses), data =\n         altruism)\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          59.38972    1.68236  35.301  < 2e-16 ***\narearural           -10.21356    2.18807  -4.668 6.87e-06 ***\nareacity            -24.96670    2.24895 -11.102  < 2e-16 ***\ncenter(neuroticism)  -0.19045    0.08967  -2.124   0.0354 *  \ncenter(ses)           0.19643    0.08333   2.357   0.0197 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 10.38 on 145 degrees of freedom\nMultiple R-squared: 0.4997\nF-statistic:  36.2 on 4 and 145 DF,  p-value: < 2.2e-16 \n    AIC     BIC \n1134.69 1152.76 \n\n\n\n\n\n\n\n\nImportant\n\n\n\n통계적으로 유의하지 않는다고 해서, 변수를 제거하는 것은 절대 아님!\n위 모형은 명시적으로 neurotism을 통제한 상태, 즉 neurotism의 효과를 제거한 후 area의 효과를 본다는 것을 말해주고 있음.\n반면, 다른 독립변수들과 상관관계가 없다면 모형에 포함(통제)하지 않는 것이 적절. (명시 후에)\n\n\nneuroticism과 ses가 통제되지 않은 모형과 비교하면,\n또한 표준화된 모형과 비교하면,\n\nmod_simple <- lm(altruism ~ area, data = altruism)\nexport_summs(mod_simple, mod_full_c, error_format = \"(p = {p.value})\", model.names = c(\"Simple\", \"Full Centered\"))\n# scale: 독립변수들을 표준화, transform.response: 종속변수를 표준화\nexport_summs(mod_simple, mod_full, scale = TRUE, transform.response = TRUE, error_format = \"(p = {p.value})\", model.names = c(\"Simple Std\", \"Full Std\"))\n\n\n\n\n\n\nSimpleFull Centered\n\n(Intercept)59.73 ***59.39 ***\n\n(p = 0.00)   (p = 0.00)   \n\narearural-11.15 ***-10.21 ***\n\n(p = 0.00)   (p = 0.00)   \n\nareacity-24.94 ***-24.97 ***\n\n(p = 0.00)   (p = 0.00)   \n\ncenter(neuroticism)       -0.19 *  \n\n       (p = 0.04)   \n\ncenter(ses)       0.20 *  \n\n       (p = 0.02)   \n\nN150       150       \n\nR20.47    0.50    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\n\n\n\nSimple StdFull Std\n\n(Intercept)0.92 ***0.90 ***\n\n(p = 0.00)   (p = 0.00)   \n\narearural-0.77 ***-0.71 ***\n\n(p = 0.00)   (p = 0.00)   \n\nareacity-1.72 ***-1.72 ***\n\n(p = 0.00)   (p = 0.00)   \n\nneuroticism       -0.13 *  \n\n       (p = 0.04)   \n\nses       0.15 *  \n\n       (p = 0.02)   \n\nN150       150       \n\nR20.47    0.50    \n\nAll continuous predictors are mean-centered and scaled by 1 standard deviation.  *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\n\n\nmod_full_c: \\(\\widehat Y = -10.21 \\cdot rural - 24.97 \\cdot city -0.190 \\cdot neuroticism_C + 0.196 \\cdot ses_C + 59.39\\)\n\n절편 59.39은 small town 사람들의 이타성의 adjusted mean (neuroticism & ses을 통제했다는 의미에서)\n기울기 -10.21은 small town과 rural 사람간의 이타성의 adjusted mean 차이 (adjusted mean difference)\n기울기 -24.97은 small town과 city 사람간의 이타성의 adjusted mean 차이 (adjusted mean difference)\n\nAdjusted mean: predicted means for each group\n\nsmall town 사람들에 대한 이타성의 adjusted mean = -10.21(0) - 24.97(0) + 59.39 = 59.39\nrural 사람들에 대한 이타성의 adjusted mean = -10.21(1) - 24.97(0) + 59.39 = 49.18\ncity 사람들에 대한 이타성의 adjusted mean = -10.21(0) - 24.97(1) + 59.39 = 34.42\n\n즉, neuroticism과 ses의 효과가 제거되었을 때 (partial out), 혹은 그 효과만큼 city가 조정받은 후 (adjusted for), 각 지역의 사람들의 이타성은 각각 59.39, 49.18, 34.42로 추정됨.\n\nlibrary(emmeans)\n# adjusted means & contrast (adjusted mean difference)\nemmeans(mod_full, pairwise ~ area)\n\n$emmeans\n area  emmean   SE  df lower.CL upper.CL\n small   59.4 1.68 145     56.1     62.7\n rural   49.2 1.41 145     46.4     52.0\n city    34.4 1.45 145     31.6     37.3\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast      estimate   SE  df t.ratio p.value\n small - rural     10.2 2.19 145   4.668  <.0001\n small - city      25.0 2.25 145  11.102  <.0001\n rural - city      14.8 2.06 145   7.145  <.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nPlot으로 표현하면: effect plot\n\nlibrary(effects)\nplot(predictorEffects(mod_full, ~ area))\n\n\n\n\n위의 선형모형 \\(\\widehat Y = -10.21 \\cdot rural - 24.97 \\cdot city -0.190 \\cdot neuroticism_C + 0.196 \\cdot ses_C + 59.39\\) 이 예측하는 값을 플랏에 추가하면,\n\n세 라인의 기울기는 -0.19로 “동일”하며, (동일해야 함!)\n그 간격은 small town 사람들에 비해 rural 사람들이이 -10.21 낮고\n그 간격은 small town 사람들에 비해 city 사람들이이 -24.97 낮음\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\nlibrary(modelr)\ngrid_city <- altruism |> data_grid(neuroticism, area = \"city\", .model = mod_full) |> \n  add_predictions(mod_full)\ngrid_rural <- altruism |> data_grid(neuroticism, area = \"rural\", .model = mod_full) |> \n  add_predictions(mod_full)\ngrid_small <- altruism |> data_grid(neuroticism, area = \"small\", .model = mod_full) |> \n  add_predictions(mod_full)\n\naltruism |> \n  ggplot(aes(x = neuroticism, y = altruism, color = area)) +\n  geom_point() +\n  geom_smooth(se = FALSE, size = .3) +\n  geom_line(data = grid_city, aes(y = pred), size = 1) + \n  geom_line(data = grid_rural, aes(y = pred), size = 1) + \n  geom_line(data = grid_small, aes(y = pred), size = 1)\n\n\n\n\n\n\n\n\n\nPartial association area의 고유한 설명력을 파악하기 위해 partial association 대해 알아보는 방식은\n\n모형의 비교를 통해 \\(R^2\\)의 변화를 살펴보는 방식: semi-partial (squared)\nSet correlation을 통해 partial out된 상관계수를 계산하는 방식: partial (squared)\nANOVA 프레임워크에서 partial eta-squared를 계산하는 방식: semi-paritl, partial (squared)\n\n\nmod_full_reduced <- lm(altruism ~ neuroticism + ses, data = altruism) # reduced model\n\n\n\n\nexport_summs(mod_full_reduced, mod_full, \n    error_format = \"({p.value})\")\n\n\n\n\nModel 1Model 2\n\n(Intercept)66.88 ***60.83 ***\n\n(0.00)   (0.00)   \n\nneuroticism-0.37 ** -0.19 *  \n\n(0.00)   (0.04)   \n\nses0.01    0.20 *  \n\n(0.95)   (0.02)   \n\narearural       -10.21 ***\n\n       (0.00)   \n\nareacity       -24.97 ***\n\n       (0.00)   \n\nN150       150       \n\nR20.06    0.50    \n\n *** p < 0.001;  ** p < 0.01;  * p < 0.05.\n\n\n\n\n\n\n\n\n\n\\(\\Delta R^2\\) = 0.50 - 0.06 = 0.44 : semi-partical correlation squared\nANOVA의 프레임워크에서 neuroticism과 ses의 효과가 partial out된 \\(\\eta^2\\)\n참고: Effect Sizes for ANOVAs\n\neta_squared(car::Anova(mod_full), partial = TRUE)  # partial correlation squared\n\n# Effect Size for ANOVA (Type II)\n\nParameter   | Eta2 (partial) |       95% CI\n-------------------------------------------\narea        |           0.47 | [0.37, 1.00]\nneuroticism |           0.03 | [0.00, 1.00]\nses         |           0.04 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nSet correlation을 통해 partial out된 상관계수\n\n# 우선 dummy variable을 생성\naltruism_dummy <- fastDummies::dummy_cols(altruism, \"area\")\naltruism_dummy |> head(3)\n\n# A tibble: 3 × 8\n  altruism   ses neuroticism area  city    area_small area_rural area_city\n     <dbl> <dbl>       <dbl> <fct> <fct>        <int>      <int>     <int>\n1     69.1  66.7        61.0 small noncity          1          0         0\n2     56.2  58.0        73.6 small noncity          1          0         0\n3     65.6  36.3        41.2 small noncity          1          0         0\n\n# neuroticism & sex partialled out!\nsetCor(altruism ~ area_rural + area_city - neuroticism - ses, data = altruism_dummy)\n\n\n\n\nCall: setCor(y = altruism ~ area_rural + area_city - neuroticism - \n    ses, data = altruism_dummy)\n\nMultiple Regression from raw data \nThe following variables were partialed out: neuroticism ses \n and are included in the calculation of df1 and df2\n\n DV =  altruism* \n             slope   se      t       p lower.ci upper.ci  VIF  Vy.x\n(Intercept)*  0.00 0.06   0.00 1.0e+00    -0.12     0.12 1.00  0.00\narea_rural*  -0.34 0.07  -4.67 6.9e-06    -0.49    -0.20 1.47 -0.04\narea_city*   -0.83 0.08 -11.10 4.1e-21    -0.98    -0.69 1.47  0.51\n\nResidual Standard Error =  0.72  with  145  degrees of freedom\n\n Multiple Regression\n            R   R2  Ruw R2uw Shrunken R2 SE of R2 overall F df1 df2       p\naltruism 0.68 0.47 0.41 0.17        0.45     0.06     63.58   2 145 1.5e-20\n\n\n즉, partial correlation = 0.68, partial correlation squared = 0.47 (=\\(\\eta^2\\))"
  },
  {
    "objectID": "contents/categorical.html#기타-예들",
    "href": "contents/categorical.html#기타-예들",
    "title": "Categorical IVs",
    "section": "기타 예들",
    "text": "기타 예들\n\n정치학자가 인종 (black, hispanic, white), 성별, 가족 소득 수준이 정치적 태도에 미치는 영향을 연구하고자 할 때,\n교육학자가 공립학교와 사립학교의 수학 성취도를 비교하고자 하는데, 가족 소득 수준을 고정(통제)시키고자 할 때,"
  },
  {
    "objectID": "contents/test.html#national-education-longitudinal-study-of-1988-nels88",
    "href": "contents/test.html#national-education-longitudinal-study-of-1988-nels88",
    "title": "Case Study tp",
    "section": "National Education Longitudinal Study of 1988 (NELS:88)",
    "text": "National Education Longitudinal Study of 1988 (NELS:88)\nSource: p.69 in Multiple Regression and Beyond (3e) by Timothy Z. Keith\n\n\n연구주제: 학생들의 과제는 성적에 영향을 주는가? 준다면 그 영향력의 크기는 어떠한가?\n데이터 NELS88 sample.csv\ngrades: 10학년의 성적 평균 in English, Math, Science, Social Studies.\npared: 부모의 교육 수준 (높은 쪽)\nhw_in, hw_out: 10학년 때 학생들이 보고한 숙제하는데 보낸 주당 평균 시간 (in school or out of school)\n\n\nnels <- read_csv(\"data/nels88_sample.csv\")\nnels <- nels |> \n    select(grades = ffugrad, pared = bypared, hw_in = f1s36a1, hw_out = f1s36a2, prev = bytests)\nnels\n\n# summarize data\nsummary(nels)\n\n# count values\nnels |> count(pared)\nnels |> count(hw_out)\n\n\n\n변수들 간의 관계 탐색\n\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .2) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"deepskyblue\", ...)\n}\n\nggpairs2 <- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\n\n\n\n\nggpairs2(nels)\n\n\n\n세 개의 독립변수로 예측\n\nB1. 인과모형 A: 부분 회귀 계수들\n\n\n\n\n\n\n\n\nD: 표준화 계수 및 부분 상관 계수\n\n\n\n\n\n\n\n\nE: 간접효과의 크기와 검증"
  },
  {
    "objectID": "contents/inference.html",
    "href": "contents/inference.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "평균이 \\(\\mu\\) 이고 분산이 \\(\\sigma^2\\) 인 모집단으로부터 추출된 표본 사이즈가 \\(n\\) (size=\\(n\\))인 표본들에 대해서\n\nSource: The Truthful Art by Albert Cairo.\n표본 평균들 \\(\\bar{X}\\) 의 분포를 평균의 표본 분포, the sampling distribution of the mean 이라고 하고, 이 분포는 the central limit theorem에 의해\n\n평균:  \\(\\displaystyle E(\\bar{X})=\\frac{m_1+m_2+m_3+\\cdots+m_w}{w}\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\mu\\) ; unbiased estimator (mean or regression coefficient vs. R)\n분산:  \\(\\displaystyle V(\\bar{X})\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\frac{\\sigma^2}{n},\\)   표준 편차 \\(\\displaystyle\\frac{\\sigma}{\\sqrt{n}}\\) 를 standard error of estimate (SE)라고 함.\n\n이 standard error of estimate는 다시 말하면, 어떤 통계치(여기서는 평균)가 표본들 간에 얼마나 차이가 나는지를 알 수 있는 중요한 지표가 됨.\n\n분포: 모집단의 분포가 normal에 가까울 수록, 또는 표본 크기가 클수록 ( \\(n\\rightarrow\\infty, n > 30\\) ) \\(\\displaystyle\\{m_1, m_2, m_3, \\cdots, m_w, \\cdots\\} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}}) : normal ~ distribution\\) (정규 분포)\n값을 정규화하면; \\(\\displaystyle Z=\\frac{X-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n분포: \\(\\displaystyle\\{z_1, z_2, z_3, \\cdots, z_w, \\cdots\\} \\sim N(0, 1) : standard ~ normal ~ distribution\\) (표준 정균 분포)\n\n실제 예를 통해서 살펴보면,\n예를 들어 어느 섬에 사는 민족의 남성 평균 키가 아래와 같은 분포를 가진다고 할 때 (평균: 173cm, 표준편차: 5cm),\n관찰한 100명의 한 표본에서 남성들의 키가 평균 174cm로 관찰되었다면 이 정도로 큰 값이 나올 가능성은 얼마정도 인가?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b)의 경우 즉, 표본 사이즈가 n = 100인 경우처럼 평균의 표본 분포는 빠르게 정규 분포에 다가가므로 근사적으로 정규 분포의 값을 이용해 그 확률 값을 쉽게 구할 수 있음.\n특히, 값들을 정규화하여 표준정규분포 (평균 0, 표준편차 1)의 값을 이용함.\n\\(\\displaystyle \\frac{174 - 173}{0.5} = 2, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n음영된 부분은 대략 2.3%이고, 따라서 100명을 관찰한 표본의 평균 키가 174cm이상이 될 가능성은 2.3%에 밖에 되지 않음. 예를 들어, 1000번 같은 연구를 반복하면 23번 정도는 174cm 이상의 평균 키를 관찰할 수 있을 것임.\n\n\n\n\n\n\n\n실제 성취하고자 하는 유용한 분석은 위 과정의 반대인, 관찰한 특정 표본으로부터 모집단에 대해 추론하는 것임.\n이를 통계적 추론, statistical inference라고 함.\n가령, 어느 섬에 사는 민족으로부터 관찰된 100명의 키의 평균이 175cm이고 표준편차가 10cm인 경우, 이 민족의 키의 평균은 얼마 정도라고 파악할 수 있는가?\n\n먼저, 모집단의 평균 \\(\\mu\\) 를 가정하는데, 가령 \\(\\mu = 173\\) 라면, 우리가 관찰한 표본의 평균 175는 충분히 나올 수 있는 값인가? 이에 대해서는 위의 논리에 따라 구할 수 있음. 즉,\n\n\\(\\displaystyle \\frac{175 - 173}{\\frac{\\sigma}{10}} = ~?, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n만약, 모집단의 표준편차 \\(\\sigma\\) 가 예전처럼 5라면, \\(\\bar{Z} = 4\\) 가 되어 매우 희박한 경우가 될 것임. (실제로 0.0032%)\n모집단의 표준편차를 알 수 없기 때문에 차선책으로, 관찰한 표본의 표준편차를 대체해서 전개함\n이 경우, 표본의 표준편차가 10이기 때문에, \\(\\bar{Z} = 2\\) 가 되어 2.3% 정도의 가능성이 있다고 볼 수 있으나,\n표준편차의 대체로 인해 생기는 문제를 보완할 수 있는데, 사실 표본분포가 정규분포가 아닌 Student’s t-분포를 따르고, 이를 이용해서 확률값을 구함.\n이 경우는 \\(\\displaystyle t = \\frac{\\bar{X}-\\mu}{\\frac{s}{\\sqrt{n}}} = 2, ~ (s: the ~sample ~sd)\\) 로 t-분포에 의하면 2.4% 정도의 가능성이 있다고 봄\n\nt-분포는 자유도(degree of freedom)에 의해 분포가 바뀌는데 df는 n-1 (n: 표본 크기)\n\n\n이제 위의 과정을 계속 반복한다고 상상하면, 즉 모집단의 평균을 다른 값으로 가정하면서,\n\n관찰된 표본 평균 175cm가 95% (양 극단 2.5%를 제외한) 이내에서 관찰될 수 있는 모집단의 평균들을 모두 찾을 수 있음\n이 평균들의 범위를 95% confidence interval 이라고 부르고,\n식으로 전개하면, \\(\\displaystyle\\Bigg| \\frac{m-\\mu}{\\frac{s}{\\sqrt{n}}} \\Bigg| < 1.66, ~(n=100)\\)\n\\(\\displaystyle m-1.66\\frac{s}{\\sqrt{n}} < \\mu < m + 1.66\\frac{s}{\\sqrt{n}}\\)\n위 예의 경우 \\(\\displaystyle 173.34 < \\mu < 176.66\\)\n즉, 우리는 95%의 확신을 갖고, 이 섬에 사는 민족의 평균 키는 173.34cm에서 176.66cm 사이에 있을 것이라고 말할 수 있음.\n이 cofidence interval의 크기를 결정하는 것은 \\(\\displaystyle\\frac{s}{\\sqrt{n}}\\) 즉, standard error of estimate인데, 범위가 좁아질수록, precision이 높다고 표현함.\n한편, 99%의 확신으로 (confidence level: 99%)는 그 키의 범위를 더 넓혀서 말할 수 있음. 이 경우 \\(|~t~| < 2.36\\) 으로부터 모집단의 키가 (172.64cm, 177.36cm) 범위가 있다고 말할 수 있음.\n\n확신이 커지는 대신 범위가 넓어지므로 모집단의 예측에 대한 유용성이 떨어짐.\n\n\n\n\n\n\n위의 논리와 비슷하게 회귀 계수가 표본 마다 얼마나 변하는 지를 구할 수 있고,\n회귀 계수에 대한 confidence interval을 구할 수 있음.\n변수가 한 개인 경우:\n회귀계수 \\(b\\) 에 대한 표본 분포는 평균이 \\(b\\) 인 정규분포를 따르고, 표준편차 즉, standard error of estimate는 근사적으로 다음과 같음\n\\(\\displaystyle SE^2(b) = \\frac{{MS}_{residual}}{N \\cdot Var(X)}\\)\nConfidence interval: \\(b\\pm t_{\\alpha/2}SE, ~(df = N-2)\\)\n다중 회귀 모형의 경우:\n예측변수 \\(X_j\\) 에 대해서 모집단의 회귀계수 \\(b_j\\) 에 대한 표본 분포는 평균이 \\(b_j\\) 인 정규분포를 따르고, 표준편차, 즉 standard error는 근사적으로 다음과 같음.\n\\(\\displaystyle SE^2(b_j) = \\frac{{MS}_{residual}}{N \\cdot Var(X_j) \\cdot (1 - R^2_j)}, ~(df = N-k-1)\\)\n\n표본 사이즈가 클수록\n평균 잔차가 작을수록\njth 예측변수의 값이 퍼져 있을수록\n다른 예측변수들로부터 jth 예측변수가 예측되지 못할수록; 즉 다른 변수들과 correlate되지 않을수록\n\n\\(1 - R^2_j\\) 을 tolerance, 그 역수를 variance inflation factor (VIF)라고 부름\nTolerance가 극히 작은 것은 intolerable! 봐줄 수 없음!\n\n예를 들어, 어느 문화에서 남자아이에게는 자기 주장이 강하도록 훈육하고, 여자아이에게는 반대로 훈육한다고 합니다. 만약, 자기주장이 강하도록 부모가 교육하는 것이 자녀가 자기주장이 강하게 되는데 영향을 미친다는 것을 살펴보는데, 성별을 통계적으로 통제한다면, 훈육의 효과는 통계적으로 계산되기 어렵습니다. 왜냐하면, 성별과 훈육방식이 크게 상관관계를 가지기 때문에, 성별과 독립적인 훈육의 변량이 작아지기 때문에, 회귀계수의 precision이 크게 낮아집니다.\n\n\n\n\nlibrary(car)\nmod_prestige <- lm(prestige ~ education + log2(income) + type, data = Prestige)\nS(mod_prestige)\n\nCall: lm(formula = prestige ~ education + log2(income) + type, data = Prestige)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -81.2019    13.7431  -5.909 5.63e-08 ***\neducation      3.2845     0.6081   5.401 5.06e-07 ***\nlog2(income)   7.2694     1.1900   6.109 2.31e-08 ***\ntypeprof       6.7509     3.6185   1.866   0.0652 .  \ntypewc        -1.4394     2.3780  -0.605   0.5465    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 6.637 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8555\nF-statistic: 137.6 on 4 and 93 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n655.93 671.44"
  },
  {
    "objectID": "contents/analysis1.html",
    "href": "contents/analysis1.html",
    "title": "Analysis I",
    "section": "",
    "text": "helping <- read_csv(\"data/altruism_full.csv\")\n\n\nhelping <- helping |>\n    mutate(\n        status = factor(status, levels = c(\"low\", \"high\")),\n        sex = factor(sex)\n    )\n\nhelping |> print()\n\n# A tibble: 168 × 6\n     id status sex    empathy public_sc helping\n  <dbl> <fct>  <fct>    <dbl>     <dbl>   <dbl>\n1     1 high   female    58.1      88.3   33.8 \n2     2 low    female    43.9      29.8   63.8 \n3     3 low    female    76.8      80     61.0 \n4     6 high   male      42.6      45.2    1.23\n5     8 low    male      80.6      52     20.8 \n6     9 high   male      44.2      69.2    7.61\n# … with 162 more rows\n\n\n\nsummary(mod <- lm(helping ~ public_sc * status + empathy, data = helping))\n\n\nCall:\nlm(formula = helping ~ public_sc * status + empathy, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.117 -14.950  -1.137  15.982  48.022 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           -0.3143    11.9954  -0.026  0.97913    \npublic_sc             -0.2133     0.1689  -1.263  0.20849    \nstatushigh           -40.9460    17.0374  -2.403  0.01737 *  \nempathy                0.7392     0.1510   4.895 2.35e-06 ***\npublic_sc:statushigh   0.6423     0.2203   2.916  0.00405 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.68 on 163 degrees of freedom\nMultiple R-squared:  0.293, Adjusted R-squared:  0.2756 \nF-statistic: 16.88 on 4 and 163 DF,  p-value: 1.335e-11\n\n\n\nsummary(mod <- lm(helping ~ scale(public_sc) * status + empathy, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(public_sc) * status + empathy, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.117 -14.950  -1.137  15.982  48.022 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 -16.3357    11.1328  -1.467  0.14421    \nscale(public_sc)             -3.4988     2.7708  -1.263  0.20849    \nstatushigh                    7.3082     3.5847   2.039  0.04310 *  \nempathy                       0.7392     0.1510   4.895 2.35e-06 ***\nscale(public_sc):statushigh  10.5379     3.6139   2.916  0.00405 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.68 on 163 degrees of freedom\nMultiple R-squared:  0.293, Adjusted R-squared:  0.2756 \nF-statistic: 16.88 on 4 and 163 DF,  p-value: 1.335e-11\n\n\n\nlibrary(car)\navPlots(mod)\n\n\n\n\n\nsummary(lm(scale(helping) ~ status, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ status, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.73766 -0.70655 -0.09683  0.73752  1.98321 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  -0.1922     0.1041  -1.846  0.06662 . \nstatushigh    0.4086     0.1518   2.692  0.00782 **\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.9818 on 166 degrees of freedom\nMultiple R-squared:  0.04184,   Adjusted R-squared:  0.03607 \nF-statistic:  7.25 on 1 and 166 DF,  p-value: 0.007819\n\n\n\nsummary(lm(scale(helping) ~ empathy, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ empathy, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01691 -0.65267 -0.03413  0.62921  2.02464 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.296418   0.329699  -6.965 7.31e-11 ***\nempathy      0.031909   0.004484   7.117 3.16e-11 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.878 on 166 degrees of freedom\nMultiple R-squared:  0.2338,    Adjusted R-squared:  0.2292 \nF-statistic: 50.65 on 1 and 166 DF,  p-value: 3.158e-11\n\n\n\nsummary(lm(scale(helping) ~ empathy + status, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ empathy + status, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.13949 -0.61254 -0.07061  0.60338  1.99294 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.349779   0.326929  -7.187 2.17e-11 ***\nempathy      0.030721   0.004467   6.878 1.20e-10 ***\nstatushigh   0.295364   0.135204   2.185   0.0303 *  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.8682 on 165 degrees of freedom\nMultiple R-squared:  0.2553,    Adjusted R-squared:  0.2463 \nF-statistic: 28.29 on 2 and 165 DF,  p-value: 2.735e-11\n\n\n\nsummary(mod2 <- lm(helping ~ scale(public_sc) * status, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(public_sc) * status, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.885 -16.726  -0.607  17.828  52.431 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  43.864      2.793  15.703  < 2e-16 ***\nscale(public_sc)             15.077      2.824   5.339 3.07e-07 ***\nstatuslow                    -7.042      3.827  -1.840  0.06757 .  \nscale(public_sc):statuslow  -12.154      3.842  -3.163  0.00186 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 24.22 on 164 degrees of freedom\nMultiple R-squared:  0.189, Adjusted R-squared:  0.1742 \nF-statistic: 12.74 on 3 and 164 DF,  p-value: 1.581e-07\n\n\n\nanova(mod2, mod) |> print()\n\nAnalysis of Variance Table\n\nModel 1: helping ~ scale(public_sc) * status\nModel 2: helping ~ scale(public_sc) * status + empathy\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    164 96189                                 \n2    163 83862  1     12327 23.96 2.348e-06 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n\n\nhelping |>\n    ggplot(aes(x = public_sc, y = helping, color = status)) +\n    geom_point() +\n    geom_smooth(method = lm) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\nlibrary(psych)\n# R squared\ncorr.test(helping |> select(empathy:helping))$r^2 |>\n    round(2) |>\n    print()\n\n          empathy public_sc helping\nempathy      1.00      0.41    0.23\npublic_sc    0.41      1.00    0.12\nhelping      0.23      0.12    1.00\n\n\n\nsummary(lm(helping ~ scale(empathy) * scale(public_sc), data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(empathy) * scale(public_sc), data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.326 -16.613  -0.074  16.524  53.692 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       39.644      2.070  19.151  < 2e-16 ***\nscale(empathy)                    12.013      2.346   5.121 8.42e-07 ***\nscale(public_sc)                   2.301      2.361   0.975   0.3312    \nscale(empathy):scale(public_sc)    2.735      1.620   1.688   0.0932 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 23.3 on 164 degrees of freedom\nMultiple R-squared:  0.2495,    Adjusted R-squared:  0.2358 \nF-statistic: 18.17 on 3 and 164 DF,  p-value: 3.138e-10\n\n\n\nsummary(lm(helping ~ scale(empathy) * scale(public_sc) + scale(public_sc) * status, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(empathy) * scale(public_sc) + scale(public_sc) * \n    status, data = helping)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-66.40 -14.81  -1.10  16.81  48.70 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       43.100      2.853  15.109  < 2e-16 ***\nscale(empathy)                    11.387      2.298   4.956  1.8e-06 ***\nscale(public_sc)                   6.951      3.116   2.231  0.02706 *  \nstatuslow                         -6.980      3.603  -1.937  0.05445 .  \nscale(empathy):scale(public_sc)    1.531      1.621   0.944  0.34637    \nscale(public_sc):statuslow        -9.815      3.695  -2.656  0.00869 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.69 on 162 degrees of freedom\nMultiple R-squared:  0.2968,    Adjusted R-squared:  0.2751 \nF-statistic: 13.68 on 5 and 162 DF,  p-value: 3.876e-11\n\n\n\nsummary(lm(helping ~ status, data = helping))\n\n\nCall:\nlm(formula = helping ~ status, data = helping)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-46.31 -18.83  -2.58  19.66  52.85 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   47.147      2.944  16.016  < 2e-16 ***\nstatuslow    -10.890      4.045  -2.692  0.00782 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 26.17 on 166 degrees of freedom\nMultiple R-squared:  0.04184,   Adjusted R-squared:  0.03607 \nF-statistic:  7.25 on 1 and 166 DF,  p-value: 0.007819"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균, sk.cho@snu.ac.kr\n면담 시간: 수업 후\n조교: 홍신영\n수업시간: 목 7:00 ~ 9:50PM\nWebsite: r.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n전통적인 통계 커리큘럼에서 조금 벗어나 programming 언어인 R과 graphical tools의 도움을 받아 통계적인 통찰을 얻는 방식으로 진행하고자 함. 예제를 중심으로 직접 분석하고, 통계 이론의 설명은 체계적으로 전개하기보다는 그때 그때 필요한 부분을 부연 설명하고자 함.\n본 강의는 주로 회귀분석(regression analysis)에 초점을 맞추며, 그 원리를 이해하고 의미를 파악하여, 현상을 올바로 분석하고, 적절한 분석기법을 적용할 수 있도록 도움을 주고자 함.\n수업은 대략 4개의 섹션으로 나눔\n\nR tutorial\n\n통계의 활용에 대한 전반적인 소개\n\n회귀 분석 (regression analysis)\n\n인과 분석 (causal analysis)\n\n\n교재\n\n주로 강의 노트를 위주로!\nR인 액션 - 빅데이터 분석도구, 홍릉 / R in Action (2e) by Rob Kabacoff\nStatistical Modeling (2e) by Daniel T. Kaplan\n\n\n\nR 참고도서\n\nR for Data Science by Wickham & Grolemund / 2nd edition in progress\n\n\n\n통계 참고도서\n\nApplied Multiple Regression/Correlation Analysis for the Behavioral Sciences By Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. Aiken\nRegression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\nMultiple Regression and Beyond (3e) by Timothy Z. Keith"
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (5%), 일반과제 (15%), 중간고사 대체 과제 (20%), 기말고사 (30%), 개별 프로젝트 (30%)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contents/diagnostics.html",
    "href": "contents/diagnostics.html",
    "title": "Diagnostics",
    "section": "",
    "text": "Ordinary least squares (OLS)\n\nMean function: \\(E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i\\)\nVariance function: \\(Var(Y | X = x_i) = \\sigma^2\\)\nDistribution: \\((Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\)\n\n\nSource: p.107, Applied Regression Analysis and Generalized Linear Models (3e), by John Fox\n\nSource: p.482, Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences (3e), by Cohen, J., Cohen, P., West, S. G., & Aiken, L. S."
  },
  {
    "objectID": "contents/diagnostics.html#linear-least-squared-regression의-가정들",
    "href": "contents/diagnostics.html#linear-least-squared-regression의-가정들",
    "title": "Diagnostics",
    "section": "Linear Least Squared Regression의 가정들",
    "text": "Linear Least Squared Regression의 가정들\n\nL (linearity, 선형성): X의 각 값에 해당하는 Y값들의 평균들은 X와 선형적인 관계를 가짐.\n\nMean function: \\(E(Y | X = x_i) = \\beta_0 + \\beta_1 x_i\\)\n\nI (independence, 독립성): 잔차들(errors)은 서로 독립.\nN (normally distributed, 정규성): X의 각 값에 해당하는 Y값들은 정규분포를 이룸.\n\n\\((Y | X = x_i) \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\)\n\nE (equal variance, 등분산성): X의 각 값에 해당하는 Y값들의 표준편차들은 모두 동일함.\n\n\\(Var(Y | X = x_i) = \\sigma^2\\)\n\n\n\n가정에 위배되는 연구/자료들\n\n공부한 시간에 따른 합격 여부\n\nY가 성공/실패 명목변수로서 0, 1로 코딩된다고 하면, Y는 정규분포를 이루지 않음.\n이런 경우 generalized linear model(GLM)의 일부로서 logistic regression 모형으로 fit을 하는 것이 더 적절함.\n\n부유한 가정은 더 적은 아이들을 가지는 경향이 있는가?\n\n가족의 크기는 정규분포를 이루기보단 한쪽으로 치우친(skewed) 분포를 이룸.\n가족의 크기는 0, 1, 2,… 등의 정수값을 가져, 연속형 변수로 보기 어려워 정규분포의 가정을 만족하기 어려움.\n이런 경우 가족의 크기는 Poisson 분포에 더 가깝다고 보고, Poisson regression 모형이나 그 변형들로 fit을 하는 것이 더 적절함.\n\n대학 안에서 임의로 선정한 남녀 학생들의 운동시간과 몸무게의 관계\n\n운동을 전혀 하지 않는 학생들의 몸무게의 변량이 규칙적으로 한 학생들에 비해 더 넓게 분포할 가능성이 큼: 이는 equal variance 가정을 위배함.\n만약, 대학 내에서 특정 장소에서 학생들을 섭외했다면, 예를 들어, 피트니스 센터에서 섭외된 학생들의 데이터는 서로 연관성이 높을 수 있음: 이는 independent 가정에 위배됨.\n\n특정 질병을 가진 환자들에 대한 특정 수술에 대한 효과를 연구한다면,\n\n동일한 의사에게 수술을 받은 환자들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n동일한 병원에서 수술을 받은 환자들의 데이터는 서로 연관성이 높을 수 있음: 이는 independence 가정에 위배됨.\n\n\n\n\n대처방안/대안들\n\nLinearity의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 고차 다항식 혹은 확장된 모형(eg. spline)을 사용\nNormality의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 generalized linear model(GLM)을 사용\nEqual variance의 가정에 위배되는 경우: 변수들을 변환(transform)하거나 weighted least squares regression을 사용\nIndependence의 가정에 위배되는 경우: multi-level (mixed-effects) 모형을 사용"
  },
  {
    "objectID": "contents/diagnostics.html#ols-가정들에-대한-진단",
    "href": "contents/diagnostics.html#ols-가정들에-대한-진단",
    "title": "Diagnostics",
    "section": "OLS 가정들에 대한 진단",
    "text": "OLS 가정들에 대한 진단\nSource: An R Companion to Applied Regression (3e), by John Fox, Sanford Weisberg.\n모집단에 대한 추론이 타당하려면, 모집단에 대한 가정들이 위배되지 않아야 함.\n연구자는 관찰된 표본이 위에 언급된 “가정을 만족하는 모집단”으로부터 표집된 표본이라고 볼만한 충분한 확신이 있어야 함.\n이를 위해서 표본들로부터 대략적인 추정을 할 수 밖에 없음.\n예제: Prestige 데이터셋\n\nlibrary(car)\n\nPrestige <- Prestige |> as_tibble() |> \n  mutate(type = factor(type, levels = c(\"bc\", \"wc\", \"prof\")))\nPrestige\n\n# A tibble: 102 × 6\n   education income women prestige census type \n       <dbl>  <int> <dbl>    <dbl>  <int> <fct>\n 1      13.1  12351 11.2      68.8   1113 prof \n 2      12.3  25879  4.02     69.1   1130 prof \n 3      12.8   9271 15.7      63.4   1171 prof \n 4      11.4   8865  9.11     56.8   1175 prof \n 5      14.6   8403 11.7      73.5   2111 prof \n 6      15.6  11030  5.13     77.6   2113 prof \n 7      15.1   8258 25.6      72.6   2133 prof \n 8      15.4  14163  2.69     78.1   2141 prof \n 9      14.5  11377  1.03     73.1   2143 prof \n10      14.6  11023  0.94     68.8   2153 prof \n# ℹ 92 more rows\n\nmod2 <- lm(prestige ~ education + income + type, data = Prestige)\nS(mod2)\n\nCall: lm(formula = prestige ~ education + income + type, data = Prestige)\n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.6229292  5.2275255  -0.119    0.905    \neducation    3.6731661  0.6405016   5.735 1.21e-07 ***\nincome       0.0010132  0.0002209   4.586 1.40e-05 ***\ntypewc      -2.7372307  2.5139324  -1.089    0.279    \ntypeprof     6.0389707  3.8668551   1.562    0.122    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 7.095 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8349\nF-statistic: 117.5 on 4 and 93 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n669.02 684.52 \n\n\n\nPlotting Residuals\n잔차들의 분포: \\((e | X = x_i) \\sim N(0, \\sigma^2)\\)\n즉, 특별한 패턴이 없어야 함.\n\nresidualPlots(\n  mod2, \n  id=list(n=3), # outliers의 수\n  smooth=TRUE, # loess smooth 커브\n  quadratic=FALSE # 3차 fitted 커브\n)\n\n\n\n\n           Test stat Pr(>|Test stat|)   \neducation    -0.6836         0.495942   \nincome       -2.8865         0.004854 **\ntype                                    \nTukey test   -2.6104         0.009043 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# 특정 변수만 선택\nresidualPlots(mod2, ~ income, fitted=FALSE, smooth=TRUE) # fitted: 예측값, smooth: loess smooth fit\n\n\n\n\n       Test stat Pr(>|Test stat|)   \nincome   -2.8865         0.004854 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nAdded-Variable Plots\nPartial regression plot이라고도 함.\n다른 변수들을 partial out시킨 잔차들로 그림.\n\n각 회귀계수에 대한 precision을 살펴볼 수 있음\n각 관측치에 대한 leverage를 살펴볼 수 있음\n\n\n# 수평선 중심에서 가장 먼 점들 2개\n# 잔차의 값이 가장 큰 점들 2개\navPlots(mod2, id=list(n=2, cex=0.8)) # id: outliers의 수, cex: 점의 크기 80%\n\n\n\n# 특정 관측치 제거 후 다시 그림\nmod2_1 = update(mod2, subset = -c(2, 24))  # 2, 24번째 관측치 제거\navPlots(mod2_1)\n\n\n\n\n\n# regression diagnostic for normality"
  },
  {
    "objectID": "contents/diagnostics.html#ols에서-모집단에-대한-가정들에-대한-진단",
    "href": "contents/diagnostics.html#ols에서-모집단에-대한-가정들에-대한-진단",
    "title": "Diagnostics",
    "section": "OLS에서 모집단에 대한 가정들에 대한 진단",
    "text": "OLS에서 모집단에 대한 가정들에 대한 진단\nSource: An R Companion to Applied Regression (3e), by John Fox, Sanford Weisberg.\n연구자는 기본적으로 변수 간의 true relationship이 존재할 것이라고 믿으며, 모집단에서 그 관계가 완전한 형태로 존재한다고 가정하고, 그 관계를 표본으로부터 최대한 추론하고자 함.\nOLS 방식으로 모집단에 대한 추론을 하려면, OLS가 요구하는 모집단에 대한 가정들이 위배되지 않아야 함.\n연구자는 관찰된 표본이 “LINE 가정들을 만족하는 모집단”으로부터 표집된 표본이라고 볼만한 충분한 확신이 있어야 함.\n이를 위해서 표본들로부터 대략적인 추정을 할 수 밖에 없음.\n예제: Prestige 데이터셋\n\nlibrary(car)\n\nPrestige <- Prestige |> as_tibble() |> \n  mutate(type = factor(type, levels = c(\"bc\", \"wc\", \"prof\")))\nPrestige\n\n# A tibble: 102 × 6\n   education income women prestige census type \n       <dbl>  <int> <dbl>    <dbl>  <int> <fct>\n 1      13.1  12351 11.2      68.8   1113 prof \n 2      12.3  25879  4.02     69.1   1130 prof \n 3      12.8   9271 15.7      63.4   1171 prof \n 4      11.4   8865  9.11     56.8   1175 prof \n 5      14.6   8403 11.7      73.5   2111 prof \n 6      15.6  11030  5.13     77.6   2113 prof \n 7      15.1   8258 25.6      72.6   2133 prof \n 8      15.4  14163  2.69     78.1   2141 prof \n 9      14.5  11377  1.03     73.1   2143 prof \n10      14.6  11023  0.94     68.8   2153 prof \n# ℹ 92 more rows\n\nmod_prestige <- lm(prestige ~ education + income + type, data = Prestige)\nS(mod_prestige)\n\nCall: lm(formula = prestige ~ education + income + type, data = Prestige)\n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.6229292  5.2275255  -0.119    0.905    \neducation    3.6731661  0.6405016   5.735 1.21e-07 ***\nincome       0.0010132  0.0002209   4.586 1.40e-05 ***\ntypewc      -2.7372307  2.5139324  -1.089    0.279    \ntypeprof     6.0389707  3.8668551   1.562    0.122    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 7.095 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8349\nF-statistic: 117.5 on 4 and 93 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n669.02 684.52 \n\n\n\nPlotting Residuals\n잔차들의 분포: \\((e | X = x_i) \\sim N(0, \\sigma^2)\\)\n즉, 특별한 패턴이 없어야 함\n\n선형적 관계성(Linearity)이 확보되고,\n등분산성(Equal variance)이 확보됨.\n\n\nresidualPlots(\n  mod_prestige, \n  id=list(n=3), # outliers의 수\n  smooth=TRUE, # loess smooth 커브\n  quadratic=FALSE # 3차 fitted 커브\n)\n\n\n\n\n           Test stat Pr(>|Test stat|)   \neducation    -0.6836         0.495942   \nincome       -2.8865         0.004854 **\ntype                                    \nTukey test   -2.6104         0.009043 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# 특정 변수만 선택\nresidualPlots(mod_prestige, ~ income, fitted=FALSE, smooth=TRUE, id=list(n=3))\n\n\n\n\n       Test stat Pr(>|Test stat|)   \nincome   -2.8865         0.004854 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# QQplot: 전체적인 잔차의 분포가 정규분포를 따르는지 확인: y=x 라인에 가까울수록 정규분포를 따름\nqqPlot(mod_prestige, id=list(n=3)) # qq plot\n\n\n\n\n[1] 31 54 82\n\n\n등분산성(equal variance)이 심하게 위배되는 경우;\n\nmod_transact <- lm(time ~ t1 + t2, data=Transact)\nresidualPlots(mod_transact, test=FALSE, layout=c(1, 3))\n\n\n\n\n통계적으로 등분산성(equal variance)을 테스트할 수 있음: ncvTest()\n\n등분산성을 만족하지 않는 경우 we might, as a reasonable approximation, refit the regression by weighted least squares, with weights given by 1/t2. Alternatively, and more naturally, the model could be fit as a generalized linear model with the identity link and gamma errors, as suggested for this example by Cunningham and Heathcote (1989). Finally, because OLS estimates are unbiased even if the variance function is incorrectly specified, the estimates could be obtained by OLS, but with standard errors and tests computed using either the bootstrap (Section 5.1.3) or a sandwich coefficient-variance estimator\n\n\n\nAdded-Variable Plots\nPartial regression plot이라고도 함.\n다른 변수들을 partial out시킨 잔차들로 그림.\n\n각 회귀계수에 대한 precision을 살펴볼 수 있음\n각 관측치에 대한 leverage를 살펴볼 수 있음\n\n\n# 수평선 중심에서 가장 먼 점들 2개\n# 잔차의 값이 가장 큰 점들 2개\navPlots(mod_prestige, id=list(n=2, cex=0.8)) # id: outliers의 수, cex: 점의 크기 80%\n\n\n\n# 특정 관측치 제거 후 다시 그림\nmod_prestige_1 = update(mod_prestige, subset = -c(2, 24))  # 2, 24번째 관측치 제거\navPlots(mod_prestige_1)\n\n\n\n\n\ncompareCoefs(mod_prestige, mod_prestige_1, se = FALSE, pvals = TRUE)\n\nCalls:\n1: lm(formula = prestige ~ education + income + type, data = Prestige)\n2: lm(formula = prestige ~ education + income + type, data = Prestige, \n  subset = -c(2, 24))\n\n            Model 1 Model 2\n(Intercept)  -0.623   0.749\nPr(>|z|)      0.905   0.889\n                           \neducation      3.67    3.31\nPr(>|z|)    9.8e-09 1.5e-06\n                           \nincome      0.00101 0.00133\nPr(>|z|)    4.5e-06 1.2e-05\n                           \ntypewc        -2.74   -1.66\nPr(>|z|)      0.276   0.526\n                           \ntypeprof       6.04    7.18\nPr(>|z|)      0.118   0.071\n                           \n\n\n\n\nUnusual Data\n\noutliers: 모형의 예측값과 크게 다른 관측치\nhigh-leverage points: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 관측치\ninfluential points: outlier이면서 high-leverage point인 관측치\n\n우선, 위에서 다룬 add-variable plots를 통해서 두 변수의 joint로써 influential points를 찾을 수 있음.\n다음은 각 변수들 내에서의 influential points에 관한 진단임.\n예제: Duncan 데이터셋\n\nDuncan <- Duncan |> as_tibble()\nDuncan\n\n# A tibble: 45 × 4\n   type  income education prestige\n   <fct>  <int>     <int>    <int>\n 1 prof      62        86       82\n 2 prof      72        76       83\n 3 prof      75        92       90\n 4 prof      55        90       76\n 5 prof      64        86       90\n 6 prof      21        84       87\n 7 prof      64        93       93\n 8 prof      80       100       90\n 9 wc        67        87       52\n10 prof      72        86       88\n# ℹ 35 more rows\n\nmod_duncan <- lm (prestige ~ income + education, data=Duncan)\nS(mod_duncan)\n\nCall: lm(formula = prestige ~ income + education, data = Duncan)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -6.06466    4.27194  -1.420    0.163    \nincome       0.59873    0.11967   5.003 1.05e-05 ***\neducation    0.54583    0.09825   5.555 1.73e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 13.37 on 42 degrees of freedom\nMultiple R-squared: 0.8282\nF-statistic: 101.2 on 2 and 42 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n365.96 373.19 \n\n\nOutliers\nqqPlot(): 95% pointwise confidence envelope for the Studentized residuals, using a parametric version of the bootstrap.\noutlierTest(): Bonferroni-adjusted p-values for the Studentized residuals.\n\nqqPlot(mod_duncan, id=list(n=3))\n\n\n\n\n[1]  6  9 17\n\noutlierTest(mod_duncan)\n\nNo Studentized residuals with Bonferroni p < 0.05\nLargest |rstudent|:\n  rstudent unadjusted p-value Bonferroni p\n6 3.134519          0.0031772      0.14297\n\n\nInfluential points에 대한 지표들\n\nCook’s distance: i번째 관측치가 제거되었을 때 회귀계수의 변화량에 대한 요약치\nStudentized residuals: 표준화한 잔차\nBonferroni-adjusted p-values: 잔차의 분포에 대한 p-value를 Bonferroni 방식으로 보정한 값\nhat-values: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 정도\n\n가장 큰 값들에 해당하는 관측치들을 제거해보고 회귀분석을 한 후 결과를 비교\n원칙적으로 한번에 한 관측치만 제거하고, 차례로 진단을 해야 함; 전체적인 fit이 변하므로\n\ninfluenceIndexPlot(mod_duncan)\n\n\n\n# 6번째 관측치 제거\nmod_duncan2 <- update(mod_duncan, subset = -6)\ncompareCoefs(mod_duncan, mod_duncan2)\n\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -6)\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.63\nSE             4.27    3.89\n                           \nincome        0.599   0.732\nSE            0.120   0.117\n                           \neducation    0.5458  0.4330\nSE           0.0983  0.0963\n                           \n\n# leave-one-out deletion diagnostics\n# i번째 관측치를 제거했을 때, 각 예측변수들의 변화량을 나타냄\n# dfbeta: 차이, debetas: SE로 표준화한 차이\ndfbetas(mod_duncan) |> head() |> print(digits = 2)\n\n  (Intercept)   income education\n1    -2.3e-02  0.00067   0.03594\n2    -2.5e-02  0.05088  -0.00812\n3    -9.2e-03  0.00648   0.00562\n4    -4.7e-05 -0.00006   0.00014\n5    -6.6e-02  0.01700   0.08678\n6     1.4e-01 -1.22094   1.26302\n\n\n\n# dfbetas를 플랏으로 나타내면,\ndf <- dfbetas(mod_duncan) |> as_tibble()\n\nlibrary(ggrepel)\ndf |> \n  ggplot(aes(x=income, y=education)) +\n  geom_point() +\n  geom_text_repel(aes(label = row.names(df)))\n\n\n\n\nAdded-variable plot으로도 확인해 볼 수 있음\n\nInfluential points가 각 예측변수에서 살펴보는 것과는 다르게\nAdded-variable plot은 joint로써의 영향력을 보고 outliers를 찾을 수 있음\n\n\navPlots(mod_duncan, id=list(n=3, method=\"mahal\")) # 중심으로부터의 거리(mahalanobis distance)만 표시\n\n\n\n\n\n# 6, 16번째 관측치 제거\nmod_duncan3 <- update(mod_duncan, subset = -c(6, 16))\ncompareCoefs(mod_duncan, mod_duncan3)\n\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -c(6,\n   16))\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.41\nSE             4.27    3.65\n                           \nincome        0.599   0.867\nSE            0.120   0.122\n                           \neducation    0.5458  0.3322\nSE           0.0983  0.0987"
  },
  {
    "objectID": "contents/diagnostics.html#선형성에-대한-진단",
    "href": "contents/diagnostics.html#선형성에-대한-진단",
    "title": "Diagnostics",
    "section": "선형성에 대한 진단",
    "text": "선형성에 대한 진단\nComponent-Plus-Residual (partial-residual plots): \\(\\displaystyle e+{\\hat {\\beta }}_{i}X_{i}\\)\ncrPlots()\n초기 탐색적 분석이나 모형을 세우 후 residualPlots으로도 살펴볼 수 있음.\n비선형성에 대해서는 변수를 변환(transform)하거나 고차 다항함수 모형, 혹은 더 복잡한 spline 모형을 이용.\n\nmod_prestige_2 <- lm(prestige ~ income + education + women, data=Prestige)\ncrPlots(mod_prestige_2)"
  },
  {
    "objectID": "contents/diagnostics.html#다중공선성에-대한-진단",
    "href": "contents/diagnostics.html#다중공선성에-대한-진단",
    "title": "Diagnostics",
    "section": "다중공선성에 대한 진단",
    "text": "다중공선성에 대한 진단\nOLS의 가정과는 관계없으나, 통계적 파워를 낮추는 요인이 됨.\n탐색적 분석 과정에서 변수들 간에 심각하게 상관계수(r)가 높은 경우 주의\n지표로는 Variance Inflation Factor(VIF)\n\n예를 들어, \\(X_1\\)에 대한 VIF: \\(\\displaystyle {1 - R^2_{1.23}}\\) 의 역수\n즉, \\(X_2, X_3\\)로 \\(X_1\\)이 설명되지 않는, 즉 독립적인 정도의 역수\n다른 예측 변수들로 잘 설명되는 예측변수라면, standard error(SE)가 증폭되어 회귀계수의 신뢰성이 떨어짐. (불안정하다는 의미)\nVIF 값은 예측변수들이 서로 독립적일 때에 비해 SE가 얼마나 증폭되는지를 나타냄.\nVIF 값이 10 이면 \\(\\sqrt{10}=3.16\\) 배의 SE 증폭이 발생.\nVIF 값이 10 이상이면 심각한 다중공선성이 발생했다고 판단.\n상호작용항이 포함된 경우, (두 변수의 곱으로 만든 항이므로) centering을 하지 않은 경우, VIF값이 크게 나올 수 있으나 실질적인 문제는 전혀 없음.\n\n\nmod_prestige_2 <- lm(prestige ~ income + education + women, data=Prestige)\nsumm(mod_prestige_2, vif=TRUE, model.info = FALSE) |> print()\n\nMODEL FIT:\nF(3,98) = 129.19, p = 0.00\nR² = 0.80\nAdj. R² = 0.79 \n\nStandard errors: OLS\n-------------------------------------------------------\n                     Est.   S.E.   t val.      p    VIF\n----------------- ------- ------ -------- ------ ------\n(Intercept)         -6.79   3.24    -2.10   0.04       \nincome               0.00   0.00     4.73   0.00   2.28\neducation            4.19   0.39    10.77   0.00   1.85\nwomen               -0.01   0.03    -0.29   0.77   1.53\n-------------------------------------------------------"
  },
  {
    "objectID": "contents/diagnostics.html#변수의-변환transform",
    "href": "contents/diagnostics.html#변수의-변환transform",
    "title": "Diagnostics",
    "section": "변수의 변환(transform)",
    "text": "변수의 변환(transform)\n선형성, 등분산성, 정규성 등은 각각 다른 개념이나 변수의 변형을 통해 동시에 해결되기도 함.\n\nlog변환은 정규성과 선형성을 동시에 해결해주는 경우가 많음.\n또한 의미적으로도 해석이 용이함. 몇 배의 의미로 바뀜.\n복잡한 변환에 대해서 다음을 참조\n\nBox-Cox Power Transformations\npowerTransform()\n\n\n예제: UN in carData\n\n\n\n\n\n\ncode\n\n\n\n\n\nUN |> \n  ggplot(aes(x=ppgdp)) +\n  geom_density()\nUN |> \n  ggplot(aes(x=infantMortality)) +\n  geom_density()\nUN |> \n  ggplot(aes(x=ppgdp, y=infantMortality)) +\n  geom_point() +\n  geom_smooth()\nUN |> \n  ggplot(aes(x=log(ppgdp), y=log(infantMortality))) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n변수의 변환이 아닌 모형의 복잡도를 높혀 좀 더 나은 fit을 얻을 수도 있음.\n\n다항함수 모형\nspline 모형\n\n예제: CPS85 in mosaicData\n\n\n\n\n\n\ncode\n\n\n\n\n\ncps <- mosaicData::CPS85 |> as_tibble()\ncps2 <- cps |> \n  mutate(log_wage = log(wage)) |> \n  filter(wage < 30 & log_wage > 1)\n\ncps2 |>\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .7) +\n  geom_smooth() +\n  scale_y_continuous(label = scales::label_dollar()) +\n  labs(y = \"wage (dollars per hour)\")\n\ncps2 |>\n  ggplot(aes(x = wage)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmod_cps <- lm(log_wage ~ married * sex + age + I(age^2), data = cps2) # 2차 다항함수\nresidualPlots(mod_cps, test=FALSE)\n\n\n\nlibrary(effects)\nplot(predictorEffects(mod_cps))\n\n\n\nlibrary(splines)\nmod_cps2 <- lm(log_wage ~ married * sex + ns(age, 3), data = cps2) # natural spline\n\nplot(predictorEffects(mod_cps2))"
  },
  {
    "objectID": "contents/diagnostics.html#nonconstant-error-variance",
    "href": "contents/diagnostics.html#nonconstant-error-variance",
    "title": "Diagnostics",
    "section": "Nonconstant Error Variance",
    "text": "Nonconstant Error Variance"
  },
  {
    "objectID": "contents/diagnostics.html#plotting-residuals",
    "href": "contents/diagnostics.html#plotting-residuals",
    "title": "Diagnostics",
    "section": "Plotting Residuals",
    "text": "Plotting Residuals\n잔차들의 분포: \\((e | X = x_i) \\sim N(0, \\sigma^2)\\)\n즉, 특별한 패턴이 없어야 함\n\n선형적 관계성(Linearity)이 확보되고,\n등분산성(Equal variance)이 확보됨.\n\n\nresidualPlots(\n  mod_prestige, \n  id=list(n=3), # outliers의 수\n  smooth=TRUE, # loess smooth 커브\n  quadratic=FALSE # 3차 fitted 커브\n)\n\n\n\n\n           Test stat Pr(>|Test stat|)   \neducation    -0.6836         0.495942   \nincome       -2.8865         0.004854 **\ntype                                    \nTukey test   -2.6104         0.009043 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# 특정 변수만 선택\nresidualPlots(mod_prestige, ~ income, fitted=FALSE, smooth=TRUE, id=list(n=3))\n\n\n\n\n       Test stat Pr(>|Test stat|)   \nincome   -2.8865         0.004854 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# QQplot: 전체적인 잔차의 분포가 정규분포를 따르는지 확인: y=x 라인에 가까울수록 정규분포를 따름\nqqPlot(mod_prestige, id=list(n=3)) # qq plot\n\n\n\n\n[1] 31 54 82\n\n\n등분산성(equal variance)이 심하게 위배되는 경우;\n\nmod_transact <- lm(time ~ t1 + t2, data=Transact)\nresidualPlots(mod_transact, test=FALSE, layout=c(1, 3))\n\n\n\n\n통계적으로 등분산성(equal variance)을 테스트할 수 있음: ncvTest()\n\n\n\n\n\n\nNote\n\n\n\n등분산성을 만족하지 않는 경우: Heteroskedasticity\n\nWeighted least squares (WLS) 방식으로 추정\n좀 더 자연스러운 generalized linear model (GLM) with the identity link and gamma errors(확률 분포).\n등분산성은 회귀계수 값 자체는 크게 영향을 주지 않으므로, OLS로 회귀계수는 추정하되, 유의성 검증(SE, p values)은 bootstrap을 이용하거나 a sandwich coefficient-variance estimator로 계산하는 방식을 선택.\n\n\nlibrary(parameters)\nmodel_parameters(mod_transact) |> print(digits=3)\n\nParameter   | Coefficient |      SE |            95% CI | t(258) |      p\n-------------------------------------------------------------------------\n(Intercept) |     144.369 | 170.544 | [-191.47, 480.21] |  0.847 | 0.398 \nt1          |       5.462 |   0.433 | [   4.61,   6.32] | 12.607 | < .001\nt2          |       2.035 |   0.094 | [   1.85,   2.22] | 21.567 | < .001\n\n\n\nSandwich coefficient-variance estimator\n\n\nmodel_parameters(mod_transact, vcov = \"HC3\") # HC3 방식\n\n# A tibble: 3 × 9\n  Parameter   Coefficient      SE    CI  CI_low CI_high      t df_error        p\n  <chr>             <dbl>   <dbl> <dbl>   <dbl>   <dbl>  <dbl>    <int>    <dbl>\n1 (Intercept)      144.   203.     0.95 -256.    544.    0.711      258 4.78e- 1\n2 t1                 5.46   0.729  0.95    4.03    6.90  7.49       258 1.06e-12\n3 t2                 2.03   0.163  0.95    1.71    2.36 12.4        258 3.60e-28\n\n\n\nBootstrap\n\n\nlibrary(parameters)\nbootstrap_parameters(mod_transact, ci_method = \"BCI\") # BCI 방식\n\n# A tibble: 3 × 5\n  Parameter   Coefficient  CI_low CI_high     p\n  <chr>             <dbl>   <dbl>   <dbl> <dbl>\n1 (Intercept)      165.   -223.    531.   0.366\n2 t1                 5.51    4.28    6.77 0    \n3 t2                 2.02    1.73    2.33 0"
  },
  {
    "objectID": "contents/diagnostics.html#added-variable-plots",
    "href": "contents/diagnostics.html#added-variable-plots",
    "title": "Diagnostics",
    "section": "Added-Variable Plots",
    "text": "Added-Variable Plots\nPartial regression plot이라고도 함.\n다른 변수들을 partial out시킨 잔차들로 그림.\n\n각 회귀계수에 대한 precision을 살펴볼 수 있음\n각 관측치에 대한 leverage를 살펴볼 수 있음\n\n\n# 수평선 중심에서 가장 먼 점들 2개\n# 잔차의 값이 가장 큰 점들 2개\navPlots(mod_prestige, id=list(n=2, cex=0.8)) # id: outliers의 수, cex: 점의 크기 80%\n\n\n\n# 특정 관측치 제거 후 다시 그림\nmod_prestige_1 = update(mod_prestige, subset = -c(2, 24))  # 2, 24번째 관측치 제거\navPlots(mod_prestige_1)\n\n\n\n\n\ncompareCoefs(mod_prestige, mod_prestige_1, se = FALSE, pvals = TRUE)\n\nCalls:\n1: lm(formula = prestige ~ education + income + type, data = Prestige)\n2: lm(formula = prestige ~ education + income + type, data = Prestige, \n  subset = -c(2, 24))\n\n            Model 1 Model 2\n(Intercept)  -0.623   0.749\nPr(>|z|)      0.905   0.889\n                           \neducation      3.67    3.31\nPr(>|z|)    9.8e-09 1.5e-06\n                           \nincome      0.00101 0.00133\nPr(>|z|)    4.5e-06 1.2e-05\n                           \ntypewc        -2.74   -1.66\nPr(>|z|)      0.276   0.526\n                           \ntypeprof       6.04    7.18\nPr(>|z|)      0.118   0.071"
  },
  {
    "objectID": "contents/diagnostics.html#unusual-data",
    "href": "contents/diagnostics.html#unusual-data",
    "title": "Diagnostics",
    "section": "Unusual Data",
    "text": "Unusual Data\n\noutliers: 모형의 예측값과 크게 다른 관측치\nhigh-leverage points: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 관측치\ninfluential points: outlier이면서 high-leverage point인 관측치\n\n우선, 위에서 다룬 add-variable plots를 통해서 두 변수의 joint로써 influential points를 찾을 수 있음.\n다음은 각 변수들 내에서의 influential points에 관한 진단임.\n예제: Duncan 데이터셋\n\nDuncan <- Duncan |> as_tibble()\nDuncan\n\n# A tibble: 45 × 4\n   type  income education prestige\n   <fct>  <int>     <int>    <int>\n 1 prof      62        86       82\n 2 prof      72        76       83\n 3 prof      75        92       90\n 4 prof      55        90       76\n 5 prof      64        86       90\n 6 prof      21        84       87\n 7 prof      64        93       93\n 8 prof      80       100       90\n 9 wc        67        87       52\n10 prof      72        86       88\n# ℹ 35 more rows\n\nmod_duncan <- lm (prestige ~ income + education, data=Duncan)\nS(mod_duncan)\n\nCall: lm(formula = prestige ~ income + education, data = Duncan)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -6.06466    4.27194  -1.420    0.163    \nincome       0.59873    0.11967   5.003 1.05e-05 ***\neducation    0.54583    0.09825   5.555 1.73e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 13.37 on 42 degrees of freedom\nMultiple R-squared: 0.8282\nF-statistic: 101.2 on 2 and 42 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n365.96 373.19 \n\n\n\nOutliers\nqqPlot(): 95% pointwise confidence envelope for the Studentized residuals, using a parametric version of the bootstrap.\noutlierTest(): Bonferroni-adjusted p-values for the Studentized residuals.\n\nqqPlot(mod_duncan, id=list(n=3))\n\n\n\n\n[1]  6  9 17\n\noutlierTest(mod_duncan)\n\nNo Studentized residuals with Bonferroni p < 0.05\nLargest |rstudent|:\n  rstudent unadjusted p-value Bonferroni p\n6 3.134519          0.0031772      0.14297\n\n\n\n\nInfluential points에 대한 지표들\n\nCook’s distance: i번째 관측치가 제거되었을 때 회귀계수의 변화량에 대한 요약치\nStudentized residuals: 표준화한 잔차\nBonferroni-adjusted p-values: 잔차의 분포에 대한 p-value를 Bonferroni 방식으로 보정한 값\nhat-values: 예측변수들의 공간에서 중심으로부터 멀리 떨어진 정도\n\n가장 큰 값들에 해당하는 관측치들을 제거해보고 회귀분석을 한 후 결과를 비교\n원칙적으로 한번에 한 관측치만 제거하고, 차례로 진단을 해야 함; 전체적인 fit이 변하므로\n\ninfluenceIndexPlot(mod_duncan)\n\n\n\n# 6번째 관측치 제거\nmod_duncan2 <- update(mod_duncan, subset = -6)\ncompareCoefs(mod_duncan, mod_duncan2)\n\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -6)\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.63\nSE             4.27    3.89\n                           \nincome        0.599   0.732\nSE            0.120   0.117\n                           \neducation    0.5458  0.4330\nSE           0.0983  0.0963\n                           \n\n# leave-one-out deletion diagnostics\n# i번째 관측치를 제거했을 때, 각 예측변수들의 변화량을 나타냄\n# dfbeta: 차이, debetas: SE로 표준화한 차이\ndfbetas(mod_duncan) |> head() |> print(digits = 2)\n\n  (Intercept)   income education\n1    -2.3e-02  0.00067   0.03594\n2    -2.5e-02  0.05088  -0.00812\n3    -9.2e-03  0.00648   0.00562\n4    -4.7e-05 -0.00006   0.00014\n5    -6.6e-02  0.01700   0.08678\n6     1.4e-01 -1.22094   1.26302\n\n\n\n# dfbetas를 플랏으로 나타내면,\ndf <- dfbetas(mod_duncan) |> as_tibble()\n\nlibrary(ggrepel)\ndf |> \n  ggplot(aes(x=income, y=education)) +\n  geom_point() +\n  geom_text_repel(aes(label = row.names(df)))\n\n\n\n\nAdded-variable plot으로도 확인해 볼 수 있음\n\nInfluential points가 각 예측변수에서 살펴보는 것과는 다르게\nAdded-variable plot은 joint로써의 영향력을 보고 outliers를 찾을 수 있음\n\n\navPlots(mod_duncan, id=list(n=3, method=\"mahal\")) # 중심으로부터의 거리(mahalanobis distance)만 표시\n\n\n\n\n\n# 6, 16번째 관측치 제거\nmod_duncan3 <- update(mod_duncan, subset = -c(6, 16))\ncompareCoefs(mod_duncan, mod_duncan3)\n\nCalls:\n1: lm(formula = prestige ~ income + education, data = Duncan)\n2: lm(formula = prestige ~ income + education, data = Duncan, subset = -c(6,\n   16))\n\n            Model 1 Model 2\n(Intercept)   -6.06   -6.41\nSE             4.27    3.65\n                           \nincome        0.599   0.867\nSE            0.120   0.122\n                           \neducation    0.5458  0.3322\nSE           0.0983  0.0987"
  },
  {
    "objectID": "contents/diagnostics.html#변수의-변환transform-및-고차원-모형",
    "href": "contents/diagnostics.html#변수의-변환transform-및-고차원-모형",
    "title": "Diagnostics",
    "section": "변수의 변환(transform) 및 고차원 모형",
    "text": "변수의 변환(transform) 및 고차원 모형\n선형성, 등분산성, 정규성 등은 각각 다른 개념이나 변수의 변형을 통해 동시에 해결되기도 함.\n\nlog변환은 정규성과 선형성을 동시에 해결해주는 경우가 많음.\n또한 의미적으로도 해석이 용이함. 몇 배의 의미로 바뀜.\n복잡한 변환에 대해서 다음을 참조\n\nBox-Cox Power Transformations\npowerTransform()\n\n\n예제: UN in carData\n\n\n\n\n\n\ncode\n\n\n\n\n\nUN |> \n  ggplot(aes(x=ppgdp)) +\n  geom_density()\nUN |> \n  ggplot(aes(x=infantMortality)) +\n  geom_density()\nUN |> \n  ggplot(aes(x=ppgdp, y=infantMortality)) +\n  geom_point() +\n  geom_smooth()\nUN |> \n  ggplot(aes(x=log(ppgdp), y=log(infantMortality))) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n위의 Presitge의 예의 경우, income을 log변환하는 것이 적절함.\n\nmod_prestige <- lm(prestige ~ education + income + type, data = Prestige)\nmod_prestige_log <- lm(prestige ~ education + log2(income) + type, data = Prestige)\n\nresidualPlots(mod_prestige, ~income, test=FALSE, fitted=FALSE)\nresidualPlots(mod_prestige_log, ~log2(income), test=FALSE, fitted=FALSE)\nS(mod_prestige_log)\n\n\n\n\n\n\n\n\n\n\n\nCall: lm(formula = prestige ~ education + log2(income) + type, data = Prestige)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -81.2019    13.7431  -5.909 5.63e-08 ***\neducation      3.2845     0.6081   5.401 5.06e-07 ***\nlog2(income)   7.2694     1.1900   6.109 2.31e-08 ***\ntypewc        -1.4394     2.3780  -0.605   0.5465    \ntypeprof       6.7509     3.6185   1.866   0.0652 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 6.637 on 93 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared: 0.8555\nF-statistic: 137.6 on 4 and 93 DF,  p-value: < 2.2e-16 \n   AIC    BIC \n655.93 671.44 \n\n\n\n\n이 때, log2(income)에 대한 회귀계수의 해석은 income이 2배 늘면(=log2(income)이 1증가하면) prestige가 7.27점 증가하는지를 나타냄.\n변수의 변환이 아닌 모형의 복잡도를 높혀 좀 더 나은 fit을 얻을 수도 있음.\n\n다항함수 모형\nSpline 모형\n\n예제: CPS85 in mosaicData\n\n\n\n\n\n\ncode\n\n\n\n\n\ncps <- mosaicData::CPS85 |> as_tibble()\ncps2 <- cps |> \n  mutate(log_wage = log(wage)) |> \n  filter(wage < 30 & log_wage > 1)\n\ncps2 |>\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .7) +\n  geom_smooth() +\n  scale_y_continuous(label = scales::label_dollar()) +\n  labs(y = \"wage (dollars per hour)\")\n\ncps2 |>\n  ggplot(aes(x = wage)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmod_cps_poly <- lm(log_wage ~ married * sex + age + I(age^2), data = cps2) # 2차 다항함수\nresidualPlots(mod_cps_poly, test=FALSE)\n\n\n\n\nSpline 모형: piece-wise polynomial\nbs(), ns() in splines 패키지\n\nns(): natural spline 모형 (boundary constraints)\n\n\nlibrary(splines)\nmod_cps_ns <- lm(log_wage ~ married * sex + ns(age, 3), data = cps2) # 3-piecewise natural spline\n\n다항함수 모형과 spline 모형의 비교\n\nlibrary(effects)\nplot(predictorEffects(mod_cps_poly, ~age))\nplot(predictorEffects(mod_cps_ns, ~age))"
  }
]