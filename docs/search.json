[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "CHA Stats in R",
    "section": "",
    "text": "Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\nDefinitions.\n“License” shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.\n“Licensor” shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.\n“Legal Entity” shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, “control” means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.\n“You” (or “Your”) shall mean an individual or Legal Entity exercising permissions granted by this License.\n“Source” form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\n“Object” form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\n“Work” shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).\n“Derivative Works” shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\n“Contribution” shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, “submitted” means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as “Not a Contribution.”\n“Contributor” shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\nGrant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.\nGrant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.\nRedistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n\nYou must give any other recipients of the Work or Derivative Works a copy of this License; and\nYou must cause any modified files to carry prominent notices stating that You changed the files; and\nYou must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and\nIf the Work includes a “NOTICE” text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.\n\nYou may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.\nSubmission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.\nTrademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.\nDisclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\nLimitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\nAccepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\nAPPENDIX: How to apply the Apache License to your work.\n  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\nCopyright [yyyy] [name of copyright owner]\nLicensed under the Apache License, Version 2.0 (the “License”); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n   http://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  {
    "objectID": "contents/tidyverse.html",
    "href": "contents/tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "함수들: print(), glimpse(), summary(), count()\n() 안에 들어가는 것을 argument라고 부름\n\nlibrary(tidyverse)\n\ncps <- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\nprint(cps) # print 생략!\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n\n\n\n\n\nprint()\n\n\n\n강의 노트에서 print()를 쓰는 것은 jupyter notebook에서 data frame을 표시하는 방식때문이므로 무시하셔도 됩니다.\n\n\n보통 print()없이 데이터 프레임을 살펴보지만, print()을 이용하면, 표시되는 방식을 조정해서 볼 수 있음.\n\nprint(cps, n = 3) # 처음 3개 행\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1   9      10 W     M     NH       NS    Married    27 Not      43 const \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales \n# … with 531 more rows\n\n\n\n\n\n\n\n\ntip: print() 옵션\n\n\n\n\n\nprint(tibble, n = 10, width = Inf) # 10개의 rows와 모든 columns\n기본 셋팅을 변경하려면\noptions(tibble.print_min = 10, tibble.width = Inf)\nColumns/변수들이 많은 경우 화면에서 다음과 같이 축약되어 나오는데, 이를 다 보려면\nprint(nycflights13::flights) # nycflights13 패키지의 flights 데이터\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#   <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n# 1  2013     1     1      517         515       2     830     819      11 UA     \n# 2  2013     1     1      533         529       4     850     830      20 UA     \n# 3  2013     1     1      542         540       2     923     850      33 AA     \n# 4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n# 5  2013     1     1      554         600      -6     812     837     -25 DL     \n# 6  2013     1     1      554         558      -4     740     728      12 UA     \n# # … with 336,770 more rows, 9 more variables: flight <int>, tailnum <chr>,\n# #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n# #   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n# #   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nprint(nycflights13::flights, n = 3, width = Inf) # 가로 열의 개수: Inf (모든 열)\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n# 1  2013     1     1      517            515         2      830            819\n# 2  2013     1     1      533            529         4      850            830\n# 3  2013     1     1      542            540         2      923            850\n#   arr_delay carrier flight tailnum origin dest  air_time distance  hour minute\n#       <dbl> <chr>    <int> <chr>   <chr>  <chr>    <dbl>    <dbl> <dbl>  <dbl>\n# 1        11 UA        1545 N14228  EWR    IAH        227     1400     5     15\n# 2        20 UA        1714 N24211  LGA    IAH        227     1416     5     29\n# 3        33 AA        1141 N619AA  JFK    MIA        160     1089     5     40\n#   time_hour          \n#   <dttm>             \n# 1 2013-01-01 05:00:00\n# 2 2013-01-01 05:00:00\n# 3 2013-01-01 05:00:00\n# # … with 336,773 more rows\n\n\n\n많은 변수들을 간략히 보는 방법으로는 glimpse()\n\nglimpse(cps)\n\nRows: 534\nColumns: 11\n$ wage     <dbl> 9.00, 5.50, 3.80, 10.50, 15.00, 9.00, 9.57, 15.00, 11.00, 5.0…\n$ educ     <int> 10, 12, 12, 12, 12, 16, 12, 14, 8, 12, 17, 17, 14, 14, 12, 14…\n$ race     <fct> W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, NW, NW, W,…\n$ sex      <fct> M, M, F, F, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F…\n$ hispanic <fct> NH, NH, NH, NH, NH, NH, NH, NH, NH, NH, Hisp, NH, Hisp, NH, N…\n$ south    <fct> NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, N…\n$ married  <fct> Married, Married, Single, Married, Married, Married, Married,…\n$ exper    <int> 27, 20, 4, 29, 40, 27, 5, 22, 42, 14, 18, 3, 4, 14, 35, 0, 7,…\n$ union    <fct> Not, Not, Not, Not, Union, Not, Union, Not, Not, Not, Not, No…\n$ age      <int> 43, 38, 22, 47, 58, 49, 23, 42, 56, 32, 41, 26, 24, 34, 53, 2…\n$ sector   <fct> const, sales, sales, clerical, const, clerical, service, sale…\n\n\n\n\n\n\n\n\nTip\n\n\n\n엑셀 스프레드시트처럼 보는 방법은\nEnvironment 패널에 보이는 cps 데이터셋 맨 끝에 네모난 마크를 클릭하거나,\nview(cps)\n\n\n변수들에 대한 통계치 요약 summary()\n\nsummary(cps)\n\n      wage             educ       race     sex     hispanic   south   \n Min.   : 1.000   Min.   : 2.00   NW: 67   F:245   Hisp: 27   NS:378  \n 1st Qu.: 5.250   1st Qu.:12.00   W :467   M:289   NH  :507   S :156  \n Median : 7.780   Median :12.00                                       \n Mean   : 9.024   Mean   :13.02                                       \n 3rd Qu.:11.250   3rd Qu.:15.00                                       \n Max.   :44.500   Max.   :18.00                                       \n                                                                      \n    married        exper         union          age             sector   \n Married:350   Min.   : 0.00   Not  :438   Min.   :18.00   prof    :105  \n Single :184   1st Qu.: 8.00   Union: 96   1st Qu.:28.00   clerical: 97  \n               Median :15.00               Median :35.00   service : 83  \n               Mean   :17.82               Mean   :36.83   manuf   : 68  \n               3rd Qu.:26.00               3rd Qu.:44.00   other   : 68  \n               Max.   :55.00               Max.   :64.00   manag   : 55  \n                                                           (Other) : 58  \n\n\n카테고리별 개수를 세주는 count()\nNumber(수)에 대해서도 적용 가능: ex. educ 수준 2, 3, … 18 각각에 대해서\n\ncps |>  # pipe operator: alt + . (option + .)\n    count(sector) |>\n    print() # 생략해도 됨\n\n# A tibble: 8 × 2\n  sector       n\n  <fct>    <int>\n1 clerical    97\n2 const       20\n3 manag       55\n4 manuf       68\n5 other       68\n6 prof       105\n7 sales       38\n8 service     83\n\n\n\ncps |>\n    count(sex, married) |>\n    print()\n\n# A tibble: 4 × 3\n  sex   married     n\n  <fct> <fct>   <int>\n1 F     Married   162\n2 F     Single     83\n3 M     Married   188\n4 M     Single    101\n\n\n\n\n\n\n\n\nPipe operator\n\n\n\n|> 또는 %>% (’then’의 의미로…)\nx |> f(y) # f(x, y),\nx |> f(y) |> g(z) # g(f(x, y), z)\nsummary(cps) 는 다음과 같음\ncps |>\n    summary()\ncount(cps, sector)는 다음과 같음\ncps |> \n    count(sector)"
  },
  {
    "objectID": "contents/tidyverse.html#rows",
    "href": "contents/tidyverse.html#rows",
    "title": "Tidyverse",
    "section": "Rows",
    "text": "Rows\n행에 적용되는 함수들\nfilter(), arrange(), distinct()\n\nfilter()\n조건에 맞는 행을 선택\n\nConditional operators:\n>, >=, <, <=, == (equal to), != (not equal to)\n& (and) | (or)\n! (not)\n%in% (includes)\n\n\n# 임금(wage)가 10이상인 사람들\ncps |>\n    filter(wage >= 10) |>\n    print()\n\n# A tibble: 184 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  15      12 W     M     NH       NS    Married    40 Union    58 const   \n3  15      14 W     M     NH       NS    Single     22 Not      42 sales   \n4  11       8 W     M     NH       NS    Married    42 Not      56 manuf   \n5  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof    \n6  20.4    17 W     M     NH       NS    Single      3 Not      26 prof    \n# … with 178 more rows\n\n\n\n# 임금(wage)가 10이상이고 여성(F)들\ncps |>\n    filter(wage >= 10 & sex == \"F\") |>\n    print()\n\n# A tibble: 62 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  11.2    17 NW    F     NH       NS    Married    32 Not      55 clerical\n3  25.0    17 W     F     NH       NS    Single      5 Not      28 prof    \n4  12.6    17 W     F     NH       NS    Married    13 Not      36 manag   \n5  11.7    16 W     F     NH       NS    Single     42 Not      64 clerical\n6  12.5    15 W     F     NH       NS    Married     6 Not      27 clerical\n# … with 56 more rows\n\n\n\n# 간부급(management)과 전문직(professional)에 종사하는 사람들\ncps |>\n    filter(sector == \"manag\" | sector == \"prof\") |>\n    print()\n\n# A tibble: 160 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# … with 154 more rows\n\n\n다음과 같이 편리하게 %in%을 이용하여 여러 항목을 포함하는, 즉 |와 ==를 합친 조건문을 생성\n즉, include인지 판별\n\n# A shorter way to select sectors for management or professional\ncps |>\n    filter(sector %in% c(\"manag\", \"prof\")) |>\n    print()\n\n# A tibble: 160 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# … with 154 more rows\n\n\n\n\n\n\n\n\nImportant\n\n\n\nfilter()로 얻은 데이터 프레임은 원래 데이터 프레임을 수정하는 것이 아니므로 계속 사용하려면 저장해야 함\n이후 모든 함수들에 대해서도 마찬가지\nprestige <- cps |>\n    filter(sector %in% c(\"manag\", \"prof\"))\n\nprestige\n#    wage  educ race  sex   hispanic south married exper union   age sector\n#   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n# 1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n# 2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n# 3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n# ...\n\n\n\n\n\n\n\n\nTip\n\n\n\n잦은 실수들\ncps |>\n    filter(sex = \"F\") # \"==\" vs. \"=\"\ncps |>\n    filter(sector == \"manage\" | \"prof\") # | 전후 모두 완결된 조건문 필요\n\n\n\n\narrange()\nColumn의 값을 기준으로 row를 정렬\n\n# 교육정도(educ)와 임금(wage)에 따라 오름차순으로 정렬\ncps |>\n    arrange(educ, wage) |>\n    print(n = 10)\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector \n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>  \n 1  3.75     2 W     M     Hisp     NS    Single     16 Not      24 service\n 2  7        3 W     M     Hisp     S     Married    55 Not      64 manuf  \n 3  6        4 W     M     NH       NS    Married    54 Not      64 service\n 4 14        5 W     M     NH       S     Married    44 Not      55 const  \n 5  3        6 W     F     Hisp     NS    Married    43 Union    55 manuf  \n 6  4.62     6 NW    F     NH       S     Single     33 Not      45 manuf  \n 7  5.75     6 W     M     NH       S     Married    45 Not      57 manuf  \n 8  3.35     7 W     M     NH       S     Married    43 Not      56 manuf  \n 9  4.5      7 W     M     Hisp     S     Married    14 Not      27 service\n10  6        7 W     F     NH       S     Married    15 Not      28 manuf  \n# … with 524 more rows\n\n\ndesc()을 이용하면 내림차순으로 정렬\n\n# educ을 내림차순으로 정렬\ncps |>\n    arrange(desc(educ)) |>\n    print(n = 10)\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector\n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n 1 15       18 W     M     NH       NS    Married    12 Not      36 prof  \n 2 14.0     18 W     F     NH       NS    Married    14 Not      38 manag \n 3 13.5     18 W     M     NH       NS    Married    14 Union    38 prof  \n 4 20       18 W     F     NH       NS    Married    19 Not      43 manag \n 5  7       18 W     M     NH       NS    Married    33 Not      57 prof  \n 6 11.2     18 W     M     NH       NS    Married    19 Not      43 prof  \n 7  5.71    18 W     M     NH       NS    Married     3 Not      27 prof  \n 8 18       18 W     M     NH       NS    Married    15 Not      39 prof  \n 9 19       18 W     M     NH       NS    Single     13 Not      37 manag \n10 22.8     18 W     F     NH       NS    Single     37 Not      61 prof  \n# … with 524 more rows\n\n\narrange()와 filter()를 함께 사용하여 좀 더 복잡한 문제를 해결할 수 있음\n\n# 높은 지위의 섹터에서 일하는 사람들 중 임금이 상위에 있는 사람들\ncps |>\n    filter(sector == \"manage\" | sector == \"prof\") |>\n    arrange(desc(wage)) |>\n    print()\n\n# A tibble: 105 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n3  25.0    17 W     M     NH       NS    Married    31 Not      54 prof  \n4  25.0    16 W     F     NH       S     Single      5 Not      27 prof  \n5  23.2    17 NW    F     NH       NS    Married    25 Union    48 prof  \n6  22.8    18 W     F     NH       NS    Single     37 Not      61 prof  \n# … with 99 more rows\n\n\n\n\ndistinct()**\n유티크한 조합들을 리스트\n\ncps |>\n    distinct(sector, sex) |>\n    print()\n\n# A tibble: 15 × 2\n   sector   sex  \n   <fct>    <fct>\n 1 const    M    \n 2 sales    M    \n 3 sales    F    \n 4 clerical F    \n 5 service  F    \n 6 manuf    M    \n 7 prof     M    \n 8 service  M    \n 9 other    M    \n10 clerical M    \n11 manag    M    \n12 prof     F    \n13 manag    F    \n14 manuf    F    \n15 other    F"
  },
  {
    "objectID": "contents/tidyverse.html#columns",
    "href": "contents/tidyverse.html#columns",
    "title": "Tidyverse",
    "section": "Columns",
    "text": "Columns\n열에 적용되는 함수들\nmutate(), select(), rename()\n\nmutate()\nColumns/변수들로부터 값을 계산하여 새로운 변수를 만듦\n\ntips <- as_tibble(reshape::tips) # reshpae 패키지 안에 tips 데이터셋\ntips |> print()\n\n# A tibble: 244 × 7\n  total_bill   tip sex    smoker day   time    size\n       <dbl> <dbl> <fct>  <fct>  <fct> <fct>  <int>\n1       17.0  1.01 Female No     Sun   Dinner     2\n2       10.3  1.66 Male   No     Sun   Dinner     3\n3       21.0  3.5  Male   No     Sun   Dinner     3\n4       23.7  3.31 Male   No     Sun   Dinner     2\n5       24.6  3.61 Female No     Sun   Dinner     4\n6       25.3  4.71 Male   No     Sun   Dinner     4\n# … with 238 more rows\n\n\n\ntips |>\n    mutate(\n        tip_pct = tip / total_bill * 100,\n        tip_pct_per = tip_pct / size\n    ) |>\n    print()\n\n# A tibble: 244 × 9\n  total_bill   tip sex    smoker day   time    size tip_pct tip_pct_per\n       <dbl> <dbl> <fct>  <fct>  <fct> <fct>  <int>   <dbl>       <dbl>\n1       17.0  1.01 Female No     Sun   Dinner     2    5.94        2.97\n2       10.3  1.66 Male   No     Sun   Dinner     3   16.1         5.35\n3       21.0  3.5  Male   No     Sun   Dinner     3   16.7         5.55\n4       23.7  3.31 Male   No     Sun   Dinner     2   14.0         6.99\n5       24.6  3.61 Female No     Sun   Dinner     4   14.7         3.67\n6       25.3  4.71 Male   No     Sun   Dinner     4   18.6         4.66\n# … with 238 more rows\n\n\n\n\nselect()\nColumns/변수를 선택\n\ntips |>\n    select(total_bill, tip, day, time) |>\n    print()\n\n# A tibble: 244 × 4\n  total_bill   tip day   time  \n       <dbl> <dbl> <fct> <fct> \n1       17.0  1.01 Sun   Dinner\n2       10.3  1.66 Sun   Dinner\n3       21.0  3.5  Sun   Dinner\n4       23.7  3.31 Sun   Dinner\n5       24.6  3.61 Sun   Dinner\n6       25.3  4.71 Sun   Dinner\n# … with 238 more rows\n\n\n\n# tip에서 smoker까지, 그리고 size columns 선택\ntips |>\n    select(tip:smoker, size) |>  # select(2:4, 7)처럼 number로 선택가능\n    print()\n\n# A tibble: 244 × 4\n    tip sex    smoker  size\n  <dbl> <fct>  <fct>  <int>\n1  1.01 Female No         2\n2  1.66 Male   No         3\n3  3.5  Male   No         3\n4  3.31 Male   No         2\n5  3.61 Female No         4\n6  4.71 Male   No         4\n# … with 238 more rows\n\n\n\n# sex에서 day까지 columns은 제외하고\ntips |>\n    select(!sex:day) |> # !: not\n    print()\n\n# A tibble: 244 × 4\n  total_bill   tip time    size\n       <dbl> <dbl> <fct>  <int>\n1       17.0  1.01 Dinner     2\n2       10.3  1.66 Dinner     3\n3       21.0  3.5  Dinner     3\n4       23.7  3.31 Dinner     2\n5       24.6  3.61 Dinner     4\n6       25.3  4.71 Dinner     4\n# … with 238 more rows\n\n\n\n# factor 타입의 변수들만 선택: 함수를 이용\ntips |>\n    select(where(is.factor)) |>  # 다른 함수들: is.numeric, is.character\n    print()\n\n# A tibble: 244 × 4\n  sex    smoker day   time  \n  <fct>  <fct>  <fct> <fct> \n1 Female No     Sun   Dinner\n2 Male   No     Sun   Dinner\n3 Male   No     Sun   Dinner\n4 Male   No     Sun   Dinner\n5 Female No     Sun   Dinner\n6 Male   No     Sun   Dinner\n# … with 238 more rows\n\n\n다양한 select()의 선택방법은 ?select로 help참고\n예를 들어, starts_with(\"abc\")는 abc로 시작하는 열의 이름을 가진 열들\n\n\n\n\n\n\nNote\n\n\n\nBase R에서 행과 열의 선택과 비교하면,\ncps[2:5, c(\"wage\", \"married\")] # 2~5행과 wage, married열\n# # A tibble: 4 × 2\n#    wage married\n#   <dbl> <fct>  \n# 1   5.5 Married\n# 2   3.8 Single \n# 3  10.5 Married\n# 4  15   Married\n\ncps |> \n    select(wage, married) |> \n    slice(2:5) # 행을 선택\n\n\n\n\nrename()\nColumns의 이름을 변경\n\ncps |>\n    rename(education = educ, marital = married) |> # new = old\n    print()\n\n# A tibble: 534 × 11\n   wage education race  sex   hispanic south marital exper union   age sector  \n  <dbl>     <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9          10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5        12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8        12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5        12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15          12 W     M     NH       NS    Married    40 Union    58 const   \n6   9          16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n변수를 select할 때 동시에 이름도 바꿀 수 있음\n\ncps |>\n    select(education = educ, marital = married) |> # new = old\n    print()\n\n# A tibble: 534 × 2\n  education marital\n      <int> <fct>  \n1        10 Married\n2        12 Married\n3        12 Single \n4        12 Married\n5        12 Married\n6        16 Married\n# … with 528 more rows"
  },
  {
    "objectID": "contents/tidyverse.html#groups",
    "href": "contents/tidyverse.html#groups",
    "title": "Tidyverse",
    "section": "Groups",
    "text": "Groups\n분석에서는 자주 카테고리별로 데이터를 나누어 통계치를 계산하곤 하는데,\ngroup_by()와 summarise()의 두 함수를 함께 사용하여 가장 자주 사용하게 됨\n\ngroup_by()\n데이터셋을 분석을 위해 의미있는 그룹으로 나눔\n다음은 성별로 데이터셋을 나눈 것인데, 실제 데이터를 수정하는 것은 아니고, 내부적으로 grouping되어 있음.\n맨 위 줄에 보면 Groups:  sex [2]로 표시되어 grouped data frame임을 명시함\n\ncps |>\n    group_by(sex) |> \n    print()\n\n# A tibble: 534 × 11\n# Groups:   sex [2]\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n\nsummarise()\nsummarize()와 동일\ngroup별로 통계치를 구해 하나의 행으로 산출\n\n# 남녀별로 임금의 평균을 구함\ncps |>\n    group_by(sex) |>\n    summarise(\n        avg_wage = mean(wage, na.rm = TRUE),  # mean(): 평균, na.rm: NA를 remove할 것인가\n        n = n()  # n(): 개수\n    ) |>\n    print()\n\n# A tibble: 2 × 3\n  sex   avg_wage     n\n  <fct>    <dbl> <int>\n1 F         7.88   245\n2 M         9.99   289\n\n\n2개 이상의 변수들로 grouping할 수 있음\n\ncps |>\n    group_by(sex, married) |>\n    summarize(\n        ave_wage = mean(wage),\n        sd_wage = sd(wage)) |>\n    print()\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 × 4\n# Groups:   sex [2]\n  sex   married ave_wage sd_wage\n  <fct> <fct>      <dbl>   <dbl>\n1 F     Married     7.68    3.73\n2 F     Single      8.26    6.23\n3 M     Married    10.9     5.35\n4 M     Single      8.35    4.78\n\n\n이때, 결과 데이터 프레임은 sex로 grouping되어 있음.\ngrouping을 해제하려면 ungroup()이 필요함.\n그렇지 않으면, 저 결과는 sex로 grouped data frame임\n\nUseful summary functions\n자세한 사항은 R for Data Science/Data transformation\n\nMeasures of location: mean(), median()\nMeasures of spread: sd(), IQR(), mad()\nMeasures of rank: min(), max(), quantile(x, 0.25)\nMeasures of position: min_rank(), first(), nth(x, 2), last()\nMeasures of count: count(), n_distinct()"
  },
  {
    "objectID": "contents/tidyverse.html#missing",
    "href": "contents/tidyverse.html#missing",
    "title": "Tidyverse",
    "section": "Missing",
    "text": "Missing\nR에서 missing values (결측치)는 NA로 표시\nNaN (not a number)는 주로 계산 결과로 나오는데, 예들 들어 0으로 나눌 때처럼, R에서는 NA로 취급되니 크게 신경쓰지 않아도 됨. 자세한 사항은 R for Data Science/Missing values 참고\nNA는 다음과 같은 성질을 지님\nNA > 5\n#> [1] NA\n10 == NA\n#> [1] NA\nNA + 10\n#> [1] NA\nNA / 2\n#> [1] NA\nNA == NA\n#> [1] NA\n\nx <- NA\nis.na(x)\n#> [1] TRUE\nNA는 filter()는 조건문의 참거짓에 상관없이 모두 제외함 - 실제로 조건문의 결과는 TRUE, FALSE로 이루어지짐\ndf <- tibble(one = c(1, NA, 3, 4, 2, NA), two = c(2, 5, 3, NA, 10, NA), three = c(\"a\", \"a\", \"a\", \"a\", \"b\", \"b\"))\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1     1     2 a    \n# 2    NA     5 a    \n# 3     3     3 a    \n# 4     4    NA a    \n# 5     2    10 b    \n# 6    NA    NA b    \n\nfilter(df, one > 1)\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1     3     3 a    \n# 2     4    NA a    \n# 3     2    10 b\n\n# NA를 포함하고자 할 때,\nfilter(df, one > 1 | is.na(one))\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1    NA     5 a    \n# 2     3     3 a    \n# 3     4    NA a    \n# 4     2    10 b    \n# 5    NA    NA b\n\n# NA를 포함하지 않은 행들만\nfilter(df, !is.na(one))\nfilter(df, !is.na(one) & !is.na(two)) # one, two 열에 모두 NA가 없는 행들만\n\nna.omit(df) # NA가 하나라도 있는 행은 모두 제거, 보통 결측치를 조심스럽게 대체한 후 사용\n#     one   two three\n#   <dbl> <dbl> <chr>\n# 1     1     2 a    \n# 2     3     3 a    \n# 3     2    10 b \n\n# 함수 중에 NA를 직접 처리하는 경우들이 많음\nmean(df$one)\n## [1] NA\n\nmean(df$one, na.rm = TRUE) # NA removed\n## [1] 2.5\nna.rm = TRUE로 얻은 계산값에서 몇 개의 데이터로 계산되었는지 알기 위해서는\ndf |> \n    group_by(three) |> \n    summarise(\n        ave = mean(two, na.rm = TRUE), \n        n = n(), \n        n_notna = sum(!is.na(two))  # TRUE는 1로, FALSE는 0으로 계산됨\n    )\n#   three   ave     n n_notna\n#   <chr> <dbl> <int>   <int>\n# 1 a      3.33     4       3\n# 2 b     10        2       1"
  },
  {
    "objectID": "contents/tidyverse.html#summary",
    "href": "contents/tidyverse.html#summary",
    "title": "Tidyverse",
    "section": "Summary",
    "text": "Summary\n다음 dplyr 패키지의 기본 verb 함수들로 데이터를 가공하면서 필요한 통계치를 구함\n\n조건에 맞는 행들(관측치)만 필터링: filter()\n열을 재정렬: arrange()\n변수들의 선택: select()\n변수들과 함수들을 이용하여 새로운 변수를 생성: mutate()\n원하는 요약 통계치를 간추림: summarise()"
  },
  {
    "objectID": "contents/import.html",
    "href": "contents/import.html",
    "title": "Import",
    "section": "",
    "text": "자세한 데이터 import에 대해서는 링크"
  },
  {
    "objectID": "contents/import.html#text-files-csv",
    "href": "contents/import.html#text-files-csv",
    "title": "Import",
    "section": "Text files: csv",
    "text": "Text files: csv\nreadr 패키지(tidyverse에 포함)\nread_csv(), write_csv()\n\nR 기본 함수 read.csv()를 개선\n다양한 옵션은 ?read_csv, ?write_csv 참고\n\n\ncsv 파일 읽기\naltruism.csv 파일 링크\n\nlibrary(tidyverse)\n\nhelping <- read_csv(\"data/altruism.csv\")\nhelping |> print()\n\n# A tibble: 120 × 12\n      id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1   250    95    95    95     1  2004      80      NA      80      80      70\n 2    32    58    62    NA     0  2003      62      58      59      57      56\n 3   109   100    50    50    NA  2003      90      51      51      51      52\n 4   209    77    77    64     1  2004      66      72      88      82      67\n 5    94    77    50    77     1  2003     100     100     100      51      78\n 6   260   100    75   100     0  2004     100      60      70      55      70\n 7   258    77    94    86     1  2004      91      93      85      91      73\n 8   244    90    68    20     0  2004      67      66      31      67      63\n 9   180   100    79    77     0  2003      61      51      30      51      51\n10   182    75    50    64     1  2003      80      80      70      65      70\n# … with 110 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n\n\n\n\n\n\nNote\n\n\n\nread_csv()의 자주 사용되는 옵션\nread_csv(\"data/file.csv\", skip = 2) # 첫 2절 스킵\nread_csv(\"data/file.csv\", na = \".\") # 결측치가 .으로 기록된 파일\n\n\n\n\ncsv 파일 쓰기\nwrite_csv(): 단, 쓰기를 하면서 변수 타입 소멸\n\nwrite_csv(helping, file=\"data/helping_new.csv\")"
  },
  {
    "objectID": "contents/import.html#excel-spreadsheets",
    "href": "contents/import.html#excel-spreadsheets",
    "title": "Import",
    "section": "Excel spreadsheets",
    "text": "Excel spreadsheets\nreadxl package\nread_excel(), read_xlsx(), read_xls()\n\n엑셀 파일 읽기\nstduents.xlsx 파일 링크\n\nlibrary(readxl) # install.packages(\"readxl\")\n\nstud <- read_xlsx(\"data/students.xlsx\")\nstud |> print()\n\n# A tibble: 1,000 × 93\n  stu_id sch_id sstratid   sex  race ethnic bys42a bys42b bys44a bys44b bys44c\n   <dbl>  <dbl>    <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 124966   1249        1     2     4      1      3      4      2      4      4\n2 124972   1249        1     1     4      1      4      5      1      3      3\n3 175551   1755        1     2     3      0     NA      3      2      3      3\n4 180660   1806        1     1     4      1      2     NA      1      4      4\n5 180672   1806        1     2     4      1      2      3      1      4      3\n6 298885   2988        2     1     3      0      5      4      2      3      3\n# … with 994 more rows, and 82 more variables: bys44d <dbl>, bys44e <dbl>,\n#   bys44f <dbl>, bys44g <dbl>, bys44h <dbl>, bys44i <dbl>, bys44j <dbl>,\n#   bys44k <dbl>, bys44l <dbl>, bys44m <dbl>, bys48a <dbl>, bys48b <dbl>,\n#   bys79a <dbl>, byfamsiz <dbl>, famcomp <dbl>, bygrads <dbl>, byses <dbl>,\n#   byfaminc <dbl>, parocc <dbl>, bytxrstd <dbl>, bytxmstd <dbl>,\n#   bytxsstd <dbl>, bytxhstd <dbl>, bypared <dbl>, bytests <dbl>,\n#   par_inv <dbl>, f1s36a1 <dbl>, f1s36a2 <dbl>, f1s36b1 <dbl>, …\n\n\n\n\n\n\n\n\nNote\n\n\n\nSpecify sheet either by position or by name\nread_excel(\"salaries.xlsx\", sheet = 2) # The default is sheet = 1\nread_excel(\"salaries.xlsx\", sheet = \"personnel\")"
  },
  {
    "objectID": "contents/import.html#statistical-packages",
    "href": "contents/import.html#statistical-packages",
    "title": "Import",
    "section": "Statistical packages",
    "text": "Statistical packages\nSPSS의 데이터: read_sav()\nstudents-shorter.sav 파일 링크\n\nlibrary(haven) # install.packages(\"haven\")\n\nstud_spss <- read_sav(\"data/students-shorter.sav\")\nstud_spss |> print()\n\n# A tibble: 1,000 × 93\n  stu_id    sch_id    sstratid sex     race    ethnic  bys42a   bys42b   bys44a \n  <dbl+lbl> <dbl+lbl> <dbl+lb> <dbl+l> <dbl+l> <dbl+l> <dbl+lb> <dbl+lb> <dbl+l>\n1 124966    1249      1        2 [Fem… 4 [Whi… 1 [whi…  3 [2-3…  4 [3-4… 2 [Agr…\n2 124972    1249      1        1 [Mal… 4 [Whi… 1 [whi…  4 [3-4…  5 [4-5… 1 [Str…\n3 175551    1755      1        2 [Fem… 3 [Bla… 0 [blk… NA        3 [2-3… 2 [Agr…\n4 180660    1806      1        1 [Mal… 4 [Whi… 1 [whi…  2 [1-2… NA       1 [Str…\n5 180672    1806      1        2 [Fem… 4 [Whi… 1 [whi…  2 [1-2…  3 [2-3… 1 [Str…\n6 298885    2988      2        1 [Mal… 3 [Bla… 0 [blk…  5 [4-5…  4 [3-4… 2 [Agr…\n# … with 994 more rows, and 84 more variables: bys44b <dbl+lbl>,\n#   bys44c <dbl+lbl>, bys44d <dbl+lbl>, bys44e <dbl+lbl>, bys44f <dbl+lbl>,\n#   bys44g <dbl+lbl>, bys44h <dbl+lbl>, bys44i <dbl+lbl>, bys44j <dbl+lbl>,\n#   bys44k <dbl+lbl>, bys44l <dbl+lbl>, bys44m <dbl+lbl>, bys48a <dbl+lbl>,\n#   bys48b <dbl+lbl>, bys79a <dbl+lbl>, byfamsiz <dbl+lbl>, famcomp <dbl+lbl>,\n#   bygrads <dbl+lbl>, byses <dbl+lbl>, byfaminc <dbl+lbl>, parocc <dbl>,\n#   bytxrstd <dbl+lbl>, bytxmstd <dbl+lbl>, bytxsstd <dbl+lbl>, …\n\n\n\nstud_spss |>\n    select(ethnic) |>\n    print()\n\n# A tibble: 1,000 × 1\n  ethnic            \n  <dbl+lbl>         \n1 1 [white-asian]   \n2 1 [white-asian]   \n3 0 [blk,namer,hisp]\n4 1 [white-asian]   \n5 1 [white-asian]   \n6 0 [blk,namer,hisp]\n# … with 994 more rows\n\n\nLabels 제거하기\n\nlibrary(labelled) # install.packages(\"labelled\")\nstud <- stud_spss |>\n    remove_val_labels()\nstud |> print()\n\n# A tibble: 1,000 × 93\n  stu_id sch_id sstratid   sex  race ethnic bys42a bys42b bys44a bys44b bys44c\n   <dbl>  <dbl>    <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 124966   1249        1     2     4      1      3      4      2      4      4\n2 124972   1249        1     1     4      1      4      5      1      3      3\n3 175551   1755        1     2     3      0     NA      3      2      3      3\n4 180660   1806        1     1     4      1      2     NA      1      4      4\n5 180672   1806        1     2     4      1      2      3      1      4      3\n6 298885   2988        2     1     3      0      5      4      2      3      3\n# … with 994 more rows, and 82 more variables: bys44d <dbl>, bys44e <dbl>,\n#   bys44f <dbl>, bys44g <dbl>, bys44h <dbl>, bys44i <dbl>, bys44j <dbl>,\n#   bys44k <dbl>, bys44l <dbl>, bys44m <dbl>, bys48a <dbl>, bys48b <dbl>,\n#   bys79a <dbl>, byfamsiz <dbl>, famcomp <dbl>, bygrads <dbl>, byses <dbl>,\n#   byfaminc <dbl>, parocc <dbl>, bytxrstd <dbl>, bytxmstd <dbl>,\n#   bytxsstd <dbl>, bytxhstd <dbl>, bypared <dbl>, bytests <dbl>,\n#   par_inv <dbl>, f1s36a1 <dbl>, f1s36a2 <dbl>, f1s36b1 <dbl>, …"
  },
  {
    "objectID": "contents/cleaning.html",
    "href": "contents/cleaning.html",
    "title": "Cleaning",
    "section": "",
    "text": "select(), mutate(), filter(), rename() : 기본 tidyverse verbs\n\nrowSums(), rowMeans() : composite 변수들의 합 또는 평균을 구함\n\nfactor() : 카테고리 변수의 변환\n\n\nlibrary(tidyverse)\n\n# import data\nhelping <- read_csv(\"data/altruism.csv\")\nhelping |> print()\n\n# A tibble: 120 × 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# … with 114 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n\n\nrename()\n\nhelping |>\n    rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3) |>\n    print()\n\n# A tibble: 120 × 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# … with 114 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n변형 후에는 꼭 변수에 assign!\n\nhelping <-     # 원래 데이터에 overwrite\n    helping |>\n    rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3)\n\nhelping |> print()\n\n# A tibble: 120 × 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n# … with 114 more rows, and 1 more variable: emp_q26 <dbl>\n\n\n\n\n\nrowSums(row, na.rm = TRUE) 함수를 이용하는 것이 직접 덧셈보다 더 적절함\nph1, ph2, ph3 세 문항을 더하려면,\n\n# 먼저 문항을 선택/확인\nhelping |>\n  select(ph1:ph3) |> # position!\n  print()\n\n# A tibble: 120 × 3\n    ph1   ph2   ph3\n  <dbl> <dbl> <dbl>\n1    95    95    95\n2    58    62    NA\n3   100    50    50\n4    77    77    64\n5    NA    NA    NA\n6   100    75   100\n# … with 114 more rows\n\n\n\nhelping |>\n  select(ph1:ph3) |>\n  rowSums(na.rm = TRUE) |>\n  print()\n\n  [1] 285 120 200 218   0 275 257 178 256 189 215 226 209 246 159 197 205 225\n [19] 150 195  44   0   0 125 225 211 270 176 241 205   0 220  98  79 143 165\n [37]  49 294 300 292 101 285 208 230 255 150 299 188 208 205 138 267 187 300\n [55] 195 300 236  59 226 193 213 250  32 228 250 300 300 190 230 281 196 268\n [73] 240 250  39 233 211 198 199 234 300 215 240   9 261 209 281 201 270 255\n [91] 177 235 161   0 242 151 182 170   3 222 172 194 300 300 293 238 243 260\n[109] 197 294 280 195 255   1 162 278 176 262 300 164\n\n\n\nhelping[\"phone\"] <-    # \"phone\"이라는 새로운 변수에 assign!\n  helping |>\n  select(ph1:ph3) |>\n  rowSums(na.rm = TRUE)\n\nhelping |> print(width = Inf)\n\n# A tibble: 120 × 13\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone\n    <dbl> <dbl>\n1      70   285\n2      59   120\n3     100   200\n4      69   218\n5      NA     0\n6      90   275\n# … with 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\n다음과 같이 직접 더하는 것은 부적절\nhelping |>\n  mutate(phone = ph1 + ph2 + ph3) \n#      id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n#   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n# 1     1    95    95    95     1  2004      80      NA      80      80      70\n# 2     2    58    62    NA     0  2003      62      58      59      57      56\n# 3     3   100    50    50    NA  2003      90      51      51      51      52\n# 4     4    77    77    64     1  2004      66      72      88      82      67\n# 5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n# 6     6   100    75   100     0  2004     100      60      70      55      70\n#   emp_q26 phone\n#     <dbl> <dbl>\n# 1      70   285\n# 2      59    NA\n# 3     100   200\n# 4      69   218\n# 5      NA    NA\n# 6      90   275\n# # … with 114 more rows\n\n\n\n\n\nrowMeans(row, na.rm = TRUE) 함수를 이용하는 것이 적절함\n\n# 먼저, 평균을 낼 문항을 선택/확인\nhelping |>\n  select(emp_q20, emp_q22:emp_q26) |>  # \":\" operator와 \",\" 섞어써도 무방\n  print()\n\n# A tibble: 120 × 6\n  emp_q20 emp_q22 emp_q23 emp_q24 emp_q25 emp_q26\n    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1      80      NA      80      80      70      70\n2      62      58      59      57      56      59\n3      90      51      51      51      52     100\n4      66      72      88      82      67      69\n5      NA      NA      NA      NA      NA      NA\n6     100      60      70      55      70      90\n# … with 114 more rows\n\n\n\nhelping[\"persp\"] <- helping |>    # \"persp\"라는 새로운 변수에 assign!\n  select(emp_q20, emp_q22:emp_q26) |>\n  rowMeans(na.rm = TRUE)\n\nhelping |> print(width = Inf)\n\n# A tibble: 120 × 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA      NA\n6     6   100    75   100     0  2004     100      60      70      55      70\n  emp_q26 phone persp\n    <dbl> <dbl> <dbl>\n1      70   285  76  \n2      59   120  58.5\n3     100   200  65.8\n4      69   218  74  \n5      NA     0 NaN  \n6      90   275  74.2\n# … with 114 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nTidyverse에서 row-wise operation을 하려면,\nhelping |>\n    rowwise() |>\n    mutate(persp = mean(c(emp_q20, c_across(emp_q22:emp_q26)), na.rm = TRUE)) |>\n    ungroup()\n참고: column-wise operation\n\n\n\n\n\n카테고리 변수는 R의 factor 타입으로 바꾸어 분석하는 것이 유리함.\n간단한 연산은 직접 계산.\n\nhelping |>\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")),  # factor 타입의 변수로 변환\n    age = 2023 - age  # 출생년도로부터 나이 계산\n  ) |>\n  print(width = Inf)\n\n# A tibble: 120 × 14\n     id   ph1   ph2   ph3 sex      age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <fct>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95 female    19      80      NA      80      80      70\n2     2    58    62    NA male      20      62      58      59      57      56\n3     3   100    50    50 NA        20      90      51      51      51      52\n4     4    77    77    64 female    19      66      72      88      82      67\n5     5    NA    NA    NA NA        NA      NA      NA      NA      NA      NA\n6     6   100    75   100 male      19     100      60      70      55      70\n  emp_q26 phone persp\n    <dbl> <dbl> <dbl>\n1      70   285  75  \n2      59   120  58.4\n3     100   200  68.8\n4      69   218  71.2\n5      NA     0 NaN  \n6      90   275  75  \n# … with 114 more rows\n\n\n\n\n\nfilter()를 활용\n예를 들어, 5번째 행을 지우려면\n\nhelping |>\n    filter(!id == 5) |> # !는 not의 의미\n    print()\n\n# 다시 helping에 assign 해야 수정됨!\n\n# A tibble: 119 × 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     1    95    95    95     1  2004      80      NA      80      80      70\n2     2    58    62    NA     0  2003      62      58      59      57      56\n3     3   100    50    50    NA  2003      90      51      51      51      52\n4     4    77    77    64     1  2004      66      72      88      82      67\n5     6   100    75   100     0  2004     100      60      70      55      70\n6     7    77    94    86     1  2004      91      93      85      91      73\n# … with 113 more rows, and 3 more variables: emp_q26 <dbl>, phone <dbl>,\n#   persp <dbl>\n\n\n여러 행을 지우려면?\n%in% 응용\n\nhelping |>\n    filter(!id %in% c(1, 3, 5)) |> # !는 not의 의미\n    print()\n\n# A tibble: 117 × 14\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     2    58    62    NA     0  2003      62      58      59      57      56\n2     4    77    77    64     1  2004      66      72      88      82      67\n3     6   100    75   100     0  2004     100      60      70      55      70\n4     7    77    94    86     1  2004      91      93      85      91      73\n5     8    90    68    20     0  2004      67      66      31      67      63\n6     9   100    79    77     0  2003      61      51      30      51      51\n# … with 111 more rows, and 3 more variables: emp_q26 <dbl>, phone <dbl>,\n#   persp <dbl>\n\n\n\n\n\nselect() 활용\nemp_q23, emp_q25 두 열을 삭제\n\nhelping |>\n    select(-emp_q23, -emp_q25) |>\n    print()\n\n# A tibble: 120 × 12\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 emp_q24 emp_q26 phone\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n1     1    95    95    95     1  2004      80      NA      80      70   285\n2     2    58    62    NA     0  2003      62      58      57      59   120\n3     3   100    50    50    NA  2003      90      51      51     100   200\n4     4    77    77    64     1  2004      66      72      82      69   218\n5     5    NA    NA    NA    NA    NA      NA      NA      NA      NA     0\n6     6   100    75   100     0  2004     100      60      55      90   275\n# … with 114 more rows, and 1 more variable: persp <dbl>\n\n\nemp_q23부터 emp_q26 열을 삭제 (위치의 의미로)\n\nhelping |>\n    select(-(emp_q23:emp_q26)) |>  # () 꼭 필요\n    print()\n\n# A tibble: 120 × 10\n     id   ph1   ph2   ph3   sex   age emp_q20 emp_q22 phone persp\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl> <dbl> <dbl>\n1     1    95    95    95     1  2004      80      NA   285  75  \n2     2    58    62    NA     0  2003      62      58   120  58.4\n3     3   100    50    50    NA  2003      90      51   200  68.8\n4     4    77    77    64     1  2004      66      72   218  71.2\n5     5    NA    NA    NA    NA    NA      NA      NA     0 NaN  \n6     6   100    75   100     0  2004     100      60   275  75  \n# … with 114 more rows"
  },
  {
    "objectID": "contents/cleaning.html#이상치-발견",
    "href": "contents/cleaning.html#이상치-발견",
    "title": "Cleaning",
    "section": "이상치 발견",
    "text": "이상치 발견\nOutliers을 찾는 방법은 다양하고 복잡한 테크닉을 요하기도 하는데, 앞으로 점차 익히게 될 것임\n예를 들어, age에 잘못 기입한 경우가 있는데\n\nhelping <- read_csv(\"data/altruism.csv\")\n\nhelping |>\n    ggplot(aes(x = age)) +\n    geom_histogram()\n\n\n\n\nage는 출생년도를 물어봤으나 다른 답을 한 경우들이 있음\n값은 2002 ~ 2004 사이가 정상이므로 filter()를 써서 확인해 볼 수 있음\n\nhelping |>\n    filter(age < 2002 | age > 2004) |>\n    print()\n\n# A tibble: 7 × 12\n     id pho_1 pho_2 pho_3   sex   age emp_q20 emp_q22 emp_q23 emp_q24 emp_q25\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1    11    65    94    56     1   203      62      86      58      47      62\n2    21    17    10    17     1 20004       0       6       1       0       4\n3    43    90    88    30     1   507     100      78      62     100      78\n4    52   100    82    85     1   723      87      83      89     100      88\n5    59    76    86    64     0   709     100      93      67      94      79\n6   108    75   100    85     1  2005     100     100     100     100      97\n7   118    92    76    94     0  1108      55      51      51      60      53\n# … with 1 more variable: emp_q26 <dbl>"
  },
  {
    "objectID": "contents/cleaning.html#샘플-r-script",
    "href": "contents/cleaning.html#샘플-r-script",
    "title": "Cleaning",
    "section": "샘플 R script",
    "text": "샘플 R script\n\nlibrary(tidyverse)\n\n# import data\nhelping <- read_csv(\"data/altruism.csv\")\n\n# rename\nhelping <- helping |>\n  rename(ph1 = pho_1, ph2 = pho_2, ph3 = pho_3) \n\n# delete reponses\nhelping <- helping |>\n  filter(!id == 5)\n\n# scoring\nhelping[\"phone\"] <- helping |>\n  select(ph1:ph3) |>\n  rowMeans(na.rm = TRUE)\n\nhelping[\"persp\"] <- helping |> \n  select(emp_q20, emp_q22, emp_q24:emp_q26) |>\n  rowMeans(na.rm = TRUE)\n\n# factors and etc.\nhelping <- helping |>\n  mutate(\n    sex = factor(sex, levels = c(0, 1), labels = c(\"male\", \"female\")),\n    age = 2023 - age\n  )\n\n# select variables\nhelping <- helping |>\n  select(id, sex, age, phone, persp)\n\n정리된 파일로 분석 시작!\n\nhelping |> print()\n\n# A tibble: 119 × 5\n     id sex      age phone persp\n  <dbl> <fct>  <dbl> <dbl> <dbl>\n1     1 female    19  95    75  \n2     2 male      20  60    58.4\n3     3 NA        20  66.7  68.8\n4     4 female    19  72.7  71.2\n5     6 male      19  91.7  75  \n6     7 female    19  85.7  82.6\n# … with 113 more rows"
  },
  {
    "objectID": "contents/inspection.html",
    "href": "contents/inspection.html",
    "title": "Inspecting",
    "section": "",
    "text": "tibble/dataframe 살펴보기 명령어들\nhead(tibble, 20) tail(tibble, 20) view(tibble) # in tidyverse, R에서는 대문자 View()\nglimpse(tibble) slice(tibble, 5:20) # row numbers\nstr() # structure\n\n\npipe operator 이용\nex. iris2 %>% glimpse() # ctrl + enter"
  },
  {
    "objectID": "contents/setup.html",
    "href": "contents/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "R 다운로드 및 설치\n\nWindows인 경우 > Download R for Windows > base > Download R-4.2.2 for Windows\n\n다운로드 링크\n\nMac인 경우 > Download R for macOS > R-4.2.2.pkg 또는 R-4.2.2-arm64.pkg (Apple silicon)\n\n다운로드 링크 일반\n\n다운로드 링크 for Apple silicon\n\n\nRStudio 다운로드 및 설치\n\n2: Install RStudio"
  },
  {
    "objectID": "contents/setup.html#rstudio-소개",
    "href": "contents/setup.html#rstudio-소개",
    "title": "환경설정",
    "section": "RStudio 소개",
    "text": "RStudio 소개\n4개의 패널로 구성\nProject 단위로 분석\n\n시작시 project을 새로 만들거나 불러와서 실행: filename.Rproj 형태로 저장\nFile > New Project or +R 버튼 > New Directory > New Project\n\nDirectory name, Sub directory\n\n\nWorking directory\n\nproject에서 참조하는 최상위 폴더\n하위폴더 지시: 예) data/file.sav\n\nR script 생성, 저장\nRStudio 닫기, 열기\n\nWorkspace 저장 vs. R script 저장\nWorkspace save/load: .Rdata 형태로 저장\n\nSession\n\nRestart R\n\n\n환경설정: Tools > Global Options\nSave workspace to .RData on exit: working space 자동 저장\nCode\n\nsoft-wrap R source files\nUse native pipe operator\n\nAppearance\n\nZoom: 전체 보기 줌\nEdiotr font: Cascadia Mono (Win), Menlo (Mac)\nEditor font size: 글자 크기\ntheme: Tomorrow Night??"
  },
  {
    "objectID": "contents/setup.html#패키지의-설치",
    "href": "contents/setup.html#패키지의-설치",
    "title": "환경설정",
    "section": "패키지의 설치",
    "text": "패키지의 설치\n\n# 메뉴를 통한 설치\n\n# 명령어를 통한 설치\ninstall.packages(\"name\")\n\n# 수업에서 필요한 기본 패키지\ninstall.packages(\"tidyverse\") # 패키지들의 패키지\n\n## ✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n## ✔ tibble  3.1.7     ✔ dplyr   1.0.9\n## ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n## ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n# 패키지들 간의 함수의 충돌에 대해서... mask\n\n# 추가 패키지\ninstall.packages(c(\"mosaicData\", \"palmerpenguins\")) # c(): combine items\n\n# 패키지 로드: 필요한 패키지는 세션마다 시행해야 함\nlibrary(\"name\")\n    e.g. library(tidyverse)"
  },
  {
    "objectID": "contents/setup.html#단축키",
    "href": "contents/setup.html#단축키",
    "title": "환경설정",
    "section": "단축키",
    "text": "단축키\n\n자동완성: tab\n\n현재 라인 실행: Ctrl+Enter (Win)   |   Command+Return (Mac)\nassignment operator (<-) 입력: Alt+- (Win)   |   Option+- (Mac)\npipe operator (%>%) 입력: Ctrl+Shift+M (Win)   |   Shift+Command+M (Mac)\nconsol에서 화살표 키\ncopy, paste\nundo, redo: Ctrl+Z / Ctrl+Shift+Z (Win)   |   Command+Z / Command+Shift+Z (Mac)\nCopy Lines Up/Down: Shift+Alt+Up/Down (Win)   |   Option+Command+Up or Down (Mac)\n\n단축키 변경: Tools >> modify keyboard shortcuts: e.g. pipe operator: Alt+."
  },
  {
    "objectID": "contents/setup.html#도움말",
    "href": "contents/setup.html#도움말",
    "title": "환경설정",
    "section": "도움말",
    "text": "도움말\nhelp() 또는 ?\ne.g. help(factor), ?factor"
  },
  {
    "objectID": "contents/overview.html",
    "href": "contents/overview.html",
    "title": "Overview",
    "section": "",
    "text": "이번 섹션에서는 통계가 어떻게 활용되는지에 대한 전반적인 landscape을 소개하고자 하며, 이는 다양한 통계적 분석 이론들 속에서 자신이 수행하고 있는 분석의 적절성을 대략 이해하며, 어떤 부분이 부족한지를 파악할 수 있도록 도움을 주고자 함.\n여기에서 소개하는 내용을 모두 수업에서 다룬다는 것은 절대 아님!\n시작하면,\n통계가 활용되는 방식은 크게 3가지로 나누어 볼 수 있음"
  },
  {
    "objectID": "contents/overview.html#descriptive-기술적-분석",
    "href": "contents/overview.html#descriptive-기술적-분석",
    "title": "Overview",
    "section": "Descriptive: 기술적 분석",
    "text": "Descriptive: 기술적 분석\n\n\n\n통계청의 조사 결과와 같이 현상에 대한 기술 \n단순한 기술은 자칫 오해의 여지와 호도할 위험이 존재\n예를 들어,\n- 남녀 임금의 차이에 대한 통계치를 제시하는 경우\n- 외국의 경우, 인종별 범죄율에 대한 통계치 등등 \n만일, 좀 더 자세히 나눠어서, 연령별, 직업군별로 남녀 임금의 차이를 본다면 만족스러운가?\n얼마나 더 상세히 나누어야 하는가?\n그 차이는 의미있는 차이인가?"
  },
  {
    "objectID": "contents/overview.html#relational-변수들-간의-진실한-관계를-분석",
    "href": "contents/overview.html#relational-변수들-간의-진실한-관계를-분석",
    "title": "Overview",
    "section": "Relational: 변수들 간의 진실한 관계를 분석",
    "text": "Relational: 변수들 간의 진실한 관계를 분석\n\nCase 1\n미혼자에 대한 임금 차별이 있는가? 차별이 의미하는 바는 무엇인가?\n아래 첫번째 그림과 같이 기혼자의 임금이 미혼자에 보다 높은 것으로 나타났다면,\n이는 정말 결혼하지 않은 것이 임금을 책정하는데 영향을 주었는가?\n하지만, 당연하게도 기혼자는 미혼자에 비해 연령이 높으며 (두번째 그림),\n높은 연령은 연차가 높거나 실무능력이 뛰어난 경향으로 인해 임금을 높을 수 있다는 것을 감안하면 (세번째 그림)\n차별처럼 보이는 차이는 차별이라고 볼 수 없을 수도 있음.\n다시 말하면, 연령을 고려한 후에도 기혼자의 임금은 미혼자보다 높은가?\n여전히 높다면, 연령을 고려한 후 혹은 연령을 조정한 후(adjusted for age)의 차이는 얼마라고 봐야하는가?\n연령을 고려한 임금 차이를 조사하는 방법은 무엇이 있겠는가?\n\n연령별로 나누어 비교?\n\nData from the 1985 Current Population Survey\n\n\n\n\n\n연령을 고려한 마라톤 기록?\n70세 노인의 기록 2시간 30분과 20세 청년의 2시간 30분은 마라톤 실력이라는 관점에서 다르게 볼 수도 있음\n예를 들어, “나이 차이가 큰 두 사람의 기록을 비교하는 것은 공평하지 않아”라는 주장에 대해서, 70세 노인의 기록은 “나이를 감안하면 2시간 10분에 해당한다”고 답변할 수 있음\n다시 말하면, 나이와는 무관한/독립적인 마라톤 능력에 대해 말할 수 있음\n이는 동일한 나이의 사람들로만 제한해서 마라톤 기록을 비교하는 것이 공평한 능력의 비교라고 말하는 것과 것이 같은 이치임\n\nSource: https://doi.org/10.1186/2052-1847-6-31\n\n\nCase 2\n기혼여부에 따른 임금의 차이가 남녀별로 다른가?\n연령이 올라감에 따라 임금이 올라가는 패턴에 차이가 있는가?\n\n\n\n\n\n왼편 그림에서 보면, 기혼여부에 따른 임금의 차이가 남녀에 따라 다르게 나타나는 것으로 보임\n이러한 현상을 변수 간에 상호작용(interaction)이 있다고 말함 (moderate라는 표현도 있음)\n말하지면, 기혼여부가 임금에 주는 효과가 성별에 따라 바뀌고, 기혼여부와 성별이 상호작용하여 임금에 영향을 준다라고 표현할 수 있음 (2-way interaction)\n비슷하게, 오른편을 보면, 연령에 따른 임금의 증가 패턴이 남녀에 따라서, 업종에 따라 다르게 나타나는 것으로 보임\n(manag: management, manuf: manufacturing, prof: professional)\n즉, 연령이 임금에 미치는 효과는 성별과 업종에 따라 바뀌고, 연령, 성별, 업종이 상호작용하여 임금에 영향을 준다라고 표현할 수 있음 (3-way interaction)\n\n\n\n\n\n\nWarning\n\n\n\n위의 표현은 모두 효과를 가정한 표현으로 설명을 위해 편의상 그렇게 표현하였음\n또한, 다른 요소들은 단순화를 위해 생략했음. 예를 들어 왼편의 상황에서 나이를 고려하면 다른 양상을 보일 수 있음\n\n\n또 다른 예로는, 나이가 듦(age)에 따라 지구력(endurance)의 감소가 강도 높은 운동을 한 기간(년수)(exercise)에 따라 변화한다는 가설을 테스트한 자료\n\n\n\n\n\n이 경우 운동을 한 기간은 앞의 예에서처럼 카테고리 변수가 아니기 때문에 임의로 3구간으로 나누어 살펴 본 것임.\n나이가 지구력에 미치는 부정적 영향이 운동을 한 기간에 따라 변하는 것으로 보임.\n즉, 나이와 운동기간이 상호작용하여 지구력에 영향을 미친다고 표현할 수 있음\n상호작용은 아래와 같이 상호작용하는 두 변수의 위치를 바꿔 살펴볼 수도 있음\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n시각화를 통해 전반적인 패턴을 살펴보는 것은 통계적 모형을 세워 수학적으로 분석하기 전에 하는 보조 수단임.\n앞에 마라톤 기록의 예처럼 실제 분석은 한 변수를 고려한 후 다른 변수의 변화를 계산하는 방식으로 분석을 하는 것이지, 나이별로 자료를 나누어 보지 않듯이, 운동기간을 위에서처럼 구간으로 쪼개어 분석하는 것은 아님.\n\n\n\n\nCase 3\n임금이 증가하면 삶의 만족도가 높아지는가? 아마도?\n\n\n\n\n\n\n하지만, 특정 A의 임금이 p 에서 q 로 증가할 때, 트렌드대로 움직이겠는가?\n혹은, 특정 B의 임금이 r 에서 s 로 감소할 때, 트렌드대로 움직이겠는가?\n개인의 변화를 살펴보는 종단연구(logitudinal)로 그 갭을 채울 수 있음\n\n\n\n\n\n\nNote\n\n\n\nLongitudinal (종단) vs. cross-sectional (횡단)\n종단 데이터는 관측의 단위, 예를 들어 개인을 반복측정하여 개개인의 특성을 함께 파악할 수 있는 장점을 가짐. 시간과 비용이 많이 들고, attrition (참여자 탈락) 비율이 높아질 우려가 있어 분석에 걸림돌이 되곤 함. 특히, 노인에 대한 연구는 사망으로 인해 참여자가 주는데, 이런 결측치를 고려한 분석에는 상당한 조심성과 기술이 요함. (missing data analysis)\n분석의 관점에서 보면, 개인을 반복 측정하기 때문에 측정값들 사이의 dependency 문제가 생기는데 이를 분석에 고려하려는 노력임. 참여자 각각의 고유한 특성과 연구자가 측정하고자 하는 특성을 분리하고자 함. 위의 예에서 보면, “임금이 삶의 만족도에 주는 영향”과 “개개인의 고유한 특성이 삶의 만족도에 주는 영향”을 분리시켜야 전자의 효과를 분명히 파악할 수 있음. 이는 이후 언급할 multi-level analysis로도 볼 수 있음.\n반면, 주로 접하게 되는 횡단 데이터는 모든 관측치가 independent, 즉 서로 영향을 받지 않는다고 가정할 수 있는데, 물론 한 가족의 구성원이 참여하는 연구는 그 가정에 위배됨.\n횡단데이터의 문제는 소위 cohort bias가 숨어 있을 수 있음. 예를 들어 다른 나이대의 사람들은 다른 사회적 경험을 통해 다른 특성을 지녔을 수 있으므로, 데이터의 관측치들이 homogenous (동질적) 하지 못함으로 인해 연구자가 보려는 관계에 노이즈를 만들 수 있음.\n\n\n하지만, 그럴지라도 임금으로 “인해” 삶의 만족도가 올라가느냐는 다른 문제임 >> 인과관계의 문제\n\n예를 들어, 연봉의 증가가 삶의 만족도를 올렸다기 보다는 상대적 비교에서 오는 자존감이 증가했기 때문일 수 있음\n연봉이 높은 곳은 직업 특성이 다를 수 있음\n또는, 인맥과 인간관계의 변화에서 오는 차이일 수도 있음\n\n다른 시각에서 보면,\n현재 A의 연봉 2천만원을 갑자기 4천만으로 올리면 삶의 만족도가 트렌드대로 0.8pt 올라가겠는가?\n\n연봉의 증가는 주변의 시기와 질투를 가져와 인관관계에 영향을 줄 수 있음\n\n본인의 자만은 여러 부정적 결과를 초래할 수 있음\n\n\nPrediction vs. intervention\n\nA의 임금이 올라가면 삶의 만족도가 따라서 올라갈 것이라고 (조심스럽게) 예측할 수는 있으나: association\n\n좀 더 정확히 말하면, 임금이 높은 것은 삶의 만족도가 높은 것과 연관이 있다라고 표현\n“올라가면”이라는 표현은 시간 개념을 포함한 것이라 횡단(cross-sectional) 데이터에서는 부적절\n\nA의 임금을 올리면 삶의 만족도가 올라갈 것이라고 단정할 수 없음: causal\nIntervention이 효과가 있으려면, 적어도 진정한 관계를 파악해야만 하며, 더 나아가 인과관계가 만족해야 함.\n진정한 관계의 문제와 인과의 문제는 서로 엮여 있으며 복잡한 문제임.\n\n예를 들어, 오렌지를 섭취하면 괴혈병이 예방되나 사실은 비타민 C의 섭취가 괴혈병을 예방하는 것임\n만약, 장거리 항해에서 상급자(높은 연령)에게만 과일이 제공되었을 때, 나이가 많은 선원들에게서 괴혈병이 덜 생겼다는 현상으로부터 연령과 괴혈병의 관계를 추론해서는 안됨. 하지만 예측은 여전히 유효함.\n\n\n또는, 신앙심이 깊은 노인들의 수명이 더 길다는 현상이 관찰되었을 때, 신앙심 자체가 심리적으로나 신체적으로 긍정적인 효과를 가질 수 있으나, 그 외에도 신앙 활동의 일부로 활동이 늘고 다른 이와의 긍정적 교류가 건강에 영향을 미쳤을 수도 있음.\n\n이 때, 신앙심과 수명과는 진정한 관계가 있다고 볼 수 있으나 (not spurious) 그 인과 관계에 대해서도 좀 더 깊은 논의가 필요함.\n다시 말하면, 어떤 노인에게 신앙을 권유했을 때, 수명이 연장되었을지라도 신앙심이 수명을 연장시킨 것인가는 별개의 논의임.\n\n\n\n\nThe strength of relationships\n변수들간의 관계와 그 관계의 크기(stength)는 중요하게 구별될 필요가 있음\n아래 두 그림은 변수 간의 관계는 동일하나 그 크기에 차이가 있음\n오른쪽 그림에서 연봉으로 그 사람의 삶의 만족도 지수를 더 정확히 예측할 수 있으며, 이를 설명력 \\((R^2)\\)이 높다고 표현\n보통 이 효과의 크기가 클수록 인과관계일 가능성은 높다고 볼 수 있으며,\n왼쪽 박스에서처럼 variability가 높다는 것은 다른 이유가 있을 가능성이 높음\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n진정한 관계를 탐구하는 것이 어려움에도 불구하고, 관계성을 파악함으로써 통찰을 얻을 수 있음.\n\n\n\n\n복잡한 변수와의 관계를 풀어내려고 노력\nSource: Multiple Regression and Beyond by Timothy Z. Keith"
  },
  {
    "objectID": "contents/overview.html#causal-인과관계의-분석",
    "href": "contents/overview.html#causal-인과관계의-분석",
    "title": "Overview",
    "section": "Causal: 인과관계의 분석",
    "text": "Causal: 인과관계의 분석\n위에서 살펴본 것들은 모두 연구자가 개입하지 않고 관찰만으로 이루어진 분석들임\n논의한 것처럼 관찰된 자료로부터 진실된 관계를 파악하는 것은 매우 정교한 분석이 요구되고 많은 요소들을 고려해야 함.\n좀 더 분명한 관계를 파악하기 위해 실험 연구가 요구되곤 함\n하지만, 많은 경우 실험이 불가능할 뿐 아니라,\n실험이 반드시 최선인 것은 아니며, 실험은 나름데로 큰 약점을 갖고 있음.\n\n\n\n\n\n\nConfounding\n\n\n\n일반적으로, 표면적으로 드러난 변수간의 관계가 숨겨진 다른 변수(lurking third variable)에 의해 매개되어 있어 진실한 관계가 아닌 경우, confounding 혹은 confounder가 존재한다고 함.\n사회과학에서 오래된 가장 핵심적인 문제이나 최근까지도 정확히 정의하기 어려움 개념이었음.\nCausal analysis라는 통계와는 별개의 개념으로 발전되어 최근에야 이론적으로 완성이 되어 관심이 높아짐.\n극단적이지만 이해하지 쉬운 예로는\n\n초등학생 발 사이즈 → 독해력\n\n머리 길이 → 우울증\n\n\n\n\n\n\n\n\n\nAnswer!\n\n\n\n\n\n\n\n\n\n맨 처음 든 예도 마찬가지로   \n올바른 관계를 파악하려면, 동일한 나이에 대해 그 관계를 파악한 후 각 나이에서의 효과를 (weighted) 평균해서 살펴봐야함\n통계에서는 이를 나이를 통제 (control for age)한다고 표현하며, 같은 의미로 다음과 같은 표현을 씀\n나이를 고려했을 때; account for age\n나이를 조정했을 때; adjust for age\n나이를 잔차화했을 때; residualize age\n나이의 변량을 넘어서서; above and beyond age\nSimpson’s paradox\n아래 첫번째 그림은 집단 전체에 대한 플랏이고, 두번째 그림은 나이대별로 나누어 본 플랏\n전체 집단을 보면 운동을 많이 할수록 콜레스테롤이 증가하는 것으로 보이나,\n나이대별로 보면, 상식적으로 운동이 긍정적 효과가 나타남.\n왜 그렇게 나타나는가?\n\nSource: The book of why by Judea Pearl\n관찰 데이터로부터 진정한 관계를 파악하기 위해서는 이와 같은 통계적인 통제를 통해 혹은 인과분석이라는 좀 더 큰 프레임에서 분석해야 하며, 깊은 논의가 필요함\n마지막 예를 들면,\n은퇴한 노인들을 대상으로 규칙적인 걷기가 사망율을 감소시킬 것이라는 가설을 확인하기 위해 1965년 이후 8000명 가량의 남성들을 추적조사한 데이터의 일부를 이용했는데,\nSource: The book of why by Judea Pearl\n\n12년 후 사망율에서 casual walker(하루 1마일 이하)와 intense walker(하루 2마일 이상)가 각각 43%, 21.5%로 나타났음.\n이 걷기의 효과를 의심케 하는 요소들(confounding)은 무엇인가?\n\n\n\n\n\n\n\nAnswers!\n\n\n\n\n\n\n건강이 나빠 많이 걷지 못했을 수도…\n많이 걷는 사람은 상대적으로 젊을 수도…\n많이 먹는 사람이 덜 걸을 수도…\n술을 많이 먹는 사람이 덜 걸을 수도…\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n무수히 많이 생각해볼 수 있는 confounding 요소들을 다 고려해야 하는가?\nYes and No!\n실제 저자들도 다음과 같이 기술\n“Of course, the effects on longevity of intentional efforts to increase the distance walked per day by physically capable older men cannot be addressed in our study.”\n이러한 조심성은 의미있느나 너무 과장될 필요는 없음\n소위 중요 역할을 할 것으로 의심되는 confounding을 충분히 통계적으로 고려/통제했다면, 충분히 인과관계 혹은 intervention을 제안할 수 있으며,\n그러한 연구는 어떤 요소들을 고려했는지에 대해 밝힘으로써 추후 연구에서 어떤 부분이 더 추가적으로 고려되야 할지 알 수 있게 함.\n\n\n앞서 살펴본 관찰 연구들이 모두 confounding의 위험을 안고 있기에 결정적인 인과관계를 파악하기 위해, 전통적으로 “통계학”의 시각에서 인과문제에 대해서는 보통 임상테스트에서 실시하는 RCT (randomized controlled trial)라고 부르는 소위 gold standard한 실험 연구를 통해서 해결하고자 했음\n개념적으로는 물리적 통제라고 볼 수 있으며, 두 그룹으로 집단을 randomly assign(무선/무작위 배정/할당)하면 모든 면에서 동질한 성향을 가짐. 예를 들어, 두 집단의 연령이 평균적으로 동일해짐.\n\n\nSource: The whats and whys of RCTs\n앞서 든 예에서, 걷기가 사망율에 미치는 효과를 검증하려면, 가령 600명을 300명씩 두 그룹으로 무작위로 나눈 후 한쪽은 1마일 이하를 걷도록 하고 나머지는 2마일 이상을 걷게 한 후 12년 후 사망율을 확인해야 함.\n분야마다 효과를 제대로 검증하기 위한 많은 실험 설계들이 발전되었음 >> 연구방법론\n그럼에도 불구하고, 실험 연구는 자체로 한계를 지님\n\n많은 경우 실험이 불가능하며\n실험에서 처치한 구체적인 상황에서만 유효하고\n그 효과는 어떻게 표현할 것인가?\n\n\nCase 1\nTerror Management Theory (TMT)\nSelf-esteem의 이론적 근거를 밝히고자 함. 왜 인간은 self-esteem을 유지하려는가?\n\nTreatment: 자신의 죽음과 고통에 대해 생각해보고 써보도록 하고\nControl: 자신의 치통에 대한 질문에 답\n측정: 고정관념에 대해 부정적으로 말하는 사람을 어떻게 평가하는가?\n결과: 그들을 더 부정적으로 평가: defences their own culural worldview\n(e.g. Stereotypes and Terror Management: Evidence That Mortality Salience Enhances Stereotypic Thinking and Preferences)\n\n죽음이나 치통에 대한 생각은 모두 두려움을 포함해 부정적 감정을 불러 일으키는데\n그저 두려움에 대한 반응인가? 아니면 정확히 “죽음에 대한 생각”이 효과를 만든 것인가?\n참여자들의 부정적 정서를 실험 마지막에 측정한 후 분석에 고려했음\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n연구 설계시 관심이 있는 효과를 효과적으로 측정하는 것과 동등하게 중요한 것은 어떤 confounding들이 존재할 수 있는지를 다각도로 검토한 후 이를 설계에 반영하는 것임.\n예를 들어, 위의 경우 죽음에 대한 생각 자체의 효과가 아닌 죽음을 생각했을때 발생할 수 있는 부수적인 감정들로 인해 효과가 난 것이 아닌가하는 것들을 고려해서 설계할 수 있음.\n\n\n\n\nCase 2\n마시멜로우 실험, 1960’s\n\nSource: Want To Teach Your Kids Self-Control?\n3-5세 아이들에게 마시멜로우 1개를 놓고 원하면 먹도록 하나, 만약, 5분을 안먹고 기다리면 2개를 먹을 수 있다고 말한 후, 기다리지 못하고 먹는지를 살펴봄\n소위 delay gratification을 self-control을 발휘한 것으로 이해했으며, 먹지 않고 기다린 아이들이 추후에 학업성취도 및 여러면에서 뛰어난 결과를 보고 하였음.\n\n아이들이 참고 기다린 것은 자력에 의한 자기통제력인가?\n어른들 즉, 권위에 대한 복종인가?\n더 많이 먹기 위한 욕심인가?\n눈 앞에 이익을 빨리 취하는 것은 좋은 전략일 수 있지 않은가?\n\n혹시 실험을 진행하는 실험자에 따라 다른 효과가 나타날까? (Experimenter effects)\n처치(treatment)의 효과인가 처지가 일어나는 상황이 만든 효과인가?\n\n\n\n\n\n\nImportant\n\n\n\n이 연구에서도 여러 confounding들을 생각해볼 수 있음\n위에서 언급한 것들 외에 어떤 것들이 있을까?\n\n\n적어도 마시멜로우 실험의 경우에서 아이들에게 기다리라고 지시한 experimenter들의 정보를 고려할 필요가 있음.\n그럼, 각 experimenter별로 자료를 분석해야 하는가?\n좀 더 확장하면,\n\n같은 처방을 내린 의사들에 따라 다른 효과가 나타날까?\n\n의사가 속한 병원마다 다른 효과가 나타날까?\n\n특정 수업방식의 효과가 학교마다 선생님마다 다르게 나타날까?\n\n\n\n\n\n\n\nNote\n\n\n\nMulti-level analysis (mixed effect model)\n이는 위에서 언급한 longitudinal (종단) 데이터가 지닌 관측치의 dependency를 고려하는 일반적인 접근임. 관측치들이 군집을 이루면서 군집끼리 비슷한 경향을 보인다면, 이를 고려한 분석이 요구됨. 보통 dependency는 데이터를 어떻게 수집했는지를 알아야 파악할 수 있으며, 데이터 내에서 찾아내기 어려움. (clustering analysis 같은 machine learning 분야에서 개발되는 알고리즘적 분석들이 있음)\n만약, 군집을 이루는 단위가 충분히 많다면,\n예를 들어, 10개의 병원에서 30명의 의사가 각각 50명의 환자에게 새롭게 개발된 처방을 처치하여 그 효과를 볼 때,\n\n병원의 효과 vs. 의사의 효과 vs. 처치의 효과를 분리하여 좀 더 분명한 효과를 찾을 수 있음\n\n또는, 30개의 학교에서 50명의 선생님들이 30명의 학생들에게 특정 수업방식의 효과를 검증할 때,\n\n학교의 효과 vs. 선생님의 효과 vs. 수업의 효과를 분리해 볼 수 있음\n\n분석을 위해 각 선생님 마다 혹은 학교마다 따로 분석하는 것도 아니며, 학교별 혹은 선생님별 특성을 측정하여 고려한다든가 하는 방식이 아님. 자료가 품고 있는 관측치들의 유사성이 통계적으로 파악되어 고려되는 것으로, 모든 샘플을 동시에 이용한 고급 통계 방법\n사회과학 자료에서도 만일 가족단위로 데이터 수집이 이루어진다면, 가족 간의 무언가 톡특한 특성이 연구결과에 반영될 수 밖에 없는데, 가족의 특성을 분리해야 연구자가 살펴보는 관심 변수들 간의 관계를 올바로 파악할 수 있음. 다시 지적하면, 연구에서 가족의 특성을 직접 측정해서 고려한다는 의미가 아니고, 자료가 품고 있는 가족간의 유사성이 통계적으로 파악되어 고려되는 것임."
  },
  {
    "objectID": "contents/overview.html#uncertainty",
    "href": "contents/overview.html#uncertainty",
    "title": "Overview",
    "section": "Uncertainty",
    "text": "Uncertainty\n관찰자가 관찰한 대상으로부터 얻은 결과를 관찰하지 않은 더 넓은 대상으로 일반화할 수 있는가?\n가령, 다음과 같이 150명에 대해 조사한 “연령이 임금에 미치는 효과”를 일반화 할 수 있는가?\n한 나라의 국민 전체?\n\n\n\n\n\nStatistical inference (통계적 추론)\n통계학의 추론(statistical inference)은 작은 샘플(sample)로부터 얻은 분석 결과를 바탕으로 모집단(population)이라고 부르는 전체에 대해 말하고자 하는 시도에서 비롯되었음\n\n어떤 비료가 특정 콩 A의 재배에 어떤 영향을 미치는지 알기 위해 하나의 sample (N=10000: sampe size) 위에서 실험이 이루어지고, 그 결과가 A라는 콩의 종 전체에 얼마나 적용될 수 있을지를 알아보고자 했음\n\n사람에게도 적용될 수 있는가?\n\n사실상 난해한 통계 이론의 상당부분을 차지함.\n하지만, 통계적 추론의 논리는 개념적으로는 다음과 같이 볼 수 있음.\n앞서 논의한 모든 내용은 “특정 샘플” 내에서 변수들 간의 관계에 대한 분석일 뿐 그 샘플을 벗어나서 논의한 것이 아님. 통계적 추론은 수많은 같은 수의 샘플들, 가령 N = 150인 즉, 150명으로 이루어진 샘플들을 반복적으로 관찰한다면 그 샘플들 간의 편차들이 어떠하겠는가에 대한 논의임.\n\n첫번째 그림에서처럼 (알수는 없지만) 어떤 population을 가정하는데, 그 모집단에는 age와 wage의 true relationship이 선형적으로 존재한다고 가정함. 연구자가 한번에 150명으로 이루어진 sample을 반복적으로 관찰한다면, 샘플마다 age와 wage의 관계는 다르게 나타날 것임 (두번째 그림).\n예를 들어, 그 기울기에 관심이 있다면, 샘플들로부터 나타나는 기울기들의 분포를 살펴봄으로써 (세번째 그림) 샘플에서 나타날 수 있는 기울기값이 어떠한가를 파악할 수 있음.\n\n이 분포를 sampling distribution이라고 부름\n이 분포에 따르면 평균이 0.066이고, 기울기 값들의 95%가 0.005 ~ 0.140 범위에 있음을 알 수 있음.\n다시말하면, 연구자가 관찰한 샘플로부터 연구자는 (age와 wage의 선형성을 가정한다면), 매우 큰 확신을 갖고 나이가 10세 늘때마다 시간당 임금의 증가율은 0.05에서 1.4달러 사이에 있을 것이라고 말할 수 있음.\n확신이 커지려면 임금증가율의 범위가 넓어져야 함. 예를 들어, 99%의 확신을 갖고 나이가 10세 늘때 시간당 임금의 증가율은 -0.18에서 1.67달러 사이에 있을 것이라고 말할 수 있음. 별로 의미없는 발언이 될 수 있음.\n반대로, 확신에 대해서는 양보하는 대신 임금증가율에 대한 범위폭을 줄일 수 있음. 예를 들어 90%의 조금 낮은 확신을 갖고 임금증가율은 0.14에서 1.3달러 사이에 있을 것이라고 말할 수 있음\n\n\n\n\n\nSource: The Truthful Art by Albert Cairo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap bca confidence intervals\n\n            Estimate 2.5 % 97.5 %\n(Intercept)    6.563 3.926  8.908\nage            0.066 0.005  0.140\n\n\n\n\n\n\n\n\nNote\n\n\n\n위와 같이 어떤 분포를 가정하고 파라미터(기울기 등등)를 포함해 상정한 모델에 대한 통계적 추정과 추론을 하는데 대한 비판이 오래전부터 있어왔음. 현실의 실제적 현상에 적용할 때는 이론적인 통계의 원리와는 별개의 더 깊은 논의가 필요함.\ne.g:\nBreiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. Basic books."
  },
  {
    "objectID": "contents/overview.html#regression-analysis",
    "href": "contents/overview.html#regression-analysis",
    "title": "Overview",
    "section": "Regression analysis",
    "text": "Regression analysis\n앞서 다뤘던 임금과 연령의 관계에 대한 간단한 회귀 분석의 예들 \n\n선형 관계를 가정한 임금과 연령의 관계에 대한 회귀분석 (N=150)\n\n\n\n\n\n\nModel: lm(wage ~ age, data = cps)\n\n\n\nMODEL INFO:\nObservations: 150\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(1,148) = 8.755, p = 0.004\nR<U+00B2> = 0.056\nAdj. R<U+00B2> = 0.049 \nStandard errors: OLS\n----------------------------------------------------------\n                     Est.    2.5%   97.5%   t val.       p\n----------------- ------- ------- ------- -------- -------\n(Intercept)         5.375   2.970   7.780    4.417   0.000\nage                 0.092   0.031   0.154    2.959   0.004\n----------------------------------------------------------\n\n\n\n\n\n맨 처음 든 예, 즉 연령을 고려한/통제한 “기혼여부에 따른 임금차이”를 회귀분석하면 (N=465)\n\n\n\n\n\n\n우선, 결혼여부에 따른 평균 임금의 차이는 미혼일 때 -0.97 (dollars/hr) 낮음.\n하지만, 모집단에서 그 차이는 (95% 확률로) -1.93에서 -0.02 사이에 있을 것이라고 추정할 수 있음\nModel: lm(wage ~ married, data = cps)\n\n\n\nMODEL INFO:\nObservations: 533\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(1,531) = 8.34, p = 0.00\nR<U+00B2> = 0.02\nAdj. R<U+00B2> = 0.01 \nStandard errors: OLS\n-----------------------------------------------------------\n                       Est.    2.5%   97.5%   t val.      p\n------------------- ------- ------- ------- -------- ------\n(Intercept)            9.40    8.89    9.91    36.07   0.00\nmarriedSingle         -1.28   -2.16   -0.41    -2.89   0.00\n-----------------------------------------------------------\n\n\n\n\n\n\n앞서 논의한데로 나이가 confounding이 될 수 있고,\n이를 통계적으로 통제하면,\n\n\n\n\n\n\nModel: lm(wage ~ married + sex + age + I(age^2), data = cps)\n\n\n\nMODEL INFO:\nObservations: 533\nDependent Variable: wage\nType: OLS linear regression \nMODEL FIT:\nF(4,528) = 23.70, p = 0.00\nR<U+00B2> = 0.15\nAdj. R<U+00B2> = 0.15 \nStandard errors: OLS\n------------------------------------------------------------\n                       Est.     2.5%   97.5%   t val.      p\n------------------- ------- -------- ------- -------- ------\n(Intercept)           -6.43   -10.87   -2.00    -2.85   0.00\nmarriedSingle         -0.17    -1.04    0.70    -0.38   0.70\nsexM                   2.44     1.67    3.22     6.18   0.00\nage                    0.68     0.46    0.91     5.95   0.00\nI(age^2)              -0.01    -0.01   -0.00    -5.26   0.00\n------------------------------------------------------------\n\n\n\n“나이를 고려했을 때”, 미혼이 기혼보다 그 임금이 0.17 (dollars/hr) 낮은데,\n모집단에서 그 차이는 -1.04 ~ 0.70 사이에 있을 확률이 매우 높은 것으로 추론됨. (95% 확률로)\n이는 사실상 임금 차이가 있다고 볼 확신을 거의 갖기 어려움\n결혼여부와 성별이 상호작용하는 것을 고려하고, 임금의 분포를 고려해서 log 변환하면,\nModel2: lm(log_wage ~ married * sex + age + I(age^2), data = cps)\n\n\n\nMODEL INFO:\nObservations: 530\nDependent Variable: log_wage\nType: OLS linear regression \nMODEL FIT:\nF(5,524) = 25.06, p = 0.00\nR<U+00B2> = 0.19\nAdj. R<U+00B2> = 0.19 \nStandard errors: OLS\n----------------------------------------------------------------\n                            Est.    2.5%   97.5%   t val.      p\n------------------------ ------- ------- ------- -------- ------\n(Intercept)                 0.23   -0.23    0.68     0.98   0.33\nmarriedSingle               0.07   -0.05    0.20     1.17   0.24\nsexM                        0.34    0.24    0.43     6.82   0.00\nage                         0.08    0.06    0.11     7.06   0.00\nI(age^2)                   -0.00   -0.00   -0.00    -6.45   0.00\nmarriedSingle:sexM         -0.21   -0.38   -0.05    -2.51   0.01\n----------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n나이와 임금의 관계가 위의 플랏에서 나타났듯이 35세부터 일정하게 유지되는 패턴을 보이므로 그 비선형성을 단순화하여 2차 함수 꼴\\((y=c+b\\cdot age+a\\cdot age^2)\\)로 모델링을 하였으나 원칙적으로는 다른 모형이 필요함"
  },
  {
    "objectID": "contents/copilot.html",
    "href": "contents/copilot.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "acad0 <- read_csv(\"data/c0301dt.csv\")\n\n\nacad0\n\n\n\nA spec_tbl_df: 15 × 3\n\n    timepubssalary\n    <dbl><dbl><dbl>\n\n\n    31851876\n    6 354511\n    3 253425\n    81761863\n    ⋮⋮⋮\n     62147047\n     71039115\n    112759677\n    183761458\n\n\n\n\n\n# create a linear model with time as the predictor time, and the outcome being the salary\n# the model is called mod1\nmod1 <- lm(salary ~ time, data = acad0)\n\n# print the model\nmod1\n\n# print the model summary\nsummary(mod1)\n\n\nCall:\nlm(formula = salary ~ time, data = acad0)\n\nCoefficients:\n(Intercept)         time  \n      43659         1224  \n\n\n\nCall:\nlm(formula = salary ~ time, data = acad0)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13114.3  -3964.4     51.4   4025.1   8409.3 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  43658.6     2978.0  14.660 1.83e-09 ***\ntime          1224.4      336.5   3.639    0.003 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5763 on 13 degrees of freedom\nMultiple R-squared:  0.5046,    Adjusted R-squared:  0.4665 \nF-statistic: 13.24 on 1 and 13 DF,  p-value: 0.003\n\n\n\n# r squared of mod1 and round to 2 decimal places\nround(summary(mod1)$r.squared, 2)\n\n0.5\n\n\n\n# correlation between all variables in acad0 with corr.test\n# corr.test is a function from the psych package\nlibrary(psych)\ncorr.test(acad0)\n\nCall:corr.test(x = acad0)\nCorrelation matrix \n       time pubs salary\ntime   1.00 0.66   0.71\npubs   0.66 1.00   0.59\nsalary 0.71 0.59   1.00\nSample Size \n[1] 15\nProbability values (Entries above the diagonal are adjusted for multiple tests.) \n       time pubs salary\ntime   0.00 0.02   0.01\npubs   0.01 0.00   0.02\nsalary 0.00 0.02   0.00\n\n To see confidence intervals of the correlations, print with the short=FALSE option\n\n\n\n# buile a linear model with time an pubs as the predictor and salary as the outcome with interaction terms between time and pubs\nmod2 <- lm(salary ~ time + pubs + time:pubs, data = acad0)\n\n# visualize the interaction between time and pubs\nggplot(acad0, aes(x = time, y = pubs, fill = salary)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  labs(x = \"Time\", y = \"Pubs\", fill = \"Salary\") +\n  theme_minimal()\n\n# visualize the interaction between time and pubs with a package visreg\nlibrary(visreg)\nvisreg(mod2, \"time\", \"pubs\")\n\n# visualize the interaction between time and pubs with a package car using effects function\nlibrary(car)\neffects(mod2, \"time\", \"pubs\")\n\n\n\n\nERROR: Error in if (set.sign) {: argument is not interpretable as logical\n\n\n\n\n\n\n# regression diagnostics for mod2\nlibrary(car)\n\n# plot the residuals against the fitted values\nplot(mod2)\n\n# plot the residuals against the fitted values with a package car\nlibrary(car)\nresidualPlots(mod2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n           Test stat Pr(>|Test stat|)\ntime         -0.9563           0.3615\npubs          0.6334           0.5407\nTukey test   -1.1784           0.2386\n\n\n\n\n\n\nhelping <- read_csv(\"data/altruism.csv\")\n\n\n# summary of helping\nsummary(helping)\n\n       id             pho_1            pho_2            pho_3       \n Min.   :  1.00   Min.   :  0.00   Min.   :  0.00   Min.   :  0.00  \n 1st Qu.: 30.75   1st Qu.: 60.50   1st Qu.: 62.50   1st Qu.: 50.00  \n Median : 60.50   Median : 76.00   Median : 77.00   Median : 66.50  \n Mean   : 60.50   Mean   : 70.89   Mean   : 70.25   Mean   : 61.58  \n 3rd Qu.: 90.25   3rd Qu.: 94.50   3rd Qu.: 91.50   3rd Qu.: 84.25  \n Max.   :120.00   Max.   :100.00   Max.   :100.00   Max.   :100.00  \n                  NA's   :1        NA's   :1        NA's   :2       \n      sex             age           emp_q20          emp_q22      \n Min.   :0.000   Min.   :  203   Min.   :  0.00   Min.   :  6.00  \n 1st Qu.:0.000   1st Qu.: 2003   1st Qu.: 62.50   1st Qu.: 65.25  \n Median :1.000   Median : 2003   Median : 80.00   Median : 80.00  \n Mean   :0.678   Mean   : 2100   Mean   : 78.24   Mean   : 78.27  \n 3rd Qu.:1.000   3rd Qu.: 2004   3rd Qu.: 91.50   3rd Qu.: 93.00  \n Max.   :1.000   Max.   :20004   Max.   :100.00   Max.   :100.00  \n NA's   :2       NA's   :3       NA's   :1        NA's   :2       \n    emp_q23          emp_q24          emp_q25          emp_q26     \n Min.   :  0.00   Min.   :  0.00   Min.   :  4.00   Min.   :  2.0  \n 1st Qu.: 56.50   1st Qu.: 60.00   1st Qu.: 64.50   1st Qu.: 59.5  \n Median : 70.00   Median : 71.00   Median : 74.00   Median : 75.0  \n Mean   : 67.49   Mean   : 73.98   Mean   : 74.46   Mean   : 73.5  \n 3rd Qu.: 85.00   3rd Qu.: 90.50   3rd Qu.: 88.00   3rd Qu.: 91.0  \n Max.   :100.00   Max.   :100.00   Max.   :100.00   Max.   :100.0  \n NA's   :1        NA's   :1        NA's   :1        NA's   :1      \n\n\n\n# rename the column pho_1 to pho1, pho_2 to pho2, pho_3 to pho3\nhelping <- helping %>% rename(pho1 = pho_1, pho2 = pho_2, pho3 = pho_3)\n\n# add a column pho to helping that is the average of pho1, pho2, and pho3 with na.rm = TRUE\nhelping <- helping %>% mutate(pho = mean(c(pho1, pho2, pho3), na.rm = TRUE))\n\n\nhelping[\"pho_mean2\"] <- rowMeans(helping[, c(\"pho1\", \"pho2\", \"pho3\")], na.rm = TRUE)\nhelping\n\n\n\nA tibble: 120 × 14\n\n    idpho1pho2pho3sexageemp_q20emp_q22emp_q23emp_q24emp_q25emp_q26phopho_mean2\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    1 959595 1200480NA808070 7067.5898995.00000\n    2 5862NA 020036258595756 5967.5898960.00000\n    31005050NA2003905151515210067.5898966.66667\n    4 777764 120046672888267 6967.5898972.66667\n    ⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮\n    117 50 50 760200352100 026 484567.58989 58.66667\n    118 92 76 940110855 515160 536467.58989 87.33333\n    1191001001000200468 755572 756367.58989100.00000\n    120 60 78 260200486 50 5501009067.58989 54.66667\n\n\n\n\n\nhelping[\"pho_mean3\"] <-    # \"phone\"이라는 새로운 변수에 assign!\n  helping |>\n  select(pho1:pho3) |>\n  rowMeans(na.rm = TRUE)\n\n\nhelping\n\n\n\nA tibble: 120 × 15\n\n    idpho1pho2pho3sexageemp_q20emp_q22emp_q23emp_q24emp_q25emp_q26phopho_mean2pho_mean3\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    1 959595 1200480NA808070 7067.5898995.0000095.00000\n    2 5862NA 020036258595756 5967.5898960.0000060.00000\n    31005050NA2003905151515210067.5898966.6666766.66667\n    4 777764 120046672888267 6967.5898972.6666772.66667\n    ⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮⋮\n    117 50 50 760200352100 026 484567.58989 58.66667 58.66667\n    118 92 76 940110855 515160 536467.58989 87.33333 87.33333\n    1191001001000200468 755572 756367.58989100.00000100.00000\n    120 60 78 260200486 50 5501009067.58989 54.66667 54.66667\n\n\n\n\n\n# load a dataset penguins from the palmerpenguins package\nlibrary(palmerpenguins)\n\n# print the first 6 rows of penguins\nhead(penguins)\n\n\n\nA tibble: 6 × 8\n\n    speciesislandbill_length_mmbill_depth_mmflipper_length_mmbody_mass_gsexyear\n    <fct><fct><dbl><dbl><int><int><fct><int>\n\n\n    AdelieTorgersen39.118.71813750male  2007\n    AdelieTorgersen39.517.41863800female2007\n    AdelieTorgersen40.318.01953250female2007\n    AdelieTorgersen  NA  NA NA  NANA    2007\n    AdelieTorgersen36.719.31933450female2007\n    AdelieTorgersen39.320.61903650male  2007\n\n\n\n\n\n# draw a scatterplot of flipper length and body mass with penguins with a facet wrap of species, with a number of columns of 2\npenguins %>% ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + geom_point() + facet_wrap(~species, ncol = 2)\n\n\n\n\n\n# Tukey's multiple comparison test of flipper length between species\nTukeyHSD(aov(flipper_length_mm ~ species, data = penguins))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = flipper_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr       upr p adj\nChinstrap-Adelie  5.869887  3.586583  8.153191     0\nGentoo-Adelie    27.233349 25.334376 29.132323     0\nGentoo-Chinstrap 21.363462 19.000841 23.726084     0\n\n\n\n# Tukey's multiple comparison test of flipper length between species using multicomp package, glht function\nlibrary(multcomp)\nglht(aov(flipper_length_mm ~ species, data = penguins), linfct = mcp(species = \"Tukey\"))\n\n# summary of the Tukey's multiple comparison test of flipper length between species using multicomp package, glht function\nsummary(glht(aov(flipper_length_mm ~ species, data = penguins), linfct = mcp(species = \"Tukey\")))\n\n# Tukey's multiple comparison test of flipper length between species using emmeans package\nlibrary(emmeans)\nemmeans(aov(flipper_length_mm ~ species, data = penguins), \"species\")\n\n\n\n     General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nLinear Hypotheses:\n                        Estimate\nChinstrap - Adelie == 0     5.87\nGentoo - Adelie == 0       27.23\nGentoo - Chinstrap == 0    21.36\n\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = flipper_length_mm ~ species, data = penguins)\n\nLinear Hypotheses:\n                        Estimate Std. Error t value Pr(>|t|)    \nChinstrap - Adelie == 0   5.8699     0.9699   6.052 1.06e-08 ***\nGentoo - Adelie == 0     27.2333     0.8067  33.760  < 1e-08 ***\nGentoo - Chinstrap == 0  21.3635     1.0036  21.286  < 1e-08 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n(Adjusted p values reported -- single-step method)\n\n\n species   emmean    SE  df lower.CL upper.CL\n Adelie       190 0.540 339      189      191\n Chinstrap    196 0.805 339      194      197\n Gentoo       217 0.599 339      216      218\n\nConfidence level used: 0.95 \n\n\n\n# import the data from the file \"data/students-shorter.sav\" using haven package\nlibrary(haven)\nstudents <- read_spss(\"data/students-shorter.sav\")\n\n# print the first 6 rows of students\nhead(students)\n\n\n\nA tibble: 6 × 93\n\n    stu_idsch_idsstratidsexraceethnicbys42abys42bbys44abys44b⋯f1s83ffugradf1cncpt1f1cncpt2f1locus1f1locus2f1txrstdf1txmstdf1txsstdf1txhstd\n    <dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl>⋯<dbl+lbl><dbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl><dbl+lbl>\n\n\n    12496612491241 3 424⋯35.25-0.33-0.10 0.03-0.1448.2963.6157.7361.71\n    12497212491141 4 513⋯33.00-0.33-0.45-0.43-0.5836.0547.6553.3646.98\n    17555117551230NA 323⋯22.50 0.42 0.33-0.45-0.5955.1343.4446.3950.48\n    18066018061141 2NA14⋯26.50 0.43-0.02 0.03 0.0742.5456.1940.1456.48\n    18067218061241 2 314⋯24.25 0.02-0.09-0.88-0.8552.9647.3646.0155.32\n    29888529882130 5 423⋯26.00-0.33-0.28 0.03 0.0744.2445.2541.8839.67"
  },
  {
    "objectID": "contents/regression1.html",
    "href": "contents/regression1.html",
    "title": "Correlation/Simple Regression",
    "section": "",
    "text": "통계에서 데이터의 타입은 대략 다음과 같이 나누어짐"
  },
  {
    "objectID": "contents/regression1.html#linear-correlation의-계산",
    "href": "contents/regression1.html#linear-correlation의-계산",
    "title": "Correlation/Simple Regression",
    "section": "Linear correlation의 계산",
    "text": "Linear correlation의 계산\n교수의 연봉(salary), 학위를 받은 후 지난 시간(time since Ph.D.), 출판물의 수(pubs)의 관계\nData: c0301dt.csv\n\n\n# A tibble: 15 x 3\n    time  pubs salary\n   <dbl> <dbl>  <dbl>\n 1     3    18  51876\n 2     6     3  54511\n 3     3     2  53425\n 4     8    17  61863\n 5     9    11  52926\n 6     6     6  47034\n 7    16    38  66432\n 8    10    48  61100\n 9     2     9  41934\n10     5    22  47454\n11     5    30  49832\n12     6    21  47047\n13     7    10  39115\n14    11    27  59677\n15    18    37  61458\n\n\nThe formula for Pearson’s correlation coefficient; the product moment correlation coefficient\n\\(X, Y\\)에 대한 standardize (Z score); \\(\\displaystyle z_X = \\frac{X-M_X}{sd_X}, \\thinspace z_Y = \\frac{Y-M_Y}{sd_Y}\\)\n\\(r_{XY} = \\displaystyle 1 - \\frac{\\sum{(z_X - z_Y)^2}}{2n}\\)   \\(z_X, z_Y\\) : 각각 standardized \\(X, Y\\)\n\\(r_{XY} = \\displaystyle\\frac{\\sum_{i=1}^{n}{(x_i - \\bar x)(y_i - \\bar y)}}{\\sqrt{\\sum_{i=1}^{n}{(x_i - \\bar x)^2}} \\sqrt{\\sum_{i=1}^{n}{(y_i - \\bar y)^2}}}\\)   \\(\\bar x : X\\) 의 평균,   \\(\\bar y :Y\\) 의 평균\n\ndf <- acad0 |>\n    mutate(\n        z_time = (time - mean(time)) / sd(time),\n        z_pubs = (pubs - mean(pubs)) / sd(pubs),\n        diff = z_time - z_pubs,\n        squared = diff^2\n    ) |>\n    print()\n\n# A tibble: 15 × 7\n    time  pubs salary  z_time  z_pubs   diff squared\n   <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>   <dbl>\n 1     3    18  51876 -1.02   -0.140  -0.880  0.774 \n 2     6     3  54511 -0.364  -1.23    0.861  0.741 \n 3     3     2  53425 -1.02   -1.30    0.278  0.0772\n 4     8    17  61863  0.0728 -0.212   0.285  0.0812\n 5     9    11  52926  0.291  -0.646   0.938  0.879 \n 6     6     6  47034 -0.364  -1.01    0.644  0.415 \n 7    16    38  66432  1.82    1.31    0.514  0.264 \n 8    10    48  61100  0.510   2.03   -1.52   2.31  \n 9     2     9  41934 -1.24   -0.791  -0.447  0.200 \n10     5    22  47454 -0.583   0.150  -0.732  0.536 \n11     5    30  49832 -0.583   0.728  -1.31   1.72  \n12     6    21  47047 -0.364   0.0772 -0.441  0.195 \n13     7    10  39115 -0.146  -0.719   0.573  0.328 \n14    11    27  59677  0.728   0.511   0.217  0.0471\n15    18    37  61458  2.26    1.23    1.02   1.05  \n\n\n\nprint(1 - sum(df$squared) / (2 * 14))\n\n[1] 0.6566546\n\n\n\ncor(acad0) |>\n    round(2) |>  # 반올림 함수\n    print()\n\n       time pubs salary\ntime   1.00 0.66   0.71\npubs   0.66 1.00   0.59\nsalary 0.71 0.59   1.00\n\n\n상관계수 크기에 대한 guidline\n\n\\(| \\thinspace r\\thinspace|<0.3\\): weak\n\\(0.3\\le|\\thinspace r\\thinspace|<0.5\\): moderate\n\\(|\\thinspace r\\thinspace|>0.5\\) : strong relationship\n\n상관계수를 제곱한 \\(r^2\\) 는 변량의 설명 정도를 나타내주는 계수; 결정계수 (\\(R^2\\), \\(R\\) squared)\n이는 좀 더 해석가능한 값이 되고, strength of association를 나타내는 주요한 지표임.\n뒤에서 자세히 다룸.\n\nlibrary(rstatix)\ncor_test(acad0) |>\n    print()\n\n# A tibble: 9 x 8\n  var1   var2     cor    statistic         p conf.low conf.high method \n  <chr>  <chr>  <dbl>        <dbl>     <dbl>    <dbl>     <dbl> <chr>  \n1 time   time    1          Inf    0            1         1     Pearson\n2 time   pubs    0.66         3.14 7.83e-  3    0.218     0.875 Pearson\n3 time   salary  0.71         3.64 3   e-  3    0.311     0.896 Pearson\n4 pubs   time    0.66         3.14 7.83e-  3    0.218     0.875 Pearson\n5 pubs   pubs    1    241964450.   3.88e-103    1         1     Pearson\n6 pubs   salary  0.59         2.62 2.12e-  2    0.108     0.845 Pearson\n7 salary time    0.71         3.64 3   e-  3    0.311     0.896 Pearson\n8 salary pubs    0.59         2.62 2.12e-  2    0.108     0.845 Pearson\n9 salary salary  1          Inf    0            1         1     Pearson\n\n\n\n\n\n\n\n\nTip\n\n\n\n# Base R의 cor()의 옵션들\ncor(acad0, use = \"pairwise.complete.obs\") # NA의 처리: pairwise deletion\n\n# rstatix 패키지의 cor_test() 이용\nlibrary(rstatix)\ncor_test(acad0) # NA를 pairwise deletion으로 처리해줌\n#   var1   var2     cor    statistic         p conf.low conf.high method \n#   <chr>  <chr>  <dbl>        <dbl>     <dbl>    <dbl>     <dbl> <chr>  \n# 1 time   time    1          Inf    0            1         1     Pearson\n# 2 time   pubs    0.66         3.14 7.83e-  3    0.218     0.875 Pearson\n# 3 time   salary  0.71         3.64 3   e-  3    0.311     0.896 Pearson\n# ...\n\n# psych 패키지의 corr.test() 이용\nlibrary(psych) \ncorr.test(acad0) # NA를 pairwise deletion으로 처리해줌\n\n## Correlation matrix \n##        time pubs salary\n## time   1.00 0.66   0.71\n## pubs   0.66 1.00   0.59\n## salary 0.71 0.59   1.00\n\n## Sample Size \n## [1] 15\n## Probability values (Entries above the diagonal are adjusted for multiple tests.) \n##        time pubs salary\n## time   0.00 0.02   0.01\n## pubs   0.01 0.00   0.02\n## salary 0.00 0.02   0.00\n## \n##  To see confidence intervals of the correlations, print with the short=FALSE option"
  },
  {
    "objectID": "contents/regression1.html#시각화를-통한-상관계수",
    "href": "contents/regression1.html#시각화를-통한-상관계수",
    "title": "Correlation/Simple Regression",
    "section": "시각화를 통한 상관계수",
    "text": "시각화를 통한 상관계수\ncorrgram(), ggpairs()\nvignette for corrgram\n\nlibrary(corrgram)\ncorrgram(acad0,\n         order = TRUE,  # 상관계수가 높은 변수들을 가까이 위치시킴\n         upper.panel = panel.cor,   # 상관계수\n         lower.panel = panel.pie,  # 파이 차트\n)\n\n\n\n\n\n\n\n\n\n\ntip: use a function\n\n\n\n\n\ncorgrm <- function(df, order = TRUE){\n    corrgram(df,\n         order = order,  # 상관계수가 높은 변수들을 가까이 위치시킴\n         upper.panel = panel.cor,   # 상관계수\n         lower.panel = panel.pie,  # 파이 차트\n    )\n}\n\ncorgrm(acad0)\ncorgrm(acad0, order = FALSE)\n\n\n\nData from the 1985 Current Population Survey (CPS85)\n임금, 교육수준, 연차, 나이, 성별 간의 상관관계\n\ncps <- mosaicData::CPS85\n\ncps |>\n    select(wage, educ, exper, age, sex) |>\n    mutate(sex = as.numeric(sex)) |>   # factor를 숫자로 변환: 1, 2, ...\n    corrgram(\n         order = TRUE, \n         upper.panel = panel.cor, \n         lower.panel = panel.pie, \n    )\n\n\n\n\n\ncorrgram(acad0,\n         order = FALSE,\n         lower.panel = panel.pts,\n         upper.panel = panel.cor,\n         diag.panel = panel.density\n)\n\n\n\n\n\n# GGally 패키지의 ggpairs()\nGGally::ggpairs(acad0)\n\n\n\n\n\n\n\n\n\n\nTip: includes fitted lines\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .6) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"skyblue\", ...)\n}\n\nggpairs(acad0, columns = 1:3, lower = list(continuous = trendlines))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n명목변수인 경우에도 measure of association을 계산하는 방법이 있는데, 자세한 사항은 Measures of Association - How to Choose? 참조\nR에서 계산은 psych::corr.test()의 옵션 method를 “pearson”, “spearman”, “kendall” 중 선택\n명목변수의 예\n\n한 변수가 binary 인 경우: 물건의 가격 ~ 구매 여부\n두 변수가 모두 binary 인 경우: 남녀 ~ 합격 여부\n두 변수가 rank(ordinal) 인 경우: 다이아몬드 투명도(clarity)와 컬러(color)\n\nbinary인 경우: 0, 1로 코딩\nrank인 경우: 1, 2, 3… 로 코딩"
  },
  {
    "objectID": "contents/regression1.html#simple-linearregression-models",
    "href": "contents/regression1.html#simple-linearregression-models",
    "title": "Correlation/Simple Regression",
    "section": "Simple linear/regression models",
    "text": "Simple linear/regression models\n단순한 상관관계를 넘어서서,\nY가 X에 의해 영향을 받거나 X에 의해 예측되는 변수라는 연구자의 가정이 있음.\n\nY: 종속변수 (dependent variable), regressand, response\n\nX: 독립변수 (independent variable), regressor, 예측변수 (predictor)\n\n선형관계임을 가정하고, 데이터에 가장 근접한 직선을 구함\n이 직선을 주어진 데이터로부터 두 변수 간의 관계를 가장 잘 represent하는 model (모형)이라고 말함.\n이는 확장된 의미에서 물리법칙에서 변수 간의 관계를 수학적 식으로 표현하고, 자연의 질서를 모델링한 것으로 이해할 수 있는 것과 같음.\n\n\n\n\n\n\n패턴: 강한 선형 관계\n선형 모델 family인   \\(Y = a_2 X + a_1\\)을 세움\n무수히 많은 \\(a_1, a_2\\)의 값들 중 위 데이터에 가장 가까운 값을 찾음\n\n이를 “fit a model to data”라고 하고, 특정 모델을 fitted model이라고 함\n그 예로, 데이터와 꽤 가까운 임의의 20개의 선형 모델을 그려보면\n\n\n\n\n\n\n\n\n즉, 선형모델 중 데이터에 가장 가까운 모델을 찾고자 하는데,\n\n가깝다는 것을 정의하기 위해 데이터와 모델과의 거리를 정의해야 함; \\(d =|~data - model~|\\)\n그 중 모델과 데이터의 수직 차이 (잔차; residuals)의 총체로 거리를 정의할 수 있음\n\n\n\n특히, 다음과 같은 RMSE (root-mean-square deviation)을 기본적인 거리로 정의하고\n\n    \\(RMSE = \\displaystyle\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}{(Y_i -\\hat Y_i)^2}},\\)   \\(Y_i -\\hat Y_i\\) : residual (잔차)\n\n최적의 모델은 이 거리를 최소로 하며,\n이 때, 잔차의 합은 0;   \\(\\displaystyle \\sum_{i=1}^{n}{(Y_i -\\hat Y_i)} = 0\\)\n\n\n\nMean absolute error: \\(MAE = \\displaystyle\\frac{1}{n} \\sum_{i=1}^{n}{|~Y_i -\\hat Y_i~|}\\)\n\n이상치에 덜 민감함\n\n\n\n이 거리를 이용해서 모델의 파라미터를 추정하는 것을 ordinary least square (OLS) esimate이라고 함\nR은 여러 형태의 a family of models을 구성할 수 있는 효율적인 툴을 제공\n\nLinear (regression) models: \\(Y = a_0 + a_1 X_1 + a_2 X_2 + ~... ~ + a_n X_n\\)\n\n앞의 예는 \\(n=1\\) 에 해당하며, \\(y =a_0 +a_1X_1\\)에 대해서 다음과 같이 편리하게 적용할 수 있음\nsim1_mod <- lm(y ~ x, data = sim1)\n\ncoef(sim1_mod) # 모델의 parameter 즉, coefficients를 내줌\n#> (Intercept)           x \n#>    4.220822    2.051533   # 위에서 구한 파라미터값과 동일함\n\n즉, 앞의 데이터에 최적인 선형 모형은 \\(Y = 4.22 + 2.05X\\)\n\nlm()은 formula y ~ x를 \\(Y =a_0 +a_1X\\) 로 변환해 줌; Y 절편은 formula에서 생략\nLinear models의 경우 위에서 처럼 수치 을 이용하지 않고 방정식의 해를 구하듯 exact form으로 최소값을 구함\n\n\\(n=2\\) 인 경우인 두 변수 \\(X_1\\), \\(X_2\\)로 \\(Y\\)를 예측하는 경우,\nlm(y ~ x1 + x2, data = df)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis formula notation is called “Wilkinson-Rogers notation”, and was initially described in Symbolic Description of Factorial Models for Analysis of Variance by G. N. Wilkinson and C. E. Rogers\n위에서 y ~ x라는 formula는 x, y라는 변수를 바로 evaluate하지 않고, \\(Y = a_0 + a_1X\\)로 해석되어 함수로 전환됨"
  },
  {
    "objectID": "contents/regression1.html#visualising-models",
    "href": "contents/regression1.html#visualising-models",
    "title": "Correlation/Simple Regression",
    "section": "Visualising models",
    "text": "Visualising models\nFitted models을 이해하기 위해 모델이 예측하는 부분(prediction)과 모델이 놓친 부분(residuals)을 시각화해서 보는 것이 유용함\n\nPredictions: the pattern that the model has captured\nResiduals: what the model has missed; 통계 분석의 핵심 요소\n앞서 구한 모형 \\(Y = 4.22 + 2.05X\\) 을 데이터와 함께 그려보면,\n\n\n\n\n\n\n이 모형에 의한 예측값들(pred)과 잔차(resid)들은\n\n\n# A tibble: 30 × 4\n      x     y  pred  resid\n  <int> <dbl> <dbl>  <dbl>\n1     1  4.20  6.27 -2.07 \n2     1  7.51  6.27  1.24 \n3     1  2.13  6.27 -4.15 \n4     2  8.99  8.32  0.665\n5     2 10.2   8.32  1.92 \n6     2 11.3   8.32  2.97 \n7     3  7.36 10.4  -3.02 \n8     3 10.5  10.4   0.130\n# … with 22 more rows\n\n\nResiduals의 분포를 시각화해서 살펴보면,\n\nresiduals의 평균은 항상 0\nresiduals의 분포는 predictions이 관측치로부터 전반적으로 얼마나 벗어났는지에 평가할 수 있음\n\n\n\n\n\n\n예측 변수와 residuals의 관계를 시각화해서 보면,\n\n이 residuals은 특별한 패턴을 보이지 않아야 모델이 데이터의 패턴을 잘 잡아낸 것으로 판단할 수 있음\n또한 어떤 부분에서 예측이 벗어났는지도 판별할 수 있음\n\n\n\n\n\n\n\nResiduals에 패턴이 보이는 경우: 모형을 수정!"
  },
  {
    "objectID": "contents/regression1.html#case-1",
    "href": "contents/regression1.html#case-1",
    "title": "Correlation/Simple Regression",
    "section": "Case 1",
    "text": "Case 1\n교수의 연봉(salary)이 학위를 받은 후 지난 시간(time since Ph.D.)과 출판물의 수(pubs)에 의해 어떻게 영향을 받는가? \n\n\n\n# A tibble: 15 × 3\n   time  pubs salary\n  <dbl> <dbl>  <dbl>\n1     3    18  51876\n2     6     3  54511\n3     3     2  53425\n4     8    17  61863\n5     9    11  52926\n6     6     6  47034\n# … with 9 more rows\n\n\n\n\n\n\n\n\n모형 세우기\n선형모형: lm(y ~ x)\n\n\\(\\hat{Y} = a_0 + a_1X\\),   (\\(\\hat{Y}\\): 예측치)\n또는 \\(Y = a_0 + a_1X +e\\),   (\\(Y\\): 관측치, \\(e\\): 잔차, 에러)\n\\(a_1\\): 기울기 (\\(X\\)가 1 증가할 때, \\(Y\\)의 증가량),   \\(a_0\\): 절편 (\\(X\\)가 0일 때, \\(Y\\)의 값)\n\n\nmod1 <- lm(salary ~ time, data = acad0): \\(\\widehat{salary} = a_0 + a_1time\\)\nmod2 <- lm(salary ~ pubs, data = acad0): \\(\\widehat{salary} = a_0 + a_1pubs\\)\n\n\nFit a model to data\n데이터에 가장 근접한 모델\n\nmod1 <- lm(salary ~ time, data = acad0)\nmod2 <- lm(salary ~ pubs, data = acad0)\n\ncoef(mod1)\n## (Intercept)        time \n##   43658.594    1224.392\ncoef(mod2)\n## (Intercept)        pubs \n##   46357.449     335.526\n\n\nModel 1: \\(\\widehat{salary} = \\$43,659 + \\$1,224\\:time\\)\n\\(a_1\\): 학위를 받은 후 1년이 지날 때마다, 연봉은 $1,224 오름 (표현에 주의!)\n\\(a_0\\): 학위를 받은 후 0년일 때, 연봉은 $43,658; 0년이 의미있는가?\nModel 2 : \\(\\widehat{salary} = \\$46,357 + \\$336\\:pubs\\)\n\\(a_1\\): 출판물 1편을 추가로 발표하면, 연봉은 $336 오름 (표현에 주의!)\n\\(a_0\\): 출판물이 0편일 때, 연봉은 $46,357\n\n\n\n\n\n\n\n\n\n\n\n연봉(salary)을 연차(time)로 예측하는 모델(mod1)에 대해서 prediction과 residuals 값을 구해보면\n단, 간편한 계산을 위해 salary를 1000으로 나누었으며, 51.876는 $51,876을 의미\n\n아래 테이블에서 가령, 6년차인 교수의 연봉은 모형에 의해 $51,000로 예측되고,\n2번째 교수의 경우 그 예측이 $3,510 정도 낮게 예측되었으며,\n6번째 교수의 경우는 $3,9700 정도 높게 예측되었음\n예측이 틀린 정도, 즉 잔차는 왜 생기는가? …\n\n\n\n\n\n\nImportant\n\n\n\n모형의 분석은 예측/설명되는 부분과 예측/설명되지 않는 부분으로 쪼개어 보는 것이 기본적인 시각\n예들 들어, 연차로 연봉을 설명할 수는 있는 부분 vs. 연차로 연봉이 설명되지 않는 부분!\n\n\n\n\n\n   time salary  pred  resid (pred-m)^2 resid^2 (salary-m)^2\n1     3  51.88 47.33   4.54      32.65   20.65         1.37\n2     6  54.51 51.00   3.51       4.16   12.29         2.15\n3     3  53.42 47.33   6.09      32.65   37.13         0.14\n4     8  61.86 53.45   8.41       0.17   70.72        77.75\n5     9  52.93 54.68  -1.75       2.67    3.07         0.01\n6     6  47.03 51.00  -3.97       4.16   15.77        36.14\n7    16  66.43 63.25   3.18     104.11   10.13       179.20\n8    10  61.10 55.90   5.20       8.16   27.01        64.87\n9     2  41.93 46.11  -4.17      48.14   17.42       123.47\n10    5  47.45 49.78  -2.33      10.66    5.41        31.27\n11    5  49.83 49.78   0.05      10.66    0.00        10.33\n12    6  47.05 51.00  -3.96       4.16   15.67        35.98\n13    7  39.12 52.23 -13.11       0.67  171.99       194.06\n14   11  59.68 57.13   2.55      16.66    6.50        43.98\n15   18  61.46 65.70  -4.24     160.07   17.97        70.77\n\n\n\n\n\n\n\n\ngraphical representation\n\n\n\n\n\n\n\n\n\nColumn별로 더하면\n\n\n  time salary   pred resid (pred-m)^2 resid^2 (salary-m)^2\n1  115 795.68 795.68     0     439.75  431.73       871.48\n\n\n우선, 연봉의 합 \\(\\sum{Y}\\) = 예측값의 합 \\(\\sum{\\hat{Y}}\\)  : \\(X\\) 의 평균은 모형에 의해 Y의 평균으로 예측됨\n\n\n\n\n\n\nImportant\n\n\n\nPartitioning of variances\n\\(\\sum{(\\hat{Y}-m)^2}=439.75\\) : 연차의 변량 (variation)으로 모형에 의해 설명되는 (attribute/acount for) 연봉의 변량\n\\(\\sum{(Y-\\hat{Y})^2}=431.73\\) : 연차의 변량 (variation)으로 모형에 의해 설명될 수 없는 (not attribute) 연봉의 변량\n\\(\\sum{(Y-m)^2}=871.48\\) : 연봉의 변량\n이 세 값의 관계는 \\(\\sum{(\\hat{Y}-m)^2} + \\sum{(Y-\\hat{Y})^2} = \\sum{(Y-m)^2}\\)\n\nSum of squares (SS)로 부르며,\n\nSSR, SSE, SSY (각각 sum of squares of Regression, Error, Y)\n\n\n\n위 값을 다시 N(=15)으로 나누면, 즉 column별 평균은\n\n\n  time salary  pred resid (pred-m)^2 resid^2 (salary-m)^2\n1 7.67  53.05 53.05     0      29.32   28.78         58.1\n\n\n위의 관계는 variance (분산)으로 보면,\n  \\(V(predictions) + V(residuals) = V(Y)\\)\n이렇게 간결하게 쪼개지는 것은 predictions과 residuals이 서로 독립(\\(r=0\\))이 되기 때문으로 이해할 수 있음\n\npredictions \\(\\hat{Y}\\) 은 \\(X\\) 의 일차 함수식으로 얻어진 것이므로 \\(X\\) 와 \\(r=1\\) 이 되고,\nresiduals \\(Y-\\hat{Y}=Y-T(X)\\) 과 \\(\\hat{Y}\\)이 상관이 있다면, \\(X\\) 와 \\(Y-\\hat{Y}\\) 과의 상관이 존재해야하는데, 이는 OLS estimate에 어긋남\n# correlations with residuals\n#         pred time salary\n# resid  0.00 0.00  0.704\n# salary 0.71 0.71  1.000\n\n다시 위의 식에서 \\(V(Y)\\) 로 양변을 나누면\n  \\(\\displaystyle\\frac{V(predictions)}{V(Y)} + \\frac{V(residuals)}{V(Y)} = 1\\)\n\n\n\n\n\n\nImportant\n\n\n\n즉, “모형에 의해 설명되는 \\(Y\\) 변량의 비율” + “모형에 의해 설명되지 않는 \\(Y\\) 변량의 비율” = 1\n첫 항을 \\(R^2\\) 라고 하고, 결정계수 혹은 R squared라고 부름\n따라서, \\(1-R^2\\) 는 설명되지 않는 변량의 비율이라고 할 수 있음\n\n\n\\(R^2\\) 를 제곱근하면 \\(R\\) 이 나오고, 이는 Pearson’s correlation coefficient와 동일함;\n\n\\(R = cor(Y, X) = cor(Y, \\hat{Y}=aX+b), ~a = r_{XY} \\frac{sd_Y}{sd_X}\\)\n\\(R\\) 은 예측의 정확성에 대한 지표라고 이해할 수 있음\n\nOverlap in variance of correlated variables\n\n\n\n\n\n\n\nANOVA\n\n\n\n\n\n모형 자체에 대한 분석으로 ANOVA 결과는 anova()함수를 써서 볼 수 있음\n\nResiduals과 predictions에 대한 분산을 이용해\nresiduals 변량 대비 얼마나 predictions의 변량이 얼마나 큰지로부터 F분포를 이용해 통계적 추론이 이루어짐\n\nanova(mod1)\n# Analysis of Variance Table\n\n# Response: salary\n#           Df Sum Sq Mean Sq F value Pr(>F)   \n# time       1 439.75  439.75  13.241  0.003 **\n# Residuals 13 431.73   33.21                  \n# ---\n# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n\n\n다음은 SPSS 결과 테이블:\n\n\nsummary(mod1)\n\n\nCall:\nlm(formula = salary ~ time, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1143  -3.9644   0.0514   4.0251   8.4093 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  43.6586     2.9780  14.660 1.83e-09 ***\ntime          1.2244     0.3365   3.639    0.003 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.763 on 13 degrees of freedom\nMultiple R-squared:  0.5046,    Adjusted R-squared:  0.4665 \nF-statistic: 13.24 on 1 and 13 DF,  p-value: 0.003\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\\(R^2\\) 는 모형이 predictor들로부터 Y의 변량을 얼마나 예측/설명해주는지에 대한 지표로서 가장 널리 쓰임.\n다음의 두 경우는 1년의 연차가 $1,224의 연봉 증가로 나타나는 동일한 관계를 보여주지만, 그 strength of association에는 큰 차이가 있음\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n출판물의 수(pubs)가 연봉(salary)에 어떻게 영향을 미치는지 살펴보세요."
  },
  {
    "objectID": "contents/regression1.html#case-2",
    "href": "contents/regression1.html#case-2",
    "title": "Correlation/Simple Regression",
    "section": "Case 2",
    "text": "Case 2\n다음 데이터는 the Octogenarian Twin Study of Aging에서 나타나는 패턴을 기반으로 생성한 데이터\nLongitudinal Analysis: Modeling Within-Person Fluctuation and Change by Lesa Hoffman\n\nincludes 550 older adults age 80 to 97 years.\nCognition was assessed by the Information Test, a measure of general world knowledge (i.e., crystallized intelligence; range = 0 to 44)\ndemgroup 1: those who will not be diagnosed with dementia (none group = 1; 72.55%),\ndemgroup 2: those who will eventually be diagnosed with dementia later in the study (future group = 2; 19.82%)\ndemgroup 3: those who already have been diagnosed with dementia (current group = 3; 7.64%)\n\n\ncognition <- read_csv(\"data/spss_chapter2.csv\")\ncognition |> print()\n\n# A tibble: 550 × 6\n  PersonID cognition   age  grip sexMW demgroup\n     <dbl>     <dbl> <dbl> <dbl> <dbl>    <dbl>\n1        1        23  92.6     9     1        1\n2        2        24  91.8    11     0        2\n3        3        29  92.6    12     0        1\n4        4        16  94.4     6     1        1\n5        5        27  85.8     9     1        1\n6        6        37  83.1    11     0        1\n# … with 544 more rows\n\n\n\n\n\n\n\n\ncode for ggpairs\n\n\n\n\n\ntrendlines <- function(data, mapping, ...){\n    ggplot(data = data, mapping = mapping) + \n        geom_point(alpha = .6) + \n        geom_smooth(method = loess, se = FALSE, color = \"orange\", ...) +\n        geom_smooth(method = lm, se = FALSE, color = \"skyblue\", ...)\n}\n\nggpairs2 <- function(data, ...) {\n    GGally::ggpairs(data, lower = list(continuous = trendlines))\n}\n\nggpairs2(cognition, columns = 2:6)\n\n\n\n\n\n\n\n\n\nlibrary(psych)\ncorr.test(cognition[-1])$r |>  # r만 선택, inference부분 제외\n    round(2) |>\n    print()\n\n          cognition   age  grip sexMW demgroup\ncognition      1.00 -0.17  0.24 -0.24    -0.41\nage           -0.17  1.00 -0.18  0.05     0.01\ngrip           0.24 -0.18  1.00 -0.40     0.04\nsexMW         -0.24  0.05 -0.40  1.00     0.01\ndemgroup      -0.41  0.01  0.04  0.01     1.00\n\n\n\ncognition |>\n    ggplot(aes(x = grip, y = cognition)) +\n    geom_jitter() +\n    geom_smooth()\n\n\n\n\n\nmod_cog <- lm(cognition ~ grip, data = cognition)\nsummary(mod_cog)\n\n\nCall:\nlm(formula = cognition ~ grip, data = cognition)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-27.3941  -7.1578   0.3877   8.8377  22.8422 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  16.7033     1.4640  11.409  < 2e-16 ***\ngrip          0.8909     0.1527   5.834 9.24e-09 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 10.67 on 548 degrees of freedom\nMultiple R-squared:  0.05848,   Adjusted R-squared:  0.05677 \nF-statistic: 34.04 on 1 and 548 DF,  p-value: 9.244e-09\n\n\n기울기 0.89를 의미있게 해석할 수 있는가?\n\n변수의 정규화\nstandardize/normalize:   \\(\\displaystyle z = \\frac{x-m}{sd}; ~ax+b\\) : zoom + translate\n\n변수를 정규화하면 평균이 0이고, 표준편차가 1로 변환\n변수가 대략적으로 정규분포(normal distribution)을 따를 때,\n내재적인 단위가 없는 측정치들의 경우 그 값을 정규화시키면 해석이 용이하며,\n표준편차(sd)가 그 눈금/단위가 됨으로써 변수에 상관없이 동일한 눈금을 갖게 되어, 변수들 간의 비교가 가능해짐\n\n즉, 정규화된 변수의 1은 1sd를 의미\n\n또한, 평균이 0이 됨으로써 선형모형에서 용이한 trick을 제공해 줌\n변수를 정규화해도 사실상 중요한 통계치는 변화하지 않음; 상관계수, \\(R^2\\), \\(p\\) value 등\n\n좀 더 일반적으로 linear transform에 의해서 변하지 않음; 온도 C/F\n\n반면, 주어진 샘플의 평균과 표준편차를 사용하므로 샘플마다 변동이 생길 수 있음을 인지해야 함.\n\n\n cognition <- cognition |>\n     select(cog_std = cognition, grip_std = grip) |>\n     scale() |>  # standardize 함수\n     bind_cols(cognition)  # column bind: 열 방향으로 두 데이터프레임을 붙힘\n\ncognition |> print()\n\n# A tibble: 550 × 8\n  cog_std grip_std PersonID cognition   age  grip sexMW demgroup\n    <dbl>    <dbl>    <dbl>     <dbl> <dbl> <dbl> <dbl>    <dbl>\n1 -0.166   -0.0378        1        23  92.6     9     1        1\n2 -0.0748   0.633         2        24  91.8    11     0        2\n3  0.380    0.968         3        29  92.6    12     0        1\n4 -0.803   -1.04          4        16  94.4     6     1        1\n5  0.198   -0.0378        5        27  85.8     9     1        1\n6  1.11     0.633         6        37  83.1    11     0        1\n# … with 544 more rows\n\n\n\ncognition |>\n    ggplot(aes(x = grip_std, y = cog_std)) +\n    geom_jitter() +\n    geom_smooth(method=lm)\n\ncognition |>\n    ggplot(aes(x = grip, y = cognition)) +\n    geom_jitter() + \n    geom_smooth(method=lm)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggpubr)\ncognition |>\n    ggplot(aes(x = cognition, y = after_stat(density))) +\n    geom_freqpoly(binwidth=2) +\n    stat_overlay_normal_density(color = \"red\")\n\ncognition |>\n    ggplot(aes(x = grip, y = after_stat(density))) +\n    geom_freqpoly(binwidth=1) +\n    stat_overlay_normal_density(color = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nNormal distribution 정규 분포; 사실상 sd만으로 결정되는 분포 곡선\n\n  Source: The Truthful Art by Albert Cairo\n\nmod_cog_std <- lm(cog_std ~ grip_std, data = cognition)\nsummary(mod_cog_std) |> print(digits = 2)\n\n\nCall:\nlm(formula = cog_std ~ grip_std, data = cognition)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.493 -0.651  0.035  0.804  2.079 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.2e-16    4.1e-02     0.0        1    \ngrip_std     2.4e-01    4.1e-02     5.8    9e-09 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.97 on 548 degrees of freedom\nMultiple R-squared:  0.058, Adjusted R-squared:  0.057 \nF-statistic:  34 on 1 and 548 DF,  p-value: 9.2e-09\n\n\n\n\\(R^2\\) 와 p values는 변함이 없으며, intercept (y 절편)은 0"
  },
  {
    "objectID": "contents/tidyverse2.html",
    "href": "contents/tidyverse2.html",
    "title": "Tidyverse",
    "section": "",
    "text": "함수들: print(), glimpse(), summary(), count()\n() 안에 들어가는 것을 argument라고 부름\n\nlibrary(tidyverse)\n\ncps <- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\nprint(cps) # print 생략!\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n\n\n\n\n\nprint()\n\n\n\n강의 노트에서 print()를 쓰는 것은 jupyter notebook에서 data frame을 표시하는 방식때문이므로 무시하셔도 됩니다.\n\n\n보통 print()없이 데이터 프레임을 살펴보지만, print()을 이용하면, 표시되는 방식을 조정해서 볼 수 있음.\n\nprint(cps, n = 3) # 처음 3개 행\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1   9      10 W     M     NH       NS    Married    27 Not      43 const \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales \n# … with 531 more rows\n\n\n\n\n\n\n\n\ntip: print() 옵션\n\n\n\n\n\nprint(tibble, n = 10, width = Inf) # 10개의 rows와 모든 columns\n기본 셋팅을 변경하려면\noptions(tibble.print_min = 10, tibble.width = Inf)\nColumns/변수들이 많은 경우 화면에서 다음과 같이 축약되어 나오는데, 이를 다 보려면\nprint(nycflights13::flights) # nycflights13 패키지의 flights 데이터\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#   <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n# 1  2013     1     1      517         515       2     830     819      11 UA     \n# 2  2013     1     1      533         529       4     850     830      20 UA     \n# 3  2013     1     1      542         540       2     923     850      33 AA     \n# 4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n# 5  2013     1     1      554         600      -6     812     837     -25 DL     \n# 6  2013     1     1      554         558      -4     740     728      12 UA     \n# # … with 336,770 more rows, 9 more variables: flight <int>, tailnum <chr>,\n# #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n# #   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n# #   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nprint(nycflights13::flights, n = 3, width = Inf) # 가로 열의 개수: Inf (모든 열)\n# # A tibble: 336,776 × 19\n#    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n# 1  2013     1     1      517            515         2      830            819\n# 2  2013     1     1      533            529         4      850            830\n# 3  2013     1     1      542            540         2      923            850\n#   arr_delay carrier flight tailnum origin dest  air_time distance  hour minute\n#       <dbl> <chr>    <int> <chr>   <chr>  <chr>    <dbl>    <dbl> <dbl>  <dbl>\n# 1        11 UA        1545 N14228  EWR    IAH        227     1400     5     15\n# 2        20 UA        1714 N24211  LGA    IAH        227     1416     5     29\n# 3        33 AA        1141 N619AA  JFK    MIA        160     1089     5     40\n#   time_hour          \n#   <dttm>             \n# 1 2013-01-01 05:00:00\n# 2 2013-01-01 05:00:00\n# 3 2013-01-01 05:00:00\n# # … with 336,773 more rows\n\n\n\n많은 변수들을 간략히 보는 방법으로는 glimpse()\n\nglimpse(cps)\n\nRows: 534\nColumns: 11\n$ wage     <dbl> 9.00, 5.50, 3.80, 10.50, 15.00, 9.00, 9.57, 15.00, 11.00, 5.0…\n$ educ     <int> 10, 12, 12, 12, 12, 16, 12, 14, 8, 12, 17, 17, 14, 14, 12, 14…\n$ race     <fct> W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, NW, NW, W,…\n$ sex      <fct> M, M, F, F, M, F, F, M, M, F, M, M, M, M, M, M, M, M, M, M, F…\n$ hispanic <fct> NH, NH, NH, NH, NH, NH, NH, NH, NH, NH, Hisp, NH, Hisp, NH, N…\n$ south    <fct> NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, NS, N…\n$ married  <fct> Married, Married, Single, Married, Married, Married, Married,…\n$ exper    <int> 27, 20, 4, 29, 40, 27, 5, 22, 42, 14, 18, 3, 4, 14, 35, 0, 7,…\n$ union    <fct> Not, Not, Not, Not, Union, Not, Union, Not, Not, Not, Not, No…\n$ age      <int> 43, 38, 22, 47, 58, 49, 23, 42, 56, 32, 41, 26, 24, 34, 53, 2…\n$ sector   <fct> const, sales, sales, clerical, const, clerical, service, sale…\n\n\n\n\n\n\n\n\nTip\n\n\n\n엑셀 스프레드시트처럼 보는 방법은\nEnvironment 패널에 보이는 cps 데이터셋 맨 끝에 네모난 마크를 클릭하거나,\nview(cps)\n\n\n변수들에 대한 통계치 요약 summary()\n\nsummary(cps)\n\n      wage             educ       race     sex     hispanic   south   \n Min.   : 1.000   Min.   : 2.00   NW: 67   F:245   Hisp: 27   NS:378  \n 1st Qu.: 5.250   1st Qu.:12.00   W :467   M:289   NH  :507   S :156  \n Median : 7.780   Median :12.00                                       \n Mean   : 9.024   Mean   :13.02                                       \n 3rd Qu.:11.250   3rd Qu.:15.00                                       \n Max.   :44.500   Max.   :18.00                                       \n                                                                      \n    married        exper         union          age             sector   \n Married:350   Min.   : 0.00   Not  :438   Min.   :18.00   prof    :105  \n Single :184   1st Qu.: 8.00   Union: 96   1st Qu.:28.00   clerical: 97  \n               Median :15.00               Median :35.00   service : 83  \n               Mean   :17.82               Mean   :36.83   manuf   : 68  \n               3rd Qu.:26.00               3rd Qu.:44.00   other   : 68  \n               Max.   :55.00               Max.   :64.00   manag   : 55  \n                                                           (Other) : 58  \n\n\n카테고리별 개수를 세주는 count()\nNumber(수)에 대해서도 적용 가능: ex. educ 수준 2, 3, … 18 각각에 대해서\n\ncps |>  # pipe operator: alt + . (option + .)\n    count(sector) |>\n    print() # 생략해도 됨\n\n# A tibble: 8 × 2\n  sector       n\n  <fct>    <int>\n1 clerical    97\n2 const       20\n3 manag       55\n4 manuf       68\n5 other       68\n6 prof       105\n7 sales       38\n8 service     83\n\n\n\ncps |>\n    count(sex, married) |>\n    print()\n\n# A tibble: 4 × 3\n  sex   married     n\n  <fct> <fct>   <int>\n1 F     Married   162\n2 F     Single     83\n3 M     Married   188\n4 M     Single    101\n\n\n\n\n\n\n\n\nPipe operator\n\n\n\n|> 또는 %>% (’then’의 의미로…)\nx |> f(y) # f(x, y),\nx |> f(y) |> g(z) # g(f(x, y), z)\nsummary(cps) 는 다음과 같음\ncps |>\n    summary()\ncount(cps, sector)는 다음과 같음\ncps |> \n    count(sector)"
  },
  {
    "objectID": "contents/tidyverse2.html#rows",
    "href": "contents/tidyverse2.html#rows",
    "title": "Tidyverse",
    "section": "Rows",
    "text": "Rows\n행에 적용되는 함수들\nfilter(), arrange(), distinct()\n\nfilter()\n조건에 맞는 행을 선택\n\nConditional operators:\n>, >=, <, <=, == (equal to), != (not equal to)\n& (and) | (or)\n! (not)\n%in% (includes)\n\n\n# 임금(wage)가 10이상인 사람들\ncps |>\n    filter(wage >= 10) |>\n    print()\n\n# A tibble: 184 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  15      12 W     M     NH       NS    Married    40 Union    58 const   \n3  15      14 W     M     NH       NS    Single     22 Not      42 sales   \n4  11       8 W     M     NH       NS    Married    42 Not      56 manuf   \n5  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof    \n6  20.4    17 W     M     NH       NS    Single      3 Not      26 prof    \n# … with 178 more rows\n\n\n\n# 임금(wage)가 10이상이고 여성(F)들\ncps |>\n    filter(wage >= 10 & sex == \"F\") |>\n    print()\n\n# A tibble: 62 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n2  11.2    17 NW    F     NH       NS    Married    32 Not      55 clerical\n3  25.0    17 W     F     NH       NS    Single      5 Not      28 prof    \n4  12.6    17 W     F     NH       NS    Married    13 Not      36 manag   \n5  11.7    16 W     F     NH       NS    Single     42 Not      64 clerical\n6  12.5    15 W     F     NH       NS    Married     6 Not      27 clerical\n# … with 56 more rows\n\n\n\n# 간부급(management)과 전문직(professional)에 종사하는 사람들\ncps |>\n    filter(sector == \"manag\" | sector == \"prof\") |>\n    print()\n\n# A tibble: 160 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# … with 154 more rows\n\n\n다음과 같이 편리하게 %in%을 이용하여 여러 항목을 포함하는, 즉 |와 ==를 합친 조건문을 생성\n즉, include인지 판별\n\n# A shorter way to select sectors for management or professional\ncps |>\n    filter(sector %in% c(\"manag\", \"prof\")) |>\n    print()\n\n# A tibble: 160 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n4  15      16 NW    M     NH       NS    Married    26 Union    48 manag \n5  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n6  10      14 W     M     NH       NS    Married    22 Not      42 prof  \n# … with 154 more rows\n\n\n\n\n\n\n\n\nImportant\n\n\n\nfilter()로 얻은 데이터 프레임은 원래 데이터 프레임을 수정하는 것이 아니므로 계속 사용하려면 저장해야 함\n이후 모든 함수들에 대해서도 마찬가지\nprestige <- cps |>\n    filter(sector %in% c(\"manag\", \"prof\"))\n\nprestige\n#    wage  educ race  sex   hispanic south married exper union   age sector\n#   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n# 1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n# 2  20.4    17 W     M     NH       NS    Single      3 Not      26 prof  \n# 3  10      16 W     M     Hisp     NS    Married     7 Union    29 manag \n# ...\n\n\n\n\n\n\n\n\nTip\n\n\n\n잦은 실수들\ncps |>\n    filter(sex = \"F\") # \"==\" vs. \"=\"\ncps |>\n    filter(sector == \"manage\" | \"prof\") # | 전후 모두 완결된 조건문 필요\n\n\n\n\narrange()\nColumn의 값을 기준으로 row를 정렬\n\n# 교육정도(educ)와 임금(wage)에 따라 오름차순으로 정렬\ncps |>\n    arrange(educ, wage) |>\n    print(n = 10)\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector \n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>  \n 1  3.75     2 W     M     Hisp     NS    Single     16 Not      24 service\n 2  7        3 W     M     Hisp     S     Married    55 Not      64 manuf  \n 3  6        4 W     M     NH       NS    Married    54 Not      64 service\n 4 14        5 W     M     NH       S     Married    44 Not      55 const  \n 5  3        6 W     F     Hisp     NS    Married    43 Union    55 manuf  \n 6  4.62     6 NW    F     NH       S     Single     33 Not      45 manuf  \n 7  5.75     6 W     M     NH       S     Married    45 Not      57 manuf  \n 8  3.35     7 W     M     NH       S     Married    43 Not      56 manuf  \n 9  4.5      7 W     M     Hisp     S     Married    14 Not      27 service\n10  6        7 W     F     NH       S     Married    15 Not      28 manuf  \n# … with 524 more rows\n\n\ndesc()을 이용하면 내림차순으로 정렬\n\n# educ을 내림차순으로 정렬\ncps |>\n    arrange(desc(educ)) |>\n    print(n = 10)\n\n# A tibble: 534 × 11\n    wage  educ race  sex   hispanic south married exper union   age sector\n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n 1 15       18 W     M     NH       NS    Married    12 Not      36 prof  \n 2 14.0     18 W     F     NH       NS    Married    14 Not      38 manag \n 3 13.5     18 W     M     NH       NS    Married    14 Union    38 prof  \n 4 20       18 W     F     NH       NS    Married    19 Not      43 manag \n 5  7       18 W     M     NH       NS    Married    33 Not      57 prof  \n 6 11.2     18 W     M     NH       NS    Married    19 Not      43 prof  \n 7  5.71    18 W     M     NH       NS    Married     3 Not      27 prof  \n 8 18       18 W     M     NH       NS    Married    15 Not      39 prof  \n 9 19       18 W     M     NH       NS    Single     13 Not      37 manag \n10 22.8     18 W     F     NH       NS    Single     37 Not      61 prof  \n# … with 524 more rows\n\n\narrange()와 filter()를 함께 사용하여 좀 더 복잡한 문제를 해결할 수 있음\n\n# 높은 지위의 섹터에서 일하는 사람들 중 임금이 상위에 있는 사람들\ncps |>\n    filter(sector == \"manage\" | sector == \"prof\") |>\n    arrange(desc(wage)) |>\n    print()\n\n# A tibble: 105 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector\n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct> \n1  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof  \n2  25.0    17 W     F     NH       NS    Single      5 Not      28 prof  \n3  25.0    17 W     M     NH       NS    Married    31 Not      54 prof  \n4  25.0    16 W     F     NH       S     Single      5 Not      27 prof  \n5  23.2    17 NW    F     NH       NS    Married    25 Union    48 prof  \n6  22.8    18 W     F     NH       NS    Single     37 Not      61 prof  \n# … with 99 more rows\n\n\n\n\ndistinct()**\n유티크한 조합들을 리스트\n\ncps |>\n    distinct(sector, sex) |>\n    print()\n\n# A tibble: 15 × 2\n   sector   sex  \n   <fct>    <fct>\n 1 const    M    \n 2 sales    M    \n 3 sales    F    \n 4 clerical F    \n 5 service  F    \n 6 manuf    M    \n 7 prof     M    \n 8 service  M    \n 9 other    M    \n10 clerical M    \n11 manag    M    \n12 prof     F    \n13 manag    F    \n14 manuf    F    \n15 other    F"
  },
  {
    "objectID": "contents/tidyverse2.html#columns",
    "href": "contents/tidyverse2.html#columns",
    "title": "Tidyverse",
    "section": "Columns",
    "text": "Columns\n열에 적용되는 함수들\nmutate(), select(), rename()\n\nmutate()\nColumns/변수들로부터 값을 계산하여 새로운 변수를 만듦\n\ntips <- as_tibble(reshape::tips) # reshpae 패키지 안에 tips 데이터셋\ntips |> print()\n\n# A tibble: 244 × 7\n  total_bill   tip sex    smoker day   time    size\n       <dbl> <dbl> <fct>  <fct>  <fct> <fct>  <int>\n1       17.0  1.01 Female No     Sun   Dinner     2\n2       10.3  1.66 Male   No     Sun   Dinner     3\n3       21.0  3.5  Male   No     Sun   Dinner     3\n4       23.7  3.31 Male   No     Sun   Dinner     2\n5       24.6  3.61 Female No     Sun   Dinner     4\n6       25.3  4.71 Male   No     Sun   Dinner     4\n# … with 238 more rows\n\n\n\ntips |>\n    mutate(\n        tip_pct = tip / total_bill * 100,\n        tip_pct_per = tip_pct / size\n    ) |>\n    print()\n\n# A tibble: 244 × 9\n  total_bill   tip sex    smoker day   time    size tip_pct tip_pct_per\n       <dbl> <dbl> <fct>  <fct>  <fct> <fct>  <int>   <dbl>       <dbl>\n1       17.0  1.01 Female No     Sun   Dinner     2    5.94        2.97\n2       10.3  1.66 Male   No     Sun   Dinner     3   16.1         5.35\n3       21.0  3.5  Male   No     Sun   Dinner     3   16.7         5.55\n4       23.7  3.31 Male   No     Sun   Dinner     2   14.0         6.99\n5       24.6  3.61 Female No     Sun   Dinner     4   14.7         3.67\n6       25.3  4.71 Male   No     Sun   Dinner     4   18.6         4.66\n# … with 238 more rows\n\n\n\n\nselect()\nColumns/변수를 선택\n\ntips |>\n    select(total_bill, tip, day, time) |>\n    print()\n\n# A tibble: 244 × 4\n  total_bill   tip day   time  \n       <dbl> <dbl> <fct> <fct> \n1       17.0  1.01 Sun   Dinner\n2       10.3  1.66 Sun   Dinner\n3       21.0  3.5  Sun   Dinner\n4       23.7  3.31 Sun   Dinner\n5       24.6  3.61 Sun   Dinner\n6       25.3  4.71 Sun   Dinner\n# … with 238 more rows\n\n\n\n# tip에서 smoker까지, 그리고 size columns 선택\ntips |>\n    select(tip:smoker, size) |>  # select(2:4, 7)처럼 number로 선택가능\n    print()\n\n# A tibble: 244 × 4\n    tip sex    smoker  size\n  <dbl> <fct>  <fct>  <int>\n1  1.01 Female No         2\n2  1.66 Male   No         3\n3  3.5  Male   No         3\n4  3.31 Male   No         2\n5  3.61 Female No         4\n6  4.71 Male   No         4\n# … with 238 more rows\n\n\n\n# sex에서 day까지 columns은 제외하고\ntips |>\n    select(!sex:day) |> # !: not\n    print()\n\n# A tibble: 244 × 4\n  total_bill   tip time    size\n       <dbl> <dbl> <fct>  <int>\n1       17.0  1.01 Dinner     2\n2       10.3  1.66 Dinner     3\n3       21.0  3.5  Dinner     3\n4       23.7  3.31 Dinner     2\n5       24.6  3.61 Dinner     4\n6       25.3  4.71 Dinner     4\n# … with 238 more rows\n\n\n\n# factor 타입의 변수들만 선택: 함수를 이용\ntips |>\n    select(where(is.factor)) |>  # 다른 함수들: is.numeric, is.character\n    print()\n\n# A tibble: 244 × 4\n  sex    smoker day   time  \n  <fct>  <fct>  <fct> <fct> \n1 Female No     Sun   Dinner\n2 Male   No     Sun   Dinner\n3 Male   No     Sun   Dinner\n4 Male   No     Sun   Dinner\n5 Female No     Sun   Dinner\n6 Male   No     Sun   Dinner\n# … with 238 more rows\n\n\n다양한 select()의 선택방법은 ?select로 help참고\n예를 들어, starts_with(\"abc\")는 abc로 시작하는 열의 이름을 가진 열들\n\n\n\n\n\n\nNote\n\n\n\nBase R에서 행과 열의 선택과 비교하면,\ncps[2:5, c(\"wage\", \"married\")] # 2~5행과 wage, married열\n# # A tibble: 4 × 2\n#    wage married\n#   <dbl> <fct>  \n# 1   5.5 Married\n# 2   3.8 Single \n# 3  10.5 Married\n# 4  15   Married\n\ncps |> \n    select(wage, married) |> \n    slice(2:5) # 행을 선택\n\n\n\n\nrename()\nColumns의 이름을 변경\n\ncps |>\n    rename(education = educ, marital = married) |> # new = old\n    print()\n\n# A tibble: 534 × 11\n   wage education race  sex   hispanic south marital exper union   age sector  \n  <dbl>     <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9          10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5        12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8        12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5        12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15          12 W     M     NH       NS    Married    40 Union    58 const   \n6   9          16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n변수를 select할 때 동시에 이름도 바꿀 수 있음\n\ncps |>\n    select(education = educ, marital = married) |> # new = old\n    print()\n\n# A tibble: 534 × 2\n  education marital\n      <int> <fct>  \n1        10 Married\n2        12 Married\n3        12 Single \n4        12 Married\n5        12 Married\n6        16 Married\n# … with 528 more rows"
  },
  {
    "objectID": "contents/tidyverse2.html#groups",
    "href": "contents/tidyverse2.html#groups",
    "title": "Tidyverse",
    "section": "Groups",
    "text": "Groups\n분석에서는 자주 카테고리별로 데이터를 나누어 통계치를 계산하곤 하는데,\ngroup_by()와 summarise()의 두 함수를 함께 사용하여 가장 자주 사용하게 됨\n\ngroup_by()\n데이터셋을 분석을 위해 의미있는 그룹으로 나눔\n다음은 성별로 데이터셋을 나눈 것인데, 실제 데이터를 수정하는 것은 아니고, 내부적으로 grouping되어 있음.\n맨 위 줄에 보면 Groups:  sex [2]로 표시되어 grouped data frame임을 명시함\n\ncps |>\n    group_by(sex) |> \n    print()\n\n# A tibble: 534 × 11\n# Groups:   sex [2]\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n\nsummarise()\nsummarize()와 동일\ngroup별로 통계치를 구해 하나의 행으로 산출\n\n# 남녀별로 임금의 평균을 구함\ncps |>\n    group_by(sex) |>\n    summarise(\n        avg_wage = mean(wage, na.rm = TRUE),  # mean(): 평균, na.rm: NA를 remove할 것인가\n        n = n()  # n(): 개수\n    ) |>\n    print()\n\n# A tibble: 2 × 3\n  sex   avg_wage     n\n  <fct>    <dbl> <int>\n1 F         7.88   245\n2 M         9.99   289\n\n\n\n\nslice_\n\ndf |> slice_head(n = 1) takes the first row from each group.\ndf |> slice_tail(n = 1) takes the last row in each group.\ndf |> slice_min(x, n = 1) takes the row with the smallest value of x.\ndf |> slice_max(x, n = 1) takes the row with the largest value of x.\n\n\n# 섹터별로 임금이 가장 높은 사람들\ncps |>\n    group_by(sector) |>\n    slice_max(wage, n = 1) |>\n    print()\n\n# A tibble: 12 × 11\n# Groups:   sector [8]\n    wage  educ race  sex   hispanic south married exper union   age sector  \n   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n 1  15.0    12 W     F     NH       NS    Married    24 Not      42 clerical\n 2  15      12 W     M     NH       NS    Married    40 Union    58 const   \n 3  15      12 W     M     NH       NS    Married    33 Union    51 const   \n 4  44.5    14 W     F     NH       NS    Single      1 Not      21 manag   \n 5  22.2    12 W     M     NH       NS    Married    26 Union    44 manuf   \n 6  26      14 W     M     NH       NS    Married    21 Union    41 other   \n 7  25.0    17 W     M     Hisp     NS    Married    18 Not      41 prof    \n 8  25.0    17 W     F     NH       NS    Single      5 Not      28 prof    \n 9  25.0    17 W     M     NH       NS    Married    31 Not      54 prof    \n10  25.0    16 W     F     NH       S     Single      5 Not      27 prof    \n11  20.0    14 W     M     NH       S     Married    44 Not      64 sales   \n12  25      14 W     M     Hisp     NS    Single      4 Union    24 service \n\n\n2개 이상의 변수들로 grouping할 수 있음\n\ncps |>\n    group_by(sex, married) |>\n    summarize(\n        ave_wage = mean(wage),\n        sd_wage = sd(wage)) |>\n    print()\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 × 4\n# Groups:   sex [2]\n  sex   married ave_wage sd_wage\n  <fct> <fct>      <dbl>   <dbl>\n1 F     Married     7.68    3.73\n2 F     Single      8.26    6.23\n3 M     Married    10.9     5.35\n4 M     Single      8.35    4.78\n\n\n이때, 결과 데이터 프레임은 sex로 grouping되어 있음.\ngrouping을 해제하려면 ungroup()이 필요함.\n그렇지 않으면, 저 결과는 sex로 grouped data frame임\n\nUseful summary functions\n자세한 사항은 R for Data Science/Data transformation\n\nMeasures of location: mean(), median()\nMeasures of spread: sd(), IQR(), mad()\nMeasures of rank: min(), max(), quantile(x, 0.25)\nMeasures of position: min_rank(), first(), nth(x, 2), last()\nMeasures of count: count(), n_distinct()"
  },
  {
    "objectID": "contents/tidyverse2.html#missing",
    "href": "contents/tidyverse2.html#missing",
    "title": "Tidyverse",
    "section": "Missing",
    "text": "Missing\nR에서 missing values (결측치)는 NA로 표시\nNaN (not a number)는 주로 계산 결과로 나오는데, 예들 들어 0으로 나눌 때처럼, R에서는 NA로 취급되니 크게 신경쓰지 않아도 됨. 자세한 사항은 R for Data Science/Missing values 참고\nNA는 다음과 같은 성질을 지님\nNA > 5\n#> [1] NA\n10 == NA\n#> [1] NA\nNA + 10\n#> [1] NA\nNA / 2\n#> [1] NA\nNA == NA\n#> [1] NA\n\nx <- NA\nis.na(x)\n#> [1] TRUE\nNA는 filter()는 조건문의 참거짓에 상관없이 모두 제외함 - 실제로 조건문의 결과는 TRUE, FALSE로 이루어지짐\ndf <- tibble(A = c(1, NA, 3, 4, 2, NA), B = c(2, 5, 3, NA, 10, NA))\n##       A     B\n##   <dbl> <dbl>\n## 1     1     2\n## 2    NA     5\n## 3     3     3\n## 4     4    NA\n## 5     2    10\n## 6    NA    NA\n\nfilter(df, A > 1)\n##       A     B\n##   <dbl> <dbl>\n## 1     3     3\n## 2     4    NA\n## 3     2    10\n\n# NA를 포함하고자 할 때,\nfilter(df, A > 1 | is.na(A))\n##       A     B\n##   <dbl> <dbl>\n## 1    NA     5\n## 2     3     3\n## 3     4    NA\n## 4     2    10\n## 5    NA    NA\n\n# NA를 포함하지 않은 행들만\nfilter(df, !is.na(A))\nfilter(df, !is.na(A) & !is.na(B))\n\nna.omit(df) # NA가 하나라도 있는 행은 모두 제거, 보통 결측치를 조심스럽게 대체한 후 사용\n##       A     B\n##   <dbl> <dbl>\n## 1     1     2\n## 2     3     3\n## 3     2    10\n\n# 함수 중에 NA를 직접 처리하는 경우들이 많음\nmean(df$A)\n## [1] NA\n\nmean(df$A, na.rm = TRUE) # NA removed\n## [1] 2.5"
  },
  {
    "objectID": "contents/tidyverse2.html#summary",
    "href": "contents/tidyverse2.html#summary",
    "title": "Tidyverse",
    "section": "Summary",
    "text": "Summary\n다음 dplyr 패키지의 기본 verb 함수들로 데이터를 가공하면서 필요한 통계치를 구함\n\n조건에 맞는 행들(관측치)만 필터링: filter()\n열을 재정렬: arrange()\n변수들의 선택: select()\n변수들과 함수들을 이용하여 새로운 변수를 생성: mutate()\n원하는 요약 통계치를 간추림: summarise()"
  },
  {
    "objectID": "contents/notice.html",
    "href": "contents/notice.html",
    "title": "Notice",
    "section": "",
    "text": "기본적으로 모두 대면으로 하겠습니다. 비대면시 따로 공지하겠습니다."
  },
  {
    "objectID": "contents/notice.html#과제",
    "href": "contents/notice.html#과제",
    "title": "Notice",
    "section": "과제",
    "text": "과제"
  },
  {
    "objectID": "contents/notice.html#중간고사-대체-과제-4.20",
    "href": "contents/notice.html#중간고사-대체-과제-4.20",
    "title": "Notice",
    "section": "중간고사 대체 과제 4.20",
    "text": "중간고사 대체 과제 4.20"
  },
  {
    "objectID": "contents/notice.html#기말시험-6.15",
    "href": "contents/notice.html#기말시험-6.15",
    "title": "Notice",
    "section": "기말시험 6.15",
    "text": "기말시험 6.15"
  },
  {
    "objectID": "contents/notice.html#개별-프로젝트",
    "href": "contents/notice.html#개별-프로젝트",
    "title": "Notice",
    "section": "개별 프로젝트",
    "text": "개별 프로젝트"
  },
  {
    "objectID": "contents/notice.html#강의-계획-tentative",
    "href": "contents/notice.html#강의-계획-tentative",
    "title": "Notice",
    "section": "강의 계획 (tentative)",
    "text": "강의 계획 (tentative)\n1주 ~ 4주: R tutorial\n5주 ~ 6주: 통계 전반적 소개 - Statistics/overview\n7주: correlation/simple linear regression\n8주: multiple regression: residualize\n9주: multiple regression: pattern of association\n10주: multiple regression: measure of association\n11주: interaction effect 1\n12주: interaction effect 2\n13주: diagnosis of assumptions 1\n14주: diagnosis of assumptions 2\n15주: beyond multiple regression\n16주: final exam"
  },
  {
    "objectID": "contents/visualize.html",
    "href": "contents/visualize.html",
    "title": "Visualize",
    "section": "",
    "text": "데이터 시각화는 탐색적 분석에 더 초점이 맞춰져 있음.\n\n소위 data mining이라고 부르는 데이터 내의 숨겨진 패턴을 찾고 분석하는 탐색적 분석은 전통적인 통계에서 discouraging되어 왔음.\n\n확률에 근거한 통계 이론은 데이터를 수집하기 전에 가설을 세우고 그 가설을 confirm하는 방식을 취함.\n\n논란의 여지가 있지만, 원칙적으로 가설에 근거해 수집한 자료가 가설과 일치하는지를 확인하는 작업에서는 자료를 두 번 이상 들여다 보지 않아야 함.\n\n그럼에도 불구하고, 탐색적 분석은 behind doors에서 이루어지거나 새로운 가설을 세우기 위한 방편으로 이용되었음.\n\n또한, 매우 엄격한 잣대를 적용하는 상황에서도 통계 이론의 특성으로 인해 기본적인 탐색적 분석은 반드시 선행되어야 함.\n\n연구 가설의 진위를 탐구할 때, 탐색적 분석에서 쉽게 빠질 수 있는 편향성(bias)는 항상 조심할 필요가 있고, 확신을 위해서는 새로이 자료를 수집해서 가설을 재검증할 필요가 있음.\n\n탐색적 분석을 위해서는 다양한 시각화 기술이 요하나, 일반적인 통계 분석을 위해서 필요로하는 최소한으로 제한하고자 함.\n또한, 복잡한 통계치를 살펴볼 때, 직접 시각화를 하기보다는 패키지가 알아서 시각화를 해주기 때문에 자세히 알지 못해도 무방함.\n좀 더 상세한 내용에 대해서는\n\nR for Data Science/Visualize\nggplot2 book\nggplot2 extensions\n통계치 표현: ggstatsplot, ggpubr\nData Visualization with R by Rob Kabacoff : 적절한 밸런스\nggplot2 cheatsheet : pdf 다운로드\n\n\n\n\n\n\n\nNote\n\n\n\n충분히 큰 데이터의 경우, 일정량의 데이터 가령 1/4을 따로 떼어놓고, 3/4만으로 탐색적 분석을 통해 모델을 만든 후, 따로 떼어놓은 1/4로 (가설)검증을 하는 cross-validation 방법이 있는데, machine leanring분야에서는 기본적인 process.\nCross-validation 방식에는 여러 변형들이 있음; e.g. 데이터를 4등분하여 각각 4번 위의 방식을 반복하여 합치는 방식, 3가지 (training, validation, test sets)로 나누어 분석"
  },
  {
    "objectID": "contents/visualize.html#basics",
    "href": "contents/visualize.html#basics",
    "title": "Visualize",
    "section": "Basics",
    "text": "Basics\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\npenguins |>\n    print() # 무시\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n  <fct>   <fct>              <dbl>         <dbl>       <int>   <int> <fct> <int>\n1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n4 Adelie  Torgersen           NA            NA            NA      NA NA     2007\n5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n6 Adelie  Torgersen           39.3          20.6         190    3650 male   2007\n# … with 338 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#   ²​body_mass_g\n\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nVariabels:\n\nspecies: a penguin’s species (Adelie, Chinstrap, or Gentoo).\n\nflipper_length_mm: length of a penguin’s flipper, in millimeters.\n\nbody_mass_g: body mass of a penguin, in grams.\n\n더 자세한 사항은 ?penguins\nggplot을 이용한 시각화는 주로 3가지 성분으로 나뉨\n\ndata: 사용할 데이터\n\nmapping: data의 변수들을 어떤 특성에 mapping할 것인지 specify\n\ngeom: 어떤 시각화 개체(graphical objects)로 데이터를 표현할 것인지 specify\n\n\n# x, y축에 변수를 mapping\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\n\n# point로 데이터를 표시: scatterplot\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#> Warning: Removed 2 rows containing missing values (`geom_point()`).\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n실제로 is.na()함수를 이용해 missing을 확인해보면,\npenguins |>\n  select(species, flipper_length_mm, body_mass_g) |>\n  filter(is.na(body_mass_g) | is.na(flipper_length_mm))  # true, false의 boolean type\n#> # A tibble: 2 × 3\n#>   species flipper_length_mm body_mass_g\n#>   <fct>               <int>       <int>\n#> 1 Adelie                 NA          NA\n#> 2 Gentoo                 NA          NA\n\n\n\nAdding aesthetics and layers\n\n# spcies에 color (aesthetics)를 mapping\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n위에서 species마다 다른 색을 입혀서 다른 패턴이 나타나는지 확인해 볼 수 있음\nggplot2는 + 기호로 연결하여 계속 layer를 추가할 수 있음.\n다음은 trendline 혹은 fitted line이라고 부르는 경향성을 확인해 볼 수 있는 라인의 layer를 추가함\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nData에 fitted curve를 구하는 방식에는 여러 방법이 있음\n\nLinear fit: 1차 함수형태인 직선으로 fit\nSmoothing fit\n\nPolynominal fit: n차 다항함수형태로 fit\nLoess/lowess: locally estimated/weighted scatterplot smoothing\nGAM: generalized additive model\nSpine: piece-wise polynominal regression\n\n\n나중에 좀 더 자세히 알아봄\n\n\nggplot2는 플랏의 대상에 다음과 같은 속성을 부여할 수 있음\ncolor, size, shape, fill, alpha\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species, shape = island)\n) +\n  geom_point() \n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n어떤 속성을 어떤 변수에 할당하는 것이 적절한지를 선택하는 것이 기술\n\n\n\n\nCategorical vs. continuous\ncolor와 같은 속성은 카테고리 변수가 좀 더 적절하나, 연속변수에서도 적용될 수 있음\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = bill_length_mm)\n) +\n  geom_point() \n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n반대로, x, y에 카테고리 변수를 mapping하여 scatterplot을 그리면 다음과 같은 overploting의 문제가 생김\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_point() \n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\nOverplotting\nOverplotting의 문제를 해결하는 방식은 주로\n\nalpha(투명도)를 조정하거나 랜덤하게 흐뜨려그리는 geom_jitter()를 사용\n\n애초에 겹치지 않게 그리는 방법도 있음: e.g. beeswarm plot\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_jitter(width = .2) # jitter의 정도: width, height\n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = species, y = body_mass_g, color = sex)\n) +\n  geom_jitter(width = .2, alpha = .5) # alpha: 투명도 0 ~ 1\n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "contents/visualize.html#geometric-objects",
    "href": "contents/visualize.html#geometric-objects",
    "title": "Visualize",
    "section": "Geometric objects",
    "text": "Geometric objects\nggplot2는 40가지 넘는 geom objects를 제공함.\n주로 통계를 위해 쓰일 geom들은\n\ngeom_point, geom_smooth()\ngeom_boxplot()\ngeom_histogram(), geom_freqploy(), geom_density()\n\nGlobal vs. local mapping\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) + # color mapping은 geom_point에만 적용\n  geom_smooth() # 맨 위의 mapping에 있는 global mapping을 inherit\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_smooth(mapping = aes(linetype = sex), se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\n\n\n\n\n\n\nggplot(\n    data = penguins,\n    mapping = aes(x = bill_depth_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +  # color mapping은 geom_point에만 \n  geom_smooth(method = lm)  # 맨 위의 mapping에 있는 global mapping을 inherit, method: fitted line의 종류\n\n\n\n\n\nggplot(\n    data = penguins,\n    mapping = aes(x = bill_depth_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = lm) +  # 맨 위의 mapping에 있는 global mapping을 inherit\n  geom_smooth(mapping = aes(color = species), method = lm) # color mapping 추가\n\n\n\n\naes() 내부, 외부에서의 mapping\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(mapping = aes(color = species)) # aesthetic color에 변수를 mapping\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(color = \"skyblue\") + # geom의 color 속성에 색을 지정\n    geom_smooth(color = \"orangered\")"
  },
  {
    "objectID": "contents/visualize.html#statistical-transformations",
    "href": "contents/visualize.html#statistical-transformations",
    "title": "Visualize",
    "section": "Statistical transformations",
    "text": "Statistical transformations\nggplot2는 편의를 위해 통계치를 구해 표시해주는데,\n경우에 따라 직접 통계치를 계산 후 새로 얻는 데이터로 그리는 것이 유리함\n\nDistribution\ngeom_histogram(), geom_freqploy(), geom_density()\n\n# y축에 표시되는 통계치들이 계산됨\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 100) # binwidth vs. bins\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, colour = sex)) +\n  geom_freqpoly(binwidth = 100)\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, colour = sex)) +\n  geom_density(bw = 100) # bw: band width\n\n\n\n\n\n\n\n\nBoxplot\nBoxplot은 분포에 대한 정보은 줄어드나, 카테고리별로 간결하게 비교되는 장점\nboxplot()\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n    geom_boxplot()\n\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_boxplot()`).”\n\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g)) +\n    geom_boxplot() +\n    geom_jitter(alpha = .6)\n\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_boxplot()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\ncps <- as_tibble(mosaicData::CPS85)\ncps |>\n    filter(wage < 30) |> \n    ggplot(aes(x = as.factor(educ), y = wage)) +  # as.factor(): numeric을 factor로 변환\n    geom_boxplot()\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = species, y = body_mass_g, fill = sex)) + # color는 box의 테두리 색, fill은 내부색\n  geom_boxplot()\n\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_boxplot()`).”\n\n\n\n\n\n\n\nBarplot\nBarplot은 여러방식으로 쓸 수 있는데, 문법이 조금 복잡하고, 수업에서 거의 사용하지 않을 예정이므로 웹사이트를 참조\nR for Data Science/Layers/Statistical transformations\n\nggplot(data = penguins) + \n  geom_bar(mapping = aes(x = species)) # 개수\n\n\n\n\n\n\nDiscretize\n연속 변수를 임의의 구간으로 나누어 카테고리처럼 적용하기 할 수 있음\ncut_width(), cut_number(), cut_interval()\n\ncut_width(): 구간의 길이를 정함\ncut_number(): 동일한 갯수의 관측값을 갖는 n개의 그룹\ncut_interval(): 동일한 길이의 n개의 그룹\n\n\nggplot(\n  data = penguins,\n  mapping = aes(\n      x = bill_length_mm, y = bill_depth_mm,\n      color = cut_interval(body_mass_g, 3) # body_mass_g의 값을 3개의 동일한 길이의 구간으로 나눔\n  )\n) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1) # span: smoothing 정도 조절\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 2 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "contents/visualize.html#facets",
    "href": "contents/visualize.html#facets",
    "title": "Visualize",
    "section": "Facets",
    "text": "Facets\n카테고리 변수들이 지니는 카테고리들(레벨)로 나누어 그리기\nfacet_wrap(), facet_grid()\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~species) # species의 레벨로 나뉘어짐\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\nfacet_wrap()은 레벨이 많아지면 다음의 facet_grid()와는 다르게 화면크기에 맞춰 다음 줄로 넘어감\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_grid(sex ~ species)  # 행과 열에 각각 sex, species\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\nggplot(\n  data = penguins, \n  aes(x = body_mass_g, y = flipper_length_mm, color = sex) # color 추가\n) +\n  geom_point(alpha = .6) +\n  facet_grid(island ~ species)  # 행과 열에 각각 sex, species\n\nWarning message:\n“Removed 11 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFacet과 color 중 어떤 방식으로 표현하는 것이 유리한가? 밸런스를 잘 선택!\n\n\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  facet_wrap(~species)\n\nggplot(data = penguins, aes(x = body_mass_g, y = flipper_length_mm, color = species)) +\n  geom_point()\n\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”\nWarning message:\n“Removed 2 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "contents/visualize.html#labels",
    "href": "contents/visualize.html#labels",
    "title": "Visualize",
    "section": "Labels",
    "text": "Labels\nlabs() 안에 각 요소별로 지정\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = island)) +\n  geom_smooth() +\n  labs(\n    title = \"Body mass and flipper length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Flipper length (mm)\", y = \"Body mass (g)\",\n    color = \"Species\", shape = \"Island\"\n  )\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n앞으로는 pipe operator와 함께, 축약 형태로\n\ndata = 대신 첫번째 argument 위치에 data frame이 위치\nmapping = 은 두번째 argument 위치에 aes()을 위치\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n은 다음과 같이\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\nPipe operator로 다음과 연결될 수 있음\n\npenguins |>\n    filter(!is.na(sex) & island != \"Torgersen\") |>  # 성별이 missing이 아니고, Torgersen섬은 제외\n    ggplot(aes(x = body_mass_g, y = flipper_length_mm, color = sex)) +\n    geom_point() +\n    geom_smooth() +\n    facet_wrap(~island)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "contents/visualize.html#examples",
    "href": "contents/visualize.html#examples",
    "title": "Visualize",
    "section": "Examples",
    "text": "Examples\n이전에 다뤘던 CPS85 데이터로 보면,\n\ncps <- as_tibble(mosaicData::CPS85) # mosaicData package의 CPS85 데이터셋\ncps |>\n   print() # 생략!\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\ncps |>\n    ggplot(aes(x = wage, color = married)) +\n    geom_freqpoly(binwidth=1)\n\n\n\n\n\ncps |>\n    ggplot(aes(x = wage, color = married)) +\n    geom_freqpoly(binwidth = 1) +\n    facet_wrap(~sex)\n\n\n\n\n\ncps |>\n  ggplot(aes(x = married, y = wage)) +\n  geom_boxplot(width = .2) +\n  geom_jitter(width = .2, alpha = .2, color = \"red\") +\n  scale_y_continuous(label = scales::label_dollar())  # y축 scale의 변경\n\n\n\n\n\ncps |>\n  ggplot(aes(x = married, y = wage, fill = sex)) +\n  geom_boxplot()\n  \n\n\n\n\n\ncps |>\n    filter(wage < 30) |> \n    ggplot(aes(x = sector, y = wage, fill = sex)) +\n    geom_boxplot()\n\n\n\n\n\ncps |>\n    filter(wage < 30) |>\n    ggplot(aes(x = sector, y = wage, fill = sex)) +\n    geom_boxplot() +\n    facet_grid(married ~ .) \n\n\n\n\n\nplot <- cps |>\n  filter(wage < 30) |>\n  ggplot(aes(x = age, y = wage)) +\n  geom_point(alpha = .6) +\n  geom_smooth()\nplot\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n확대, 축소 혹은 제한된 범위에서 보려면 다음 2가지를 구분해야 함\ncoord_cartesian() vs. xlim() or ylim()\n\n\n\nplot + coord_cartesian(xlim = c(18, 40)) # zoom in\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nplot + xlim(18, 40) # data crop\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\nWarning message:\n“Removed 181 rows containing non-finite values (`stat_smooth()`).”\nWarning message:\n“Removed 181 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\ncps |>\n    filter(wage < 30 & sector %in% c(\"manag\", \"manuf\", \"prof\", \"sales\")) |>\n    ggplot(aes(x = age, y = wage, color = sex)) +\n    geom_point() +\n    geom_smooth(se = FALSE, span = 1) +\n    facet_wrap(~sector)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "contents/anova.html",
    "href": "contents/anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "data(CO2)\nw1b1 <- CO2 |> filter(Treatment == \"chilled\") |> select(-Treatment)\n\n\nw1b1 |> print()\n\n   Plant        Type conc uptake\n1    Qc1      Quebec   95   14.2\n2    Qc1      Quebec  175   24.1\n3    Qc1      Quebec  250   30.3\n4    Qc1      Quebec  350   34.6\n5    Qc1      Quebec  500   32.5\n6    Qc1      Quebec  675   35.4\n7    Qc1      Quebec 1000   38.7\n8    Qc2      Quebec   95    9.3\n9    Qc2      Quebec  175   27.3\n10   Qc2      Quebec  250   35.0\n11   Qc2      Quebec  350   38.8\n12   Qc2      Quebec  500   38.6\n13   Qc2      Quebec  675   37.5\n14   Qc2      Quebec 1000   42.4\n15   Qc3      Quebec   95   15.1\n16   Qc3      Quebec  175   21.0\n17   Qc3      Quebec  250   38.1\n18   Qc3      Quebec  350   34.0\n19   Qc3      Quebec  500   38.9\n20   Qc3      Quebec  675   39.6\n21   Qc3      Quebec 1000   41.4\n22   Mc1 Mississippi   95   10.5\n23   Mc1 Mississippi  175   14.9\n24   Mc1 Mississippi  250   18.1\n25   Mc1 Mississippi  350   18.9\n26   Mc1 Mississippi  500   19.5\n27   Mc1 Mississippi  675   22.2\n28   Mc1 Mississippi 1000   21.9\n29   Mc2 Mississippi   95    7.7\n30   Mc2 Mississippi  175   11.4\n31   Mc2 Mississippi  250   12.3\n32   Mc2 Mississippi  350   13.0\n33   Mc2 Mississippi  500   12.5\n34   Mc2 Mississippi  675   13.7\n35   Mc2 Mississippi 1000   14.4\n36   Mc3 Mississippi   95   10.6\n37   Mc3 Mississippi  175   18.0\n38   Mc3 Mississippi  250   17.9\n39   Mc3 Mississippi  350   17.9\n40   Mc3 Mississippi  500   17.9\n41   Mc3 Mississippi  675   18.9\n42   Mc3 Mississippi 1000   19.9\n\n\n\nw1b1 <- w1b1 |>\n    mutate(\n        conc = factor(conc),\n        Plant = factor(Plant, ordered = FALSE)\n    )\n\n\nw1b1 |> pivot_wider(names_from = \"conc\", values_from = \"uptake\")\n\n\n\nA tibble: 6 x 9\n\n    PlantType951752503505006751000\n    <fct><fct><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    Qc1Quebec     14.224.130.334.632.535.438.7\n    Qc2Quebec      9.327.335.038.838.637.542.4\n    Qc3Quebec     15.121.038.134.038.939.641.4\n    Mc1Mississippi10.514.918.118.919.522.221.9\n    Mc2Mississippi 7.711.412.313.012.513.714.4\n    Mc3Mississippi10.618.017.917.917.918.919.9\n\n\n\n\n\nfit <- aov(uptake ~ conc*Type + Error(Plant/conc), w1b1)\nsummary(fit)\n\n\nError: Plant\n          Df Sum Sq Mean Sq F value  Pr(>F)   \nType       1 2667.2  2667.2   60.41 0.00148 **\nResiduals  4  176.6    44.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Plant:conc\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nconc       6 1472.4  245.40   52.52 1.26e-12 ***\nconc:Type  6  428.8   71.47   15.30 3.75e-07 ***\nResiduals 24  112.1    4.67                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(ez)\nw1b1_aov <- ezANOVA(\n    data = w1b1,\n    dv = uptake,\n    wid = Plant,\n    # between = Type,\n    within = conc,\n    # detailed = TRUE,\n    type = 3,\n    # return_aov = TRUE\n)\nw1b1_aov\n\n\n$ANOVA = \nA data.frame: 1 x 7\n\n    EffectDFnDFdFpp<.05ges\n    <chr><dbl><dbl><dbl><dbl><chr><dbl>\n\n\n    2conc63013.60882.09137e-07*0.3031357\n\n\n\n\n\nlmer(uptake ~ conc + (1 | Plant), data = w1b1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: uptake ~ conc + (1 | Plant)\n   Data: w1b1\nREML criterion at convergence: 230.3504\nRandom effects:\n Groups   Name        Std.Dev.\n Plant    (Intercept) 8.870   \n Residual             4.246   \nNumber of obs: 42, groups:  Plant, 6\nFixed Effects:\n(Intercept)      conc175      conc250      conc350      conc500      conc675  \n     11.233        8.217       14.050       14.967       15.417       16.650  \n   conc1000  \n     18.550  \n\n\n\nw1b1 |>\n    ggplot(aes(x = conc, y = uptake, fill = Type)) +\n    geom_boxplot()\n\n\n\n\n\nw1b1\n\n\n\nA data.frame: 42 x 4\n\n    PlantTypeconcuptake\n    <ord><fct><fct><dbl>\n\n\n    1Qc1Quebec95 14.2\n    2Qc1Quebec17524.1\n    3Qc1Quebec25030.3\n    4Qc1Quebec35034.6\n    ...............\n    39Mc3Mississippi350 17.9\n    40Mc3Mississippi500 17.9\n    41Mc3Mississippi675 18.9\n    42Mc3Mississippi100019.9\n\n\n\n\n\nw1b1 |>\n    ggplot(aes(x = conc, y = uptake, color = Type)) +\n    geom_jitter(width = .2) +\n    facet_wrap(~Plant)\n\n\n\n\n\nw1b1 |>\n    ggplot(aes(x = Plant, y = uptake)) +\n    geom_jitter(width = .1)"
  },
  {
    "objectID": "contents/anova.html#blog",
    "href": "contents/anova.html#blog",
    "title": "ANOVA",
    "section": "blog",
    "text": "blog\nhttps://yury-zablotski.netlify.app/post/rma/#introduction\n\n# load(url(\"http://coltekin.net/cagri/R/data/newborn.rda\"))\nnewborn <- read.csv(\"data/newborn.csv\")\nnewborn\n\n\n\nA data.frame: 60 x 3\n\n    participantlanguagerate\n    <int><chr><dbl>\n\n\n    1native 29.01\n    1foreign20.06\n    2native 29.49\n    2foreign31.60\n    .........\n    29native 28.62\n    29foreign20.28\n    30native 16.56\n    30foreign14.68\n\n\n\n\n\nggplot(newborn, aes(language, rate))+\n  geom_violin()+\n  geom_dotplot(binaxis='y', stackdir='center', dotsize=.5)\n\n\n\n\n\nnewborn\n\n\n\nA data.frame: 60 x 3\n\n    participantlanguagerate\n    <fct><fct><dbl>\n\n\n    1native 29.01\n    1foreign20.06\n    2native 29.49\n    2foreign31.60\n    .........\n    29native 28.62\n    29foreign20.28\n    30native 16.56\n    30foreign14.68\n\n\n\n\n\nnewborn |>\n    ggplot(aes(x = language, y = rate, group = participant, color = as.numeric(participant))) +\n    geom_line() +\n    facet_wrap(~participant)\n\n\n\n\n\nnewborn_wide <- newborn |>\n    pivot_wider(names_from = \"language\", values_from = \"rate\") |>\n    mutate(diff = native - foreign)\nnewborn_wide |> print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  <fct>        <dbl>   <dbl>  <dbl>\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# ... with 24 more rows\n\n\n\nt.test(rate ~ language, data = newborn)\n\n\n    Welch Two Sample t-test\n\ndata:  rate by language\nt = -1.7074, df = 57.994, p-value = 0.0931\nalternative hypothesis: true difference in means between group foreign and group native is not equal to 0\n95 percent confidence interval:\n -9.8271059  0.7797726\nsample estimates:\nmean in group foreign  mean in group native \n             31.84367              36.36733 \n\n\n\nsummary(lm(rate ~ language, data = newborn))\n\n\nCall:\nlm(formula = rate ~ language, data = newborn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.8837  -7.4548   0.8927   6.5913  21.8863 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      31.844      1.873  16.997   <2e-16 ***\nlanguagenative    4.524      2.649   1.707   0.0931 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.26 on 58 degrees of freedom\nMultiple R-squared:  0.04786,   Adjusted R-squared:  0.03144 \nF-statistic: 2.915 on 1 and 58 DF,  p-value: 0.0931\n\n\n\nt.test(rate ~ language, data = newborn, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  rate by language\nt = -5.3138, df = 29, p-value = 1.06e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -6.264775 -2.782559\nsample estimates:\nmean difference \n      -4.523667 \n\n\n\nezANOVA(data = newborn, \n                dv = rate, \n                wid = participant,, \n                within = language, \n                detailed = TRUE, \n                type = 3,\n                return_aov = TRUE)\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd        F            p p<.05\n1 (Intercept)   1  29 69791.1078 5791.737 349.4534 1.015654e-17     *\n2    language   1  29   306.9534  315.251  28.2367 1.060479e-05     *\n         ges\n1 0.91953700\n2 0.04785722\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 34.1055\n\nStratum 1: participant\n\nTerms:\n                Residuals\nSum of Squares   5791.737\nDeg. of Freedom        29\n\nResidual standard error: 14.13206\n\nStratum 2: participant:language\n\nTerms:\n                language Residuals\nSum of Squares  306.9534  315.2511\nDeg. of Freedom        1        29\n\nResidual standard error: 3.297078\nEstimated effects are balanced\n\n\n\nlibrary(lme4)\nmodel_lmer <- lmer(rate ~ language + (1 | participant), data = newborn)\nsummary(model_lmer)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: rate ~ language + (1 | participant)\n   Data: newborn\n\nREML criterion at convergence: 394.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.79385 -0.50665 -0.03044  0.42331  2.00234 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n participant (Intercept) 94.42    9.717   \n Residual                10.87    3.297   \nNumber of obs: 60, groups:  participant, 30\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     31.8437     1.8734  16.997\nlanguagenative   4.5237     0.8513   5.314\n\nCorrelation of Fixed Effects:\n            (Intr)\nlanguagentv -0.227\n\n\n\nlibrary(report)\nreport(model_lmer) |> print()\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict rate with language (formula: rate ~ language). The model included\nparticipant as random effect (formula: ~1 | participant). The model's total\nexplanatory power is substantial (conditional R2 = 0.90) and the part related\nto the fixed effects alone (marginal R2) is of 0.05. The model's intercept,\ncorresponding to language = foreign, is at 31.84 (95% CI [28.09, 35.60], t(56)\n= 17.00, p < .001). Within this model:\n\n  - The effect of language [native] is statistically significant and positive\n(beta = 4.52, 95% CI [2.82, 6.23], t(56) = 5.31, p < .001; Std. beta = 0.43,\n95% CI [0.27, 0.60])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\nreport(model_lmer) |>\n    table_long() |>\n    print()\n\nERROR: Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': could not find function \"table_long\"\n\n\n\nlibrary(broom)\nlibrary(emmeans)\nemmeans(model_lmer, pairwise ~ language, adjust = \"bonferroni\")\n\n$emmeans\n language emmean   SE   df lower.CL upper.CL\n foreign    31.8 1.87 32.1     28.0     35.7\n native     36.4 1.87 32.1     32.6     40.2\n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \n\n$contrasts\n contrast         estimate    SE df t.ratio p.value\n foreign - native    -4.52 0.851 29  -5.314  <.0001\n\nDegrees-of-freedom method: kenward-roger \n\n\n\n# install.packages(\"TMB\", type = \"source\")\nplot_model(model_lmer, type = \"diag\")\n\n\n\n\n\n\n\n[[1]]\n\n[[2]]\n[[2]]$participant\n\n\n[[3]]\n\n[[4]]\n\n\n\n\n\n\n\n\n\ncar::influencePlot(model_lmer)\n\n\n\nA data.frame: 4 x 3\n\n    StudResHatCookD\n    <dbl><dbl><dbl>\n\n\n    1 0.71894960.49035830.2486654\n    2-1.16158950.49035830.6491183\n    25 2.80482230.49035833.7846806\n    26-2.51277390.49035833.0375634\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_model(model_lmer)\n\n\nlibrary(effects)\nplot(allEffects(model_lmer))\n\n\n\n\n\nlibrary(sjPlot)\ntab_model(model_lmer, p.style = \"scientific\")"
  },
  {
    "objectID": "contents/anova.html#appendix-mlm",
    "href": "contents/anova.html#appendix-mlm",
    "title": "ANOVA",
    "section": "Appendix MLM",
    "text": "Appendix MLM\n\nOBrienKaiser <- carData::OBrienKaiser\nOBrienKaiser\n\n\n\nA data.frame: 16 x 17\n\n    treatmentgenderpre.1pre.2pre.3pre.4pre.5post.1post.2post.3post.4post.5fup.1fup.2fup.3fup.4fup.5\n    <fct><fct><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    1controlM124213253223244\n    2controlM445342235345641\n    3controlM565774575476976\n    4controlF547542235344534\n    ......................................................\n    13BF556864668677 8108\n    14BF223125675267 8 63\n    15BF223446679777 8 67\n    16BF45754778677810 87\n\n\n\n\n\nphase <- factor(rep(c(\"pretest\", \"posttest\", \"followup\"), c(5, 5, 5)),\n    levels=c(\"pretest\", \"posttest\", \"followup\"))\nhour <- ordered(rep(1:5, 3))\nidata <- data.frame(phase, hour)\nidata\n\n\n\nA data.frame: 15 x 2\n\n    phasehour\n    <fct><ord>\n\n\n    pretest1\n    pretest2\n    pretest3\n    pretest4\n    ......\n    followup2\n    followup3\n    followup4\n    followup5\n\n\n\n\n\nOBrien.long <- reshape(OBrienKaiser,\n    varying=c(\"pre.1\", \"pre.2\", \"pre.3\", \"pre.4\", \"pre.5\",\n        \"post.1\", \"post.2\", \"post.3\", \"post.4\", \"post.5\",\n        \"fup.1\", \"fup.2\", \"fup.3\",  \"fup.4\", \"fup.5\"),\n    v.names=\"score\",\n    timevar=\"phase.hour\", direction=\"long\")\nOBrien.long$phase <- ordered(\n      c(\"pre\", \"post\", \"fup\")[1 + ((OBrien.long$phase.hour - 1) %/% 5)],\n    levels=c(\"pre\", \"post\", \"fup\"))\nOBrien.long$hour <- ordered(1 + ((OBrien.long$phase.hour - 1) %% 5))\n\n\nOBrien.long\n\n\n\nA data.frame: 240 x 7\n\n    treatmentgenderphase.hourscoreidphasehour\n    <fct><fct><int><dbl><int><ord><ord>\n\n\n    1.1controlM111pre1\n    2.1controlM142pre1\n    3.1controlM153pre1\n    4.1controlF154pre1\n    ........................\n    13.15BF15813fup5\n    14.15BF15314fup5\n    15.15BF15715fup5\n    16.15BF15716fup5\n\n\n\n\n\nmod.ok <- lm(cbind(pre.1, pre.2, pre.3, pre.4, pre.5,\n                     post.1, post.2, post.3, post.4, post.5,\n                     fup.1, fup.2, fup.3, fup.4, fup.5) ~  treatment*gender,\n                data=OBrienKaiser)\nmod.ok\n\n\nCall:\nlm(formula = cbind(pre.1, pre.2, pre.3, pre.4, pre.5, post.1, \n    post.2, post.3, post.4, post.5, fup.1, fup.2, fup.3, fup.4, \n    fup.5) ~ treatment * gender, data = OBrienKaiser)\n\nCoefficients:\n                    pre.1       pre.2       pre.3       pre.4       pre.5     \n(Intercept)          3.903e+00   4.278e+00   5.431e+00   4.611e+00   4.139e+00\ntreatment1           1.181e-01   1.389e-01  -7.639e-02   1.806e-01   1.944e-01\ntreatment2          -2.292e-01  -3.333e-01  -1.458e-01  -7.083e-01  -6.667e-01\ngender1             -6.528e-01  -7.778e-01  -1.806e-01  -1.111e-01  -6.389e-01\ntreatment1:gender1  -4.931e-01  -3.889e-01  -5.486e-01  -1.806e-01  -1.944e-01\ntreatment2:gender1   6.042e-01   5.833e-01   2.708e-01   7.083e-01   1.167e+00\n                    post.1      post.2      post.3      post.4      post.5    \n(Intercept)          5.028e+00   5.542e+00   6.917e+00   6.361e+00   4.833e+00\ntreatment1           7.639e-01   8.958e-01   8.333e-01   7.222e-01   9.167e-01\ntreatment2           2.917e-01   1.875e-01  -2.500e-01   8.333e-02  -2.047e-17\ngender1             -8.611e-01  -4.583e-01  -4.167e-01  -5.278e-01  -1.000e+00\ntreatment1:gender1  -6.806e-01  -6.042e-01  -3.333e-01  -5.556e-01  -5.000e-01\ntreatment2:gender1   9.583e-01   6.875e-01   2.500e-01   9.167e-01   1.250e+00\n                    fup.1       fup.2       fup.3       fup.4       fup.5     \n(Intercept)          6.014e+00   6.153e+00   7.778e+00   6.167e+00   5.347e+00\ntreatment1           9.236e-01   1.035e+00   1.097e+00   9.583e-01   8.819e-01\ntreatment2          -6.250e-02  -6.250e-02  -1.250e-01   1.250e-01   2.292e-01\ngender1             -5.972e-01  -9.028e-01  -7.778e-01  -8.333e-01  -4.306e-01\ntreatment1:gender1  -2.153e-01  -1.597e-01  -3.472e-01  -4.167e-02  -1.736e-01\ntreatment2:gender1   6.875e-01   1.187e+00   8.750e-01   1.125e+00   3.958e-01\n\n\n\nlibrary(car)\n(av.ok <- Anova(mod.ok, idata=idata, idesign=~phase*hour, type=3))\n\n\nType III Repeated Measures MANOVA Tests: Pillai test statistic\n                            Df test stat approx F num Df den Df    Pr(>F)    \n(Intercept)                  1   0.96736  296.389      1     10 9.241e-09 ***\ntreatment                    2   0.44075    3.940      2     10 0.0547069 .  \ngender                       1   0.26789    3.659      1     10 0.0848003 .  \ntreatment:gender             2   0.36350    2.855      2     10 0.1044692    \nphase                        1   0.81363   19.645      2      9 0.0005208 ***\ntreatment:phase              2   0.69621    2.670      4     20 0.0621085 .  \ngender:phase                 1   0.06614    0.319      2      9 0.7349696    \ntreatment:gender:phase       2   0.31060    0.919      4     20 0.4721498    \nhour                         1   0.93286   24.315      4      7 0.0003345 ***\ntreatment:hour               2   0.31634    0.376      8     16 0.9183275    \ngender:hour                  1   0.33922    0.898      4      7 0.5129764    \ntreatment:gender:hour        2   0.57022    0.798      8     16 0.6131884    \nphase:hour                   1   0.56043    0.478      8      3 0.8202673    \ntreatment:phase:hour         2   0.66238    0.248     16      8 0.9915531    \ngender:phase:hour            1   0.71151    0.925      8      3 0.5894907    \ntreatment:gender:phase:hour  2   0.79277    0.328     16      8 0.9723693    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "contents/repeated.html",
    "href": "contents/repeated.html",
    "title": "Repeated ANOVA",
    "section": "",
    "text": "newborn <- read.csv(\"data/newborn.csv\")\nnewborn <- newborn |>\n    mutate(\n        participant = factor(participant),\n        language = factor(language)\n    )\nnewborn |>\n    as_tibble() |>\n    print()\n\n# A tibble: 60 x 3\n  participant language  rate\n  <fct>       <fct>    <dbl>\n1 1           native    29.0\n2 1           foreign   20.1\n3 2           native    29.5\n4 2           foreign   31.6\n5 3           native    50.9\n6 3           foreign   53.7\n# i 54 more rows\n\n\n\n# wide format\nnewborn_wide <- newborn |>\n    pivot_wider(names_from = \"language\", values_from = \"rate\") |>\n    mutate(diff = native - foreign)\nnewborn_wide |> print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  <fct>        <dbl>   <dbl>  <dbl>\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# i 24 more rows\n\n\n\n\nAssuming the newborn data came from two independent groups of babies (no baby is tested twice), test whether the babies respond diﬀerently to their native language and the foreign language.\nTwo normal Q-Q plots, one for each language, and var.test() testing for equivalence of variances would be ways to test for normality and homogeneity of variance assumptions. A boxplot() is also useful for visualizing the distributions of both groups.\n\nnewborn |>\n    ggplot(aes(x = language, y = rate)) +\n    geom_boxplot(fill = \"white\") +\n    geom_jitter(width = .2)\n\n\n\n\n\nnewborn |>\n    ggplot(aes(x = language, y = rate, group = participant, color = as.numeric(participant))) +\n    geom_line() +\n    facet_wrap(~participant)\n\n\n\n\n\nlibrary(broom)\n\nmod_ind <- lm(rate ~ language, data = newborn)  # assumes independence\ntidy(mod_ind) |> print(digits = 2)\n\n# A tibble: 2 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)       31.8       1.87     17.0  3.39e-24\n2 languagenative     4.52      2.65      1.71 9.31e- 2\n\n\n\nt.test(rate ~ language, data = newborn)  # assumes independence\n\n\n    Welch Two Sample t-test\n\ndata:  rate by language\nt = -1.7074, df = 57.994, p-value = 0.0931\nalternative hypothesis: true difference in means between group foreign and group native is not equal to 0\n95 percent confidence interval:\n -9.8271059  0.7797726\nsample estimates:\nmean in group foreign  mean in group native \n             31.84367              36.36733 \n\n\n\nlibrary(car)\nqqPlot(mod_ind)\n\n\n654\n\n\n\n\n\n\nresidualPlots(mod_ind)\n\n\n\n\n\nvar.test(rate ~ language, data = newborn)\n\n\n    F test to compare two variances\n\ndata:  rate by language\nF = 0.98053, num df = 29, denom df = 29, p-value = 0.9581\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.4666972 2.0600871\nsample estimates:\nratio of variances \n         0.9805289 \n\n\n\n\n\nPerform a paired t test. Compare your results and to the independent-samples t test you have just performed.\n\nt.test(rate ~ language, data = newborn, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  rate by language\nt = -5.3138, df = 29, p-value = 1.06e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -6.264775 -2.782559\nsample estimates:\nmean difference \n      -4.523667 \n\n\n\nnewborn_wide |> print()\n\n# A tibble: 30 x 4\n  participant native foreign   diff\n  <fct>        <dbl>   <dbl>  <dbl>\n1 1             29.0    20.1  8.95 \n2 2             29.5    31.6 -2.11 \n3 3             50.9    53.7 -2.81 \n4 4             55.2    47.7  7.44 \n5 5             26.8    25.9  0.970\n6 6             45.1    37.6  7.57 \n# i 24 more rows\n\n\n\nnewborn_wide |>\n    ggplot(aes(x = diff)) +\n    geom_freqpoly(binwidth = 2)\n\n\n\n\n\nqqPlot(newborn_wide$diff)\n\n\n1322\n\n\n\n\n\n\n\nIn this case, we tell aov() that the response corresponding to every level of language is measured for each participant. The speciﬁcation of the error term could be confusing at ﬁrst sight. Within the Error() term, the part before the slash ‘/’ speciﬁes the ‘case’ or ‘subject’ variable. The part after the slash speciﬁes the ‘within subject’ variable(s).\nHowever, aov() does not run any diagnostics or present corrected results in case of violation of the assumptions, does not report any eﬀect size, cannot handle unbalanced designs or missing data.\nWe will only present an example using ezANOVA() from the package ez. However, when things are not perfectly balanced, and neat, the repeated-measures ANOVA becomes diﬃcult to interpret. One reasonable course of action when ANOVA design becomes too complicated, or assumptions are violated at some level is to switch to so-called mixed-eﬀect models which also oﬀer some other beneﬁts.\n\nm <- aov(rate ~ language + Error(participant / language), data = newborn)\nsummary(m)\n\n\nError: participant\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals 29   5792   199.7               \n\nError: participant:language\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nlanguage   1  306.9  306.95   28.24 1.06e-05 ***\nResiduals 29  315.2   10.87                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nlibrary(ez)\n# The ez package defaults to the “median-centered” ANOVA, which is usually more robust then “mean-centered”.\n# The ez package also defaults to the “Satterthwaite” approximation for the degrees of freedom, which is usually more robust than the “Kenward-Roger” approximation.\nezANOVA(data = newborn, \n                dv = rate, \n                wid = participant,, \n                within = language, \n                detailed = TRUE, \n                type = 3,\n                return_aov = TRUE)\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd        F            p p<.05\n1 (Intercept)   1  29 69791.1078 5791.737 349.4534 1.015654e-17     *\n2    language   1  29   306.9534  315.251  28.2367 1.060479e-05     *\n         ges\n1 0.91953700\n2 0.04785722\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 34.1055\n\nStratum 1: participant\n\nTerms:\n                Residuals\nSum of Squares   5791.737\nDeg. of Freedom        29\n\nResidual standard error: 14.13206\n\nStratum 2: participant:language\n\nTerms:\n                language Residuals\nSum of Squares  306.9534  315.2511\nDeg. of Freedom        1        29\n\nResidual standard error: 3.297078\nEstimated effects are balanced\n\n\n\nlibrary(lme4)\nmodel_lmer <- lmer(rate ~ language + (1 | participant), data = newborn)\nsummary(model_lmer)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: rate ~ language + (1 | participant)\n   Data: newborn\n\nREML criterion at convergence: 394.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.79385 -0.50665 -0.03044  0.42331  2.00234 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n participant (Intercept) 94.42    9.717   \n Residual                10.87    3.297   \nNumber of obs: 60, groups:  participant, 30\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     31.8437     1.8734  16.997\nlanguagenative   4.5237     0.8513   5.314\n\nCorrelation of Fixed Effects:\n            (Intr)\nlanguagentv -0.227\n\n\n\nlibrary(effects)\nplot(allEffects(model_lmer))"
  },
  {
    "objectID": "contents/repeated.html#exercise-5.8.",
    "href": "contents/repeated.html#exercise-5.8.",
    "title": "Repeated ANOVA",
    "section": "Exercise 5.8.",
    "text": "Exercise 5.8.\nPerform a repeated measures ANOVA that tests the eﬀect of language and age on mlu in the bilingual data set\n\nlibrary(ez)\n# The ez package defaults to the “median-centered” ANOVA, which is usually more robust then “mean-centered”.\n# The ez package also defaults to the “Satterthwaite” approximation for the degrees of freedom, which is usually more robust than the “Kenward-Roger” approximation.\n\n\nmod_bilingual <- ezANOVA(\n        data = bilingual,\n        dv = mlu,\n        wid = .(subj),\n        within = .(language, age),\n        between = gender,\n        type = 3,\n        # detailed = TRUE, \n        # return_aov = TRUE\n)\nmod_bilingual |> print(digits = 2)\n\n$ANOVA\n               Effect DFn DFd       F       p p<.05     ges\n2              gender   1  18 2.9e-04 9.9e-01       0.00001\n3            language   1  18 6.8e+00 1.8e-02     * 0.03377\n5                 age   2  36 1.7e+01 5.1e-06     * 0.14702\n4     gender:language   1  18 2.0e-01 6.6e-01       0.00102\n6          gender:age   2  36 6.5e-01 5.3e-01       0.00636\n7        language:age   2  36 3.1e+00 5.9e-02       0.01659\n8 gender:language:age   2  36 1.4e+00 2.5e-01       0.00776\n\n$`Mauchly's Test for Sphericity`\n               Effect    W    p p<.05\n5                 age 0.99 0.95      \n6          gender:age 0.99 0.95      \n7        language:age 0.99 0.92      \n8 gender:language:age 0.99 0.92      \n\n$`Sphericity Corrections`\n               Effect  GGe   p[GG] p[GG]<.05 HFe   p[HF] p[HF]<.05\n5                 age 0.99 5.4e-06         * 1.1 5.1e-06         *\n6          gender:age 0.99 5.3e-01           1.1 5.3e-01          \n7        language:age 0.99 5.9e-02           1.1 5.9e-02          \n8 gender:language:age 0.99 2.5e-01           1.1 2.5e-01          \n\n\n\n\nlibrary(lme4)\nmlm <- lmer(data = bilingual, mlu ~ age*language + (1|subj))\n\n\nsummary(mlm)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: mlu ~ age * language + (1 | subj)\n   Data: bilingual\n\nREML criterion at convergence: 360.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.48540 -0.54268 -0.04216  0.55965  2.27307 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subj     (Intercept) 0.9997   0.9999  \n Residual             0.8344   0.9135  \nNumber of obs: 120, groups:  subj, 20\n\nFixed effects:\n                              Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)                     3.8880     0.3028 45.8663  12.839  < 2e-16 ***\nagefirstgrade                   0.3625     0.2889 95.0000   1.255  0.21262    \nagesecondgrade                  0.9106     0.2889 95.0000   3.152  0.00217 ** \nlanguageschool                  0.1336     0.2889 95.0000   0.462  0.64482    \nagefirstgrade:languageschool    0.2541     0.4085 95.0000   0.622  0.53538    \nagesecondgrade:languageschool   0.8145     0.4085 95.0000   1.994  0.04903 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) agfrst agscnd lnggsc agfrs:\nagefirstgrd -0.477                            \nagesecndgrd -0.477  0.500                     \nlanguagschl -0.477  0.500  0.500              \nagfrstgrd:l  0.337 -0.707 -0.354 -0.707       \nagscndgrd:l  0.337 -0.354 -0.707 -0.707  0.500\n\n\n\nlibrary(report)\nreport(mlm) |> print()\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\nto predict mlu with age and language (formula: mlu ~ age * language). The model\nincluded subj as random effect (formula: ~1 | subj). The model's total\nexplanatory power is substantial (conditional R2 = 0.62) and the part related\nto the fixed effects alone (marginal R2) is of 0.17. The model's intercept,\ncorresponding to age = preschool and language = home.only, is at 3.89 (95% CI\n[3.29, 4.49], t(112) = 12.84, p < .001). Within this model:\n\n  - The effect of age [firstgrade] is statistically non-significant and positive\n(beta = 0.36, 95% CI [-0.21, 0.93], t(112) = 1.25, p = 0.212; Std. beta = 0.25,\n95% CI [-0.14, 0.64])\n  - The effect of age [secondgrade] is statistically significant and positive\n(beta = 0.91, 95% CI [0.34, 1.48], t(112) = 3.15, p = 0.002; Std. beta = 0.62,\n95% CI [0.23, 1.01])\n  - The effect of language [school] is statistically non-significant and positive\n(beta = 0.13, 95% CI [-0.44, 0.71], t(112) = 0.46, p = 0.645; Std. beta = 0.09,\n95% CI [-0.30, 0.48])\n  - The interaction effect of language [school] on age [firstgrade] is\nstatistically non-significant and positive (beta = 0.25, 95% CI [-0.56, 1.06],\nt(112) = 0.62, p = 0.535; Std. beta = 0.17, 95% CI [-0.38, 0.73])\n  - The interaction effect of language [school] on age [secondgrade] is\nstatistically significant and positive (beta = 0.81, 95% CI [5.10e-03, 1.62],\nt(112) = 1.99, p = 0.049; Std. beta = 0.56, 95% CI [3.49e-03, 1.11])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "contents/baser.html",
    "href": "contents/baser.html",
    "title": "Base R",
    "section": "",
    "text": "90년대에 통계 분석을 위해 개발된 R 언어와 대비하여, 좀 더 직관적이고 효율적인 데이터 분석을 위해 새로운 문법이 R내의 패키지 형태로 구현되었는데 이 새로운 생태계 안의 패키지들의 모임이 Tidyverse라는 이름하에 발전하고 있음: Tidyverse\n이 패키지들은 design philosophy, grammar, data structures를 공유하며 유기적으로 작동됨.\n기존 R의 문법과는 상당한 차이가 있어 단점도 지적되고 있고, 소위 base-R을 고수하는 사람들과 tidyverse를 기본으로 사용하는 사람들이 나뉘어 있다고 알려져 있음.\n아마도 빠르게 발전하고 있는 tidyverse/tidymodel 생태계의 언어들이 기본으로 자리잡지 않을까 함.\n본 강의에서는 주로 tidyverse의 언어로만 분석하고자 함."
  },
  {
    "objectID": "contents/baser.html#r의-데이터-구조와-변수-타입",
    "href": "contents/baser.html#r의-데이터-구조와-변수-타입",
    "title": "Base R",
    "section": "R의 데이터 구조와 변수 타입",
    "text": "R의 데이터 구조와 변수 타입\n주로 vector (벡터)와 data frame (데이터프레임)을 다룸\n\nSource: R in Action by Rob Kabacoff\nData frame의 예\n\n각 column이 하나의 variable (변수)를 구성하고, 한가지 타입의 데이터로 이루어짐\n\n각 Row가 하나의 observation (관측치)을 구성함.\n\n이러한 형태를 갖춘 데이터를 tidy라고도 부르며, 이를 벗어난 형태의 경우 가공이 필요함.\nex. “m23”: male이고 23세임을 나타내는 표기도 있음\n\n\nlibrary(tidyverse)\n\ncps <- mosaicData::CPS85 # mosaicData package의 CPS85 데이터셋\ncps # data.frame\n\n\ncps <- as_tibble(cps) # tibble vs. data.frame\nprint(cps) # print는 생략해도 됨\n\n# A tibble: 534 × 11\n   wage  educ race  sex   hispanic south married exper union   age sector  \n  <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# … with 528 more rows\n\n\n\n# Dataset의 설명\nhelp(CPS85, package=\"mosaicData\") # 또는\n?mosaicData::CPS85"
  },
  {
    "objectID": "contents/baser.html#vector",
    "href": "contents/baser.html#vector",
    "title": "Base R",
    "section": "Vector",
    "text": "Vector\n한 가지 타입으로만 구성: 숫자 (numeric), 문자 (character), 논리형 (logical), factor, etc\n\nvar <- c(1, 2, 5, 3, 6, -2, 4) # 변수에 assign: '=' 대신 '<-'\nnm <- c(\"one\", \"two\", \"three\")\ntf <- c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE)\n\n# 타입 확인\nclass(var)\n## [1] \"numeric\"\n\nclass(nm)\n## [1] \"character\"\n\nclass(tf)\n## [1] \"logical\"\n\n\n원소의 추출 및 대체\n다음은 원소를 추출, 대체하는 R의 native한 방식임\n수업에서는 뒤에서 다룰 tidyverse 문법을 주로 활용할 것임\nVector의 경우\n\nvar\n## [1]  1  2  5  3  6 -2  4\n\nvar[3]\n## [1] 5\n\nvar[c(1, 3, 5)]\n## [1] 1 5 6\n\nvar[2:6] # \":\"\" slicing: c(2, 3, 4, 5, 6)\n## [1]  2  5  3  6 -2\n\nvar[c(1, 3:5)] # 혼합\n## [1] 1 5 3 6\n\nvar[-c(1, 3)] # \"-\"는 제외라는 의미\n## [1]  2  3  6 -2  4\n\nc(10, var, 100, 101) # 추가\n##  [1]  10   1   2   5   3   6  -2   4 100 101\n\nvar[2] <- 55 # 대체\n## var\n## [1]  1 55  5  3  6 -2  4\n\nvar[c(2, 5)] <- c(200, 500) # 대체\n## var\n## [1]   1 200   5   3 500  -2   4\n\n# numeric 벡터의 연산: recycling rule\n1:5 * 2\n## [1]  2  4  6  8 10\n\nc(1, 3, 5) - 5\n## [1] -4 -2  0\n\nc(2, 4, 6) / 2\n## [1] 1 2 3\n\nc(1, 3) * c(2, 4)\n## [1]  2 12\n\nc(1, 3) - c(2, 4)\n## [1] -1 -1"
  },
  {
    "objectID": "contents/baser.html#factor",
    "href": "contents/baser.html#factor",
    "title": "Base R",
    "section": "Factor",
    "text": "Factor\nVector로서 명목변수(카테고리)를 다룸\npatientID <- c(1, 2, 1, 3)\ndiabetes <- c(\"Type1\", \"Type2\", \"Type1\", \"Type1\")\nstatus <- c(\"Poor\", \"Improved\", \"Excellent\", \"Poor\")\n\n# factor로 변환: 알파벳 순서로 levels의 순서가 정해짐\nfactor(patientID)\n## [1] 1 2 1 3\n## Levels: 1 2 3\n\nfactor(diabetes)\n## [1] Type1 Type2 Type1 Type1\n## Levels: Type1 Type2\n\nfactor(status, order = TRUE) # order를 표시\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Excellent < Improved < Poor\n\n# 구체적으로 표시하는 것을 추천: 지정한 성분 순서대로 levels의 순서가 정해짐\nfactor(status, levels = c(\"Poor\", \"Improved\", \"Excellent\"),\n                                         order = TRUE)\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Poor < Improved < Excellent\n\n# order가 없을시\nfactor(status, levels = c(\"Poor\", \"Improved\", \"Excellent\"))\n## [1] Poor      Improved  Excellent Poor     \n## Levels: Poor Improved Excellent\n\n# 대표적으로 성별을 코딩할 때: 숫자대신 레이블로 표시\nsex <- c(1, 2, 1, 1, 1, 2, 2, 1)\nfactor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\n## [1] Male   Female Male   Male   Male   Female Female Male  \n## Levels: Male Female\n\nsex_fct <- factor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\n\nlevels(sex) # 레벨 확인\n## NULL\nlevels(sex_fct) # 레벨 확인\n## [1] \"Male\"   \"Female\"\n\nsex\n## [1] 1 2 1 1 1 2 2 1\nsex_fct\n## [1] Male   Female Male   Male   Male   Female Female Male  \n## Levels: Male Female"
  },
  {
    "objectID": "contents/baser.html#data-frame",
    "href": "contents/baser.html#data-frame",
    "title": "Base R",
    "section": "Data Frame",
    "text": "Data Frame\n\n데이터 프레임의 구성\n# 벡터들로부터 데이터 프레임 구성\npatientID <- c(1, 2, 3, 4)\nage <- c(25, 34, 28, 52)\ndiabetes <- c(\"Type1\", \"Type2\", \"Type1\", \"Type1\")\nstatus <- c(\"Poor\", \"Improved\", \"Excellent\", \"Poor\")\n\npatientdata <- data.frame(patientID, age, diabetes, status)\n\npatientdata\n##   patientID age diabetes    status\n## 1         1  25    Type1      Poor\n## 2         2  34    Type2  Improved\n## 3         3  28    Type1 Excellent\n## 4         4  52    Type1      Poor\n\nmidterm <- data.frame(english = c(90, 80, 60, 70),\n                      math = c(50, 60, 100, 20),\n                      class = c(1, 1, 2, 2))\nmidterm\n##   english math class\n## 1      90   50     1\n## 2      80   60     1\n## 3      60  100     2\n## 4      70   20     2\n\n\n원소의 추출 및 대체\n# 원소의 추출\npatientdata[1:2] # 변수의 열을 지정\n##   patientID age\n## 1         1  25\n## 2         2  34\n## 3         3  28\n## 4         4  52\n\npatientdata[c(\"diabetes\", \"status\")] # 열 이름을 지정\n##   diabetes    status\n## 1    Type1      Poor\n## 2    Type2  Improved\n## 3    Type1 Excellent\n## 4    Type1      Poor\n\npatientdata[c(1, 3), c(\"age\", \"status\")] # 행과 열을 모두 지정\n##   age    status\n## 1  25      Poor\n## 3  28 Excellent\n\npatientdata[c(1, 3), c(2, 4)]\n##   age    status\n## 1  25      Poor\n## 3  28 Excellent\n\npatientdata[, 1:2] # patientdata[1:2]과 동일, 빈칸은 모든 행을 의미\n##   patientID age\n## 1         1  25\n## 2         2  34\n## 3         3  28\n## 4         4  52\n\npatientdata[1:2, ] # 빈칸은 모든 열을 의미\n##   patientID age diabetes   status\n## 1         1  25    Type1     Poor\n## 2         2  34    Type2 Improved\n\npatientdata[-1] # 열 제외\n##   age diabetes    status\n## 1  25    Type1      Poor\n## 2  34    Type2  Improved\n## 3  28    Type1 Excellent\n## 4  52    Type1      Poor\n\npatientdata[-c(1, 3)] # 열 제외\n##   age    status\n## 1  25      Poor\n## 2  34  Improved\n## 3  28 Excellent\n## 4  52      Poor\n\npatientdata[-c(1:2), 2:4] # 행 제외 & 열 선택\n##   age diabetes    status\n## 3  28    Type1 Excellent\n## 4  52    Type1      Poor\n\n\n# 변수/열의 성분을 벡터로 추출: $ 또는 [[ ]]을 이용\npatientdata$age # $를 이용\n## [1] 25 34 28 52\n\nclass(patientdata$age) # numeric vector임을 확인\n## [1] \"numeric\"\n\npatientdata[[\"age\"]] # patientdata$age과 동일, [[ ]] doule bracket을 이용해 벡터로 추출\n## [1] 25 34 28 52\n\npatientdata[[2]] # 열의 위치를 이용해도 동일한 추출\n## [1] 25 34 28 52\n\npatientdata[\"age\"] # [ ] single bracket은 열을 선택하는 것으로 데이터 프레임으로 추출\n##   age\n## 1  25\n## 2  34\n## 3  28\n## 4  52\n\npatientdata[2] # 2번째 열을 추출; patientdata[\"age\"]과 동일\n##   age\n## 1  25\n## 2  34\n## 3  28\n## 4  52\n\n\n데이터의 추가 및 대체\n# 데이터 추가\npatientdata$gender <- c(1, 1, 2, 2) \n\npatientdata\n##   patientID age diabetes    status gender\n## 1         1  25    Type1      Poor      1\n## 2         2  34    Type2  Improved      1\n## 3         3  28    Type1 Excellent      2\n## 4         4  52    Type1      Poor      2\n\n# 데이터 대체\npatientdata[c(1,3), \"age\"] # 혼동: 원칙적으로 데이터프레임으로 추출되어야하나 벡터로 추출됨\n## [1] 25 28\n\npatientdata[c(1,3), \"age\"] <- c(88, 99)\npatientdata\n##   patientID age diabetes    status gender\n## 1         1  88    Type1      Poor      1\n## 2         2  34    Type2  Improved      1\n## 3         3  99    Type1 Excellent      2\n## 4         4  52    Type1      Poor      2\n\n\n# 참고\nrow.names(patientdata) # 데이터 프레임의 행 이름\n## [1] \"1\" \"2\" \"3\" \"4\"\n\nrow.names(patientdata) <- c(\"a\", \"b\", \"c\", \"d\")\npatientdata\n##   patientID age diabetes    status gender\n## a         1  88    Type1      Poor      1\n## b         2  34    Type2  Improved      1\n## c         3  99    Type1 Excellent      2\n## d         4  52    Type1      Poor      2"
  },
  {
    "objectID": "contents/baser.html#tibble",
    "href": "contents/baser.html#tibble",
    "title": "Base R",
    "section": "Tibble",
    "text": "Tibble\n기존 data.frame의 단점을 보안한 tidyverse에서 기본이 되는 데이터 형식\n\nData frame vs. tibble\nPrinting의 차이\ncps <- mosaicData::CPS85 # data.frame\ncps\n#   wage educ race sex hispanic south married exper union age   sector\n# 1  9.0   10    W   M       NH    NS Married    27   Not  43    const\n# 2  5.5   12    W   M       NH    NS Married    20   Not  38    sales\n# 3  3.8   12    W   F       NH    NS  Single     4   Not  22    sales\n# 4 10.5   12    W   F       NH    NS Married    29   Not  47 clerical\n# 5 15.0   12    W   M       NH    NS Married    40 Union  58    const\n# 6  9.0   16    W   F       NH    NS Married    27   Not  49 clerical\n...\n\ncps_tibble <- as_tibble(cps)\ncps_tibble\n# # A tibble: 534 × 11\n#    wage  educ race  sex   hispanic south married exper union   age sector  \n#   <dbl> <int> <fct> <fct> <fct>    <fct> <fct>   <int> <fct> <int> <fct>   \n# 1   9      10 W     M     NH       NS    Married    27 Not      43 const   \n# 2   5.5    12 W     M     NH       NS    Married    20 Not      38 sales   \n# 3   3.8    12 W     F     NH       NS    Single      4 Not      22 sales   \n# 4  10.5    12 W     F     NH       NS    Married    29 Not      47 clerical\n# 5  15      12 W     M     NH       NS    Married    40 Union    58 const   \n# 6   9      16 W     F     NH       NS    Married    27 Not      49 clerical\n# # … with 528 more rows\n그 외의 차이는 R for Data Science/10.3 Tibbles vs. data.frame을 참고"
  },
  {
    "objectID": "contents/inference.html",
    "href": "contents/inference.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "평균이 \\(\\mu\\) 이고 분산이 \\(\\sigma^2\\) 인 모집단으로부터 추출된 표본 사이즈가 \\(n\\) (size=\\(n\\))인 표본들에 대해서\n\nSource: The Truthful Art by Albert Cairo.\n표본 평균들 \\(\\bar{X}\\) 의 분포를 평균의 표본 분포, the sampling distribution of the mean 이라고 하고, 이 분포는 the central limit theorem에 의해\n\n평균:  \\(\\displaystyle E(\\bar{X})=\\frac{m_1+m_2+m_3+\\cdots+m_w}{w}\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\mu\\) ; unbiased estimator (mean or regression coefficient vs. R)\n분산:  \\(\\displaystyle V(\\bar{X})\\Bigg|_{w\\rightarrow\\infty}\\rightarrow ~~~\\frac{\\sigma^2}{n},\\)   표준 편차 \\(\\displaystyle\\frac{\\sigma}{\\sqrt{n}}\\) 를 standard error of estimate (SE)라고 함.\n\n이 standard error of estimate는 다시 말하면, 어떤 통계치(여기서는 평균)가 표본들 간에 얼마나 차이가 나는지를 알 수 있는 중요한 지표가 됨.\n\n분포: 모집단의 분포가 normal에 가까울 수록, 또는 표본 크기가 클수록 ( \\(n\\rightarrow\\infty, n > 30\\) ) \\(\\displaystyle\\{m_1, m_2, m_3, \\cdots, m_w, \\cdots\\} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}}) : normal ~ distribution\\) (정규 분포)\n값을 정규화하면; \\(\\displaystyle Z=\\frac{X-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n분포: \\(\\displaystyle\\{z_1, z_2, z_3, \\cdots, z_w, \\cdots\\} \\sim N(0, 1) : standard ~ normal ~ distribution\\) (표준 정균 분포)\n\n실제 예를 통해서 살펴보면,\n예를 들어 어느 섬에 사는 민족의 남성 평균 키가 아래와 같은 분포를 가진다고 할 때 (평균: 173cm, 표준편차: 5cm),\n관찰한 100명의 한 표본에서 남성들의 키가 평균 174cm로 관찰되었다면 이 정도로 큰 값이 나올 가능성은 얼마정도 인가?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b)의 경우 즉, 표본 사이즈가 n = 100인 경우처럼 평균의 표본 분포는 빠르게 정규 분포에 다가가므로 근사적으로 정규 분포의 값을 이용해 그 확률 값을 쉽게 구할 수 있음.\n특히, 값들을 정규화하여 표준정규분포 (평균 0, 표준편차 1)의 값을 이용함.\n\\(\\displaystyle \\frac{174 - 173}{0.5} = 2, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n음영된 부분은 대략 2.3%이고, 따라서 100명을 관찰한 표본의 평균 키가 174cm이상이 될 가능성은 2.3%에 밖에 되지 않음.\n\n\n\n\n\n\n\n실제 성취하고자 하는 유용한 분석은 위 과정의 반대인, 관찰한 특정 표본으로부터 모집단에 대해 추론하는 것임.\n이를 통계적 추론, statistical inference라고 함.\n가령, 어느 섬에 사는 민족으로부터 관찰된 100명의 키의 평균이 175cm이고 표준편차가 10cm인 경우, 이 민족의 키의 평균은 얼마 정도라고 파악할 수 있는가?\n\n먼저, 모집단의 평균 \\(\\mu\\) 를 가정하는데, 가령 \\(\\mu = 173\\) 라면, 우리가 관찰한 표본의 평균 175는 충분히 나올 수 있는 값인가? 이에 대해서는 위의 논리에 따라 구할 수 있음. 즉,\n\n\\(\\displaystyle \\frac{175 - 173}{\\frac{\\sigma}{10}} = ~?, ~~ \\bar{Z}=\\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n만약, 모집단의 표준편차 \\(\\sigma\\) 가 예전처럼 5라면, \\(\\bar{Z} = 4\\) 가 되어 매우 희박한 경우가 될 것임. (실제로 0.0032%)\n모집단의 표준편차를 알 수 없기 때문에 차선책으로, 관찰한 표본의 표준편차를 대체해서 전개함\n이 경우, 표본의 표준편차가 10이기 때문에, \\(\\bar{Z} = 2\\) 가 되어 2.3% 정도의 가능성이 있다고 볼 수 있으나,\n표준편차의 대체로 인해 생기는 문제를 보완할 수 있는데, 사실 표본분포가 정규분포가 아닌 Student’s t-분포를 따르고, 이를 이용해서 확률값을 구함.\n이 경우는 \\(\\displaystyle t = \\frac{\\bar{X}-\\mu}{\\frac{s}{\\sqrt{n}}} = 2, ~ (s: the ~sample ~sd)\\) 로 t-분포에 의하면 2.4% 정도의 가능성이 있다고 봄\n\nt-분포는 자유도(degree of freedom)에 의해 분포가 바뀌는데 df는 n-1 (n: 표본 크기)\n\n\n이제 위의 과정을 계속 반복한다고 상상하면, 즉 모집단의 평균을 다른 값으로 가정하면서,\n\n관찰된 표본 평균 175cm가 95% (양 극단 2.5%를 제외한) 이내에서 관찰될 수 있는 모집단의 평균들을 모두 찾을 수 있음\n이 평균들의 범위를 95% confidence interval 이라고 부르고,\n식으로 전개하면, \\(\\displaystyle\\Bigg| \\frac{m-\\mu}{\\frac{s}{\\sqrt{n}}} \\Bigg| < 1.66, ~(n=100)\\)\n\\(\\displaystyle m-1.66\\frac{s}{\\sqrt{n}} < \\mu < m + 1.66\\frac{s}{\\sqrt{n}}\\)\n위 예의 경우 \\(\\displaystyle 173.34 < \\mu < 176.66\\)\n즉, 우리는 95%의 확신을 갖고, 이 섬에 사는 민족의 평균 키는 173.34cm에서 176.66cm 사이에 있을 것이라고 말할 수 있음.\n이 cofidence interval의 크기를 결정하는 것은 \\(\\displaystyle\\frac{s}{\\sqrt{n}}\\) 즉, standard error of estimate인데, 범위가 좁아질수록, precision이 높다고 표현함.\n한편, 99%의 확신으로 (confidence level: 99%)는 그 키의 범위를 더 넓혀서 말할 수 있음. 이 경우 \\(|~t~| < 2.36\\) 으로부터 모집단의 키가 (172.64cm, 177.36cm) 범위가 있다고 말할 수 있음.\n\n확신이 커지는 대신 범위가 넓어지므로 모집단의 예측에 대한 유용성이 떨어짐.\n\n\n\n\n\n\n위의 논리와 비슷하게 회귀 계수가 표본 마다 얼마나 변하는 지를 구할 수 있고,\n회귀 계수에 대한 confidence interval을 구할 수 있음.\n변수가 한 개인 경우:\n회귀계수 \\(b\\) 에 대한 표본 분포는 평균이 \\(b\\) 인 정규분포를 따르고, 표준편차 즉, standard error of estimate는 근사적으로 다음과 같음\n\\(\\displaystyle SE^2(b) = \\frac{{MS}_{residual}}{N \\cdot Var(X)}\\)\nConfidence interval: \\(b\\pm t_{\\alpha/2}SE, ~(df = N-2)\\)\n다중 회귀 모형의 경우:\n예측변수 \\(X_j\\) 에 대해서 모집단의 회귀계수 \\(b_j\\) 에 대한 표본 분포는 평균이 \\(b_j\\) 인 정규분포를 따르고, 표준편차, 즉 standard error는 근사적으로 다음과 같음.\n\\(\\displaystyle SE^2(b_j) = \\frac{{MS}_{residual}}{N \\cdot Var(X_j) \\cdot (1 - R^2_j)}, ~(df = N-k-1)\\)\n\n표본 사이즈가 클수록\n평균 잔차가 작을수록\njth 예측변수의 값이 퍼져 있을수록\n다른 예측변수들로부터 jth 예측변수가 예측되지 못할수록; 즉 다른 변수들과 correlate되지 않을수록\n\n\\(1 - R^2_j\\) 을 tolerance, 그 역수를 variance inflation factor (VIF)라고 부름\nTolerance가 극히 작은 것은 intolerable! 봐줄 수 없음!\n\n예를 들어, 어느 문화에서 남자아이에게는 자기 주장이 강하도록 훈육하고, 여자아이에게는 반대로 훈육한다고 합니다. 만약, 자기주장이 강하도록 부모가 교육하는 것이 자녀가 자기주장이 강하게 되는데 영향을 미친다는 것을 살펴보는데, 성별을 통계적으로 통제한다면, 훈육의 효과는 통계적으로 계산되기 어렵습니다. 왜냐하면, 성별과 훈육방식이 크게 상관관계를 가지기 때문에, 성별과 독립적인 훈육의 변량이 작아지기 때문에, 회귀계수의 precision이 크게 낮아집니다."
  },
  {
    "objectID": "contents/analysis1.html",
    "href": "contents/analysis1.html",
    "title": "Analysis I",
    "section": "",
    "text": "helping <- read_csv(\"data/altruism_full.csv\")\n\n\nhelping <- helping |>\n    mutate(\n        status = factor(status, levels = c(\"low\", \"high\")),\n        sex = factor(sex)\n    )\n\nhelping |> print()\n\n# A tibble: 168 × 6\n     id status sex    empathy public_sc helping\n  <dbl> <fct>  <fct>    <dbl>     <dbl>   <dbl>\n1     1 high   female    58.1      88.3   33.8 \n2     2 low    female    43.9      29.8   63.8 \n3     3 low    female    76.8      80     61.0 \n4     6 high   male      42.6      45.2    1.23\n5     8 low    male      80.6      52     20.8 \n6     9 high   male      44.2      69.2    7.61\n# … with 162 more rows\n\n\n\nsummary(mod <- lm(helping ~ public_sc * status + empathy, data = helping))\n\n\nCall:\nlm(formula = helping ~ public_sc * status + empathy, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.117 -14.950  -1.137  15.982  48.022 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           -0.3143    11.9954  -0.026  0.97913    \npublic_sc             -0.2133     0.1689  -1.263  0.20849    \nstatushigh           -40.9460    17.0374  -2.403  0.01737 *  \nempathy                0.7392     0.1510   4.895 2.35e-06 ***\npublic_sc:statushigh   0.6423     0.2203   2.916  0.00405 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.68 on 163 degrees of freedom\nMultiple R-squared:  0.293, Adjusted R-squared:  0.2756 \nF-statistic: 16.88 on 4 and 163 DF,  p-value: 1.335e-11\n\n\n\nsummary(mod <- lm(helping ~ scale(public_sc) * status + empathy, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(public_sc) * status + empathy, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.117 -14.950  -1.137  15.982  48.022 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 -16.3357    11.1328  -1.467  0.14421    \nscale(public_sc)             -3.4988     2.7708  -1.263  0.20849    \nstatushigh                    7.3082     3.5847   2.039  0.04310 *  \nempathy                       0.7392     0.1510   4.895 2.35e-06 ***\nscale(public_sc):statushigh  10.5379     3.6139   2.916  0.00405 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.68 on 163 degrees of freedom\nMultiple R-squared:  0.293, Adjusted R-squared:  0.2756 \nF-statistic: 16.88 on 4 and 163 DF,  p-value: 1.335e-11\n\n\n\nlibrary(car)\navPlots(mod)\n\n\n\n\n\nsummary(lm(scale(helping) ~ status, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ status, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.73766 -0.70655 -0.09683  0.73752  1.98321 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  -0.1922     0.1041  -1.846  0.06662 . \nstatushigh    0.4086     0.1518   2.692  0.00782 **\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.9818 on 166 degrees of freedom\nMultiple R-squared:  0.04184,   Adjusted R-squared:  0.03607 \nF-statistic:  7.25 on 1 and 166 DF,  p-value: 0.007819\n\n\n\nsummary(lm(scale(helping) ~ empathy, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ empathy, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01691 -0.65267 -0.03413  0.62921  2.02464 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.296418   0.329699  -6.965 7.31e-11 ***\nempathy      0.031909   0.004484   7.117 3.16e-11 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.878 on 166 degrees of freedom\nMultiple R-squared:  0.2338,    Adjusted R-squared:  0.2292 \nF-statistic: 50.65 on 1 and 166 DF,  p-value: 3.158e-11\n\n\n\nsummary(lm(scale(helping) ~ empathy + status, data = helping))\n\n\nCall:\nlm(formula = scale(helping) ~ empathy + status, data = helping)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.13949 -0.61254 -0.07061  0.60338  1.99294 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.349779   0.326929  -7.187 2.17e-11 ***\nempathy      0.030721   0.004467   6.878 1.20e-10 ***\nstatushigh   0.295364   0.135204   2.185   0.0303 *  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.8682 on 165 degrees of freedom\nMultiple R-squared:  0.2553,    Adjusted R-squared:  0.2463 \nF-statistic: 28.29 on 2 and 165 DF,  p-value: 2.735e-11\n\n\n\nsummary(mod2 <- lm(helping ~ scale(public_sc) * status, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(public_sc) * status, data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-65.885 -16.726  -0.607  17.828  52.431 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  43.864      2.793  15.703  < 2e-16 ***\nscale(public_sc)             15.077      2.824   5.339 3.07e-07 ***\nstatuslow                    -7.042      3.827  -1.840  0.06757 .  \nscale(public_sc):statuslow  -12.154      3.842  -3.163  0.00186 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 24.22 on 164 degrees of freedom\nMultiple R-squared:  0.189, Adjusted R-squared:  0.1742 \nF-statistic: 12.74 on 3 and 164 DF,  p-value: 1.581e-07\n\n\n\nanova(mod2, mod) |> print()\n\nAnalysis of Variance Table\n\nModel 1: helping ~ scale(public_sc) * status\nModel 2: helping ~ scale(public_sc) * status + empathy\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    164 96189                                 \n2    163 83862  1     12327 23.96 2.348e-06 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n\n\nhelping |>\n    ggplot(aes(x = public_sc, y = helping, color = status)) +\n    geom_point() +\n    geom_smooth(method = lm) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\nlibrary(psych)\n# R squared\ncorr.test(helping |> select(empathy:helping))$r^2 |>\n    round(2) |>\n    print()\n\n          empathy public_sc helping\nempathy      1.00      0.41    0.23\npublic_sc    0.41      1.00    0.12\nhelping      0.23      0.12    1.00\n\n\n\nsummary(lm(helping ~ scale(empathy) * scale(public_sc), data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(empathy) * scale(public_sc), data = helping)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.326 -16.613  -0.074  16.524  53.692 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       39.644      2.070  19.151  < 2e-16 ***\nscale(empathy)                    12.013      2.346   5.121 8.42e-07 ***\nscale(public_sc)                   2.301      2.361   0.975   0.3312    \nscale(empathy):scale(public_sc)    2.735      1.620   1.688   0.0932 .  \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 23.3 on 164 degrees of freedom\nMultiple R-squared:  0.2495,    Adjusted R-squared:  0.2358 \nF-statistic: 18.17 on 3 and 164 DF,  p-value: 3.138e-10\n\n\n\nsummary(lm(helping ~ scale(empathy) * scale(public_sc) + scale(public_sc) * status, data = helping))\n\n\nCall:\nlm(formula = helping ~ scale(empathy) * scale(public_sc) + scale(public_sc) * \n    status, data = helping)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-66.40 -14.81  -1.10  16.81  48.70 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       43.100      2.853  15.109  < 2e-16 ***\nscale(empathy)                    11.387      2.298   4.956  1.8e-06 ***\nscale(public_sc)                   6.951      3.116   2.231  0.02706 *  \nstatuslow                         -6.980      3.603  -1.937  0.05445 .  \nscale(empathy):scale(public_sc)    1.531      1.621   0.944  0.34637    \nscale(public_sc):statuslow        -9.815      3.695  -2.656  0.00869 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 22.69 on 162 degrees of freedom\nMultiple R-squared:  0.2968,    Adjusted R-squared:  0.2751 \nF-statistic: 13.68 on 5 and 162 DF,  p-value: 3.876e-11\n\n\n\nsummary(lm(helping ~ status, data = helping))\n\n\nCall:\nlm(formula = helping ~ status, data = helping)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-46.31 -18.83  -2.58  19.66  52.85 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   47.147      2.944  16.016  < 2e-16 ***\nstatuslow    -10.890      4.045  -2.692  0.00782 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 26.17 on 166 degrees of freedom\nMultiple R-squared:  0.04184,   Adjusted R-squared:  0.03607 \nF-statistic:  7.25 on 1 and 166 DF,  p-value: 0.007819"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균, sk.cho@snu.ac.kr\n면담 시간: 수업 후\n조교: 홍신영\n수업시간: 목 7:00 ~ 9:50PM\nWebsite: r.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n전통적인 통계 커리큘럼에서 조금 벗어나 programming 언어인 R과 graphical tools의 도움을 받아 통계적인 통찰을 얻는 방식으로 진행하고자 함. 예제를 중심으로 직접 분석하고, 통계 이론의 설명은 체계적으로 전개하기보다는 그때 그때 필요한 부분을 부연 설명하고자 함.\n본 강의는 주로 회귀분석(regression analysis)에 초점을 맞추며, 그 원리를 이해하고 의미를 파악하여, 현상을 올바로 분석하고, 적절한 분석기법을 적용할 수 있도록 도움을 주고자 함.\n수업은 대략 4개의 섹션으로 나눔\n\nR tutorial\n\n통계의 활용에 대한 전반적인 소개\n\n회귀 분석 (regression analysis)\n\n인과 분석 (causal analysis)\n\n\n교재\n\n주로 강의 노트를 위주로!\nR인 액션 - 빅데이터 분석도구, 홍릉 / R in Action (2e) by Rob Kabacoff\nStatistical Modeling (2e) by Daniel T. Kaplan\n\n\n\nR 참고도서\n\nR for Data Science by Wickham & Grolemund / 2nd edition in progress\n\n\n\n통계 참고도서\n\nApplied Multiple Regression/Correlation Analysis for the Behavioral Sciences By Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. Aiken\nRegression Analysis and Linear Models by Richard B. Darlington & Andrew F. Hayes\nMultiple Regression and Beyond (3e) by Timothy Z. Keith"
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (5%), 일반과제 (15%), 중간고사 대체 과제 (20%), 기말고사 (30%), 개별 프로젝트 (30%)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]